{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aoforfie/BAH_TechEx_Guided_Project_Phase2/blob/main/Guided_Project_2_Handwritten_Digit_Recognition_with_a_Simple_CNN_AOwusuForfie_and_MMoreno_04_16_2024_V10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project 2: Handwritten Digit Recognition with a Simple CNN"
      ],
      "metadata": {
        "id": "BJUhhblyqmA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CONTRIBUTORS: Afia Owusu-Forfie and Martin Moreno\n",
        "# DATE(S): April 8, 2024 & April 12, 2024 -- April 16, 2024"
      ],
      "metadata": {
        "id": "BFfOhfcsIf6T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project Overview\n",
        "\n",
        "This project focuses on the development and understanding of a Convolutional Neural Network (CNN) for recognizing handwritten digits using the MNIST dataset. It is structured to provide a comprehensive introduction to deep learning techniques and their practical applications. Participants will engage in:\n",
        "\n",
        "* **Setting up a Python project environment**, emphasizing the importance of virtual environments for effective dependency management in machine learning initiatives.\n",
        "* **Performing data collection and preprocessing**, which includes normalization, reshaping, and batching of image data, essential steps for the successful application of machine learning models.\n",
        "* **Designing and refining a CNN architecture**, where participants will gain hands-on experience in neural network design, layer configuration, and model compilation specific to image recognition tasks.\n",
        "* **Conducting model training and evaluation**, teaching participants to apply training procedures, assess performance metrics, and gauge model accuracy on test data.\n",
        "* **Executing results analysis and model optimization**, aimed at enhancing model performance through methods such as hyperparameter tuning and data augmentation, while mitigating common issues like overfitting.\n",
        "* **Preparing the model for deployment**, which covers model conversion for production environments, development of an interaction interface, and comprehensive project documentation for future scalability and reproducibility.\n",
        "\n",
        "The project aims to build proficiency in utilizing TensorFlow and Keras, equipping participants with the necessary skills to develop, train, and deploy effective machine learning models. Emphasis is placed on following best practices for machine learning project workflows, from data preprocessing to deployment, ensuring participants are well-prepared to handle a variety of data science challenges.\n",
        "\n",
        "**Estimated Completion Time**\n",
        "\n",
        "12 to 14 hours\n"
      ],
      "metadata": {
        "id": "XL5-DXTQqv5h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1: Project Setup and Environment Preparation\n",
        "\n",
        "**Objective:** Set up the project environment and install necessary libraries to ensure a smooth workflow.\n",
        "\n",
        "**Activities:**\n",
        "\n",
        "1. Install Python and necessary libraries (NumPy, TensorFlow/Keras, Matplotlib, etc.).\n",
        "2. Set up a virtual environment for the project to manage dependencies.\n",
        "3. Verify the installation by running a simple Python script.\n",
        "\n",
        "**Estimated Completion Time:** 60 minutes"
      ],
      "metadata": {
        "id": "uqwEw3x50tFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing a Virtual Environment using Venv"
      ],
      "metadata": {
        "id": "Sxta93ldJ29j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install virtualenv"
      ],
      "metadata": {
        "id": "yVE6G2mfJ9uQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3485e807-dd4c-4305-973c-570f5ab9c98e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting virtualenv\n",
            "  Downloading virtualenv-20.25.1-py3-none-any.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distlib<1,>=0.3.7 (from virtualenv)\n",
            "  Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (3.13.4)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (4.2.0)\n",
            "Installing collected packages: distlib, virtualenv\n",
            "Successfully installed distlib-0.3.8 virtualenv-20.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vwbU1G5PSdk0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edc51809-7947-4c0d-b16c-c7dd99c40368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Version of Python being used in this Google Colab\n",
        "#Python 3.10.12"
      ],
      "metadata": {
        "id": "XzB3ODpuK8Ym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3.10.12 -m venv GuidedProject2"
      ],
      "metadata": {
        "id": "5b59muhtLOv3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edf973f4-1166-4849-890f-24962dc077e3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: python3.10.12: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **#NOTE: Above command only works for cmd: prompts so it did NOT work**"
      ],
      "metadata": {
        "id": "BnQiLxmQSiny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Installing and/or importing majority of the relevant libraries"
      ],
      "metadata": {
        "id": "4rb_7K5QEp_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import datasets, layers, models\n",
        "from keras.optimizers import SGD\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.datasets import fetch_openml\n",
        "from scipy.ndimage.interpolation import shift #scipy.ndimage.interpolation is deprecated\n",
        "from scipy.ndimage import shift\n",
        "\n",
        "#Importing ImageDataGenerator\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from matplotlib.colors import LogNorm\n",
        "\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1ww3TfVFKld",
        "outputId": "3216d0a5-48c8-4e51-f7b4-bf147cc2d3b5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-66792c33ca63>:10: DeprecationWarning: Please use `shift` from the `scipy.ndimage` namespace, the `scipy.ndimage.interpolation` namespace is deprecated.\n",
            "  from scipy.ndimage.interpolation import shift #scipy.ndimage.interpolation is deprecated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 2: Data Collection and Preprocessing**  \n",
        "\n",
        "**Objective:** Gather and prepare the handwritten digits data for training and testing the CNN.  \n",
        "\n",
        "**Activities:**  \n",
        "1. Download the MNIST dataset.  \n",
        "2. Normalize the image pixel values and reshape them for the CNN.  \n",
        "3. Split the data into training, validation, and testing sets.  \n",
        "4. Perform data augmentation to increase the diversity of the training set (e.g., rotations, translations).  \n",
        "5. Implement data loaders for efficient loading and batching operations during training.  \n",
        "6. Visualize the augmented images to verify the data augmentation process.  \n",
        "7. Save the preprocessed data for easy access in subsequent training sessions.\n",
        "\n",
        "**Estimated Completion Time:** 180 minutes"
      ],
      "metadata": {
        "id": "ieB-kYcW2zkg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Downloading the MNIST dataset and splitting it into Training and Test datasets (X and y)."
      ],
      "metadata": {
        "id": "ue9bZ0UaMHSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Splitting the MNIST dataset into X_train, y_train and X_test, y_test at the same time downloading it.\n",
        "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "opIwjIFGJml8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5bd0e46-f924-41cc-de05-30fa87616b3c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aZlWa9QqSX_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting 4 images of the X_train data as grayscale\n",
        "plt.subplot(221)\n",
        "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(222)\n",
        "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(223)\n",
        "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(224)\n",
        "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ykkhOa-GSgTm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "13e88a8f-0f16-4219-ab0b-915fb8c401ea"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting 4 images of the X_test data as grayscale\n",
        "plt.subplot(221)\n",
        "plt.imshow(X_test[0], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(222)\n",
        "plt.imshow(X_test[1], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(223)\n",
        "plt.imshow(X_test[2], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(224)\n",
        "plt.imshow(X_test[3], cmap=plt.get_cmap('gray'))\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4LogpclfTPLO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "d33dacf1-e032-4dcc-a027-a74be8bb17db"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Looking at the shapes of the split datasets\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "id": "f_UBE7S2Kokv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49abb296-cade-484d-8001-3caa2aaf17c3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(linewidth=28 * 28)\n",
        "i = 1\n",
        "print(y_train[i])  # the class label == the actual digit\n",
        "\n",
        "# Scroll down to see non-zero values that make up the grayscale image\n",
        "# of number 0 as per the y_train[0] ground truth\n"
      ],
      "metadata": {
        "id": "v9-BeQxKd7TU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd7e2001-be55-4a4d-ae6f-6c4403ca50df"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[i])"
      ],
      "metadata": {
        "id": "vFDixfvheBta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b08aca6b-0b49-4174-90f1-25f7d41e864e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  51 159 253 159  50   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  48 238 252 252 252 237   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  54 227 253 252 239 233 252  57   6   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  10  60 224 252 253 252 202  84 252 253 122   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 163 252 252 252 253 252 252  96 189 253 167   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  51 238 253 253 190 114 253 228  47  79 255 168   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  48 238 252 252 179  12  75 121  21   0   0 253 243  50   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  38 165 253 233 208  84   0   0   0   0   0   0 253 252 165   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   7 178 252 240  71  19  28   0   0   0   0   0   0 253 252 195   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  57 252 252  63   0   0   0   0   0   0   0   0   0 253 252 195   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 198 253 190   0   0   0   0   0   0   0   0   0   0 255 253 196   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  76 246 252 112   0   0   0   0   0   0   0   0   0   0 253 252 148   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 230  25   0   0   0   0   0   0   0   0   7 135 253 186  12   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 223   0   0   0   0   0   0   0   0   7 131 252 225  71   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 145   0   0   0   0   0   0   0  48 165 252 173   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  86 253 225   0   0   0   0   0   0 114 238 253 162   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 249 146  48  29  85 178 225 253 223 167  56   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 252 252 229 215 252 252 252 196 130   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  28 199 252 252 253 252 252 233 145   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  25 128 252 253 252 141  37   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(linewidth=28 * 28)\n",
        "i = 1\n",
        "print(X_test[i])  # the class label == the actual digit\n",
        "\n",
        "# Scroll down to see non-zero values that make up the grayscale image\n",
        "# of number 0 as per the y_train[0] ground truth"
      ],
      "metadata": {
        "id": "M3Vk-LIpIuLc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd0b2b72-057a-4a3c-aef0-25d104ee5f0a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 116 125 171 255 255 150  93   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 169 253 253 253 253 253 253 218  30   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 169 253 253 253 213 142 176 253 253 122   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  52 250 253 210  32  12   0   6 206 253 140   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  77 251 210  25   0   0   0 122 248 253  65   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  31  18   0   0   0   0 209 253 253  65   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 117 247 253 198  10   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  76 247 253 231  63   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0 128 253 253 144   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 176 246 253 159  12   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  25 234 253 233  35   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 198 253 253 141   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  78 248 253 189  12   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  19 200 253 253 141   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 134 253 253 173  12   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 248 253 253  25   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 248 253 253  43  20  20  20  20   5   0   5  20  20  37 150 150 150 147  10   0]\n",
            " [  0   0   0   0   0   0   0   0 248 253 253 253 253 253 253 253 168 143 166 253 253 253 253 253 253 253 123   0]\n",
            " [  0   0   0   0   0   0   0   0 174 253 253 253 253 253 253 253 253 253 253 253 249 247 247 169 117 117  57   0]\n",
            " [  0   0   0   0   0   0   0   0   0 118 123 123 123 166 253 253 253 155 123 123  41   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many classes (unique digits)?\n",
        "unique_labels = np.unique(y_train)\n",
        "print (unique_labels)\n",
        "num_classes = len(unique_labels)\n",
        "print (num_classes)"
      ],
      "metadata": {
        "id": "y3QNWnU4eOD1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f204c74-11e3-4e51-c0aa-2c92017b1b4c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3 4 5 6 7 8 9]\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Normalize the image pixel values"
      ],
      "metadata": {
        "id": "HS_zA3lCOP4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled = X_train / 255\n",
        "X_test_scaled = X_test / 255"
      ],
      "metadata": {
        "id": "aqgHmfOwMgGR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled"
      ],
      "metadata": {
        "id": "j7WGooV_8q6F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2b3c875-cb1d-4c90-9d6f-db9a25ee4770"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(linewidth=28 * 28)\n",
        "i = 1\n",
        "print(X_train_scaled[i])"
      ],
      "metadata": {
        "id": "w46wAjIQKUA5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1081062a-1bc9-45df-c901-4378825e966b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.2        0.62352941 0.99215686 0.62352941 0.19607843 0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.18823529 0.93333333 0.98823529 0.98823529 0.98823529 0.92941176 0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.21176471 0.89019608 0.99215686 0.98823529 0.9372549  0.91372549 0.98823529 0.22352941 0.02352941 0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.03921569 0.23529412 0.87843137 0.98823529 0.99215686 0.98823529 0.79215686 0.32941176 0.98823529 0.99215686 0.47843137 0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.63921569 0.98823529 0.98823529 0.98823529 0.99215686 0.98823529 0.98823529 0.37647059 0.74117647 0.99215686 0.65490196 0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.2        0.93333333 0.99215686 0.99215686 0.74509804 0.44705882 0.99215686 0.89411765 0.18431373 0.30980392 1.         0.65882353 0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.18823529 0.93333333 0.98823529 0.98823529 0.70196078 0.04705882 0.29411765 0.4745098  0.08235294 0.         0.         0.99215686 0.95294118 0.19607843 0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.14901961 0.64705882 0.99215686 0.91372549 0.81568627 0.32941176 0.         0.         0.         0.         0.         0.         0.99215686 0.98823529 0.64705882 0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.02745098 0.69803922 0.98823529 0.94117647 0.27843137 0.0745098  0.10980392 0.         0.         0.         0.         0.         0.         0.99215686 0.98823529 0.76470588 0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.22352941 0.98823529 0.98823529 0.24705882 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.99215686 0.98823529 0.76470588 0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.77647059 0.99215686 0.74509804 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         1.         0.99215686 0.76862745 0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.29803922 0.96470588 0.98823529 0.43921569 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.99215686 0.98823529 0.58039216 0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.33333333 0.98823529 0.90196078 0.09803922 0.         0.         0.         0.         0.         0.         0.         0.         0.02745098 0.52941176 0.99215686 0.72941176 0.04705882 0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.33333333 0.98823529 0.8745098  0.         0.         0.         0.         0.         0.         0.         0.         0.02745098 0.51372549 0.98823529 0.88235294 0.27843137 0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.33333333 0.98823529 0.56862745 0.         0.         0.         0.         0.         0.         0.         0.18823529 0.64705882 0.98823529 0.67843137 0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.3372549  0.99215686 0.88235294 0.         0.         0.         0.         0.         0.         0.44705882 0.93333333 0.99215686 0.63529412 0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.33333333 0.98823529 0.97647059 0.57254902 0.18823529 0.11372549 0.33333333 0.69803922 0.88235294 0.99215686 0.8745098  0.65490196 0.21960784 0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.33333333 0.98823529 0.98823529 0.98823529 0.89803922 0.84313725 0.98823529 0.98823529 0.98823529 0.76862745 0.50980392 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.10980392 0.78039216 0.98823529 0.98823529 0.99215686 0.98823529 0.98823529 0.91372549 0.56862745 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.09803922 0.50196078 0.98823529 0.99215686 0.98823529 0.55294118 0.14509804 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_scaled"
      ],
      "metadata": {
        "id": "eiM_f10E8vxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0dd0333-255b-434f-9a79-4dd4b7b0fb17"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(linewidth=28 * 28)\n",
        "i = 1\n",
        "print(X_test_scaled[i])"
      ],
      "metadata": {
        "id": "DIz3SxeHKe_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "850d1efc-fe8d-4681-e1d7-a169c003d109"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.45490196 0.49019608 0.67058824 1.         1.         0.58823529 0.36470588 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.6627451  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.85490196 0.11764706 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.6627451  0.99215686 0.99215686 0.99215686 0.83529412 0.55686275 0.69019608 0.99215686 0.99215686 0.47843137 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.20392157 0.98039216 0.99215686 0.82352941 0.1254902  0.04705882 0.         0.02352941 0.80784314 0.99215686 0.54901961 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.30196078 0.98431373 0.82352941 0.09803922 0.         0.         0.         0.47843137 0.97254902 0.99215686 0.25490196 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.12156863 0.07058824 0.         0.         0.         0.         0.81960784 0.99215686 0.99215686 0.25490196 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.45882353 0.96862745 0.99215686 0.77647059 0.03921569 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.29803922 0.96862745 0.99215686 0.90588235 0.24705882 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.50196078 0.99215686 0.99215686 0.56470588 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.69019608 0.96470588 0.99215686 0.62352941 0.04705882 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.09803922 0.91764706 0.99215686 0.91372549 0.1372549  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.77647059 0.99215686 0.99215686 0.55294118 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.30588235 0.97254902 0.99215686 0.74117647 0.04705882 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.0745098  0.78431373 0.99215686 0.99215686 0.55294118 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.5254902  0.99215686 0.99215686 0.67843137 0.04705882 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.97254902 0.99215686 0.99215686 0.09803922 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.97254902 0.99215686 0.99215686 0.16862745 0.07843137 0.07843137 0.07843137 0.07843137 0.01960784 0.         0.01960784 0.07843137 0.07843137 0.14509804 0.58823529 0.58823529 0.58823529 0.57647059 0.03921569 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.97254902 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.65882353 0.56078431 0.65098039 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.48235294 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.68235294 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.97647059 0.96862745 0.96862745 0.6627451  0.45882353 0.45882353 0.22352941 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.4627451  0.48235294 0.48235294 0.48235294 0.65098039 0.99215686 0.99215686 0.99215686 0.60784314 0.48235294 0.48235294 0.16078431 0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reshaping the data"
      ],
      "metadata": {
        "id": "uXt5P_L_GNbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled2 = X_train_scaled.reshape(60000,28,28,1)"
      ],
      "metadata": {
        "id": "5CcpWIW9GLQf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Split the data into training, validation, and testing sets. *Of note, this step has already been accomplished simultaneously when we loaded the MNIST data in step 1. above.*\n"
      ],
      "metadata": {
        "id": "DNQEEySTTwZp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Performing data augmentation to increase the diversity of the training set (e.g., rotations, translations)."
      ],
      "metadata": {
        "id": "xAQ3uJLPR6lP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **** We received counsel from Niranjan on April 8, 2024 to use the ImageDataGenerator() for the Data Augmentation instead of our original inclination to use ndimage."
      ],
      "metadata": {
        "id": "viBRMkkJZNDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Method to shift the image by given dimension\n",
        "# def shift_image(image, dx, dy):\n",
        "#     image = image.reshape((28, 28))\n",
        "#     shifted_image = shift(image, [dy, dx], cval=0, mode=\"constant\")\n",
        "#     return shifted_image.reshape([-1])"
      ],
      "metadata": {
        "id": "fycRQSQ-RCgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Creating Augmented Dataset\n",
        "# X_train_augmented = [image for image in X_train_scaled]\n",
        "# y_train_augmented = [image for image in y_train]\n",
        "\n",
        "# for dx, dy in ((1,0), (-1,0), (0,1), (0,-1)):\n",
        "#      for image, label in zip(X_train_scaled, y_train):\n",
        "#              X_train_augmented.append(shift_image(image, dx, dy))\n",
        "#              y_train_augmented.append(label)"
      ],
      "metadata": {
        "id": "NovewqDCP9tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train_augmented"
      ],
      "metadata": {
        "id": "_4ScsDYT-0Hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train_augmented"
      ],
      "metadata": {
        "id": "7lXvs_Hx-7xA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def visualize(X_train, X_train_augmented):\n",
        "#     fig = plt.figure()\n",
        "#     plt.subplot(1,2,1)\n",
        "#     plt.title('Original image')\n",
        "#     plt.imshow(X_train)\n",
        "\n",
        "#     plt.subplot(1,2,2)\n",
        "#     plt.title('Augmented image')\n",
        "#     plt.imshow(X_train_augmented)\n",
        "#     flipped = tf.image.flip_left_right(image)\n",
        "#     visualize(image, flipped)"
      ],
      "metadata": {
        "id": "DOkUUFsk_o9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train"
      ],
      "metadata": {
        "id": "WSVUSuOYAHTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(y_train)"
      ],
      "metadata": {
        "id": "B44EqTLugbgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Shuffle the dataset\n",
        "# shuffle_idx = np.random.permutation(len(X_train_augmented))\n",
        "# X_train_augmented = np.array(X_train_augmented)[shuffle_idx]\n",
        "# y_train_augmented = np.array(y_train_augmented)[shuffle_idx]"
      ],
      "metadata": {
        "id": "B2bOdnaASx2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train.shape"
      ],
      "metadata": {
        "id": "FrF6xP_-TFWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train_augmented_tensor = tf.convert_to_tensor(X_train_augmented, dtype = tf.float32)"
      ],
      "metadata": {
        "id": "Dh3NVjJVA0NH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train_augmented_tensor = tf.convert_to_tensor(y_train_augmented)"
      ],
      "metadata": {
        "id": "CGDuD6X7-oUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1st Alternative method to ImageDataGenerator() ends here"
      ],
      "metadata": {
        "id": "jhRawLQwZhWW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **# Alternative 2 : 4. Performing data augmentation to increase the diversity of the training set (e.g., rotations, translations) with ImageDataGenerator().**"
      ],
      "metadata": {
        "id": "Y69u8bYMZq-i"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "za7rECZC2Eye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled2 = X_train_scaled.reshape(60000,28,28,1)"
      ],
      "metadata": {
        "id": "rgLQTK_KThIp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    # rotation_range=35,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    rotation_range=35,\n",
        "    width_shift_range=0.3,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.3,  # randomly shift images vertically (fraction of total height)\n",
        "    zoom_range=0.2,  # randomly zoom into images\n",
        "    fill_mode='nearest',  # fill in newly created pixels, which can appear after a rotation or a width/height shift\n",
        "    validation_split = 0.2\n",
        ")\n",
        "\n",
        "\n",
        "# Fit the datagen object to our training data\n",
        "datagen.fit(X_train_scaled2)\n",
        "\n",
        "train_generator = datagen.flow(X_train_scaled2, y_train, batch_size=32, shuffle=True,seed=2, save_to_dir=None, subset='training')\n",
        "\n",
        "# Generate a batch of augmented images from the dataset\n",
        "validation_generator = datagen.flow(X_train_scaled2, batch_size=32, shuffle=True,seed=2, save_to_dir=None, subset='validation')\n",
        "\n",
        "\n",
        "# # Plot the augmented images\n",
        "# fig, axes = plt.subplots(1, 10, figsize=(20, 3))\n",
        "# for img, ax in zip(validation_generator, axes):\n",
        "#     ax.imshow(img.reshape(28, 28, 1), cmap='gray')\n",
        "#     ax.axis('off')\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "L_MRkynC1dYl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Beginning Anew at 2:33 PM ET On April 12, 2024\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YGI_o0OBljaL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Implementing data loaders for efficient loading and batching operations during training."
      ],
      "metadata": {
        "id": "TZCmC3yeZSxr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run num_classes"
      ],
      "metadata": {
        "id": "6ElhcNt__A5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10"
      ],
      "metadata": {
        "id": "Yc4zeG0_etOE"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Visualize the augmented images to verify the data augmentation process"
      ],
      "metadata": {
        "id": "90yHqHXNadsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Visualizing import image data"
      ],
      "metadata": {
        "id": "Hy39ltLbOgKi"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(linewidth=28 * 28)\n",
        "i = 1\n",
        "print(y_train[i])  # the class label == the actual digit\n",
        "print(X_train[i])\n",
        "# Scroll down to see non-zero values that make up the grayscale image\n",
        "# of number 0 as per the y_train[0] ground truth\n"
      ],
      "metadata": {
        "id": "ajNA6vg3Oj4o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba1c8593-9ac5-437e-a4ab-af0f30463b77"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  51 159 253 159  50   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  48 238 252 252 252 237   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  54 227 253 252 239 233 252  57   6   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  10  60 224 252 253 252 202  84 252 253 122   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 163 252 252 252 253 252 252  96 189 253 167   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  51 238 253 253 190 114 253 228  47  79 255 168   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  48 238 252 252 179  12  75 121  21   0   0 253 243  50   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  38 165 253 233 208  84   0   0   0   0   0   0 253 252 165   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   7 178 252 240  71  19  28   0   0   0   0   0   0 253 252 195   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  57 252 252  63   0   0   0   0   0   0   0   0   0 253 252 195   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 198 253 190   0   0   0   0   0   0   0   0   0   0 255 253 196   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  76 246 252 112   0   0   0   0   0   0   0   0   0   0 253 252 148   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 230  25   0   0   0   0   0   0   0   0   7 135 253 186  12   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 223   0   0   0   0   0   0   0   0   7 131 252 225  71   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 145   0   0   0   0   0   0   0  48 165 252 173   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  86 253 225   0   0   0   0   0   0 114 238 253 162   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 249 146  48  29  85 178 225 253 223 167  56   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 252 252 229 215 252 252 252 196 130   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  28 199 252 252 253 252 252 233 145   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  25 128 252 253 252 141  37   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(linewidth=28 * 28)\n",
        "i = 1\n",
        "print(y_train[i])  # the class label == the actual digit\n",
        "print(X_train_scaled2[i])\n",
        "# Scroll down to see non-zero values that make up the grayscale image\n",
        "# of number 0 as per the y_train[0] ground truth"
      ],
      "metadata": {
        "id": "b-qMcXqKO_jf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a402b724-6ef0-4e35-fe1a-76e7fa4a31a2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "[[[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.2       ]\n",
            "  [0.62352941]\n",
            "  [0.99215686]\n",
            "  [0.62352941]\n",
            "  [0.19607843]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.18823529]\n",
            "  [0.93333333]\n",
            "  [0.98823529]\n",
            "  [0.98823529]\n",
            "  [0.98823529]\n",
            "  [0.92941176]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.21176471]\n",
            "  [0.89019608]\n",
            "  [0.99215686]\n",
            "  [0.98823529]\n",
            "  [0.9372549 ]\n",
            "  [0.91372549]\n",
            "  [0.98823529]\n",
            "  [0.22352941]\n",
            "  [0.02352941]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.03921569]\n",
            "  [0.23529412]\n",
            "  [0.87843137]\n",
            "  [0.98823529]\n",
            "  [0.99215686]\n",
            "  [0.98823529]\n",
            "  [0.79215686]\n",
            "  [0.32941176]\n",
            "  [0.98823529]\n",
            "  [0.99215686]\n",
            "  [0.47843137]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.63921569]\n",
            "  [0.98823529]\n",
            "  [0.98823529]\n",
            "  [0.98823529]\n",
            "  [0.99215686]\n",
            "  [0.98823529]\n",
            "  [0.98823529]\n",
            "  [0.37647059]\n",
            "  [0.74117647]\n",
            "  [0.99215686]\n",
            "  [0.65490196]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.2       ]\n",
            "  [0.93333333]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.74509804]\n",
            "  [0.44705882]\n",
            "  [0.99215686]\n",
            "  [0.89411765]\n",
            "  [0.18431373]\n",
            "  [0.30980392]\n",
            "  [1.        ]\n",
            "  [0.65882353]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.18823529]\n",
            "  [0.93333333]\n",
            "  [0.98823529]\n",
            "  [0.98823529]\n",
            "  [0.70196078]\n",
            "  [0.04705882]\n",
            "  [0.29411765]\n",
            "  [0.4745098 ]\n",
            "  [0.08235294]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.99215686]\n",
            "  [0.95294118]\n",
            "  [0.19607843]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.14901961]\n",
            "  [0.64705882]\n",
            "  [0.99215686]\n",
            "  [0.91372549]\n",
            "  [0.81568627]\n",
            "  [0.32941176]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.99215686]\n",
            "  [0.98823529]\n",
            "  [0.64705882]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.02745098]\n",
            "  [0.69803922]\n",
            "  [0.98823529]\n",
            "  [0.94117647]\n",
            "  [0.27843137]\n",
            "  [0.0745098 ]\n",
            "  [0.10980392]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.99215686]\n",
            "  [0.98823529]\n",
            "  [0.76470588]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.22352941]\n",
            "  [0.98823529]\n",
            "  [0.98823529]\n",
            "  [0.24705882]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.99215686]\n",
            "  [0.98823529]\n",
            "  [0.76470588]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.77647059]\n",
            "  [0.99215686]\n",
            "  [0.74509804]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [1.        ]\n",
            "  [0.99215686]\n",
            "  [0.76862745]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.29803922]\n",
            "  [0.96470588]\n",
            "  [0.98823529]\n",
            "  [0.43921569]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.99215686]\n",
            "  [0.98823529]\n",
            "  [0.58039216]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.33333333]\n",
            "  [0.98823529]\n",
            "  [0.90196078]\n",
            "  [0.09803922]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.02745098]\n",
            "  [0.52941176]\n",
            "  [0.99215686]\n",
            "  [0.72941176]\n",
            "  [0.04705882]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.33333333]\n",
            "  [0.98823529]\n",
            "  [0.8745098 ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.02745098]\n",
            "  [0.51372549]\n",
            "  [0.98823529]\n",
            "  [0.88235294]\n",
            "  [0.27843137]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.33333333]\n",
            "  [0.98823529]\n",
            "  [0.56862745]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.18823529]\n",
            "  [0.64705882]\n",
            "  [0.98823529]\n",
            "  [0.67843137]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.3372549 ]\n",
            "  [0.99215686]\n",
            "  [0.88235294]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.44705882]\n",
            "  [0.93333333]\n",
            "  [0.99215686]\n",
            "  [0.63529412]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.33333333]\n",
            "  [0.98823529]\n",
            "  [0.97647059]\n",
            "  [0.57254902]\n",
            "  [0.18823529]\n",
            "  [0.11372549]\n",
            "  [0.33333333]\n",
            "  [0.69803922]\n",
            "  [0.88235294]\n",
            "  [0.99215686]\n",
            "  [0.8745098 ]\n",
            "  [0.65490196]\n",
            "  [0.21960784]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.33333333]\n",
            "  [0.98823529]\n",
            "  [0.98823529]\n",
            "  [0.98823529]\n",
            "  [0.89803922]\n",
            "  [0.84313725]\n",
            "  [0.98823529]\n",
            "  [0.98823529]\n",
            "  [0.98823529]\n",
            "  [0.76862745]\n",
            "  [0.50980392]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.10980392]\n",
            "  [0.78039216]\n",
            "  [0.98823529]\n",
            "  [0.98823529]\n",
            "  [0.99215686]\n",
            "  [0.98823529]\n",
            "  [0.98823529]\n",
            "  [0.91372549]\n",
            "  [0.56862745]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.09803922]\n",
            "  [0.50196078]\n",
            "  [0.98823529]\n",
            "  [0.99215686]\n",
            "  [0.98823529]\n",
            "  [0.55294118]\n",
            "  [0.14509804]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]\n",
            "\n",
            " [[0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.        ]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving the preprocessed data"
      ],
      "metadata": {
        "id": "ISbBWQAcdCbA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making a zip file with extension .npz"
      ],
      "metadata": {
        "id": "MnpmOG5nN66w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.savez_compressed('CNN_DATA',\n",
        "                    X_train = X_train_scaled2,\n",
        "                    X_test = X_test_scaled,\n",
        "                    y_train = y_train,\n",
        "                    y_test = y_test)"
      ],
      "metadata": {
        "id": "UTwok65Meu5F"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mounting an instance of Google Drive"
      ],
      "metadata": {
        "id": "MTMBURFYOaGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngp7r5ImNoAW",
        "outputId": "2979dbaa-a2f6-4f21-87f8-bc4efaf5104d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Changing Directory"
      ],
      "metadata": {
        "id": "sWDPrYrqPpiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzKmW6fxNrrB",
        "outputId": "f8c88bf7-7029-42a1-98bb-c7e6dd19782c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9KlZlVAiNxP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading the CNN_DATA.npz file for later upload on GitHub"
      ],
      "metadata": {
        "id": "dCGRFBnhPiBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('CNN_DATA.npz')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gCAjFwOvN2H-",
        "outputId": "016e9856-aa0d-475d-9145-7925f0286275"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c2d11714-d5b1-45a7-b7fd-5b7c32c47c17\", \"CNN_DATA.npz\", 22181452)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "yTHf_FY0RKgx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 3: Designing the CNN Architecture**  \n",
        "\n",
        "**Objective:** Design a simple Convolutional Neural Network architecture suitable for handwritten digit recognition.  \n",
        "\n",
        "**Activities:**\n",
        "\n",
        "1. Define the CNN layers, including convolutional, activation, pooling, and fully connected layers.  \n",
        "2. Choose activation functions and initialize weights.  \n",
        "3. Configure the optimizer, loss function, and metrics for model compilation.  \n",
        "4. Summarize the model to visualize the architecture and parameters.\n",
        "\n",
        "**Estimated Completion Time:** 90 minutes"
      ],
      "metadata": {
        "id": "I1kUAhZb2ziE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dwJYPoeupQmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def build_model():\n",
        "#    '''\n",
        "#    Build a Sequential model with regular densely-connected NN layers.\n",
        "#    Return the constructed model.\n",
        "#   '''\n",
        "#   model = keras.Sequential(name = 'Image_Classifier')\n",
        "\n",
        "#   # The input layer\n",
        "#   # We will use Flatten utility layer to flatten 2D images into 1D arrays\n",
        "#   model.add(layers.Flatten(input_shape = (28,28,1)))\n",
        "\n",
        "#   # Hidden Layers\n",
        "#   model.add(layers.Dense(128, name = \"HL1\", activation = 'relu'))\n",
        "#   model.add(layers.Dense(64, name = \"HL2\", activation = 'relu'))\n",
        "\n",
        "#   # The model's output layer\n",
        "#   # We create a classifier for as many classes (digits) as there are in the inout data\n",
        "#   model.add(layers.Dense(num_classes, name = \"OUTL\", activation = 'softmax'))\n",
        "\n",
        "#   model.summary()\n",
        "#   print(model.inputs, model.outputs)\n",
        "#   return model"
      ],
      "metadata": {
        "id": "ZpOFN4EIpRkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def compile_model(model):\n",
        "\n",
        "#   model.compile(\n",
        "#       optimizer = SGD(learning_rate = .001, momentum=0.9, nesterov = True),\n",
        "\n",
        "#       loss = keras.losses.SparseCategoricalCrossentropy(),\n",
        "#       metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
        "#   )\n",
        "#   return model"
      ],
      "metadata": {
        "id": "k-NLQ9Ei4fWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def train(model):\n",
        "\n",
        "#   history = model.fit(X_train, y_train, batch_size =128,\n",
        "#                       epochs = 20, verbose = 1)\n",
        "#   return history"
      ],
      "metadata": {
        "id": "xhSMJcj-5lPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # random generator\n",
        "# tf.keras.utils.set_random_seed(42)\n",
        "\n",
        "# #trigger sequence\n",
        "# model = build_model()\n",
        "# model = compile_model(model)\n",
        "# history = train(model)\n"
      ],
      "metadata": {
        "id": "g7Ltif4a68BO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **** Previous Joint Effort from Afia and Martin ended here on April 8, 2024 ****"
      ],
      "metadata": {
        "id": "MvZ9hv6kpT4l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ****  Individual work with Afia begins on April 12, 2024 ****"
      ],
      "metadata": {
        "id": "y2LIRVRVPm0o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the Model"
      ],
      "metadata": {
        "id": "52eUxyw6P2wV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "  '''\n",
        "   Build a Sequential model with regular densely-connected NN layers.\n",
        "   Return the constructed model.\n",
        "  '''\n",
        "  input_shape = (28, 28, 1)  # 1 is the count of channels (no RGB)\n",
        "\n",
        "  model = keras.Sequential ([\n",
        "\n",
        "    # // The input layer\n",
        "    layers.Input(shape=input_shape),\n",
        "\n",
        "    # // Hidden layers\n",
        "    layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\", name='CL1'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2), name='MPL1'),\n",
        "\n",
        "    layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\", name='CL2'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2), name='MPL2'),\n",
        "\n",
        "    layers.Flatten(name='FL'),\n",
        "\n",
        "    layers.Dropout(0.2),\n",
        "\n",
        "    # // The model's output layer\n",
        "    # We create a classifier for as many classes as there are in the input data\n",
        "    #model.add(layers.Dense(num_classes, name=\"OUTL\", activation='softmax'))\n",
        "    layers.Dense(num_classes, name=\"OUTL\", activation='softmax')\n",
        "  ])\n",
        "\n",
        "  model.summary()\n",
        "  print (model.inputs, model.outputs)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "tfYn4I-RPqt0"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compiling the Model"
      ],
      "metadata": {
        "id": "DeqjWrEBQEEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compile_model(model):\n",
        "  '''\n",
        "    Compile the pre-built model with the model hyperparameters.\n",
        "    Return the compiled model\n",
        "  '''\n",
        "  model.compile(\n",
        "      #optimizer=keras.optimizers.RMSprop(),\n",
        "      optimizer=SGD(learning_rate=1e-2, momentum=0.9, nesterov=True),\n",
        "\n",
        "      # The loss function that we need to minimize\n",
        "      loss=keras.losses.SparseCategoricalCrossentropy(),  # we have a lot of \"holes\" in the dataset (the black pixels with a value of 0)\n",
        "\n",
        "      # The metrics (can be more than one) to monitor\n",
        "      metrics=[keras.metrics.SparseCategoricalAccuracy()], # The \"dangling\" comma , before the closing bracket is good practice ...\n",
        "  )\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "VTTu7ZIBP5ze"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Model"
      ],
      "metadata": {
        "id": "OXl6H38oQPuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model):\n",
        "  '''\n",
        "    Train the model with a fixed number of epochs\n",
        "    Return the history (log)\n",
        "  '''\n",
        "  # In a CPU-only CoLab environment, training may take about 5 minutes, give or take, so be patient and wait until the training is done ...\n",
        "  history = model.fit(X_train_scaled2, y_train, batch_size = 128, epochs = 5, verbose=1)\n",
        "\n",
        "  return history"
      ],
      "metadata": {
        "id": "y470OOgiQOoK"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# augmented_data_loader\n",
        "# augmented_images"
      ],
      "metadata": {
        "id": "KhzbeXMiM68V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def train(model):\n",
        "#   '''\n",
        "#     Train the model with a fixed number of epochs\n",
        "#     Return the history (log)\n",
        "#   '''\n",
        "#   # In a CPU-only CoLab environment, training may take about 5 minutes, give or take, so be patient and wait until the training is done ...\n",
        "#   history = model.fit_generator(augmented_data_loader, validation_data=augmented_images)\n",
        "\n",
        "#   return history"
      ],
      "metadata": {
        "id": "ysji4GIzNELr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Seeding the random generator, triggering the sequence and training the model."
      ],
      "metadata": {
        "id": "eZz5PoNOQiZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seed the random generator for reproducible results\n",
        "tf.keras.utils.set_random_seed(2424)\n",
        "\n",
        "# Trigger the sequence ..\n",
        "model = build_model()\n",
        "model = compile_model(model)\n",
        "history = train(model)\n",
        "\n",
        "# Note: CoLab reports the wall time of running a cell at the bottom of the browser window"
      ],
      "metadata": {
        "id": "8LTin7OoQeYQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b8b1fbf-162b-4889-f45a-cdccd955bc3d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " CL1 (Conv2D)                (None, 26, 26, 128)       1280      \n",
            "                                                                 \n",
            " MPL1 (MaxPooling2D)         (None, 13, 13, 128)       0         \n",
            "                                                                 \n",
            " CL2 (Conv2D)                (None, 11, 11, 64)        73792     \n",
            "                                                                 \n",
            " MPL2 (MaxPooling2D)         (None, 5, 5, 64)          0         \n",
            "                                                                 \n",
            " FL (Flatten)                (None, 1600)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1600)              0         \n",
            "                                                                 \n",
            " OUTL (Dense)                (None, 10)                16010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 91,082\n",
            "Trainable params: 91,082\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "[<KerasTensor: shape=(None, 28, 28, 1) dtype=float32 (created by layer 'input_2')>] [<KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'OUTL')>]\n",
            "Epoch 1/5\n",
            "469/469 [==============================] - 205s 435ms/step - loss: 0.4090 - sparse_categorical_accuracy: 0.8769\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 206s 438ms/step - loss: 0.1201 - sparse_categorical_accuracy: 0.9638\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 199s 423ms/step - loss: 0.0927 - sparse_categorical_accuracy: 0.9712\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 192s 410ms/step - loss: 0.0778 - sparse_categorical_accuracy: 0.9763\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 182s 388ms/step - loss: 0.0690 - sparse_categorical_accuracy: 0.9791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "l58hexSFbrrn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb7a63a5-1c71-4655-f6f4-5d6d2d764eec"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 8s 25ms/step - loss: 0.0501 - sparse_categorical_accuracy: 0.9841\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.05009949207305908, 0.9840999841690063]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Predictions"
      ],
      "metadata": {
        "id": "aFi_cYXnb-Pn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob = model.predict(X_test_scaled)\n",
        "y_pred_prob.shape"
      ],
      "metadata": {
        "id": "sONdiDpIcDvS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91be5332-66ce-4552-abe0-61a699f1957b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 8s 25ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(y_pred_prob[0]) == y_test[0] == 7"
      ],
      "metadata": {
        "id": "hhgU83w4cNmW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65400aa6-8622-42a0-d110-20484b859c21"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_labels = np.zeros(len(y_pred_prob), dtype=int)\n",
        "for i in range(len(y_pred_prob)):\n",
        "  y_pred_labels[i] = np.argmax(y_pred_prob[i])\n",
        "\n",
        "print (y_pred_labels[:31])\n",
        "print ('-' * 60)\n",
        "print (y_test[:31])"
      ],
      "metadata": {
        "id": "pYm3tGincVDn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "609b0fc0-6f2a-424e-b46d-bb28a1100778"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 8 4 9 6 6 5 4 0 7 4 0 1 3]\n",
            "------------------------------------------------------------\n",
            "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Including the augmented data"
      ],
      "metadata": {
        "id": "EiZsBOx9PnqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rank = np.linalg.matrix_rank(X_train_scaled)\n",
        "# print(f\"The rank of the matrix is {rank}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "535xvgv9RF0Y",
        "outputId": "805e18e3-071a-4742-b353-e07f3c9df0e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The rank of the matrix is [20 17 13 ... 17 18 19].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Previously failed attempt to run the model"
      ],
      "metadata": {
        "id": "C5jPyXSgK7j6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train_scaled = X_train_scaled.reshape(1, 60000, 28 , 28)"
      ],
      "metadata": {
        "id": "1HzQ5xCvR4LZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# datagen.fit(X_train_scaled2)\n",
        "\n",
        "# train_generator = datagen.flow(X_train_scaled2, y_train, batch_size=64, shuffle=True,\n",
        "#                                seed=2, save_to_dir=None, subset='training')\n",
        "\n",
        "# validation_generator = datagen.flow(X_train_scaled2, y_train, batch_size=64, shuffle=True,\n",
        "#                                seed=2, save_to_dir=None, subset='validation')\n",
        "\n",
        "\n",
        "# history = model.fit_generator(train_generator,\n",
        "#                                                 steps_per_epoch = 600,\n",
        "#                                                 epochs=30,\n",
        "#                                                 validation_data = validation_generator,\n",
        "#                                                 validation_steps = 150,\n",
        "#                                                 )"
      ],
      "metadata": {
        "id": "gTq-mTQoKvaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Seed the random generator for reproducible results\n",
        "# tf.keras.utils.set_random_seed(2424)\n",
        "\n",
        "# # Trigger the sequence ..\n",
        "# model = build_model()\n",
        "# model = compile_model(model)\n",
        "# history = train(model)\n",
        "\n",
        "# # Note: CoLab reports the wall time of running a cell at the bottom of the browser window"
      ],
      "metadata": {
        "id": "aD5S9MOGWaCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Failed attempt ends here"
      ],
      "metadata": {
        "id": "BfNcpRPELC2o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trying the Augmented Data but knowing that it would have great impact on the Model's Accuracy"
      ],
      "metadata": {
        "id": "N5uKZiN4QI6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**## Re-running the Train portion with new augmented images**"
      ],
      "metadata": {
        "id": "uMsCl95TW569"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model):\n",
        "  '''\n",
        "    Train the model with a fixed number of epochs\n",
        "    Return the history (log)\n",
        "  '''\n",
        "  # In a CPU-only CoLab environment, training may take about 5 minutes, give or take, so be patient and wait until the training is done ...\n",
        "  history = model.fit_generator(train_generator, validation_data = validation_generator, epochs = 5, verbose=1)\n",
        "\n",
        "  return history"
      ],
      "metadata": {
        "id": "X0J1bNfSWacv"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trigger the sequence ..\n",
        "model = build_model()\n",
        "model = compile_model(model)\n",
        "history = train(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9OPQ1ReWB0E",
        "outputId": "6119535d-e495-4134-950f-5c98c3319893"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " CL1 (Conv2D)                (None, 26, 26, 128)       1280      \n",
            "                                                                 \n",
            " MPL1 (MaxPooling2D)         (None, 13, 13, 128)       0         \n",
            "                                                                 \n",
            " CL2 (Conv2D)                (None, 11, 11, 64)        73792     \n",
            "                                                                 \n",
            " MPL2 (MaxPooling2D)         (None, 5, 5, 64)          0         \n",
            "                                                                 \n",
            " FL (Flatten)                (None, 1600)              0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1600)              0         \n",
            "                                                                 \n",
            " OUTL (Dense)                (None, 10)                16010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 91,082\n",
            "Trainable params: 91,082\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "[<KerasTensor: shape=(None, 28, 28, 1) dtype=float32 (created by layer 'input_3')>] [<KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'OUTL')>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-8bbaa9f805ff>:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(train_generator, validation_data = validation_generator, epochs = 5, verbose=1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 158s 105ms/step - loss: 1.5474 - sparse_categorical_accuracy: 0.4643 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 159s 106ms/step - loss: 0.8297 - sparse_categorical_accuracy: 0.7334 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 165s 110ms/step - loss: 0.6564 - sparse_categorical_accuracy: 0.7912 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 160s 106ms/step - loss: 0.5595 - sparse_categorical_accuracy: 0.8240 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 161s 107ms/step - loss: 0.5162 - sparse_categorical_accuracy: 0.8395 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GGg2TtU5Psm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OBSERVATION: The augmented images does NOT seem to help the model. The model lost accuracy from 0.9825 to become 0.8666. Also the loss was smaller 0.0569 compared to the increased loss of 0.4343 when the images were augmented. This means more model tuning will be necessary**"
      ],
      "metadata": {
        "id": "9B0Z0-XEq2Ac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**UPDATED OBSERVATION AFTER RE-RUNS: The augmented images does NOT seem to help the model. The model lost accuracy from 0.9825 to become 0.8395. Also the loss was smaller 0.0569 compared to the increased loss of 0.5162 when the images were augmented. This means more model tuning will be necessary**"
      ],
      "metadata": {
        "id": "dNsdNJiQIFoI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yC44ryDerwQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **Task 4: Model Training and Evaluation**  \n",
        "\n",
        "**Objective:** Train the CNN with the training data and evaluate its performance on the test set.  \n",
        "\n",
        "**Activities:**\n",
        "\n",
        "1. Integrate TensorBoard callbacks for real-time tracking of training metrics.\n",
        "2. Set up callbacks for model checkpoints, early stopping, and learning rate adjustments.  \n",
        "3. Train the model with the training set while validating on the validation set.  \n",
        "4. Use TensorBoard to plot training and validation loss and accuracy.  \n",
        "5. Evaluate the model on the test set to assess its generalization capability.  \n",
        "6. Perform error analysis by reviewing misclassified images to understand the model's weaknesses.  \n",
        "7. Test the model with external images (e.g., hand-drawn digits) to further assess its performance.\n",
        "\n",
        "**Estimated Completion Time:** 300 minutes"
      ],
      "metadata": {
        "id": "VGDQQvgm2zfL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Integrate TensorBoard callbacks for real-time tracking of training metrics."
      ],
      "metadata": {
        "id": "yASpwJPheXLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import datetime\n"
      ],
      "metadata": {
        "id": "-3bZf974ehyl"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Set up callbacks for model checkpoints, early stopping, and learning rate adjustments."
      ],
      "metadata": {
        "id": "SJCIQsPNoCsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup TensorBoard callback\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "metadata": {
        "id": "P9UOjfGsebc5"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Train the model with the training set while validating on the validation set."
      ],
      "metadata": {
        "id": "dhxQtlqZoJES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train_scaled2, y_train, epochs=5, validation_data=(X_test_scaled, y_test), callbacks=[tensorboard_callback])\n"
      ],
      "metadata": {
        "id": "pK_QSF3UexO9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44546b38-aff5-4d37-e148-68f53c73d1ec"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 185s 99ms/step - loss: 0.0646 - sparse_categorical_accuracy: 0.9797 - val_loss: 0.0284 - val_sparse_categorical_accuracy: 0.9906\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 187s 100ms/step - loss: 0.0370 - sparse_categorical_accuracy: 0.9883 - val_loss: 0.0248 - val_sparse_categorical_accuracy: 0.9911\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 182s 97ms/step - loss: 0.0308 - sparse_categorical_accuracy: 0.9905 - val_loss: 0.0209 - val_sparse_categorical_accuracy: 0.9934\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 188s 100ms/step - loss: 0.0257 - sparse_categorical_accuracy: 0.9916 - val_loss: 0.0256 - val_sparse_categorical_accuracy: 0.9914\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 186s 99ms/step - loss: 0.0238 - sparse_categorical_accuracy: 0.9925 - val_loss: 0.0242 - val_sparse_categorical_accuracy: 0.9930\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7c7c209e9990>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/logs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TmPDDl7lSc_",
        "outputId": "f48ede31-e926-4afd-fbf0-c04fa119a414"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/logs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r logs.zip /content/logs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6g8JDz5lXlz",
        "outputId": "c9ec2185-0603-42de-d67f-85bff6df85df"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/logs/ (stored 0%)\n",
            "  adding: content/logs/fit/ (stored 0%)\n",
            "  adding: content/logs/fit/20240417-004128/ (stored 0%)\n",
            "  adding: content/logs/fit/20240417-004128/train/ (stored 0%)\n",
            "  adding: content/logs/fit/20240417-004128/train/events.out.tfevents.1713314598.86ff6ece5a5f.1603.0.v2 (deflated 77%)\n",
            "  adding: content/logs/fit/20240417-004128/validation/ (stored 0%)\n",
            "  adding: content/logs/fit/20240417-004128/validation/events.out.tfevents.1713314775.86ff6ece5a5f.1603.1.v2 (deflated 68%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('logs.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "68yYFnnZld1y",
        "outputId": "5a9fad3b-9aa5-4372-e9a0-9b45147eba6b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d6fde228-af2e-4ade-8aa2-743a93c57e71\", \"logs.zip\", 17507)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup TensorBoard callback\n",
        "log_dir2 = \"logs2/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback2 = tf.keras.callbacks.TensorBoard(log_dir=log_dir2, histogram_freq=1)"
      ],
      "metadata": {
        "id": "mInheB1bJQFd"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(train_generator, validation_data = validation_generator, epochs = 5, verbose=1, callbacks=[tensorboard_callback2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1gKAN_0tEm_",
        "outputId": "136861dc-5a16-4cd8-cf3d-2357649b5560"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-c85d52a8140f>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(train_generator, validation_data = validation_generator, epochs = 5, verbose=1, callbacks=[tensorboard_callback2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1500/1500 [==============================] - 165s 110ms/step - loss: 0.5392 - sparse_categorical_accuracy: 0.8294 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 160s 107ms/step - loss: 0.4504 - sparse_categorical_accuracy: 0.8589 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 160s 106ms/step - loss: 0.4328 - sparse_categorical_accuracy: 0.8651 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 158s 106ms/step - loss: 0.4103 - sparse_categorical_accuracy: 0.8711 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 158s 105ms/step - loss: 0.3955 - sparse_categorical_accuracy: 0.8771 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7c7c1b36ea70>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Use TensorBoard to plot training and validation loss and accuracy."
      ],
      "metadata": {
        "id": "tI3DL9oWoUrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWqfPqgOqu0F",
        "outputId": "9373412f-5bc7-4ac0-fa5f-1fcbc438b4a4"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir=logs/fit\n"
      ],
      "metadata": {
        "id": "O9DwyfYTmpeX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "3e71af7d-1c6d-46e7-b1be-a62d0eb404f1"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ERROR: Failed to launch TensorBoard (exited with 1).\n",
              "Contents of stderr:\n",
              "2024-04-17 01:28:24.273817: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
              "\n",
              "NOTE: Using experimental fast data loading logic. To disable, pass\n",
              "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
              "    https://github.com/tensorflow/tensorboard/issues/4784\n",
              "\n",
              "Address already in use\n",
              "Port 6006 is in use by another program. Either identify and stop that program, or start the server with a different port."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The original logs folder was renamed to logs1 so that the new model with augmented images using TensorBoard will replace it (ie logs). This was done so the images from TensorBoard could show for both the normalized data versus the normalized AND augmented data for comparison analysis purposes."
      ],
      "metadata": {
        "id": "S_JEUhe4T9eJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir=logs/fit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "wa6egTZ107WI",
        "outputId": "0d212cbb-d60f-488b-8473-f7843b1ae133"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ERROR: Failed to launch TensorBoard (exited with 1).\n",
              "Contents of stderr:\n",
              "2024-04-17 01:27:08.255429: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
              "\n",
              "NOTE: Using experimental fast data loading logic. To disable, pass\n",
              "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
              "    https://github.com/tensorflow/tensorboard/issues/4784\n",
              "\n",
              "Address already in use\n",
              "Port 6006 is in use by another program. Either identify and stop that program, or start the server with a different port."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Evaluate the model on the test set to assess its generalization capability."
      ],
      "metadata": {
        "id": "nZ9fByT-ox2K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**# The second model performs poorly than the first model**"
      ],
      "metadata": {
        "id": "ifTXTQmfUbkO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The confusion matrix"
      ],
      "metadata": {
        "id": "u2pQe4S6ccz_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Model's Performance on the Test Data"
      ],
      "metadata": {
        "id": "d8rvvr4ibvDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cf = tf.math.confusion_matrix(y_pred_labels, y_test)\n",
        "print (cf)"
      ],
      "metadata": {
        "id": "QjGFFdP5cwHM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c272778d-a509-48ec-f064-f3e779db6ab5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 975    0    3    0    1    1    6    0    5    4]\n",
            " [   0 1130    3    0    1    0    2    5    0    5]\n",
            " [   0    1 1019    5    1    1    1   15    2    1]\n",
            " [   0    1    0  989    0    3    0    2    1    1]\n",
            " [   0    0    1    0  965    0    2    0    1    1]\n",
            " [   1    0    0    7    0  883    4    0    1    5]\n",
            " [   1    1    0    0    0    1  941    0    1    0]\n",
            " [   1    1    2    5    0    1    0  993    3    2]\n",
            " [   2    1    4    4    3    2    2    3  956    0]\n",
            " [   0    0    0    0   11    0    0   10    4  990]], shape=(10, 10), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cf_np = cf.numpy(); cf_np"
      ],
      "metadata": {
        "id": "zdy3OEWAcBNc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c7c34c7-a5f7-4e96-bc7d-61f3cd75e604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 975,    0,    3,    0,    1,    1,    6,    0,    5,    4],\n",
              "       [   0, 1130,    3,    0,    1,    0,    2,    5,    0,    5],\n",
              "       [   0,    1, 1019,    5,    1,    1,    1,   15,    2,    1],\n",
              "       [   0,    1,    0,  989,    0,    3,    0,    2,    1,    1],\n",
              "       [   0,    0,    1,    0,  965,    0,    2,    0,    1,    1],\n",
              "       [   1,    0,    0,    7,    0,  883,    4,    0,    1,    5],\n",
              "       [   1,    1,    0,    0,    0,    1,  941,    0,    1,    0],\n",
              "       [   1,    1,    2,    5,    0,    1,    0,  993,    3,    2],\n",
              "       [   2,    1,    4,    4,    3,    2,    2,    3,  956,    0],\n",
              "       [   0,    0,    0,    0,   11,    0,    0,   10,    4,  990]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for r in range(cf_np.shape[0]):\n",
        "  cf_np[r,r] = 0\n",
        "\n",
        "print (cf_np)"
      ],
      "metadata": {
        "id": "U3anhDwZdB-J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8948a665-3059-4333-d132-7203f259b8e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  3  0  1  1  6  0  5  4]\n",
            " [ 0  0  3  0  1  0  2  5  0  5]\n",
            " [ 0  1  0  5  1  1  1 15  2  1]\n",
            " [ 0  1  0  0  0  3  0  2  1  1]\n",
            " [ 0  0  1  0  0  0  2  0  1  1]\n",
            " [ 1  0  0  7  0  0  4  0  1  5]\n",
            " [ 1  1  0  0  0  1  0  0  1  0]\n",
            " [ 1  1  2  5  0  1  0  0  3  2]\n",
            " [ 2  1  4  4  3  2  2  3  0  0]\n",
            " [ 0  0  0  0 11  0  0 10  4  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_cf = cf_np.max(axis = 1); max_cf"
      ],
      "metadata": {
        "id": "Cog3AelxdH6V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74487c59-0e93-4d80-d05b-562b674ea4f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6,  5, 15,  3,  2,  7,  1,  5,  4, 11], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for r in range(cf_np.shape[0]):\n",
        "   m = np.argmax(cf_np[r])\n",
        "   print (f'{r} was confused for {m} {cf_np[r,m]} times...')"
      ],
      "metadata": {
        "id": "3pQmocr1dZvz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "088ffb76-7822-4be8-c1d0-137d7d000919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 was confused for 6 6 times...\n",
            "1 was confused for 7 5 times...\n",
            "2 was confused for 7 15 times...\n",
            "3 was confused for 5 3 times...\n",
            "4 was confused for 6 2 times...\n",
            "5 was confused for 3 7 times...\n",
            "6 was confused for 0 1 times...\n",
            "7 was confused for 3 5 times...\n",
            "8 was confused for 2 4 times...\n",
            "9 was confused for 4 11 times...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Looking at the Accuracy Score"
      ],
      "metadata": {
        "id": "apdJ-dAoF8V6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "2gHYk3VSDvJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "accuracy = accuracy_score(y_pred_labels, y_test)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "lluiLZS7oxku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f4990a2-63e1-4daf-fbec-c661a154db18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OBSERVATION:"
      ],
      "metadata": {
        "id": "qEQrrcPyxRha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Perform error analysis by reviewing misclassified images to understand the model's weaknesses."
      ],
      "metadata": {
        "id": "DPUfGS0PGUH1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Test the model with external images (e.g., hand-drawn digits) to further assess its performance."
      ],
      "metadata": {
        "id": "zLRiAgy6Gb0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # evaluate a model using k-fold cross-validation\n",
        "# def evaluate_model(dataX, dataY, n_folds=5):\n",
        "# \tscores, histories = list(), list()\n",
        "# \t# prepare cross validation\n",
        "# \tkfold = KFold(n_folds, shuffle=True, random_state=1)\n",
        "# \t# enumerate splits\n",
        "# \tfor train_ix, test_ix in kfold.split(dataX):\n",
        "# \t\t# define model\n",
        "# \t\tmodel = define_model()\n",
        "# \t\t# select rows for train and test\n",
        "# \t\tX_train_norm,y_train, X_test_norm, y_test = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n",
        "# \t\t# fit model\n",
        "# \t\thistory = model.fit(X_train_norm, y_train, epochs=10, batch_size=32, validation_data=(X_test_norm, y_test), verbose=0)\n",
        "# \t\t# evaluate model\n",
        "# \t\t_, acc = model.evaluate(X_test_norm, y_test, verbose=0)\n",
        "# \t\tprint('> %.3f' % (acc * 100.0))\n",
        "# \t\t# stores scores\n",
        "# \t\tscores.append(acc)\n",
        "# \t\thistories.append(history)\n",
        "# \treturn scores, histories"
      ],
      "metadata": {
        "id": "nJxC2TL2xN6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate_model"
      ],
      "metadata": {
        "id": "6y2u6oRG14lF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # plot diagnostic learning curves\n",
        "# def summarize_diagnostics(histories):\n",
        "# \tfor i in range(len(histories)):\n",
        "# \t\t# plot loss\n",
        "# \t\tplt.subplot(2, 1, 1)\n",
        "# \t\tplt.title('Cross Entropy Loss')\n",
        "# \t\tplt.plot(histories[i].history['loss'], color='blue', label='train')\n",
        "# \t\tplt.plot(histories[i].history['val_loss'], color='orange', label='test')\n",
        "# \t\t# plot accuracy\n",
        "# \t\tplt.subplot(2, 1, 2)\n",
        "# \t\tplt.title('Classification Accuracy')\n",
        "# \t\tplt.plot(histories[i].history['accuracy'], color='blue', label='train')\n",
        "# \t\tplt.plot(histories[i].history['val_accuracy'], color='orange', label='test')\n",
        "# \tplt.show()"
      ],
      "metadata": {
        "id": "TqxJMu59xRt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # summarize model performance\n",
        "# def summarize_performance(scores):\n",
        "# \t# print summary\n",
        "# \tprint('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\n",
        "# \t# box and whisker plots of results\n",
        "# \tplt.boxplot(scores)\n",
        "# \tplt.show()\n"
      ],
      "metadata": {
        "id": "r4Mg1oZlxTpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "VYI4_aW34V9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train_norm.head()"
      ],
      "metadata": {
        "id": "rT4Pt8mL5a_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # run the test harness for evaluating a model\n",
        "# def run_test_harness():\n",
        "# \t# load dataset\n",
        "# \tX_train, y_train, X_test, y_test = load_dataset()\n",
        "#   #prepare pixel data\n",
        "# X_train_norm, X_test_norm = prep_pixels(X_train, X_test)\n",
        "# \t# evaluate model\n",
        "# scores, histories = evaluate_model(dataX, dataY)\n",
        "# \t# learning curves\n",
        "# summarize_diagnostics(histories)\n",
        "# \t# summarize estimated performance\n",
        "# summarize_performance(scores)"
      ],
      "metadata": {
        "id": "gH_V2MmJxUYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # entry point, run the test harness\n",
        "# run_test_harness()"
      ],
      "metadata": {
        "id": "O50hgs8zxXtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # cnn model with batch normalization for mnist\n",
        "# from numpy import mean\n",
        "# from numpy import std\n",
        "# from matplotlib import pyplot as plt\n",
        "# from sklearn.model_selection import KFold\n",
        "# from tensorflow.keras.datasets import mnist\n",
        "# from tensorflow.keras.utils import to_categorical\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Conv2D\n",
        "# from tensorflow.keras.layers import MaxPooling2D\n",
        "# from tensorflow.keras.layers import Dense\n",
        "# from tensorflow.keras.layers import Flatten\n",
        "# from tensorflow.keras.optimizers import SGD\n",
        "# from tensorflow.keras.layers import BatchNormalization"
      ],
      "metadata": {
        "id": "T1MGCNlpropO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # load train and test dataset\n",
        "# def load_dataset():\n",
        "# \t# load dataset\n",
        "# \t(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# \t# reshape dataset to have a single channel\n",
        "# \tX_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
        "# \tX_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
        "# \t# one hot encode target values\n",
        "# \ty_train = to_categorical(y_train)\n",
        "# \ty_test = to_categorical(y_test)\n",
        "# \treturn X_train, y_train, X_test, y_test"
      ],
      "metadata": {
        "id": "gpd66YODrrHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train"
      ],
      "metadata": {
        "id": "8of2YaqouvXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train"
      ],
      "metadata": {
        "id": "KgI-hfiqu7FM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_test"
      ],
      "metadata": {
        "id": "c9Mvp4whu-MK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_test"
      ],
      "metadata": {
        "id": "o3TAQ4wbvBgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # scale pixels\n",
        "# def prep_pixels(train, test):\n",
        "# \t# convert from integers to floats\n",
        "# \ttrain_norm = train.astype('float32')\n",
        "# \ttest_norm = test.astype('float32')\n",
        "# \t# normalize to range 0-1\n",
        "# \ttrain_norm = train_norm / 255.0\n",
        "# \ttest_norm = test_norm / 255.0\n",
        "# \t# return normalized images\n",
        "# \treturn train_norm, test_norm"
      ],
      "metadata": {
        "id": "gxyzIkg9sZN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # scale pixels\n",
        "# def prep_pixels(X_train, X_test):\n",
        "# \t# convert from integers to floats\n",
        "# \tX_train_norm = X_train.astype('float32')\n",
        "# \tX_test_norm = X_test.astype('float32')\n",
        "# \t# normalize to range 0-1\n",
        "# \tX_train_norm = X_train_norm / 255.0\n",
        "# \tX_test_norm = X_test_norm / 255.0\n",
        "# \t# return normalized images\n",
        "# \treturn X_train_norm, X_test_norm"
      ],
      "metadata": {
        "id": "AHv9e9XEvw-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prep_pixels\n"
      ],
      "metadata": {
        "id": "rJb6IwKOvIUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # define cnn model\n",
        "# def define_model():\n",
        "# \tmodel = Sequential()\n",
        "# \tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
        "# \tmodel.add(BatchNormalization())\n",
        "# \tmodel.add(MaxPooling2D((2, 2)))\n",
        "# \tmodel.add(Flatten())\n",
        "# \tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "# \tmodel.add(BatchNormalization())\n",
        "# \tmodel.add(Dense(10, activation='softmax'))\n",
        "# \t# compile model\n",
        "# \topt = SGD(learning_rate=0.01, momentum=0.9)\n",
        "# \tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# \treturn model"
      ],
      "metadata": {
        "id": "oG9fOIjIsrgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # evaluate a model using k-fold cross-validation\n",
        "# def evaluate_model(data_X, data_y, n_folds=5):\n",
        "# \tscores, histories = list(), list()\n",
        "# \t# prepare cross validation\n",
        "# \tkfold = KFold(n_folds, shuffle=True, random_state=1)\n",
        "# \t# enumerate splits\n",
        "# \tfor train_ix, test_ix in kfold.split(dataX):\n",
        "# \t\t# define model\n",
        "# \t\tmodel = define_model()\n",
        "# \t\t# select rows for train and test\n",
        "# \t\tX_train, y_train, X_test, y_test = data_X[train_ix], data_y[train_ix], data_X[test_ix], data_y[test_ix]\n",
        "# \t\t# fit model\n",
        "# \t\thistory = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=0)\n",
        "# \t\t# evaluate model\n",
        "# \t\t_, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "# \t\tprint('> %.3f' % (acc * 100.0))\n",
        "# \t\t# stores scores\n",
        "# \t\tscores.append(acc)\n",
        "# \t\thistories.append(history)\n",
        "# \treturn scores, histories"
      ],
      "metadata": {
        "id": "xCQqxBRjsyjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # plot diagnostic learning curves\n",
        "# def summarize_diagnostics(histories):\n",
        "# \tfor i in range(len(histories)):\n",
        "# \t\t# plot loss\n",
        "# \t\tplt.subplot(2, 1, 1)\n",
        "# \t\tplt.title('Cross Entropy Loss')\n",
        "# \t\tplt.plot(histories[i].history['loss'], color='blue', label='train')\n",
        "# \t\tplt.plot(histories[i].history['val_loss'], color='orange', label='test')\n",
        "# \t\t# plot accuracy\n",
        "# \t\tplt.subplot(2, 1, 2)\n",
        "# \t\tplt.title('Classification Accuracy')\n",
        "# \t\tplt.plot(histories[i].history['accuracy'], color='blue', label='train')\n",
        "# \t\tplt.plot(histories[i].history['val_accuracy'], color='orange', label='test')\n",
        "# \tplt.show()"
      ],
      "metadata": {
        "id": "-yvTjwz9twtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # summarize model performance\n",
        "# def summarize_performance(scores):\n",
        "# \t# print summary\n",
        "# \tprint('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\n",
        "# \t# box and whisker plots of results\n",
        "# \tplt.boxplot(scores)\n",
        "# \tplt.show()"
      ],
      "metadata": {
        "id": "pn1FugEat2Nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # run the test harness for evaluating a model\n",
        "# def run_test_harness():\n",
        "# \t# load dataset\n",
        "# \tX_train, y_train, X_test, y_train = load_dataset()\n",
        "# \t# prepare pixel data\n",
        "# \tX_train, X_test = prep_pixels(X_train, X_test)\n",
        "# \t# evaluate model\n",
        "# \tscores, histories = evaluate_model(X_train, y_train)\n",
        "# \t# learning curves\n",
        "# \tsummarize_diagnostics(histories)\n",
        "# \t# summarize estimated performance\n",
        "# \tsummarize_performance(scores)"
      ],
      "metadata": {
        "id": "ZHkclv7kt6vW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # entry point, run the test harness\n",
        "# run_test_harness()"
      ],
      "metadata": {
        "id": "HuOTXjcQT7rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "G4qVhTA_UDsi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "pHcwFbyEUfJQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **Task 5: Results Analysis and Model Tuning**  \n",
        "\n",
        "**Objective:** Analyze the results and refine the model for better performance.  \n",
        "\n",
        "**Activities:**\n",
        "\n",
        "1. Use TensorBoard to perform detailed analysis of model performance, including confusion matrices and histograms of model weights.\n",
        "2. Investigate layer activations and feature maps to understand what the model is learning.\n",
        "3. Experiment with different architectures using `model.get_config()` and hyperparameters to improve performance.\n",
        "4. Apply techniques like dropout and batch normalization to mitigate overfitting.\n",
        "5. Evaluate the effects of data augmentation on model robustness using TensorBoard.\n",
        "6. Conduct ablation studies, using TensorBoard to track and compare results.\n",
        "\n",
        "**Estimated Completion Time:** 240 minutes\n",
        "\n"
      ],
      "metadata": {
        "id": "mMLzoQiS2zW9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing hyperopt and related functions"
      ],
      "metadata": {
        "id": "gLhnAuFVJ69C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow\n",
        "!pip install hyperopt\n",
        "!pip install xgboost"
      ],
      "metadata": {
        "id": "JCS61o-nJ-3o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c3cb0ac-34b9-4cd0-8baa-27c7527653a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.10/dist-packages (2.11.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.1)\n",
            "Requirement already satisfied: entrypoints<1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.43)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (6.0.1)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.20.3)\n",
            "Requirement already satisfied: pytz<2025 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2023.4)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.31.0)\n",
            "Requirement already satisfied: packaging<24 in /usr/local/lib/python3.10/dist-packages (from mlflow) (23.2)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4.4)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.13.1)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (7.0.0)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.23.5)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.11.4)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.5.3)\n",
            "Requirement already satisfied: querystring-parser<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.2.4)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.29)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.2.2)\n",
            "Requirement already satisfied: pyarrow<16,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (14.0.2)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.6)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.1)\n",
            "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.3)\n",
            "Requirement already satisfied: gunicorn<22 in /usr/local/lib/python3.10/dist-packages (from mlflow) (21.2.0)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.3)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.11.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker<8,>=4.0.0->mlflow) (2.0.7)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.0.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.1.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython<4,>=3.1.9->mlflow) (4.0.11)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (3.2.3)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: aniso8601<10,>=8 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (9.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow) (3.18.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from querystring-parser<2->mlflow) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.4.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow) (5.0.1)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.10/dist-packages (0.2.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.11.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.16.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt) (3.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.18.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from hyperopt) (4.66.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.10.9.7)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras import layers\n",
        "from hyperopt import hp,fmin, tpe, Trials, STATUS_OK, STATUS_FAIL\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import mlflow\n",
        "import mlflow.keras"
      ],
      "metadata": {
        "id": "9d11SbZPKDLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import RandomFlip, RandomRotation, Rescaling, BatchNormalization, Conv2D, MaxPooling2D, Dense, Input, Flatten, Dropout\n",
        "from keras.models import Model, Sequential\n",
        "#BatchNormalization after running the Augmented Data through the models above"
      ],
      "metadata": {
        "id": "wMaQxi8RKHXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#param_space is the same as search_space\n",
        "param_space = {\n",
        "    'conv1_filters': hp.choice('conv1_filters', [32,64,128]),\n",
        "    'conv2_filters': hp.choice('conv2_filters', [64,128,256]),\n",
        "    'dropout_rate': hp.uniform('dropout_rate', 0.2,0.3),\n",
        "    'dense_units': hp.choice('dense_units', [64,128,256])}"
      ],
      "metadata": {
        "id": "iTRZBSh1KU-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The list of 'convX_filters'.... should match the corresponding list in the def objective(params): section"
      ],
      "metadata": {
        "id": "vGOseUMGME_U"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jSH9i1S4NJD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Consider adding a dropout rate"
      ],
      "metadata": {
        "id": "tkjvgqRpMnUB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Expect this model to run for about 30 minutes\n",
        "# Also play with the following from \"Yet another. Colab Notebook.\n",
        "#        MaxPooling2D(pool_size=(2, 2)),\n",
        "        <!-- Flatten(),\n",
        "        Dropout(params['dropout_rate']),\n",
        "        Dense(params['dense_units'], activation=\"relu\"),\n",
        "        Dense(num_classes, activation=\"softmax\") -->"
      ],
      "metadata": {
        "id": "xWy8Z5R7M7Yb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(params):\n",
        "  '''\n",
        "   Build a Sequential model with regular densely-connected NN layers.\n",
        "   Return the constructed model.\n",
        "\n",
        "   Compile the pre-built model with the model hyperparameters.\n",
        "   Return the compiled model\n",
        "\n",
        "   Train the model with a fixed number of epochs\n",
        "   Return the history (log)\n",
        "\n",
        "  '''\n",
        "\n",
        "  # Automatic logging of metrics, parameters and models.\n",
        "  mlflow.tensorflow.autolog()\n",
        "  with mlflow.start_run():\n",
        "\n",
        "    input_shape = (28, 28, 1)  # 1 is the count of channels (no RGB)\n",
        "\n",
        "    model = keras.Sequential ([\n",
        "\n",
        "    # // The input layer\n",
        "    layers.Input(shape=input_shape),\n",
        "\n",
        "    # // Hidden layers\n",
        "    layers.Conv2D(params['conv1_filters'], kernel_size=(3, 3), activation=\"relu\", name='CL1'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2), name='MPL1'),\n",
        "\n",
        "    layers.Conv2D(params['conv2_filters'], kernel_size=(3, 3), activation=\"relu\", name='CL2'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2), name='MPL2'),\n",
        "\n",
        "    layers.Flatten(name='FL'),\n",
        "    # run this line for Drop Out if you re-run the HyperOpt as of 4/14/2024 at 5:55 PM ET.\n",
        "    layers.Dropout(rate=params['dropout_rate']),\n",
        "    # // The model's output layer\n",
        "    # We create a classifier for as many classes as there are in the input data\n",
        "    #model.add(layers.Dense(num_classes, name=\"OUTL\", activation='softmax'))\n",
        "    #layers.Dense(num_classes, name=\"OUTL\", activation='softmax'),\n",
        "    # the dense ought to have been updated as of 4/15/2024 5:53 PM ET :\n",
        "    layers.Dense(params['dense_units'], name=\"OUTL\", activation='softmax')\n",
        "    ])\n",
        "    model.compile(\n",
        "      #optimizer=keras.optimizers.RMSprop(),\n",
        "      optimizer=SGD(learning_rate=1e-2, momentum=0.9, nesterov=True),\n",
        "\n",
        "      # The loss function that we need to minimize\n",
        "      loss=keras.losses.SparseCategoricalCrossentropy(),  # we have a lot of \"holes\" in the dataset (the black pixels with a value of 0)\n",
        "\n",
        "      # The metrics (can be more than one) to monitor\n",
        "      metrics=[keras.metrics.SparseCategoricalAccuracy()], # The \"dangling\" comma , before the closing bracket is good practice ...\n",
        "    )\n",
        "  # In a CPU-only CoLab environment, training may take about 5 minutes, give or take, so be patient and wait until the training is done ...\n",
        "    model.fit(X_train_scaled, y_train, batch_size = 128, epochs = 5, verbose=1)\n",
        "    score = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "\n",
        "    mlflow.log_param(\"Number of Neurons in the first CNN Layer\", params['conv1_filters'])\n",
        "    mlflow.log_param(\"Number of Neurons in the second CNN Layer\", params ['conv2_filters'])\n",
        "    mlflow.log_param(\"The Dropout Rate\", params['dropout_rate'])\n",
        "    mlflow.log_param(\"Dense Units\", params['dense_units'])\n",
        "  return {'loss': -score[1], 'status': STATUS_OK, 'model': model}"
      ],
      "metadata": {
        "id": "80WzATvEKuvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def compile_objective(model):\n",
        "#   '''\n",
        "#     Compile the pre-built model with the model hyperparameters.\n",
        "#     Return the compiled model\n",
        "#   '''\n",
        "#   model.compile(\n",
        "#       #optimizer=keras.optimizers.RMSprop(),\n",
        "#       optimizer=SGD(learning_rate=1e-2, momentum=0.9, nesterov=True),\n",
        "\n",
        "#       # The loss function that we need to minimize\n",
        "#       loss=keras.losses.SparseCategoricalCrossentropy(),  # we have a lot of \"holes\" in the dataset (the black pixels with a value of 0)\n",
        "\n",
        "#       # The metrics (can be more than one) to monitor\n",
        "#       metrics=[keras.metrics.SparseCategoricalAccuracy()], # The \"dangling\" comma , before the closing bracket is good practice ...\n",
        "#   )\n",
        "\n",
        "#   return model"
      ],
      "metadata": {
        "id": "cYtPLCZoN-i4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def train_objective(model):\n",
        "#   '''\n",
        "#     Train the model with a fixed number of epochs\n",
        "#     Return the history (log)\n",
        "#   '''\n",
        "#   # In a CPU-only CoLab environment, training may take about 5 minutes, give or take, so be patient and wait until the training is done ...\n",
        "#   history = model.fit(X_train_scaled, y_train, batch_size = 128, epochs = 10, verbose=1)\n",
        "\n",
        "#   return history"
      ],
      "metadata": {
        "id": "bBLpQMHuOL-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trials = Trials()\n",
        "best_params = fmin(objective, param_space, algo = tpe.suggest, max_evals = 5, trials = trials)\n",
        "print (\"Best HyperParameters:\", best_params)"
      ],
      "metadata": {
        "id": "pDpu8_xpNmtA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68293ee6-256f-42ee-e639-5ef94679745e"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\n",
            "  1/469 [..............................] - ETA: 13:00 - loss: 4.1635 - sparse_categorical_accuracy: 0.0469\n",
            "  2/469 [..............................] - ETA: 6:10 - loss: 4.1472 - sparse_categorical_accuracy: 0.0586 \n",
            "  3/469 [..............................] - ETA: 5:57 - loss: 4.1307 - sparse_categorical_accuracy: 0.0833\n",
            "  4/469 [..............................] - ETA: 5:54 - loss: 4.1110 - sparse_categorical_accuracy: 0.0859\n",
            "  5/469 [..............................] - ETA: 5:52 - loss: 4.0857 - sparse_categorical_accuracy: 0.1000\n",
            "  6/469 [..............................] - ETA: 5:47 - loss: 4.0569 - sparse_categorical_accuracy: 0.1055\n",
            "  7/469 [..............................] - ETA: 5:45 - loss: 4.0242 - sparse_categorical_accuracy: 0.1105\n",
            "  8/469 [..............................] - ETA: 5:45 - loss: 3.9842 - sparse_categorical_accuracy: 0.1143\n",
            "  9/469 [..............................] - ETA: 5:51 - loss: 3.9401 - sparse_categorical_accuracy: 0.1111\n",
            " 10/469 [..............................] - ETA: 6:11 - loss: 3.8830 - sparse_categorical_accuracy: 0.1203\n",
            " 11/469 [..............................] - ETA: 6:26 - loss: 3.8104 - sparse_categorical_accuracy: 0.1300\n",
            " 12/469 [..............................] - ETA: 6:35 - loss: 3.7271 - sparse_categorical_accuracy: 0.1393\n",
            " 13/469 [..............................] - ETA: 6:29 - loss: 3.6309 - sparse_categorical_accuracy: 0.1502\n",
            " 14/469 [..............................] - ETA: 6:24 - loss: 3.5332 - sparse_categorical_accuracy: 0.1596\n",
            " 15/469 [..............................] - ETA: 6:20 - loss: 3.4517 - sparse_categorical_accuracy: 0.1672\n",
            " 16/469 [>.............................] - ETA: 6:16 - loss: 3.3654 - sparse_categorical_accuracy: 0.1753\n",
            " 17/469 [>.............................] - ETA: 6:12 - loss: 3.2795 - sparse_categorical_accuracy: 0.1898\n",
            " 18/469 [>.............................] - ETA: 6:09 - loss: 3.2019 - sparse_categorical_accuracy: 0.2036\n",
            " 19/469 [>.............................] - ETA: 6:07 - loss: 3.1319 - sparse_categorical_accuracy: 0.2109\n",
            " 20/469 [>.............................] - ETA: 6:03 - loss: 3.0586 - sparse_categorical_accuracy: 0.2277\n",
            " 21/469 [>.............................] - ETA: 6:01 - loss: 2.9925 - sparse_categorical_accuracy: 0.2377\n",
            " 22/469 [>.............................] - ETA: 5:58 - loss: 2.9235 - sparse_categorical_accuracy: 0.2525\n",
            " 23/469 [>.............................] - ETA: 5:56 - loss: 2.8514 - sparse_categorical_accuracy: 0.2694\n",
            " 24/469 [>.............................] - ETA: 5:54 - loss: 2.7890 - sparse_categorical_accuracy: 0.2822\n",
            " 25/469 [>.............................] - ETA: 5:52 - loss: 2.7239 - sparse_categorical_accuracy: 0.2969\n",
            " 26/469 [>.............................] - ETA: 5:52 - loss: 2.6650 - sparse_categorical_accuracy: 0.3089\n",
            " 27/469 [>.............................] - ETA: 5:59 - loss: 2.6157 - sparse_categorical_accuracy: 0.3180\n",
            " 28/469 [>.............................] - ETA: 6:04 - loss: 2.5587 - sparse_categorical_accuracy: 0.3304\n",
            " 29/469 [>.............................] - ETA: 6:06 - loss: 2.5071 - sparse_categorical_accuracy: 0.3416\n",
            " 30/469 [>.............................] - ETA: 6:03 - loss: 2.4580 - sparse_categorical_accuracy: 0.3518\n",
            " 31/469 [>.............................] - ETA: 6:00 - loss: 2.4225 - sparse_categorical_accuracy: 0.3586\n",
            " 32/469 [=>............................] - ETA: 5:58 - loss: 2.3875 - sparse_categorical_accuracy: 0.3687\n",
            " 33/469 [=>............................] - ETA: 5:56 - loss: 2.3521 - sparse_categorical_accuracy: 0.3783\n",
            " 34/469 [=>............................] - ETA: 5:54 - loss: 2.3145 - sparse_categorical_accuracy: 0.3856\n",
            " 35/469 [=>............................] - ETA: 5:52 - loss: 2.2823 - sparse_categorical_accuracy: 0.3935\n",
            " 36/469 [=>............................] - ETA: 5:50 - loss: 2.2594 - sparse_categorical_accuracy: 0.3980\n",
            " 37/469 [=>............................] - ETA: 5:48 - loss: 2.2310 - sparse_categorical_accuracy: 0.4052\n",
            " 38/469 [=>............................] - ETA: 5:46 - loss: 2.2103 - sparse_categorical_accuracy: 0.4118\n",
            " 39/469 [=>............................] - ETA: 5:44 - loss: 2.1836 - sparse_categorical_accuracy: 0.4199\n",
            " 40/469 [=>............................] - ETA: 5:43 - loss: 2.1592 - sparse_categorical_accuracy: 0.4264\n",
            " 41/469 [=>............................] - ETA: 5:41 - loss: 2.1284 - sparse_categorical_accuracy: 0.4335\n",
            " 42/469 [=>............................] - ETA: 5:40 - loss: 2.1025 - sparse_categorical_accuracy: 0.4375\n",
            " 43/469 [=>............................] - ETA: 5:40 - loss: 2.0749 - sparse_categorical_accuracy: 0.4440\n",
            " 44/469 [=>............................] - ETA: 5:43 - loss: 2.0407 - sparse_categorical_accuracy: 0.4537\n",
            " 45/469 [=>............................] - ETA: 5:46 - loss: 2.0075 - sparse_categorical_accuracy: 0.4615\n",
            " 46/469 [=>............................] - ETA: 5:46 - loss: 1.9741 - sparse_categorical_accuracy: 0.4696\n",
            " 47/469 [==>...........................] - ETA: 5:45 - loss: 1.9437 - sparse_categorical_accuracy: 0.4781\n",
            " 48/469 [==>...........................] - ETA: 5:43 - loss: 1.9217 - sparse_categorical_accuracy: 0.4826\n",
            " 49/469 [==>...........................] - ETA: 5:41 - loss: 1.8936 - sparse_categorical_accuracy: 0.4901\n",
            " 50/469 [==>...........................] - ETA: 5:40 - loss: 1.8666 - sparse_categorical_accuracy: 0.4977\n",
            " 51/469 [==>...........................] - ETA: 5:38 - loss: 1.8426 - sparse_categorical_accuracy: 0.5038\n",
            " 52/469 [==>...........................] - ETA: 5:36 - loss: 1.8136 - sparse_categorical_accuracy: 0.5120\n",
            " 53/469 [==>...........................] - ETA: 5:35 - loss: 1.7899 - sparse_categorical_accuracy: 0.5178\n",
            " 54/469 [==>...........................] - ETA: 5:34 - loss: 1.7693 - sparse_categorical_accuracy: 0.5229\n",
            " 55/469 [==>...........................] - ETA: 5:33 - loss: 1.7458 - sparse_categorical_accuracy: 0.5288\n",
            " 56/469 [==>...........................] - ETA: 5:32 - loss: 1.7230 - sparse_categorical_accuracy: 0.5350\n",
            " 57/469 [==>...........................] - ETA: 5:31 - loss: 1.7013 - sparse_categorical_accuracy: 0.5406\n",
            " 58/469 [==>...........................] - ETA: 5:29 - loss: 1.6811 - sparse_categorical_accuracy: 0.5465\n",
            " 59/469 [==>...........................] - ETA: 5:28 - loss: 1.6599 - sparse_categorical_accuracy: 0.5520\n",
            " 60/469 [==>...........................] - ETA: 5:28 - loss: 1.6395 - sparse_categorical_accuracy: 0.5573\n",
            " 61/469 [==>...........................] - ETA: 5:30 - loss: 1.6238 - sparse_categorical_accuracy: 0.5613\n",
            " 62/469 [==>...........................] - ETA: 5:31 - loss: 1.6064 - sparse_categorical_accuracy: 0.5662\n",
            " 63/469 [===>..........................] - ETA: 5:31 - loss: 1.5904 - sparse_categorical_accuracy: 0.5694\n",
            " 64/469 [===>..........................] - ETA: 5:30 - loss: 1.5728 - sparse_categorical_accuracy: 0.5742\n",
            " 65/469 [===>..........................] - ETA: 5:29 - loss: 1.5558 - sparse_categorical_accuracy: 0.5785\n",
            " 66/469 [===>..........................] - ETA: 5:27 - loss: 1.5405 - sparse_categorical_accuracy: 0.5829\n",
            " 67/469 [===>..........................] - ETA: 5:26 - loss: 1.5269 - sparse_categorical_accuracy: 0.5868\n",
            " 68/469 [===>..........................] - ETA: 5:24 - loss: 1.5129 - sparse_categorical_accuracy: 0.5903\n",
            " 69/469 [===>..........................] - ETA: 5:23 - loss: 1.4979 - sparse_categorical_accuracy: 0.5938\n",
            " 70/469 [===>..........................] - ETA: 5:22 - loss: 1.4830 - sparse_categorical_accuracy: 0.5975\n",
            " 71/469 [===>..........................] - ETA: 5:20 - loss: 1.4692 - sparse_categorical_accuracy: 0.6010\n",
            " 72/469 [===>..........................] - ETA: 5:19 - loss: 1.4553 - sparse_categorical_accuracy: 0.6042\n",
            " 73/469 [===>..........................] - ETA: 5:18 - loss: 1.4410 - sparse_categorical_accuracy: 0.6077\n",
            " 74/469 [===>..........................] - ETA: 5:17 - loss: 1.4286 - sparse_categorical_accuracy: 0.6109\n",
            " 75/469 [===>..........................] - ETA: 5:16 - loss: 1.4150 - sparse_categorical_accuracy: 0.6146\n",
            " 76/469 [===>..........................] - ETA: 5:15 - loss: 1.4020 - sparse_categorical_accuracy: 0.6181\n",
            " 77/469 [===>..........................] - ETA: 5:15 - loss: 1.3908 - sparse_categorical_accuracy: 0.6207\n",
            " 78/469 [===>..........................] - ETA: 5:17 - loss: 1.3777 - sparse_categorical_accuracy: 0.6238\n",
            " 79/469 [====>.........................] - ETA: 5:18 - loss: 1.3652 - sparse_categorical_accuracy: 0.6269\n",
            " 80/469 [====>.........................] - ETA: 5:17 - loss: 1.3537 - sparse_categorical_accuracy: 0.6300\n",
            " 81/469 [====>.........................] - ETA: 5:16 - loss: 1.3417 - sparse_categorical_accuracy: 0.6328\n",
            " 82/469 [====>.........................] - ETA: 5:15 - loss: 1.3305 - sparse_categorical_accuracy: 0.6358\n",
            " 83/469 [====>.........................] - ETA: 5:14 - loss: 1.3210 - sparse_categorical_accuracy: 0.6379\n",
            " 84/469 [====>.........................] - ETA: 5:13 - loss: 1.3098 - sparse_categorical_accuracy: 0.6410\n",
            " 85/469 [====>.........................] - ETA: 5:12 - loss: 1.2998 - sparse_categorical_accuracy: 0.6437\n",
            " 86/469 [====>.........................] - ETA: 5:11 - loss: 1.2873 - sparse_categorical_accuracy: 0.6473\n",
            " 87/469 [====>.........................] - ETA: 5:10 - loss: 1.2779 - sparse_categorical_accuracy: 0.6498\n",
            " 88/469 [====>.........................] - ETA: 5:09 - loss: 1.2699 - sparse_categorical_accuracy: 0.6517\n",
            " 89/469 [====>.........................] - ETA: 5:08 - loss: 1.2609 - sparse_categorical_accuracy: 0.6543\n",
            " 90/469 [====>.........................] - ETA: 5:07 - loss: 1.2510 - sparse_categorical_accuracy: 0.6571\n",
            " 91/469 [====>.........................] - ETA: 5:06 - loss: 1.2424 - sparse_categorical_accuracy: 0.6598\n",
            " 92/469 [====>.........................] - ETA: 5:05 - loss: 1.2327 - sparse_categorical_accuracy: 0.6622\n",
            " 93/469 [====>.........................] - ETA: 5:04 - loss: 1.2240 - sparse_categorical_accuracy: 0.6646\n",
            " 94/469 [=====>........................] - ETA: 5:05 - loss: 1.2151 - sparse_categorical_accuracy: 0.6666\n",
            " 95/469 [=====>........................] - ETA: 5:06 - loss: 1.2064 - sparse_categorical_accuracy: 0.6687\n",
            " 96/469 [=====>........................] - ETA: 5:06 - loss: 1.1981 - sparse_categorical_accuracy: 0.6708\n",
            " 97/469 [=====>........................] - ETA: 5:04 - loss: 1.1903 - sparse_categorical_accuracy: 0.6729\n",
            " 98/469 [=====>........................] - ETA: 5:03 - loss: 1.1836 - sparse_categorical_accuracy: 0.6744\n",
            " 99/469 [=====>........................] - ETA: 5:02 - loss: 1.1749 - sparse_categorical_accuracy: 0.6765\n",
            "100/469 [=====>........................] - ETA: 5:00 - loss: 1.1668 - sparse_categorical_accuracy: 0.6786\n",
            "101/469 [=====>........................] - ETA: 4:59 - loss: 1.1618 - sparse_categorical_accuracy: 0.6800\n",
            "102/469 [=====>........................] - ETA: 4:58 - loss: 1.1535 - sparse_categorical_accuracy: 0.6821\n",
            "103/469 [=====>........................] - ETA: 4:57 - loss: 1.1454 - sparse_categorical_accuracy: 0.6842\n",
            "104/469 [=====>........................] - ETA: 4:56 - loss: 1.1369 - sparse_categorical_accuracy: 0.6866\n",
            "105/469 [=====>........................] - ETA: 4:55 - loss: 1.1295 - sparse_categorical_accuracy: 0.6882\n",
            "106/469 [=====>........................] - ETA: 4:53 - loss: 1.1219 - sparse_categorical_accuracy: 0.6904\n",
            "107/469 [=====>........................] - ETA: 4:52 - loss: 1.1144 - sparse_categorical_accuracy: 0.6922\n",
            "108/469 [=====>........................] - ETA: 4:51 - loss: 1.1076 - sparse_categorical_accuracy: 0.6938\n",
            "109/469 [=====>........................] - ETA: 4:50 - loss: 1.1022 - sparse_categorical_accuracy: 0.6951\n",
            "110/469 [======>.......................] - ETA: 4:49 - loss: 1.0953 - sparse_categorical_accuracy: 0.6969\n",
            "111/469 [======>.......................] - ETA: 4:48 - loss: 1.0888 - sparse_categorical_accuracy: 0.6986\n",
            "112/469 [======>.......................] - ETA: 4:49 - loss: 1.0822 - sparse_categorical_accuracy: 0.7003\n",
            "113/469 [======>.......................] - ETA: 4:49 - loss: 1.0759 - sparse_categorical_accuracy: 0.7020\n",
            "114/469 [======>.......................] - ETA: 4:48 - loss: 1.0704 - sparse_categorical_accuracy: 0.7036\n",
            "115/469 [======>.......................] - ETA: 4:47 - loss: 1.0640 - sparse_categorical_accuracy: 0.7052\n",
            "116/469 [======>.......................] - ETA: 4:46 - loss: 1.0578 - sparse_categorical_accuracy: 0.7068\n",
            "117/469 [======>.......................] - ETA: 4:45 - loss: 1.0511 - sparse_categorical_accuracy: 0.7085\n",
            "118/469 [======>.......................] - ETA: 4:44 - loss: 1.0453 - sparse_categorical_accuracy: 0.7099\n",
            "119/469 [======>.......................] - ETA: 4:43 - loss: 1.0392 - sparse_categorical_accuracy: 0.7114\n",
            "120/469 [======>.......................] - ETA: 4:41 - loss: 1.0340 - sparse_categorical_accuracy: 0.7126\n",
            "121/469 [======>.......................] - ETA: 4:40 - loss: 1.0293 - sparse_categorical_accuracy: 0.7140\n",
            "122/469 [======>.......................] - ETA: 4:39 - loss: 1.0228 - sparse_categorical_accuracy: 0.7159\n",
            "123/469 [======>.......................] - ETA: 4:38 - loss: 1.0188 - sparse_categorical_accuracy: 0.7168\n",
            "124/469 [======>.......................] - ETA: 4:37 - loss: 1.0138 - sparse_categorical_accuracy: 0.7181\n",
            "125/469 [======>.......................] - ETA: 4:36 - loss: 1.0075 - sparse_categorical_accuracy: 0.7196\n",
            "126/469 [=======>......................] - ETA: 4:35 - loss: 1.0024 - sparse_categorical_accuracy: 0.7209\n",
            "127/469 [=======>......................] - ETA: 4:34 - loss: 0.9964 - sparse_categorical_accuracy: 0.7224\n",
            "128/469 [=======>......................] - ETA: 4:33 - loss: 0.9908 - sparse_categorical_accuracy: 0.7239\n",
            "129/469 [=======>......................] - ETA: 4:33 - loss: 0.9851 - sparse_categorical_accuracy: 0.7254\n",
            "130/469 [=======>......................] - ETA: 4:33 - loss: 0.9798 - sparse_categorical_accuracy: 0.7269\n",
            "131/469 [=======>......................] - ETA: 4:33 - loss: 0.9742 - sparse_categorical_accuracy: 0.7284\n",
            "132/469 [=======>......................] - ETA: 4:32 - loss: 0.9688 - sparse_categorical_accuracy: 0.7299\n",
            "133/469 [=======>......................] - ETA: 4:31 - loss: 0.9635 - sparse_categorical_accuracy: 0.7315\n",
            "134/469 [=======>......................] - ETA: 4:30 - loss: 0.9586 - sparse_categorical_accuracy: 0.7326\n",
            "135/469 [=======>......................] - ETA: 4:29 - loss: 0.9535 - sparse_categorical_accuracy: 0.7340\n",
            "136/469 [=======>......................] - ETA: 4:28 - loss: 0.9490 - sparse_categorical_accuracy: 0.7353\n",
            "137/469 [=======>......................] - ETA: 4:27 - loss: 0.9450 - sparse_categorical_accuracy: 0.7364\n",
            "138/469 [=======>......................] - ETA: 4:26 - loss: 0.9406 - sparse_categorical_accuracy: 0.7377\n",
            "139/469 [=======>......................] - ETA: 4:25 - loss: 0.9361 - sparse_categorical_accuracy: 0.7389\n",
            "140/469 [=======>......................] - ETA: 4:23 - loss: 0.9319 - sparse_categorical_accuracy: 0.7399\n",
            "141/469 [========>.....................] - ETA: 4:22 - loss: 0.9270 - sparse_categorical_accuracy: 0.7412\n",
            "142/469 [========>.....................] - ETA: 4:21 - loss: 0.9223 - sparse_categorical_accuracy: 0.7424\n",
            "143/469 [========>.....................] - ETA: 4:20 - loss: 0.9183 - sparse_categorical_accuracy: 0.7437\n",
            "144/469 [========>.....................] - ETA: 4:19 - loss: 0.9146 - sparse_categorical_accuracy: 0.7447\n",
            "145/469 [========>.....................] - ETA: 4:18 - loss: 0.9097 - sparse_categorical_accuracy: 0.7460\n",
            "146/469 [========>.....................] - ETA: 4:18 - loss: 0.9065 - sparse_categorical_accuracy: 0.7471\n",
            "147/469 [========>.....................] - ETA: 4:18 - loss: 0.9025 - sparse_categorical_accuracy: 0.7480\n",
            "148/469 [========>.....................] - ETA: 4:17 - loss: 0.8981 - sparse_categorical_accuracy: 0.7493\n",
            "149/469 [========>.....................] - ETA: 4:17 - loss: 0.8938 - sparse_categorical_accuracy: 0.7506\n",
            "150/469 [========>.....................] - ETA: 4:16 - loss: 0.8897 - sparse_categorical_accuracy: 0.7516\n",
            "151/469 [========>.....................] - ETA: 4:15 - loss: 0.8854 - sparse_categorical_accuracy: 0.7528\n",
            "152/469 [========>.....................] - ETA: 4:14 - loss: 0.8818 - sparse_categorical_accuracy: 0.7537\n",
            "153/469 [========>.....................] - ETA: 4:13 - loss: 0.8783 - sparse_categorical_accuracy: 0.7545\n",
            "154/469 [========>.....................] - ETA: 4:12 - loss: 0.8748 - sparse_categorical_accuracy: 0.7554\n",
            "155/469 [========>.....................] - ETA: 4:11 - loss: 0.8718 - sparse_categorical_accuracy: 0.7565\n",
            "156/469 [========>.....................] - ETA: 4:10 - loss: 0.8679 - sparse_categorical_accuracy: 0.7575\n",
            "157/469 [=========>....................] - ETA: 4:09 - loss: 0.8637 - sparse_categorical_accuracy: 0.7587\n",
            "158/469 [=========>....................] - ETA: 4:07 - loss: 0.8597 - sparse_categorical_accuracy: 0.7598\n",
            "159/469 [=========>....................] - ETA: 4:07 - loss: 0.8563 - sparse_categorical_accuracy: 0.7607\n",
            "160/469 [=========>....................] - ETA: 4:06 - loss: 0.8523 - sparse_categorical_accuracy: 0.7617\n",
            "161/469 [=========>....................] - ETA: 4:05 - loss: 0.8490 - sparse_categorical_accuracy: 0.7623\n",
            "162/469 [=========>....................] - ETA: 4:04 - loss: 0.8451 - sparse_categorical_accuracy: 0.7634\n",
            "163/469 [=========>....................] - ETA: 4:03 - loss: 0.8421 - sparse_categorical_accuracy: 0.7641\n",
            "164/469 [=========>....................] - ETA: 4:03 - loss: 0.8383 - sparse_categorical_accuracy: 0.7651\n",
            "165/469 [=========>....................] - ETA: 4:03 - loss: 0.8360 - sparse_categorical_accuracy: 0.7658\n",
            "166/469 [=========>....................] - ETA: 4:02 - loss: 0.8329 - sparse_categorical_accuracy: 0.7665\n",
            "167/469 [=========>....................] - ETA: 4:01 - loss: 0.8292 - sparse_categorical_accuracy: 0.7675\n",
            "168/469 [=========>....................] - ETA: 4:00 - loss: 0.8259 - sparse_categorical_accuracy: 0.7685\n",
            "169/469 [=========>....................] - ETA: 3:59 - loss: 0.8228 - sparse_categorical_accuracy: 0.7693\n",
            "170/469 [=========>....................] - ETA: 3:58 - loss: 0.8198 - sparse_categorical_accuracy: 0.7701\n",
            "171/469 [=========>....................] - ETA: 3:57 - loss: 0.8172 - sparse_categorical_accuracy: 0.7707\n",
            "172/469 [==========>...................] - ETA: 3:56 - loss: 0.8140 - sparse_categorical_accuracy: 0.7715\n",
            "173/469 [==========>...................] - ETA: 3:55 - loss: 0.8107 - sparse_categorical_accuracy: 0.7724\n",
            "174/469 [==========>...................] - ETA: 3:54 - loss: 0.8075 - sparse_categorical_accuracy: 0.7734\n",
            "175/469 [==========>...................] - ETA: 3:53 - loss: 0.8049 - sparse_categorical_accuracy: 0.7742\n",
            "176/469 [==========>...................] - ETA: 3:52 - loss: 0.8023 - sparse_categorical_accuracy: 0.7749\n",
            "177/469 [==========>...................] - ETA: 3:51 - loss: 0.7993 - sparse_categorical_accuracy: 0.7757\n",
            "178/469 [==========>...................] - ETA: 3:50 - loss: 0.7966 - sparse_categorical_accuracy: 0.7765\n",
            "179/469 [==========>...................] - ETA: 3:49 - loss: 0.7937 - sparse_categorical_accuracy: 0.7773\n",
            "180/469 [==========>...................] - ETA: 3:48 - loss: 0.7908 - sparse_categorical_accuracy: 0.7781\n",
            "181/469 [==========>...................] - ETA: 3:48 - loss: 0.7881 - sparse_categorical_accuracy: 0.7787\n",
            "182/469 [==========>...................] - ETA: 3:48 - loss: 0.7849 - sparse_categorical_accuracy: 0.7797\n",
            "183/469 [==========>...................] - ETA: 3:47 - loss: 0.7817 - sparse_categorical_accuracy: 0.7805\n",
            "184/469 [==========>...................] - ETA: 3:47 - loss: 0.7788 - sparse_categorical_accuracy: 0.7812\n",
            "185/469 [==========>...................] - ETA: 3:46 - loss: 0.7760 - sparse_categorical_accuracy: 0.7821\n",
            "186/469 [==========>...................] - ETA: 3:45 - loss: 0.7742 - sparse_categorical_accuracy: 0.7825\n",
            "187/469 [==========>...................] - ETA: 3:44 - loss: 0.7717 - sparse_categorical_accuracy: 0.7832\n",
            "188/469 [===========>..................] - ETA: 3:43 - loss: 0.7691 - sparse_categorical_accuracy: 0.7839\n",
            "189/469 [===========>..................] - ETA: 3:42 - loss: 0.7662 - sparse_categorical_accuracy: 0.7848\n",
            "190/469 [===========>..................] - ETA: 3:41 - loss: 0.7639 - sparse_categorical_accuracy: 0.7854\n",
            "191/469 [===========>..................] - ETA: 3:40 - loss: 0.7614 - sparse_categorical_accuracy: 0.7860\n",
            "192/469 [===========>..................] - ETA: 3:39 - loss: 0.7592 - sparse_categorical_accuracy: 0.7867\n",
            "193/469 [===========>..................] - ETA: 3:38 - loss: 0.7576 - sparse_categorical_accuracy: 0.7870\n",
            "194/469 [===========>..................] - ETA: 3:37 - loss: 0.7552 - sparse_categorical_accuracy: 0.7877\n",
            "195/469 [===========>..................] - ETA: 3:36 - loss: 0.7534 - sparse_categorical_accuracy: 0.7882\n",
            "196/469 [===========>..................] - ETA: 3:35 - loss: 0.7508 - sparse_categorical_accuracy: 0.7887\n",
            "197/469 [===========>..................] - ETA: 3:35 - loss: 0.7480 - sparse_categorical_accuracy: 0.7897\n",
            "198/469 [===========>..................] - ETA: 3:34 - loss: 0.7454 - sparse_categorical_accuracy: 0.7903\n",
            "199/469 [===========>..................] - ETA: 3:33 - loss: 0.7428 - sparse_categorical_accuracy: 0.7910\n",
            "200/469 [===========>..................] - ETA: 3:33 - loss: 0.7405 - sparse_categorical_accuracy: 0.7917\n",
            "201/469 [===========>..................] - ETA: 3:33 - loss: 0.7377 - sparse_categorical_accuracy: 0.7925\n",
            "202/469 [===========>..................] - ETA: 3:32 - loss: 0.7351 - sparse_categorical_accuracy: 0.7933\n",
            "203/469 [===========>..................] - ETA: 3:31 - loss: 0.7321 - sparse_categorical_accuracy: 0.7941\n",
            "204/469 [============>.................] - ETA: 3:30 - loss: 0.7297 - sparse_categorical_accuracy: 0.7949\n",
            "205/469 [============>.................] - ETA: 3:29 - loss: 0.7272 - sparse_categorical_accuracy: 0.7955\n",
            "206/469 [============>.................] - ETA: 3:28 - loss: 0.7248 - sparse_categorical_accuracy: 0.7962\n",
            "207/469 [============>.................] - ETA: 3:27 - loss: 0.7231 - sparse_categorical_accuracy: 0.7967\n",
            "208/469 [============>.................] - ETA: 3:26 - loss: 0.7206 - sparse_categorical_accuracy: 0.7975\n",
            "209/469 [============>.................] - ETA: 3:25 - loss: 0.7185 - sparse_categorical_accuracy: 0.7980\n",
            "210/469 [============>.................] - ETA: 3:25 - loss: 0.7160 - sparse_categorical_accuracy: 0.7988\n",
            "211/469 [============>.................] - ETA: 3:24 - loss: 0.7139 - sparse_categorical_accuracy: 0.7993\n",
            "212/469 [============>.................] - ETA: 3:23 - loss: 0.7112 - sparse_categorical_accuracy: 0.8001\n",
            "213/469 [============>.................] - ETA: 3:22 - loss: 0.7089 - sparse_categorical_accuracy: 0.8008\n",
            "214/469 [============>.................] - ETA: 3:21 - loss: 0.7069 - sparse_categorical_accuracy: 0.8013\n",
            "215/469 [============>.................] - ETA: 3:20 - loss: 0.7049 - sparse_categorical_accuracy: 0.8019\n",
            "216/469 [============>.................] - ETA: 3:19 - loss: 0.7030 - sparse_categorical_accuracy: 0.8024\n",
            "217/469 [============>.................] - ETA: 3:19 - loss: 0.7011 - sparse_categorical_accuracy: 0.8030\n",
            "218/469 [============>.................] - ETA: 3:18 - loss: 0.6985 - sparse_categorical_accuracy: 0.8036\n",
            "219/469 [=============>................] - ETA: 3:18 - loss: 0.6963 - sparse_categorical_accuracy: 0.8042\n",
            "220/469 [=============>................] - ETA: 3:17 - loss: 0.6940 - sparse_categorical_accuracy: 0.8048\n",
            "221/469 [=============>................] - ETA: 3:16 - loss: 0.6917 - sparse_categorical_accuracy: 0.8055\n",
            "222/469 [=============>................] - ETA: 3:15 - loss: 0.6896 - sparse_categorical_accuracy: 0.8060\n",
            "223/469 [=============>................] - ETA: 3:14 - loss: 0.6879 - sparse_categorical_accuracy: 0.8065\n",
            "224/469 [=============>................] - ETA: 3:13 - loss: 0.6857 - sparse_categorical_accuracy: 0.8071\n",
            "225/469 [=============>................] - ETA: 3:12 - loss: 0.6833 - sparse_categorical_accuracy: 0.8077\n",
            "226/469 [=============>................] - ETA: 3:12 - loss: 0.6813 - sparse_categorical_accuracy: 0.8082\n",
            "227/469 [=============>................] - ETA: 3:11 - loss: 0.6795 - sparse_categorical_accuracy: 0.8087\n",
            "228/469 [=============>................] - ETA: 3:10 - loss: 0.6773 - sparse_categorical_accuracy: 0.8093\n",
            "229/469 [=============>................] - ETA: 3:09 - loss: 0.6755 - sparse_categorical_accuracy: 0.8098\n",
            "230/469 [=============>................] - ETA: 3:08 - loss: 0.6734 - sparse_categorical_accuracy: 0.8104\n",
            "231/469 [=============>................] - ETA: 3:07 - loss: 0.6712 - sparse_categorical_accuracy: 0.8110\n",
            "232/469 [=============>................] - ETA: 3:06 - loss: 0.6691 - sparse_categorical_accuracy: 0.8116\n",
            "233/469 [=============>................] - ETA: 3:05 - loss: 0.6671 - sparse_categorical_accuracy: 0.8121\n",
            "234/469 [=============>................] - ETA: 3:05 - loss: 0.6652 - sparse_categorical_accuracy: 0.8127\n",
            "235/469 [==============>...............] - ETA: 3:04 - loss: 0.6633 - sparse_categorical_accuracy: 0.8132\n",
            "236/469 [==============>...............] - ETA: 3:04 - loss: 0.6613 - sparse_categorical_accuracy: 0.8138\n",
            "237/469 [==============>...............] - ETA: 3:03 - loss: 0.6597 - sparse_categorical_accuracy: 0.8141\n",
            "238/469 [==============>...............] - ETA: 3:02 - loss: 0.6576 - sparse_categorical_accuracy: 0.8147\n",
            "239/469 [==============>...............] - ETA: 3:01 - loss: 0.6553 - sparse_categorical_accuracy: 0.8153\n",
            "240/469 [==============>...............] - ETA: 3:01 - loss: 0.6536 - sparse_categorical_accuracy: 0.8158\n",
            "241/469 [==============>...............] - ETA: 3:00 - loss: 0.6515 - sparse_categorical_accuracy: 0.8163\n",
            "242/469 [==============>...............] - ETA: 2:59 - loss: 0.6493 - sparse_categorical_accuracy: 0.8169\n",
            "243/469 [==============>...............] - ETA: 2:58 - loss: 0.6476 - sparse_categorical_accuracy: 0.8173\n",
            "244/469 [==============>...............] - ETA: 2:57 - loss: 0.6456 - sparse_categorical_accuracy: 0.8178\n",
            "245/469 [==============>...............] - ETA: 2:56 - loss: 0.6440 - sparse_categorical_accuracy: 0.8182\n",
            "246/469 [==============>...............] - ETA: 2:55 - loss: 0.6421 - sparse_categorical_accuracy: 0.8188\n",
            "247/469 [==============>...............] - ETA: 2:54 - loss: 0.6407 - sparse_categorical_accuracy: 0.8192\n",
            "248/469 [==============>...............] - ETA: 2:54 - loss: 0.6386 - sparse_categorical_accuracy: 0.8197\n",
            "249/469 [==============>...............] - ETA: 2:53 - loss: 0.6366 - sparse_categorical_accuracy: 0.8203\n",
            "250/469 [==============>...............] - ETA: 2:52 - loss: 0.6349 - sparse_categorical_accuracy: 0.8208\n",
            "251/469 [===============>..............] - ETA: 2:51 - loss: 0.6330 - sparse_categorical_accuracy: 0.8213\n",
            "252/469 [===============>..............] - ETA: 2:51 - loss: 0.6313 - sparse_categorical_accuracy: 0.8217\n",
            "253/469 [===============>..............] - ETA: 2:50 - loss: 0.6298 - sparse_categorical_accuracy: 0.8220\n",
            "254/469 [===============>..............] - ETA: 2:50 - loss: 0.6280 - sparse_categorical_accuracy: 0.8225\n",
            "255/469 [===============>..............] - ETA: 2:49 - loss: 0.6263 - sparse_categorical_accuracy: 0.8229\n",
            "256/469 [===============>..............] - ETA: 2:48 - loss: 0.6248 - sparse_categorical_accuracy: 0.8233\n",
            "257/469 [===============>..............] - ETA: 2:47 - loss: 0.6229 - sparse_categorical_accuracy: 0.8238\n",
            "258/469 [===============>..............] - ETA: 2:46 - loss: 0.6211 - sparse_categorical_accuracy: 0.8244\n",
            "259/469 [===============>..............] - ETA: 2:45 - loss: 0.6195 - sparse_categorical_accuracy: 0.8249\n",
            "260/469 [===============>..............] - ETA: 2:44 - loss: 0.6178 - sparse_categorical_accuracy: 0.8253\n",
            "261/469 [===============>..............] - ETA: 2:43 - loss: 0.6163 - sparse_categorical_accuracy: 0.8257\n",
            "262/469 [===============>..............] - ETA: 2:42 - loss: 0.6147 - sparse_categorical_accuracy: 0.8262\n",
            "263/469 [===============>..............] - ETA: 2:42 - loss: 0.6128 - sparse_categorical_accuracy: 0.8268\n",
            "264/469 [===============>..............] - ETA: 2:41 - loss: 0.6115 - sparse_categorical_accuracy: 0.8270\n",
            "265/469 [===============>..............] - ETA: 2:40 - loss: 0.6097 - sparse_categorical_accuracy: 0.8275\n",
            "266/469 [================>.............] - ETA: 2:39 - loss: 0.6077 - sparse_categorical_accuracy: 0.8282\n",
            "267/469 [================>.............] - ETA: 2:38 - loss: 0.6059 - sparse_categorical_accuracy: 0.8287\n",
            "268/469 [================>.............] - ETA: 2:37 - loss: 0.6044 - sparse_categorical_accuracy: 0.8289\n",
            "269/469 [================>.............] - ETA: 2:37 - loss: 0.6027 - sparse_categorical_accuracy: 0.8294\n",
            "270/469 [================>.............] - ETA: 2:36 - loss: 0.6010 - sparse_categorical_accuracy: 0.8298\n",
            "271/469 [================>.............] - ETA: 2:35 - loss: 0.5992 - sparse_categorical_accuracy: 0.8303\n",
            "272/469 [================>.............] - ETA: 2:35 - loss: 0.5974 - sparse_categorical_accuracy: 0.8308\n",
            "273/469 [================>.............] - ETA: 2:34 - loss: 0.5959 - sparse_categorical_accuracy: 0.8312\n",
            "274/469 [================>.............] - ETA: 2:33 - loss: 0.5942 - sparse_categorical_accuracy: 0.8317\n",
            "275/469 [================>.............] - ETA: 2:32 - loss: 0.5927 - sparse_categorical_accuracy: 0.8321\n",
            "276/469 [================>.............] - ETA: 2:31 - loss: 0.5914 - sparse_categorical_accuracy: 0.8325\n",
            "277/469 [================>.............] - ETA: 2:31 - loss: 0.5898 - sparse_categorical_accuracy: 0.8330\n",
            "278/469 [================>.............] - ETA: 2:30 - loss: 0.5884 - sparse_categorical_accuracy: 0.8334\n",
            "279/469 [================>.............] - ETA: 2:29 - loss: 0.5868 - sparse_categorical_accuracy: 0.8339\n",
            "280/469 [================>.............] - ETA: 2:28 - loss: 0.5853 - sparse_categorical_accuracy: 0.8343\n",
            "281/469 [================>.............] - ETA: 2:27 - loss: 0.5842 - sparse_categorical_accuracy: 0.8345\n",
            "282/469 [=================>............] - ETA: 2:26 - loss: 0.5830 - sparse_categorical_accuracy: 0.8349\n",
            "283/469 [=================>............] - ETA: 2:25 - loss: 0.5815 - sparse_categorical_accuracy: 0.8354\n",
            "284/469 [=================>............] - ETA: 2:25 - loss: 0.5802 - sparse_categorical_accuracy: 0.8358\n",
            "285/469 [=================>............] - ETA: 2:24 - loss: 0.5785 - sparse_categorical_accuracy: 0.8363\n",
            "286/469 [=================>............] - ETA: 2:23 - loss: 0.5772 - sparse_categorical_accuracy: 0.8366\n",
            "287/469 [=================>............] - ETA: 2:22 - loss: 0.5758 - sparse_categorical_accuracy: 0.8369\n",
            "288/469 [=================>............] - ETA: 2:22 - loss: 0.5744 - sparse_categorical_accuracy: 0.8373\n",
            "289/469 [=================>............] - ETA: 2:21 - loss: 0.5729 - sparse_categorical_accuracy: 0.8378\n",
            "290/469 [=================>............] - ETA: 2:20 - loss: 0.5718 - sparse_categorical_accuracy: 0.8381\n",
            "291/469 [=================>............] - ETA: 2:20 - loss: 0.5706 - sparse_categorical_accuracy: 0.8384\n",
            "292/469 [=================>............] - ETA: 2:19 - loss: 0.5694 - sparse_categorical_accuracy: 0.8388\n",
            "293/469 [=================>............] - ETA: 2:18 - loss: 0.5679 - sparse_categorical_accuracy: 0.8391\n",
            "294/469 [=================>............] - ETA: 2:17 - loss: 0.5667 - sparse_categorical_accuracy: 0.8394\n",
            "295/469 [=================>............] - ETA: 2:16 - loss: 0.5652 - sparse_categorical_accuracy: 0.8399\n",
            "296/469 [=================>............] - ETA: 2:15 - loss: 0.5639 - sparse_categorical_accuracy: 0.8402\n",
            "297/469 [=================>............] - ETA: 2:15 - loss: 0.5628 - sparse_categorical_accuracy: 0.8406\n",
            "298/469 [==================>...........] - ETA: 2:14 - loss: 0.5617 - sparse_categorical_accuracy: 0.8408\n",
            "299/469 [==================>...........] - ETA: 2:13 - loss: 0.5604 - sparse_categorical_accuracy: 0.8412\n",
            "300/469 [==================>...........] - ETA: 2:12 - loss: 0.5593 - sparse_categorical_accuracy: 0.8416\n",
            "301/469 [==================>...........] - ETA: 2:11 - loss: 0.5580 - sparse_categorical_accuracy: 0.8419\n",
            "302/469 [==================>...........] - ETA: 2:10 - loss: 0.5568 - sparse_categorical_accuracy: 0.8422\n",
            "303/469 [==================>...........] - ETA: 2:10 - loss: 0.5555 - sparse_categorical_accuracy: 0.8425\n",
            "304/469 [==================>...........] - ETA: 2:09 - loss: 0.5544 - sparse_categorical_accuracy: 0.8429\n",
            "305/469 [==================>...........] - ETA: 2:08 - loss: 0.5531 - sparse_categorical_accuracy: 0.8432\n",
            "306/469 [==================>...........] - ETA: 2:08 - loss: 0.5518 - sparse_categorical_accuracy: 0.8435\n",
            "307/469 [==================>...........] - ETA: 2:07 - loss: 0.5506 - sparse_categorical_accuracy: 0.8438\n",
            "308/469 [==================>...........] - ETA: 2:06 - loss: 0.5492 - sparse_categorical_accuracy: 0.8442\n",
            "309/469 [==================>...........] - ETA: 2:05 - loss: 0.5482 - sparse_categorical_accuracy: 0.8444\n",
            "310/469 [==================>...........] - ETA: 2:04 - loss: 0.5469 - sparse_categorical_accuracy: 0.8448\n",
            "311/469 [==================>...........] - ETA: 2:04 - loss: 0.5457 - sparse_categorical_accuracy: 0.8452\n",
            "312/469 [==================>...........] - ETA: 2:03 - loss: 0.5448 - sparse_categorical_accuracy: 0.8455\n",
            "313/469 [===================>..........] - ETA: 2:02 - loss: 0.5436 - sparse_categorical_accuracy: 0.8458\n",
            "314/469 [===================>..........] - ETA: 2:01 - loss: 0.5426 - sparse_categorical_accuracy: 0.8461\n",
            "315/469 [===================>..........] - ETA: 2:00 - loss: 0.5417 - sparse_categorical_accuracy: 0.8463\n",
            "316/469 [===================>..........] - ETA: 1:59 - loss: 0.5405 - sparse_categorical_accuracy: 0.8467\n",
            "317/469 [===================>..........] - ETA: 1:59 - loss: 0.5397 - sparse_categorical_accuracy: 0.8469\n",
            "318/469 [===================>..........] - ETA: 1:58 - loss: 0.5387 - sparse_categorical_accuracy: 0.8472\n",
            "319/469 [===================>..........] - ETA: 1:57 - loss: 0.5376 - sparse_categorical_accuracy: 0.8475\n",
            "320/469 [===================>..........] - ETA: 1:56 - loss: 0.5366 - sparse_categorical_accuracy: 0.8479\n",
            "321/469 [===================>..........] - ETA: 1:55 - loss: 0.5351 - sparse_categorical_accuracy: 0.8483\n",
            "322/469 [===================>..........] - ETA: 1:55 - loss: 0.5340 - sparse_categorical_accuracy: 0.8486\n",
            "323/469 [===================>..........] - ETA: 1:54 - loss: 0.5329 - sparse_categorical_accuracy: 0.8489\n",
            "324/469 [===================>..........] - ETA: 1:53 - loss: 0.5317 - sparse_categorical_accuracy: 0.8492\n",
            "325/469 [===================>..........] - ETA: 1:53 - loss: 0.5309 - sparse_categorical_accuracy: 0.8494\n",
            "326/469 [===================>..........] - ETA: 1:52 - loss: 0.5297 - sparse_categorical_accuracy: 0.8497\n",
            "327/469 [===================>..........] - ETA: 1:51 - loss: 0.5284 - sparse_categorical_accuracy: 0.8501\n",
            "328/469 [===================>..........] - ETA: 1:50 - loss: 0.5274 - sparse_categorical_accuracy: 0.8504\n",
            "329/469 [====================>.........] - ETA: 1:49 - loss: 0.5262 - sparse_categorical_accuracy: 0.8507\n",
            "330/469 [====================>.........] - ETA: 1:49 - loss: 0.5251 - sparse_categorical_accuracy: 0.8510\n",
            "331/469 [====================>.........] - ETA: 1:48 - loss: 0.5240 - sparse_categorical_accuracy: 0.8513\n",
            "332/469 [====================>.........] - ETA: 1:47 - loss: 0.5229 - sparse_categorical_accuracy: 0.8517\n",
            "333/469 [====================>.........] - ETA: 1:46 - loss: 0.5217 - sparse_categorical_accuracy: 0.8521\n",
            "334/469 [====================>.........] - ETA: 1:45 - loss: 0.5203 - sparse_categorical_accuracy: 0.8525\n",
            "335/469 [====================>.........] - ETA: 1:44 - loss: 0.5195 - sparse_categorical_accuracy: 0.8528\n",
            "336/469 [====================>.........] - ETA: 1:44 - loss: 0.5185 - sparse_categorical_accuracy: 0.8531\n",
            "337/469 [====================>.........] - ETA: 1:43 - loss: 0.5175 - sparse_categorical_accuracy: 0.8533\n",
            "338/469 [====================>.........] - ETA: 1:42 - loss: 0.5166 - sparse_categorical_accuracy: 0.8536\n",
            "339/469 [====================>.........] - ETA: 1:41 - loss: 0.5154 - sparse_categorical_accuracy: 0.8539\n",
            "340/469 [====================>.........] - ETA: 1:41 - loss: 0.5143 - sparse_categorical_accuracy: 0.8543\n",
            "341/469 [====================>.........] - ETA: 1:40 - loss: 0.5133 - sparse_categorical_accuracy: 0.8546\n",
            "342/469 [====================>.........] - ETA: 1:39 - loss: 0.5120 - sparse_categorical_accuracy: 0.8549\n",
            "343/469 [====================>.........] - ETA: 1:38 - loss: 0.5111 - sparse_categorical_accuracy: 0.8552\n",
            "344/469 [=====================>........] - ETA: 1:38 - loss: 0.5101 - sparse_categorical_accuracy: 0.8555\n",
            "345/469 [=====================>........] - ETA: 1:37 - loss: 0.5092 - sparse_categorical_accuracy: 0.8557\n",
            "346/469 [=====================>........] - ETA: 1:36 - loss: 0.5081 - sparse_categorical_accuracy: 0.8560\n",
            "347/469 [=====================>........] - ETA: 1:35 - loss: 0.5070 - sparse_categorical_accuracy: 0.8563\n",
            "348/469 [=====================>........] - ETA: 1:34 - loss: 0.5061 - sparse_categorical_accuracy: 0.8566\n",
            "349/469 [=====================>........] - ETA: 1:34 - loss: 0.5049 - sparse_categorical_accuracy: 0.8569\n",
            "350/469 [=====================>........] - ETA: 1:33 - loss: 0.5041 - sparse_categorical_accuracy: 0.8571\n",
            "351/469 [=====================>........] - ETA: 1:32 - loss: 0.5030 - sparse_categorical_accuracy: 0.8574\n",
            "352/469 [=====================>........] - ETA: 1:31 - loss: 0.5025 - sparse_categorical_accuracy: 0.8576\n",
            "353/469 [=====================>........] - ETA: 1:30 - loss: 0.5018 - sparse_categorical_accuracy: 0.8578\n",
            "354/469 [=====================>........] - ETA: 1:30 - loss: 0.5009 - sparse_categorical_accuracy: 0.8580\n",
            "355/469 [=====================>........] - ETA: 1:29 - loss: 0.5002 - sparse_categorical_accuracy: 0.8583\n",
            "356/469 [=====================>........] - ETA: 1:28 - loss: 0.4993 - sparse_categorical_accuracy: 0.8585\n",
            "357/469 [=====================>........] - ETA: 1:27 - loss: 0.4983 - sparse_categorical_accuracy: 0.8588\n",
            "358/469 [=====================>........] - ETA: 1:27 - loss: 0.4976 - sparse_categorical_accuracy: 0.8590\n",
            "359/469 [=====================>........] - ETA: 1:26 - loss: 0.4967 - sparse_categorical_accuracy: 0.8592\n",
            "360/469 [======================>.......] - ETA: 1:25 - loss: 0.4964 - sparse_categorical_accuracy: 0.8594\n",
            "361/469 [======================>.......] - ETA: 1:24 - loss: 0.4952 - sparse_categorical_accuracy: 0.8597\n",
            "362/469 [======================>.......] - ETA: 1:23 - loss: 0.4943 - sparse_categorical_accuracy: 0.8600\n",
            "363/469 [======================>.......] - ETA: 1:23 - loss: 0.4932 - sparse_categorical_accuracy: 0.8603\n",
            "364/469 [======================>.......] - ETA: 1:22 - loss: 0.4924 - sparse_categorical_accuracy: 0.8605\n",
            "365/469 [======================>.......] - ETA: 1:21 - loss: 0.4914 - sparse_categorical_accuracy: 0.8608\n",
            "366/469 [======================>.......] - ETA: 1:20 - loss: 0.4905 - sparse_categorical_accuracy: 0.8610\n",
            "367/469 [======================>.......] - ETA: 1:19 - loss: 0.4895 - sparse_categorical_accuracy: 0.8612\n",
            "368/469 [======================>.......] - ETA: 1:19 - loss: 0.4885 - sparse_categorical_accuracy: 0.8615\n",
            "369/469 [======================>.......] - ETA: 1:18 - loss: 0.4876 - sparse_categorical_accuracy: 0.8618\n",
            "370/469 [======================>.......] - ETA: 1:17 - loss: 0.4868 - sparse_categorical_accuracy: 0.8620\n",
            "371/469 [======================>.......] - ETA: 1:16 - loss: 0.4860 - sparse_categorical_accuracy: 0.8623\n",
            "372/469 [======================>.......] - ETA: 1:15 - loss: 0.4851 - sparse_categorical_accuracy: 0.8625\n",
            "373/469 [======================>.......] - ETA: 1:15 - loss: 0.4842 - sparse_categorical_accuracy: 0.8627\n",
            "374/469 [======================>.......] - ETA: 1:14 - loss: 0.4831 - sparse_categorical_accuracy: 0.8631\n",
            "375/469 [======================>.......] - ETA: 1:13 - loss: 0.4822 - sparse_categorical_accuracy: 0.8633\n",
            "376/469 [=======================>......] - ETA: 1:12 - loss: 0.4815 - sparse_categorical_accuracy: 0.8635\n",
            "377/469 [=======================>......] - ETA: 1:12 - loss: 0.4806 - sparse_categorical_accuracy: 0.8637\n",
            "378/469 [=======================>......] - ETA: 1:11 - loss: 0.4797 - sparse_categorical_accuracy: 0.8640\n",
            "379/469 [=======================>......] - ETA: 1:10 - loss: 0.4789 - sparse_categorical_accuracy: 0.8642\n",
            "380/469 [=======================>......] - ETA: 1:09 - loss: 0.4780 - sparse_categorical_accuracy: 0.8644\n",
            "381/469 [=======================>......] - ETA: 1:08 - loss: 0.4776 - sparse_categorical_accuracy: 0.8646\n",
            "382/469 [=======================>......] - ETA: 1:08 - loss: 0.4769 - sparse_categorical_accuracy: 0.8647\n",
            "383/469 [=======================>......] - ETA: 1:07 - loss: 0.4761 - sparse_categorical_accuracy: 0.8650\n",
            "384/469 [=======================>......] - ETA: 1:06 - loss: 0.4752 - sparse_categorical_accuracy: 0.8652\n",
            "385/469 [=======================>......] - ETA: 1:05 - loss: 0.4745 - sparse_categorical_accuracy: 0.8653\n",
            "386/469 [=======================>......] - ETA: 1:04 - loss: 0.4736 - sparse_categorical_accuracy: 0.8656\n",
            "387/469 [=======================>......] - ETA: 1:04 - loss: 0.4728 - sparse_categorical_accuracy: 0.8658\n",
            "388/469 [=======================>......] - ETA: 1:03 - loss: 0.4720 - sparse_categorical_accuracy: 0.8661\n",
            "389/469 [=======================>......] - ETA: 1:02 - loss: 0.4713 - sparse_categorical_accuracy: 0.8663\n",
            "390/469 [=======================>......] - ETA: 1:01 - loss: 0.4703 - sparse_categorical_accuracy: 0.8665\n",
            "391/469 [========================>.....] - ETA: 1:00 - loss: 0.4694 - sparse_categorical_accuracy: 0.8668\n",
            "392/469 [========================>.....] - ETA: 1:00 - loss: 0.4685 - sparse_categorical_accuracy: 0.8671\n",
            "393/469 [========================>.....] - ETA: 59s - loss: 0.4676 - sparse_categorical_accuracy: 0.8673 \n",
            "394/469 [========================>.....] - ETA: 58s - loss: 0.4669 - sparse_categorical_accuracy: 0.8675\n",
            "395/469 [========================>.....] - ETA: 58s - loss: 0.4663 - sparse_categorical_accuracy: 0.8677\n",
            "396/469 [========================>.....] - ETA: 57s - loss: 0.4655 - sparse_categorical_accuracy: 0.8679\n",
            "397/469 [========================>.....] - ETA: 56s - loss: 0.4645 - sparse_categorical_accuracy: 0.8682\n",
            "398/469 [========================>.....] - ETA: 55s - loss: 0.4637 - sparse_categorical_accuracy: 0.8685\n",
            "399/469 [========================>.....] - ETA: 54s - loss: 0.4630 - sparse_categorical_accuracy: 0.8686\n",
            "400/469 [========================>.....] - ETA: 54s - loss: 0.4621 - sparse_categorical_accuracy: 0.8688\n",
            "401/469 [========================>.....] - ETA: 53s - loss: 0.4613 - sparse_categorical_accuracy: 0.8691\n",
            "402/469 [========================>.....] - ETA: 52s - loss: 0.4605 - sparse_categorical_accuracy: 0.8693\n",
            "403/469 [========================>.....] - ETA: 51s - loss: 0.4599 - sparse_categorical_accuracy: 0.8695\n",
            "404/469 [========================>.....] - ETA: 50s - loss: 0.4591 - sparse_categorical_accuracy: 0.8697\n",
            "405/469 [========================>.....] - ETA: 50s - loss: 0.4583 - sparse_categorical_accuracy: 0.8699\n",
            "406/469 [========================>.....] - ETA: 49s - loss: 0.4574 - sparse_categorical_accuracy: 0.8702\n",
            "407/469 [=========================>....] - ETA: 48s - loss: 0.4567 - sparse_categorical_accuracy: 0.8703\n",
            "408/469 [=========================>....] - ETA: 47s - loss: 0.4560 - sparse_categorical_accuracy: 0.8705\n",
            "409/469 [=========================>....] - ETA: 46s - loss: 0.4553 - sparse_categorical_accuracy: 0.8708\n",
            "410/469 [=========================>....] - ETA: 46s - loss: 0.4544 - sparse_categorical_accuracy: 0.8710\n",
            "411/469 [=========================>....] - ETA: 45s - loss: 0.4536 - sparse_categorical_accuracy: 0.8713\n",
            "412/469 [=========================>....] - ETA: 44s - loss: 0.4532 - sparse_categorical_accuracy: 0.8714\n",
            "413/469 [=========================>....] - ETA: 43s - loss: 0.4525 - sparse_categorical_accuracy: 0.8716\n",
            "414/469 [=========================>....] - ETA: 43s - loss: 0.4516 - sparse_categorical_accuracy: 0.8718\n",
            "415/469 [=========================>....] - ETA: 42s - loss: 0.4508 - sparse_categorical_accuracy: 0.8721\n",
            "416/469 [=========================>....] - ETA: 41s - loss: 0.4500 - sparse_categorical_accuracy: 0.8723\n",
            "417/469 [=========================>....] - ETA: 40s - loss: 0.4492 - sparse_categorical_accuracy: 0.8726\n",
            "418/469 [=========================>....] - ETA: 39s - loss: 0.4484 - sparse_categorical_accuracy: 0.8728\n",
            "419/469 [=========================>....] - ETA: 39s - loss: 0.4478 - sparse_categorical_accuracy: 0.8729\n",
            "420/469 [=========================>....] - ETA: 38s - loss: 0.4469 - sparse_categorical_accuracy: 0.8732\n",
            "421/469 [=========================>....] - ETA: 37s - loss: 0.4462 - sparse_categorical_accuracy: 0.8734\n",
            "422/469 [=========================>....] - ETA: 36s - loss: 0.4455 - sparse_categorical_accuracy: 0.8736\n",
            "423/469 [==========================>...] - ETA: 35s - loss: 0.4447 - sparse_categorical_accuracy: 0.8738\n",
            "424/469 [==========================>...] - ETA: 35s - loss: 0.4439 - sparse_categorical_accuracy: 0.8739\n",
            "425/469 [==========================>...] - ETA: 34s - loss: 0.4431 - sparse_categorical_accuracy: 0.8742\n",
            "426/469 [==========================>...] - ETA: 33s - loss: 0.4423 - sparse_categorical_accuracy: 0.8744\n",
            "427/469 [==========================>...] - ETA: 32s - loss: 0.4416 - sparse_categorical_accuracy: 0.8746\n",
            "428/469 [==========================>...] - ETA: 32s - loss: 0.4408 - sparse_categorical_accuracy: 0.8748\n",
            "429/469 [==========================>...] - ETA: 31s - loss: 0.4399 - sparse_categorical_accuracy: 0.8751\n",
            "430/469 [==========================>...] - ETA: 30s - loss: 0.4390 - sparse_categorical_accuracy: 0.8754\n",
            "431/469 [==========================>...] - ETA: 29s - loss: 0.4383 - sparse_categorical_accuracy: 0.8755\n",
            "432/469 [==========================>...] - ETA: 28s - loss: 0.4375 - sparse_categorical_accuracy: 0.8757\n",
            "433/469 [==========================>...] - ETA: 28s - loss: 0.4367 - sparse_categorical_accuracy: 0.8760\n",
            "434/469 [==========================>...] - ETA: 27s - loss: 0.4359 - sparse_categorical_accuracy: 0.8762\n",
            "435/469 [==========================>...] - ETA: 26s - loss: 0.4352 - sparse_categorical_accuracy: 0.8764\n",
            "436/469 [==========================>...] - ETA: 25s - loss: 0.4346 - sparse_categorical_accuracy: 0.8766\n",
            "437/469 [==========================>...] - ETA: 25s - loss: 0.4339 - sparse_categorical_accuracy: 0.8768\n",
            "438/469 [===========================>..] - ETA: 24s - loss: 0.4332 - sparse_categorical_accuracy: 0.8770\n",
            "439/469 [===========================>..] - ETA: 23s - loss: 0.4324 - sparse_categorical_accuracy: 0.8772\n",
            "440/469 [===========================>..] - ETA: 22s - loss: 0.4316 - sparse_categorical_accuracy: 0.8774\n",
            "441/469 [===========================>..] - ETA: 21s - loss: 0.4308 - sparse_categorical_accuracy: 0.8776\n",
            "442/469 [===========================>..] - ETA: 21s - loss: 0.4303 - sparse_categorical_accuracy: 0.8778\n",
            "443/469 [===========================>..] - ETA: 20s - loss: 0.4298 - sparse_categorical_accuracy: 0.8779\n",
            "444/469 [===========================>..] - ETA: 19s - loss: 0.4292 - sparse_categorical_accuracy: 0.8780\n",
            "445/469 [===========================>..] - ETA: 18s - loss: 0.4285 - sparse_categorical_accuracy: 0.8782\n",
            "446/469 [===========================>..] - ETA: 18s - loss: 0.4280 - sparse_categorical_accuracy: 0.8784\n",
            "447/469 [===========================>..] - ETA: 17s - loss: 0.4274 - sparse_categorical_accuracy: 0.8785\n",
            "448/469 [===========================>..] - ETA: 16s - loss: 0.4269 - sparse_categorical_accuracy: 0.8787\n",
            "449/469 [===========================>..] - ETA: 15s - loss: 0.4261 - sparse_categorical_accuracy: 0.8789\n",
            "450/469 [===========================>..] - ETA: 14s - loss: 0.4255 - sparse_categorical_accuracy: 0.8791\n",
            "451/469 [===========================>..] - ETA: 14s - loss: 0.4248 - sparse_categorical_accuracy: 0.8793\n",
            "452/469 [===========================>..] - ETA: 13s - loss: 0.4241 - sparse_categorical_accuracy: 0.8795\n",
            "453/469 [===========================>..] - ETA: 12s - loss: 0.4235 - sparse_categorical_accuracy: 0.8796\n",
            "454/469 [============================>.] - ETA: 11s - loss: 0.4228 - sparse_categorical_accuracy: 0.8798\n",
            "455/469 [============================>.] - ETA: 10s - loss: 0.4223 - sparse_categorical_accuracy: 0.8799\n",
            "456/469 [============================>.] - ETA: 10s - loss: 0.4217 - sparse_categorical_accuracy: 0.8801\n",
            "457/469 [============================>.] - ETA: 9s - loss: 0.4210 - sparse_categorical_accuracy: 0.8804 \n",
            "458/469 [============================>.] - ETA: 8s - loss: 0.4205 - sparse_categorical_accuracy: 0.8805\n",
            "459/469 [============================>.] - ETA: 7s - loss: 0.4199 - sparse_categorical_accuracy: 0.8807\n",
            "460/469 [============================>.] - ETA: 7s - loss: 0.4192 - sparse_categorical_accuracy: 0.8808\n",
            "461/469 [============================>.] - ETA: 6s - loss: 0.4186 - sparse_categorical_accuracy: 0.8810\n",
            "462/469 [============================>.] - ETA: 5s - loss: 0.4180 - sparse_categorical_accuracy: 0.8812\n",
            "463/469 [============================>.] - ETA: 4s - loss: 0.4174 - sparse_categorical_accuracy: 0.8814\n",
            "464/469 [============================>.] - ETA: 3s - loss: 0.4167 - sparse_categorical_accuracy: 0.8816\n",
            "465/469 [============================>.] - ETA: 3s - loss: 0.4161 - sparse_categorical_accuracy: 0.8818\n",
            "466/469 [============================>.] - ETA: 2s - loss: 0.4154 - sparse_categorical_accuracy: 0.8819\n",
            "467/469 [============================>.] - ETA: 1s - loss: 0.4147 - sparse_categorical_accuracy: 0.8821\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.4140 - sparse_categorical_accuracy: 0.8823\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.4135 - sparse_categorical_accuracy: 0.8824\n",
            "  0%|          | 0/5 [06:08<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/04/16 00:38:09 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 368s 782ms/step - loss: 0.4135 - sparse_categorical_accuracy: 0.8824\n",
            "\n",
            "Epoch 2/5\n",
            "\n",
            "  1/469 [..............................] - ETA: 5:37 - loss: 0.2241 - sparse_categorical_accuracy: 0.9219\n",
            "  2/469 [..............................] - ETA: 5:30 - loss: 0.1478 - sparse_categorical_accuracy: 0.9453\n",
            "  3/469 [..............................] - ETA: 5:28 - loss: 0.1322 - sparse_categorical_accuracy: 0.9557\n",
            "  4/469 [..............................] - ETA: 5:24 - loss: 0.1233 - sparse_categorical_accuracy: 0.9609\n",
            "  5/469 [..............................] - ETA: 5:20 - loss: 0.1255 - sparse_categorical_accuracy: 0.9594\n",
            "  6/469 [..............................] - ETA: 5:19 - loss: 0.1186 - sparse_categorical_accuracy: 0.9622\n",
            "  7/469 [..............................] - ETA: 5:20 - loss: 0.1140 - sparse_categorical_accuracy: 0.9654\n",
            "  8/469 [..............................] - ETA: 5:18 - loss: 0.1254 - sparse_categorical_accuracy: 0.9619\n",
            "  9/469 [..............................] - ETA: 5:17 - loss: 0.1291 - sparse_categorical_accuracy: 0.9609\n",
            " 10/469 [..............................] - ETA: 5:32 - loss: 0.1245 - sparse_categorical_accuracy: 0.9625\n",
            " 11/469 [..............................] - ETA: 5:49 - loss: 0.1293 - sparse_categorical_accuracy: 0.9616\n",
            " 12/469 [..............................] - ETA: 5:57 - loss: 0.1229 - sparse_categorical_accuracy: 0.9642\n",
            " 13/469 [..............................] - ETA: 6:01 - loss: 0.1249 - sparse_categorical_accuracy: 0.9639\n",
            " 14/469 [..............................] - ETA: 5:56 - loss: 0.1197 - sparse_categorical_accuracy: 0.9654\n",
            " 15/469 [..............................] - ETA: 5:52 - loss: 0.1223 - sparse_categorical_accuracy: 0.9641\n",
            " 16/469 [>.............................] - ETA: 5:49 - loss: 0.1200 - sparse_categorical_accuracy: 0.9644\n",
            " 17/469 [>.............................] - ETA: 5:45 - loss: 0.1186 - sparse_categorical_accuracy: 0.9651\n",
            " 18/469 [>.............................] - ETA: 5:42 - loss: 0.1181 - sparse_categorical_accuracy: 0.9648\n",
            " 19/469 [>.............................] - ETA: 5:40 - loss: 0.1162 - sparse_categorical_accuracy: 0.9650\n",
            " 20/469 [>.............................] - ETA: 5:37 - loss: 0.1157 - sparse_categorical_accuracy: 0.9656\n",
            " 21/469 [>.............................] - ETA: 5:35 - loss: 0.1129 - sparse_categorical_accuracy: 0.9665\n",
            " 22/469 [>.............................] - ETA: 5:32 - loss: 0.1146 - sparse_categorical_accuracy: 0.9663\n",
            " 23/469 [>.............................] - ETA: 5:30 - loss: 0.1126 - sparse_categorical_accuracy: 0.9671\n",
            " 24/469 [>.............................] - ETA: 5:28 - loss: 0.1156 - sparse_categorical_accuracy: 0.9655\n",
            " 25/469 [>.............................] - ETA: 5:27 - loss: 0.1170 - sparse_categorical_accuracy: 0.9644\n",
            " 26/469 [>.............................] - ETA: 5:25 - loss: 0.1176 - sparse_categorical_accuracy: 0.9633\n",
            " 27/469 [>.............................] - ETA: 5:23 - loss: 0.1207 - sparse_categorical_accuracy: 0.9621\n",
            " 28/469 [>.............................] - ETA: 5:28 - loss: 0.1195 - sparse_categorical_accuracy: 0.9621\n",
            " 29/469 [>.............................] - ETA: 5:34 - loss: 0.1204 - sparse_categorical_accuracy: 0.9612\n",
            " 30/469 [>.............................] - ETA: 5:38 - loss: 0.1194 - sparse_categorical_accuracy: 0.9617\n",
            " 31/469 [>.............................] - ETA: 5:36 - loss: 0.1177 - sparse_categorical_accuracy: 0.9624\n",
            " 32/469 [=>............................] - ETA: 5:34 - loss: 0.1193 - sparse_categorical_accuracy: 0.9617\n",
            " 33/469 [=>............................] - ETA: 5:32 - loss: 0.1187 - sparse_categorical_accuracy: 0.9624\n",
            " 34/469 [=>............................] - ETA: 5:30 - loss: 0.1195 - sparse_categorical_accuracy: 0.9621\n",
            " 35/469 [=>............................] - ETA: 5:28 - loss: 0.1195 - sparse_categorical_accuracy: 0.9625\n",
            " 36/469 [=>............................] - ETA: 5:26 - loss: 0.1175 - sparse_categorical_accuracy: 0.9635\n",
            " 37/469 [=>............................] - ETA: 5:24 - loss: 0.1186 - sparse_categorical_accuracy: 0.9637\n",
            " 38/469 [=>............................] - ETA: 5:22 - loss: 0.1194 - sparse_categorical_accuracy: 0.9634\n",
            " 39/469 [=>............................] - ETA: 5:21 - loss: 0.1201 - sparse_categorical_accuracy: 0.9627\n",
            " 40/469 [=>............................] - ETA: 5:20 - loss: 0.1213 - sparse_categorical_accuracy: 0.9623\n",
            " 41/469 [=>............................] - ETA: 5:18 - loss: 0.1219 - sparse_categorical_accuracy: 0.9619\n",
            " 42/469 [=>............................] - ETA: 5:17 - loss: 0.1230 - sparse_categorical_accuracy: 0.9615\n",
            " 43/469 [=>............................] - ETA: 5:16 - loss: 0.1220 - sparse_categorical_accuracy: 0.9617\n",
            " 44/469 [=>............................] - ETA: 5:15 - loss: 0.1228 - sparse_categorical_accuracy: 0.9615\n",
            " 45/469 [=>............................] - ETA: 5:14 - loss: 0.1219 - sparse_categorical_accuracy: 0.9622\n",
            " 46/469 [=>............................] - ETA: 5:17 - loss: 0.1205 - sparse_categorical_accuracy: 0.9628\n",
            " 47/469 [==>...........................] - ETA: 5:20 - loss: 0.1192 - sparse_categorical_accuracy: 0.9633\n",
            " 48/469 [==>...........................] - ETA: 5:22 - loss: 0.1189 - sparse_categorical_accuracy: 0.9634\n",
            " 49/469 [==>...........................] - ETA: 5:20 - loss: 0.1193 - sparse_categorical_accuracy: 0.9633\n",
            " 50/469 [==>...........................] - ETA: 5:19 - loss: 0.1186 - sparse_categorical_accuracy: 0.9634\n",
            " 51/469 [==>...........................] - ETA: 5:18 - loss: 0.1177 - sparse_categorical_accuracy: 0.9637\n",
            " 52/469 [==>...........................] - ETA: 5:17 - loss: 0.1168 - sparse_categorical_accuracy: 0.9639\n",
            " 53/469 [==>...........................] - ETA: 5:15 - loss: 0.1164 - sparse_categorical_accuracy: 0.9640\n",
            " 54/469 [==>...........................] - ETA: 5:14 - loss: 0.1158 - sparse_categorical_accuracy: 0.9643\n",
            " 55/469 [==>...........................] - ETA: 5:13 - loss: 0.1163 - sparse_categorical_accuracy: 0.9642\n",
            " 56/469 [==>...........................] - ETA: 5:11 - loss: 0.1167 - sparse_categorical_accuracy: 0.9641\n",
            " 57/469 [==>...........................] - ETA: 5:10 - loss: 0.1174 - sparse_categorical_accuracy: 0.9640\n",
            " 58/469 [==>...........................] - ETA: 5:09 - loss: 0.1168 - sparse_categorical_accuracy: 0.9639\n",
            " 59/469 [==>...........................] - ETA: 5:08 - loss: 0.1170 - sparse_categorical_accuracy: 0.9641\n",
            " 60/469 [==>...........................] - ETA: 5:07 - loss: 0.1165 - sparse_categorical_accuracy: 0.9643\n",
            " 61/469 [==>...........................] - ETA: 5:06 - loss: 0.1167 - sparse_categorical_accuracy: 0.9643\n",
            " 62/469 [==>...........................] - ETA: 5:04 - loss: 0.1166 - sparse_categorical_accuracy: 0.9643\n",
            " 63/469 [===>..........................] - ETA: 5:04 - loss: 0.1160 - sparse_categorical_accuracy: 0.9644\n",
            " 64/469 [===>..........................] - ETA: 5:07 - loss: 0.1158 - sparse_categorical_accuracy: 0.9645\n",
            " 65/469 [===>..........................] - ETA: 5:08 - loss: 0.1157 - sparse_categorical_accuracy: 0.9644\n",
            " 66/469 [===>..........................] - ETA: 5:08 - loss: 0.1153 - sparse_categorical_accuracy: 0.9646\n",
            " 67/469 [===>..........................] - ETA: 5:07 - loss: 0.1158 - sparse_categorical_accuracy: 0.9646\n",
            " 68/469 [===>..........................] - ETA: 5:05 - loss: 0.1152 - sparse_categorical_accuracy: 0.9650\n",
            " 69/469 [===>..........................] - ETA: 5:04 - loss: 0.1178 - sparse_categorical_accuracy: 0.9642\n",
            " 70/469 [===>..........................] - ETA: 5:03 - loss: 0.1181 - sparse_categorical_accuracy: 0.9642\n",
            " 71/469 [===>..........................] - ETA: 5:02 - loss: 0.1183 - sparse_categorical_accuracy: 0.9641\n",
            " 72/469 [===>..........................] - ETA: 5:01 - loss: 0.1181 - sparse_categorical_accuracy: 0.9641\n",
            " 73/469 [===>..........................] - ETA: 4:59 - loss: 0.1176 - sparse_categorical_accuracy: 0.9643\n",
            " 74/469 [===>..........................] - ETA: 4:58 - loss: 0.1196 - sparse_categorical_accuracy: 0.9640\n",
            " 75/469 [===>..........................] - ETA: 4:57 - loss: 0.1202 - sparse_categorical_accuracy: 0.9634\n",
            " 76/469 [===>..........................] - ETA: 4:56 - loss: 0.1201 - sparse_categorical_accuracy: 0.9635\n",
            " 77/469 [===>..........................] - ETA: 4:55 - loss: 0.1201 - sparse_categorical_accuracy: 0.9635\n",
            " 78/469 [===>..........................] - ETA: 4:54 - loss: 0.1194 - sparse_categorical_accuracy: 0.9637\n",
            " 79/469 [====>.........................] - ETA: 4:54 - loss: 0.1206 - sparse_categorical_accuracy: 0.9635\n",
            " 80/469 [====>.........................] - ETA: 4:53 - loss: 0.1205 - sparse_categorical_accuracy: 0.9635\n",
            " 81/469 [====>.........................] - ETA: 4:55 - loss: 0.1207 - sparse_categorical_accuracy: 0.9636\n",
            " 82/469 [====>.........................] - ETA: 4:56 - loss: 0.1204 - sparse_categorical_accuracy: 0.9638\n",
            " 83/469 [====>.........................] - ETA: 4:56 - loss: 0.1200 - sparse_categorical_accuracy: 0.9639\n",
            " 84/469 [====>.........................] - ETA: 4:56 - loss: 0.1209 - sparse_categorical_accuracy: 0.9637\n",
            " 85/469 [====>.........................] - ETA: 4:55 - loss: 0.1213 - sparse_categorical_accuracy: 0.9635\n",
            " 86/469 [====>.........................] - ETA: 4:54 - loss: 0.1208 - sparse_categorical_accuracy: 0.9636\n",
            " 87/469 [====>.........................] - ETA: 4:53 - loss: 0.1214 - sparse_categorical_accuracy: 0.9635\n",
            " 88/469 [====>.........................] - ETA: 4:52 - loss: 0.1208 - sparse_categorical_accuracy: 0.9638\n",
            " 89/469 [====>.........................] - ETA: 4:51 - loss: 0.1228 - sparse_categorical_accuracy: 0.9631\n",
            " 90/469 [====>.........................] - ETA: 4:50 - loss: 0.1231 - sparse_categorical_accuracy: 0.9628\n",
            " 91/469 [====>.........................] - ETA: 4:49 - loss: 0.1232 - sparse_categorical_accuracy: 0.9627\n",
            " 92/469 [====>.........................] - ETA: 4:48 - loss: 0.1231 - sparse_categorical_accuracy: 0.9628\n",
            " 93/469 [====>.........................] - ETA: 4:47 - loss: 0.1245 - sparse_categorical_accuracy: 0.9624\n",
            " 94/469 [=====>........................] - ETA: 4:46 - loss: 0.1242 - sparse_categorical_accuracy: 0.9626\n",
            " 95/469 [=====>........................] - ETA: 4:45 - loss: 0.1237 - sparse_categorical_accuracy: 0.9628\n",
            " 96/469 [=====>........................] - ETA: 4:44 - loss: 0.1231 - sparse_categorical_accuracy: 0.9631\n",
            " 97/469 [=====>........................] - ETA: 4:44 - loss: 0.1228 - sparse_categorical_accuracy: 0.9631\n",
            " 98/469 [=====>........................] - ETA: 4:45 - loss: 0.1222 - sparse_categorical_accuracy: 0.9633\n",
            " 99/469 [=====>........................] - ETA: 4:46 - loss: 0.1225 - sparse_categorical_accuracy: 0.9633\n",
            "100/469 [=====>........................] - ETA: 4:46 - loss: 0.1223 - sparse_categorical_accuracy: 0.9634\n",
            "101/469 [=====>........................] - ETA: 4:45 - loss: 0.1222 - sparse_categorical_accuracy: 0.9635\n",
            "102/469 [=====>........................] - ETA: 4:43 - loss: 0.1225 - sparse_categorical_accuracy: 0.9634\n",
            "103/469 [=====>........................] - ETA: 4:42 - loss: 0.1220 - sparse_categorical_accuracy: 0.9636\n",
            "104/469 [=====>........................] - ETA: 4:41 - loss: 0.1222 - sparse_categorical_accuracy: 0.9635\n",
            "105/469 [=====>........................] - ETA: 4:41 - loss: 0.1219 - sparse_categorical_accuracy: 0.9635\n",
            "106/469 [=====>........................] - ETA: 4:40 - loss: 0.1217 - sparse_categorical_accuracy: 0.9637\n",
            "107/469 [=====>........................] - ETA: 4:39 - loss: 0.1224 - sparse_categorical_accuracy: 0.9634\n",
            "108/469 [=====>........................] - ETA: 4:38 - loss: 0.1223 - sparse_categorical_accuracy: 0.9634\n",
            "109/469 [=====>........................] - ETA: 4:37 - loss: 0.1218 - sparse_categorical_accuracy: 0.9635\n",
            "110/469 [======>.......................] - ETA: 4:36 - loss: 0.1222 - sparse_categorical_accuracy: 0.9632\n",
            "111/469 [======>.......................] - ETA: 4:35 - loss: 0.1226 - sparse_categorical_accuracy: 0.9630\n",
            "112/469 [======>.......................] - ETA: 4:34 - loss: 0.1233 - sparse_categorical_accuracy: 0.9629\n",
            "113/469 [======>.......................] - ETA: 4:33 - loss: 0.1230 - sparse_categorical_accuracy: 0.9631\n",
            "114/469 [======>.......................] - ETA: 4:32 - loss: 0.1226 - sparse_categorical_accuracy: 0.9632\n",
            "115/469 [======>.......................] - ETA: 4:33 - loss: 0.1228 - sparse_categorical_accuracy: 0.9632\n",
            "116/469 [======>.......................] - ETA: 4:33 - loss: 0.1227 - sparse_categorical_accuracy: 0.9633\n",
            "117/469 [======>.......................] - ETA: 4:34 - loss: 0.1228 - sparse_categorical_accuracy: 0.9633\n",
            "118/469 [======>.......................] - ETA: 4:33 - loss: 0.1231 - sparse_categorical_accuracy: 0.9632\n",
            "119/469 [======>.......................] - ETA: 4:32 - loss: 0.1238 - sparse_categorical_accuracy: 0.9630\n",
            "120/469 [======>.......................] - ETA: 4:31 - loss: 0.1235 - sparse_categorical_accuracy: 0.9630\n",
            "121/469 [======>.......................] - ETA: 4:30 - loss: 0.1238 - sparse_categorical_accuracy: 0.9629\n",
            "122/469 [======>.......................] - ETA: 4:29 - loss: 0.1241 - sparse_categorical_accuracy: 0.9627\n",
            "123/469 [======>.......................] - ETA: 4:28 - loss: 0.1236 - sparse_categorical_accuracy: 0.9628\n",
            "124/469 [======>.......................] - ETA: 4:28 - loss: 0.1239 - sparse_categorical_accuracy: 0.9628\n",
            "125/469 [======>.......................] - ETA: 4:27 - loss: 0.1237 - sparse_categorical_accuracy: 0.9629\n",
            "126/469 [=======>......................] - ETA: 4:26 - loss: 0.1237 - sparse_categorical_accuracy: 0.9627\n",
            "127/469 [=======>......................] - ETA: 4:25 - loss: 0.1234 - sparse_categorical_accuracy: 0.9628\n",
            "128/469 [=======>......................] - ETA: 4:24 - loss: 0.1235 - sparse_categorical_accuracy: 0.9626\n",
            "129/469 [=======>......................] - ETA: 4:23 - loss: 0.1239 - sparse_categorical_accuracy: 0.9625\n",
            "130/469 [=======>......................] - ETA: 4:23 - loss: 0.1238 - sparse_categorical_accuracy: 0.9626\n",
            "131/469 [=======>......................] - ETA: 4:23 - loss: 0.1235 - sparse_categorical_accuracy: 0.9627\n",
            "132/469 [=======>......................] - ETA: 4:23 - loss: 0.1233 - sparse_categorical_accuracy: 0.9628\n",
            "133/469 [=======>......................] - ETA: 4:23 - loss: 0.1241 - sparse_categorical_accuracy: 0.9627\n",
            "134/469 [=======>......................] - ETA: 4:23 - loss: 0.1242 - sparse_categorical_accuracy: 0.9627\n",
            "135/469 [=======>......................] - ETA: 4:22 - loss: 0.1243 - sparse_categorical_accuracy: 0.9626\n",
            "136/469 [=======>......................] - ETA: 4:21 - loss: 0.1240 - sparse_categorical_accuracy: 0.9626\n",
            "137/469 [=======>......................] - ETA: 4:20 - loss: 0.1240 - sparse_categorical_accuracy: 0.9626\n",
            "138/469 [=======>......................] - ETA: 4:19 - loss: 0.1246 - sparse_categorical_accuracy: 0.9625\n",
            "139/469 [=======>......................] - ETA: 4:18 - loss: 0.1246 - sparse_categorical_accuracy: 0.9623\n",
            "140/469 [=======>......................] - ETA: 4:17 - loss: 0.1244 - sparse_categorical_accuracy: 0.9624\n",
            "141/469 [========>.....................] - ETA: 4:16 - loss: 0.1250 - sparse_categorical_accuracy: 0.9623\n",
            "142/469 [========>.....................] - ETA: 4:15 - loss: 0.1249 - sparse_categorical_accuracy: 0.9624\n",
            "143/469 [========>.....................] - ETA: 4:14 - loss: 0.1250 - sparse_categorical_accuracy: 0.9624\n",
            "144/469 [========>.....................] - ETA: 4:13 - loss: 0.1245 - sparse_categorical_accuracy: 0.9626\n",
            "145/469 [========>.....................] - ETA: 4:12 - loss: 0.1241 - sparse_categorical_accuracy: 0.9627\n",
            "146/469 [========>.....................] - ETA: 4:11 - loss: 0.1238 - sparse_categorical_accuracy: 0.9627\n",
            "147/469 [========>.....................] - ETA: 4:10 - loss: 0.1237 - sparse_categorical_accuracy: 0.9626\n",
            "148/469 [========>.....................] - ETA: 4:10 - loss: 0.1235 - sparse_categorical_accuracy: 0.9627\n",
            "149/469 [========>.....................] - ETA: 4:09 - loss: 0.1239 - sparse_categorical_accuracy: 0.9627\n",
            "150/469 [========>.....................] - ETA: 4:09 - loss: 0.1235 - sparse_categorical_accuracy: 0.9628\n",
            "151/469 [========>.....................] - ETA: 4:09 - loss: 0.1237 - sparse_categorical_accuracy: 0.9627\n",
            "152/469 [========>.....................] - ETA: 4:08 - loss: 0.1237 - sparse_categorical_accuracy: 0.9627\n",
            "153/469 [========>.....................] - ETA: 4:07 - loss: 0.1235 - sparse_categorical_accuracy: 0.9628\n",
            "154/469 [========>.....................] - ETA: 4:06 - loss: 0.1240 - sparse_categorical_accuracy: 0.9625\n",
            "155/469 [========>.....................] - ETA: 4:05 - loss: 0.1239 - sparse_categorical_accuracy: 0.9625\n",
            "156/469 [========>.....................] - ETA: 4:05 - loss: 0.1241 - sparse_categorical_accuracy: 0.9625\n",
            "157/469 [=========>....................] - ETA: 4:04 - loss: 0.1237 - sparse_categorical_accuracy: 0.9627\n",
            "158/469 [=========>....................] - ETA: 4:03 - loss: 0.1236 - sparse_categorical_accuracy: 0.9627\n",
            "159/469 [=========>....................] - ETA: 4:02 - loss: 0.1233 - sparse_categorical_accuracy: 0.9629\n",
            "160/469 [=========>....................] - ETA: 4:01 - loss: 0.1230 - sparse_categorical_accuracy: 0.9629\n",
            "161/469 [=========>....................] - ETA: 4:00 - loss: 0.1225 - sparse_categorical_accuracy: 0.9631\n",
            "162/469 [=========>....................] - ETA: 3:59 - loss: 0.1226 - sparse_categorical_accuracy: 0.9631\n",
            "163/469 [=========>....................] - ETA: 3:58 - loss: 0.1230 - sparse_categorical_accuracy: 0.9628\n",
            "164/469 [=========>....................] - ETA: 3:57 - loss: 0.1231 - sparse_categorical_accuracy: 0.9627\n",
            "165/469 [=========>....................] - ETA: 3:57 - loss: 0.1229 - sparse_categorical_accuracy: 0.9627\n",
            "166/469 [=========>....................] - ETA: 3:56 - loss: 0.1225 - sparse_categorical_accuracy: 0.9629\n",
            "167/469 [=========>....................] - ETA: 3:56 - loss: 0.1226 - sparse_categorical_accuracy: 0.9629\n",
            "168/469 [=========>....................] - ETA: 3:56 - loss: 0.1222 - sparse_categorical_accuracy: 0.9631\n",
            "169/469 [=========>....................] - ETA: 3:55 - loss: 0.1217 - sparse_categorical_accuracy: 0.9632\n",
            "170/469 [=========>....................] - ETA: 3:54 - loss: 0.1213 - sparse_categorical_accuracy: 0.9634\n",
            "171/469 [=========>....................] - ETA: 3:53 - loss: 0.1212 - sparse_categorical_accuracy: 0.9634\n",
            "172/469 [==========>...................] - ETA: 3:53 - loss: 0.1210 - sparse_categorical_accuracy: 0.9634\n",
            "173/469 [==========>...................] - ETA: 3:52 - loss: 0.1207 - sparse_categorical_accuracy: 0.9634\n",
            "174/469 [==========>...................] - ETA: 3:51 - loss: 0.1204 - sparse_categorical_accuracy: 0.9635\n",
            "175/469 [==========>...................] - ETA: 3:50 - loss: 0.1201 - sparse_categorical_accuracy: 0.9636\n",
            "176/469 [==========>...................] - ETA: 3:49 - loss: 0.1203 - sparse_categorical_accuracy: 0.9635\n",
            "177/469 [==========>...................] - ETA: 3:48 - loss: 0.1199 - sparse_categorical_accuracy: 0.9636\n",
            "178/469 [==========>...................] - ETA: 3:47 - loss: 0.1196 - sparse_categorical_accuracy: 0.9637\n",
            "179/469 [==========>...................] - ETA: 3:46 - loss: 0.1194 - sparse_categorical_accuracy: 0.9637\n",
            "180/469 [==========>...................] - ETA: 3:45 - loss: 0.1195 - sparse_categorical_accuracy: 0.9637\n",
            "181/469 [==========>...................] - ETA: 3:44 - loss: 0.1193 - sparse_categorical_accuracy: 0.9637\n",
            "182/469 [==========>...................] - ETA: 3:44 - loss: 0.1196 - sparse_categorical_accuracy: 0.9636\n",
            "183/469 [==========>...................] - ETA: 3:44 - loss: 0.1199 - sparse_categorical_accuracy: 0.9635\n",
            "184/469 [==========>...................] - ETA: 3:43 - loss: 0.1201 - sparse_categorical_accuracy: 0.9635\n",
            "185/469 [==========>...................] - ETA: 3:43 - loss: 0.1197 - sparse_categorical_accuracy: 0.9636\n",
            "186/469 [==========>...................] - ETA: 3:42 - loss: 0.1195 - sparse_categorical_accuracy: 0.9638\n",
            "187/469 [==========>...................] - ETA: 3:41 - loss: 0.1197 - sparse_categorical_accuracy: 0.9637\n",
            "188/469 [===========>..................] - ETA: 3:40 - loss: 0.1195 - sparse_categorical_accuracy: 0.9637\n",
            "189/469 [===========>..................] - ETA: 3:40 - loss: 0.1193 - sparse_categorical_accuracy: 0.9637\n",
            "190/469 [===========>..................] - ETA: 3:39 - loss: 0.1192 - sparse_categorical_accuracy: 0.9636\n",
            "191/469 [===========>..................] - ETA: 3:38 - loss: 0.1191 - sparse_categorical_accuracy: 0.9637\n",
            "192/469 [===========>..................] - ETA: 3:37 - loss: 0.1197 - sparse_categorical_accuracy: 0.9635\n",
            "193/469 [===========>..................] - ETA: 3:36 - loss: 0.1195 - sparse_categorical_accuracy: 0.9636\n",
            "194/469 [===========>..................] - ETA: 3:35 - loss: 0.1198 - sparse_categorical_accuracy: 0.9635\n",
            "195/469 [===========>..................] - ETA: 3:34 - loss: 0.1197 - sparse_categorical_accuracy: 0.9636\n",
            "196/469 [===========>..................] - ETA: 3:33 - loss: 0.1196 - sparse_categorical_accuracy: 0.9636\n",
            "197/469 [===========>..................] - ETA: 3:33 - loss: 0.1195 - sparse_categorical_accuracy: 0.9637\n",
            "198/469 [===========>..................] - ETA: 3:32 - loss: 0.1196 - sparse_categorical_accuracy: 0.9636\n",
            "199/469 [===========>..................] - ETA: 3:31 - loss: 0.1196 - sparse_categorical_accuracy: 0.9636\n",
            "200/469 [===========>..................] - ETA: 3:31 - loss: 0.1194 - sparse_categorical_accuracy: 0.9638\n",
            "201/469 [===========>..................] - ETA: 3:31 - loss: 0.1192 - sparse_categorical_accuracy: 0.9639\n",
            "202/469 [===========>..................] - ETA: 3:30 - loss: 0.1191 - sparse_categorical_accuracy: 0.9639\n",
            "203/469 [===========>..................] - ETA: 3:29 - loss: 0.1189 - sparse_categorical_accuracy: 0.9640\n",
            "204/469 [============>.................] - ETA: 3:28 - loss: 0.1187 - sparse_categorical_accuracy: 0.9641\n",
            "205/469 [============>.................] - ETA: 3:27 - loss: 0.1187 - sparse_categorical_accuracy: 0.9641\n",
            "206/469 [============>.................] - ETA: 3:27 - loss: 0.1186 - sparse_categorical_accuracy: 0.9640\n",
            "207/469 [============>.................] - ETA: 3:26 - loss: 0.1186 - sparse_categorical_accuracy: 0.9640\n",
            "208/469 [============>.................] - ETA: 3:25 - loss: 0.1186 - sparse_categorical_accuracy: 0.9639\n",
            "209/469 [============>.................] - ETA: 3:24 - loss: 0.1182 - sparse_categorical_accuracy: 0.9641\n",
            "210/469 [============>.................] - ETA: 3:23 - loss: 0.1180 - sparse_categorical_accuracy: 0.9642\n",
            "211/469 [============>.................] - ETA: 3:22 - loss: 0.1181 - sparse_categorical_accuracy: 0.9642\n",
            "212/469 [============>.................] - ETA: 3:21 - loss: 0.1178 - sparse_categorical_accuracy: 0.9643\n",
            "213/469 [============>.................] - ETA: 3:20 - loss: 0.1177 - sparse_categorical_accuracy: 0.9643\n",
            "214/469 [============>.................] - ETA: 3:20 - loss: 0.1176 - sparse_categorical_accuracy: 0.9643\n",
            "215/469 [============>.................] - ETA: 3:19 - loss: 0.1173 - sparse_categorical_accuracy: 0.9644\n",
            "216/469 [============>.................] - ETA: 3:18 - loss: 0.1173 - sparse_categorical_accuracy: 0.9644\n",
            "217/469 [============>.................] - ETA: 3:18 - loss: 0.1174 - sparse_categorical_accuracy: 0.9644\n",
            "218/469 [============>.................] - ETA: 3:17 - loss: 0.1178 - sparse_categorical_accuracy: 0.9642\n",
            "219/469 [=============>................] - ETA: 3:17 - loss: 0.1177 - sparse_categorical_accuracy: 0.9642\n",
            "220/469 [=============>................] - ETA: 3:16 - loss: 0.1176 - sparse_categorical_accuracy: 0.9642\n",
            "221/469 [=============>................] - ETA: 3:15 - loss: 0.1180 - sparse_categorical_accuracy: 0.9641\n",
            "222/469 [=============>................] - ETA: 3:14 - loss: 0.1177 - sparse_categorical_accuracy: 0.9642\n",
            "223/469 [=============>................] - ETA: 3:13 - loss: 0.1174 - sparse_categorical_accuracy: 0.9643\n",
            "224/469 [=============>................] - ETA: 3:12 - loss: 0.1177 - sparse_categorical_accuracy: 0.9643\n",
            "225/469 [=============>................] - ETA: 3:12 - loss: 0.1176 - sparse_categorical_accuracy: 0.9642\n",
            "226/469 [=============>................] - ETA: 3:11 - loss: 0.1174 - sparse_categorical_accuracy: 0.9643\n",
            "227/469 [=============>................] - ETA: 3:10 - loss: 0.1173 - sparse_categorical_accuracy: 0.9643\n",
            "228/469 [=============>................] - ETA: 3:09 - loss: 0.1170 - sparse_categorical_accuracy: 0.9644\n",
            "229/469 [=============>................] - ETA: 3:08 - loss: 0.1170 - sparse_categorical_accuracy: 0.9645\n",
            "230/469 [=============>................] - ETA: 3:07 - loss: 0.1173 - sparse_categorical_accuracy: 0.9644\n",
            "231/469 [=============>................] - ETA: 3:06 - loss: 0.1175 - sparse_categorical_accuracy: 0.9644\n",
            "232/469 [=============>................] - ETA: 3:06 - loss: 0.1174 - sparse_categorical_accuracy: 0.9644\n",
            "233/469 [=============>................] - ETA: 3:05 - loss: 0.1174 - sparse_categorical_accuracy: 0.9644\n",
            "234/469 [=============>................] - ETA: 3:04 - loss: 0.1173 - sparse_categorical_accuracy: 0.9644\n",
            "235/469 [==============>...............] - ETA: 3:04 - loss: 0.1172 - sparse_categorical_accuracy: 0.9645\n",
            "236/469 [==============>...............] - ETA: 3:04 - loss: 0.1170 - sparse_categorical_accuracy: 0.9645\n",
            "237/469 [==============>...............] - ETA: 3:03 - loss: 0.1174 - sparse_categorical_accuracy: 0.9644\n",
            "238/469 [==============>...............] - ETA: 3:02 - loss: 0.1175 - sparse_categorical_accuracy: 0.9643\n",
            "239/469 [==============>...............] - ETA: 3:01 - loss: 0.1178 - sparse_categorical_accuracy: 0.9643\n",
            "240/469 [==============>...............] - ETA: 3:00 - loss: 0.1175 - sparse_categorical_accuracy: 0.9644\n",
            "241/469 [==============>...............] - ETA: 2:59 - loss: 0.1174 - sparse_categorical_accuracy: 0.9644\n",
            "242/469 [==============>...............] - ETA: 2:59 - loss: 0.1173 - sparse_categorical_accuracy: 0.9645\n",
            "243/469 [==============>...............] - ETA: 2:58 - loss: 0.1172 - sparse_categorical_accuracy: 0.9645\n",
            "244/469 [==============>...............] - ETA: 2:57 - loss: 0.1172 - sparse_categorical_accuracy: 0.9645\n",
            "245/469 [==============>...............] - ETA: 2:56 - loss: 0.1172 - sparse_categorical_accuracy: 0.9645\n",
            "246/469 [==============>...............] - ETA: 2:55 - loss: 0.1174 - sparse_categorical_accuracy: 0.9644\n",
            "247/469 [==============>...............] - ETA: 2:54 - loss: 0.1171 - sparse_categorical_accuracy: 0.9645\n",
            "248/469 [==============>...............] - ETA: 2:53 - loss: 0.1170 - sparse_categorical_accuracy: 0.9646\n",
            "249/469 [==============>...............] - ETA: 2:53 - loss: 0.1167 - sparse_categorical_accuracy: 0.9647\n",
            "250/469 [==============>...............] - ETA: 2:52 - loss: 0.1166 - sparse_categorical_accuracy: 0.9647\n",
            "251/469 [===============>..............] - ETA: 2:52 - loss: 0.1163 - sparse_categorical_accuracy: 0.9648\n",
            "252/469 [===============>..............] - ETA: 2:51 - loss: 0.1162 - sparse_categorical_accuracy: 0.9648\n",
            "253/469 [===============>..............] - ETA: 2:50 - loss: 0.1160 - sparse_categorical_accuracy: 0.9649\n",
            "254/469 [===============>..............] - ETA: 2:50 - loss: 0.1161 - sparse_categorical_accuracy: 0.9648\n",
            "255/469 [===============>..............] - ETA: 2:49 - loss: 0.1160 - sparse_categorical_accuracy: 0.9649\n",
            "256/469 [===============>..............] - ETA: 2:48 - loss: 0.1160 - sparse_categorical_accuracy: 0.9649\n",
            "257/469 [===============>..............] - ETA: 2:47 - loss: 0.1160 - sparse_categorical_accuracy: 0.9648\n",
            "258/469 [===============>..............] - ETA: 2:46 - loss: 0.1160 - sparse_categorical_accuracy: 0.9648\n",
            "259/469 [===============>..............] - ETA: 2:45 - loss: 0.1162 - sparse_categorical_accuracy: 0.9647\n",
            "260/469 [===============>..............] - ETA: 2:44 - loss: 0.1161 - sparse_categorical_accuracy: 0.9647\n",
            "261/469 [===============>..............] - ETA: 2:44 - loss: 0.1161 - sparse_categorical_accuracy: 0.9647\n",
            "262/469 [===============>..............] - ETA: 2:43 - loss: 0.1159 - sparse_categorical_accuracy: 0.9648\n",
            "263/469 [===============>..............] - ETA: 2:42 - loss: 0.1157 - sparse_categorical_accuracy: 0.9649\n",
            "264/469 [===============>..............] - ETA: 2:41 - loss: 0.1157 - sparse_categorical_accuracy: 0.9648\n",
            "265/469 [===============>..............] - ETA: 2:40 - loss: 0.1155 - sparse_categorical_accuracy: 0.9649\n",
            "266/469 [================>.............] - ETA: 2:39 - loss: 0.1156 - sparse_categorical_accuracy: 0.9648\n",
            "267/469 [================>.............] - ETA: 2:39 - loss: 0.1155 - sparse_categorical_accuracy: 0.9648\n",
            "268/469 [================>.............] - ETA: 2:38 - loss: 0.1156 - sparse_categorical_accuracy: 0.9648\n",
            "269/469 [================>.............] - ETA: 2:38 - loss: 0.1155 - sparse_categorical_accuracy: 0.9649\n",
            "270/469 [================>.............] - ETA: 2:37 - loss: 0.1154 - sparse_categorical_accuracy: 0.9649\n",
            "271/469 [================>.............] - ETA: 2:36 - loss: 0.1151 - sparse_categorical_accuracy: 0.9650\n",
            "272/469 [================>.............] - ETA: 2:35 - loss: 0.1150 - sparse_categorical_accuracy: 0.9650\n",
            "273/469 [================>.............] - ETA: 2:35 - loss: 0.1149 - sparse_categorical_accuracy: 0.9650\n",
            "274/469 [================>.............] - ETA: 2:34 - loss: 0.1148 - sparse_categorical_accuracy: 0.9650\n",
            "275/469 [================>.............] - ETA: 2:33 - loss: 0.1149 - sparse_categorical_accuracy: 0.9650\n",
            "276/469 [================>.............] - ETA: 2:32 - loss: 0.1148 - sparse_categorical_accuracy: 0.9650\n",
            "277/469 [================>.............] - ETA: 2:31 - loss: 0.1145 - sparse_categorical_accuracy: 0.9651\n",
            "278/469 [================>.............] - ETA: 2:30 - loss: 0.1143 - sparse_categorical_accuracy: 0.9651\n",
            "279/469 [================>.............] - ETA: 2:30 - loss: 0.1142 - sparse_categorical_accuracy: 0.9651\n",
            "280/469 [================>.............] - ETA: 2:29 - loss: 0.1141 - sparse_categorical_accuracy: 0.9652\n",
            "281/469 [================>.............] - ETA: 2:28 - loss: 0.1140 - sparse_categorical_accuracy: 0.9652\n",
            "282/469 [=================>............] - ETA: 2:27 - loss: 0.1138 - sparse_categorical_accuracy: 0.9653\n",
            "283/469 [=================>............] - ETA: 2:26 - loss: 0.1137 - sparse_categorical_accuracy: 0.9653\n",
            "284/469 [=================>............] - ETA: 2:25 - loss: 0.1138 - sparse_categorical_accuracy: 0.9653\n",
            "285/469 [=================>............] - ETA: 2:25 - loss: 0.1137 - sparse_categorical_accuracy: 0.9654\n",
            "286/469 [=================>............] - ETA: 2:24 - loss: 0.1136 - sparse_categorical_accuracy: 0.9654\n",
            "287/469 [=================>............] - ETA: 2:24 - loss: 0.1136 - sparse_categorical_accuracy: 0.9654\n",
            "288/469 [=================>............] - ETA: 2:23 - loss: 0.1136 - sparse_categorical_accuracy: 0.9654\n",
            "289/469 [=================>............] - ETA: 2:22 - loss: 0.1135 - sparse_categorical_accuracy: 0.9653\n",
            "290/469 [=================>............] - ETA: 2:21 - loss: 0.1133 - sparse_categorical_accuracy: 0.9654\n",
            "291/469 [=================>............] - ETA: 2:20 - loss: 0.1133 - sparse_categorical_accuracy: 0.9653\n",
            "292/469 [=================>............] - ETA: 2:20 - loss: 0.1131 - sparse_categorical_accuracy: 0.9655\n",
            "293/469 [=================>............] - ETA: 2:19 - loss: 0.1132 - sparse_categorical_accuracy: 0.9654\n",
            "294/469 [=================>............] - ETA: 2:18 - loss: 0.1131 - sparse_categorical_accuracy: 0.9654\n",
            "295/469 [=================>............] - ETA: 2:17 - loss: 0.1130 - sparse_categorical_accuracy: 0.9655\n",
            "296/469 [=================>............] - ETA: 2:16 - loss: 0.1129 - sparse_categorical_accuracy: 0.9655\n",
            "297/469 [=================>............] - ETA: 2:15 - loss: 0.1129 - sparse_categorical_accuracy: 0.9655\n",
            "298/469 [==================>...........] - ETA: 2:14 - loss: 0.1128 - sparse_categorical_accuracy: 0.9655\n",
            "299/469 [==================>...........] - ETA: 2:14 - loss: 0.1127 - sparse_categorical_accuracy: 0.9655\n",
            "300/469 [==================>...........] - ETA: 2:13 - loss: 0.1124 - sparse_categorical_accuracy: 0.9656\n",
            "301/469 [==================>...........] - ETA: 2:12 - loss: 0.1123 - sparse_categorical_accuracy: 0.9656\n",
            "302/469 [==================>...........] - ETA: 2:11 - loss: 0.1123 - sparse_categorical_accuracy: 0.9656\n",
            "303/469 [==================>...........] - ETA: 2:11 - loss: 0.1121 - sparse_categorical_accuracy: 0.9657\n",
            "304/469 [==================>...........] - ETA: 2:11 - loss: 0.1124 - sparse_categorical_accuracy: 0.9657\n",
            "305/469 [==================>...........] - ETA: 2:11 - loss: 0.1127 - sparse_categorical_accuracy: 0.9657\n",
            "306/469 [==================>...........] - ETA: 2:10 - loss: 0.1128 - sparse_categorical_accuracy: 0.9656\n",
            "307/469 [==================>...........] - ETA: 2:10 - loss: 0.1126 - sparse_categorical_accuracy: 0.9657\n",
            "308/469 [==================>...........] - ETA: 2:09 - loss: 0.1124 - sparse_categorical_accuracy: 0.9657\n",
            "309/469 [==================>...........] - ETA: 2:08 - loss: 0.1125 - sparse_categorical_accuracy: 0.9657\n",
            "310/469 [==================>...........] - ETA: 2:08 - loss: 0.1124 - sparse_categorical_accuracy: 0.9657\n",
            "311/469 [==================>...........] - ETA: 2:07 - loss: 0.1122 - sparse_categorical_accuracy: 0.9658\n",
            "312/469 [==================>...........] - ETA: 2:06 - loss: 0.1120 - sparse_categorical_accuracy: 0.9659\n",
            "313/469 [===================>..........] - ETA: 2:05 - loss: 0.1120 - sparse_categorical_accuracy: 0.9659\n",
            "314/469 [===================>..........] - ETA: 2:04 - loss: 0.1121 - sparse_categorical_accuracy: 0.9659\n",
            "315/469 [===================>..........] - ETA: 2:03 - loss: 0.1122 - sparse_categorical_accuracy: 0.9659\n",
            "316/469 [===================>..........] - ETA: 2:03 - loss: 0.1124 - sparse_categorical_accuracy: 0.9659\n",
            "317/469 [===================>..........] - ETA: 2:02 - loss: 0.1123 - sparse_categorical_accuracy: 0.9659\n",
            "318/469 [===================>..........] - ETA: 2:01 - loss: 0.1121 - sparse_categorical_accuracy: 0.9660\n",
            "319/469 [===================>..........] - ETA: 2:01 - loss: 0.1122 - sparse_categorical_accuracy: 0.9659\n",
            "320/469 [===================>..........] - ETA: 2:00 - loss: 0.1120 - sparse_categorical_accuracy: 0.9659\n",
            "321/469 [===================>..........] - ETA: 1:59 - loss: 0.1119 - sparse_categorical_accuracy: 0.9660\n",
            "322/469 [===================>..........] - ETA: 1:58 - loss: 0.1119 - sparse_categorical_accuracy: 0.9659\n",
            "323/469 [===================>..........] - ETA: 1:57 - loss: 0.1118 - sparse_categorical_accuracy: 0.9660\n",
            "324/469 [===================>..........] - ETA: 1:56 - loss: 0.1121 - sparse_categorical_accuracy: 0.9659\n",
            "325/469 [===================>..........] - ETA: 1:56 - loss: 0.1120 - sparse_categorical_accuracy: 0.9660\n",
            "326/469 [===================>..........] - ETA: 1:55 - loss: 0.1119 - sparse_categorical_accuracy: 0.9660\n",
            "327/469 [===================>..........] - ETA: 1:54 - loss: 0.1120 - sparse_categorical_accuracy: 0.9660\n",
            "328/469 [===================>..........] - ETA: 1:53 - loss: 0.1121 - sparse_categorical_accuracy: 0.9659\n",
            "329/469 [====================>.........] - ETA: 1:52 - loss: 0.1121 - sparse_categorical_accuracy: 0.9658\n",
            "330/469 [====================>.........] - ETA: 1:51 - loss: 0.1122 - sparse_categorical_accuracy: 0.9658\n",
            "331/469 [====================>.........] - ETA: 1:51 - loss: 0.1124 - sparse_categorical_accuracy: 0.9658\n",
            "332/469 [====================>.........] - ETA: 1:50 - loss: 0.1126 - sparse_categorical_accuracy: 0.9657\n",
            "333/469 [====================>.........] - ETA: 1:49 - loss: 0.1125 - sparse_categorical_accuracy: 0.9657\n",
            "334/469 [====================>.........] - ETA: 1:48 - loss: 0.1124 - sparse_categorical_accuracy: 0.9657\n",
            "335/469 [====================>.........] - ETA: 1:48 - loss: 0.1123 - sparse_categorical_accuracy: 0.9658\n",
            "336/469 [====================>.........] - ETA: 1:47 - loss: 0.1123 - sparse_categorical_accuracy: 0.9658\n",
            "337/469 [====================>.........] - ETA: 1:46 - loss: 0.1121 - sparse_categorical_accuracy: 0.9659\n",
            "338/469 [====================>.........] - ETA: 1:45 - loss: 0.1120 - sparse_categorical_accuracy: 0.9659\n",
            "339/469 [====================>.........] - ETA: 1:44 - loss: 0.1121 - sparse_categorical_accuracy: 0.9659\n",
            "340/469 [====================>.........] - ETA: 1:44 - loss: 0.1120 - sparse_categorical_accuracy: 0.9658\n",
            "341/469 [====================>.........] - ETA: 1:43 - loss: 0.1121 - sparse_categorical_accuracy: 0.9658\n",
            "342/469 [====================>.........] - ETA: 1:42 - loss: 0.1122 - sparse_categorical_accuracy: 0.9658\n",
            "343/469 [====================>.........] - ETA: 1:41 - loss: 0.1121 - sparse_categorical_accuracy: 0.9658\n",
            "344/469 [=====================>........] - ETA: 1:40 - loss: 0.1124 - sparse_categorical_accuracy: 0.9658\n",
            "345/469 [=====================>........] - ETA: 1:40 - loss: 0.1122 - sparse_categorical_accuracy: 0.9658\n",
            "346/469 [=====================>........] - ETA: 1:39 - loss: 0.1121 - sparse_categorical_accuracy: 0.9658\n",
            "347/469 [=====================>........] - ETA: 1:38 - loss: 0.1125 - sparse_categorical_accuracy: 0.9657\n",
            "348/469 [=====================>........] - ETA: 1:37 - loss: 0.1128 - sparse_categorical_accuracy: 0.9655\n",
            "349/469 [=====================>........] - ETA: 1:36 - loss: 0.1128 - sparse_categorical_accuracy: 0.9655\n",
            "350/469 [=====================>........] - ETA: 1:36 - loss: 0.1127 - sparse_categorical_accuracy: 0.9656\n",
            "351/469 [=====================>........] - ETA: 1:35 - loss: 0.1126 - sparse_categorical_accuracy: 0.9656\n",
            "352/469 [=====================>........] - ETA: 1:34 - loss: 0.1127 - sparse_categorical_accuracy: 0.9656\n",
            "353/469 [=====================>........] - ETA: 1:33 - loss: 0.1127 - sparse_categorical_accuracy: 0.9657\n",
            "354/469 [=====================>........] - ETA: 1:33 - loss: 0.1126 - sparse_categorical_accuracy: 0.9657\n",
            "355/469 [=====================>........] - ETA: 1:32 - loss: 0.1128 - sparse_categorical_accuracy: 0.9657\n",
            "356/469 [=====================>........] - ETA: 1:31 - loss: 0.1126 - sparse_categorical_accuracy: 0.9658\n",
            "357/469 [=====================>........] - ETA: 1:30 - loss: 0.1125 - sparse_categorical_accuracy: 0.9658\n",
            "358/469 [=====================>........] - ETA: 1:29 - loss: 0.1125 - sparse_categorical_accuracy: 0.9658\n",
            "359/469 [=====================>........] - ETA: 1:29 - loss: 0.1126 - sparse_categorical_accuracy: 0.9658\n",
            "360/469 [======================>.......] - ETA: 1:28 - loss: 0.1125 - sparse_categorical_accuracy: 0.9658\n",
            "361/469 [======================>.......] - ETA: 1:27 - loss: 0.1124 - sparse_categorical_accuracy: 0.9659\n",
            "362/469 [======================>.......] - ETA: 1:26 - loss: 0.1125 - sparse_categorical_accuracy: 0.9658\n",
            "363/469 [======================>.......] - ETA: 1:25 - loss: 0.1124 - sparse_categorical_accuracy: 0.9659\n",
            "364/469 [======================>.......] - ETA: 1:24 - loss: 0.1125 - sparse_categorical_accuracy: 0.9659\n",
            "365/469 [======================>.......] - ETA: 1:24 - loss: 0.1125 - sparse_categorical_accuracy: 0.9659\n",
            "366/469 [======================>.......] - ETA: 1:23 - loss: 0.1125 - sparse_categorical_accuracy: 0.9659\n",
            "367/469 [======================>.......] - ETA: 1:22 - loss: 0.1124 - sparse_categorical_accuracy: 0.9659\n",
            "368/469 [======================>.......] - ETA: 1:22 - loss: 0.1123 - sparse_categorical_accuracy: 0.9660\n",
            "369/469 [======================>.......] - ETA: 1:21 - loss: 0.1122 - sparse_categorical_accuracy: 0.9660\n",
            "370/469 [======================>.......] - ETA: 1:20 - loss: 0.1121 - sparse_categorical_accuracy: 0.9660\n",
            "371/469 [======================>.......] - ETA: 1:19 - loss: 0.1119 - sparse_categorical_accuracy: 0.9661\n",
            "372/469 [======================>.......] - ETA: 1:18 - loss: 0.1118 - sparse_categorical_accuracy: 0.9661\n",
            "373/469 [======================>.......] - ETA: 1:18 - loss: 0.1119 - sparse_categorical_accuracy: 0.9661\n",
            "374/469 [======================>.......] - ETA: 1:17 - loss: 0.1118 - sparse_categorical_accuracy: 0.9661\n",
            "375/469 [======================>.......] - ETA: 1:16 - loss: 0.1118 - sparse_categorical_accuracy: 0.9661\n",
            "376/469 [=======================>......] - ETA: 1:15 - loss: 0.1117 - sparse_categorical_accuracy: 0.9662\n",
            "377/469 [=======================>......] - ETA: 1:14 - loss: 0.1120 - sparse_categorical_accuracy: 0.9660\n",
            "378/469 [=======================>......] - ETA: 1:14 - loss: 0.1121 - sparse_categorical_accuracy: 0.9660\n",
            "379/469 [=======================>......] - ETA: 1:13 - loss: 0.1122 - sparse_categorical_accuracy: 0.9660\n",
            "380/469 [=======================>......] - ETA: 1:12 - loss: 0.1122 - sparse_categorical_accuracy: 0.9660\n",
            "381/469 [=======================>......] - ETA: 1:11 - loss: 0.1120 - sparse_categorical_accuracy: 0.9660\n",
            "382/469 [=======================>......] - ETA: 1:11 - loss: 0.1120 - sparse_categorical_accuracy: 0.9661\n",
            "383/469 [=======================>......] - ETA: 1:10 - loss: 0.1121 - sparse_categorical_accuracy: 0.9660\n",
            "384/469 [=======================>......] - ETA: 1:09 - loss: 0.1120 - sparse_categorical_accuracy: 0.9660\n",
            "385/469 [=======================>......] - ETA: 1:08 - loss: 0.1119 - sparse_categorical_accuracy: 0.9661\n",
            "386/469 [=======================>......] - ETA: 1:08 - loss: 0.1118 - sparse_categorical_accuracy: 0.9661\n",
            "387/469 [=======================>......] - ETA: 1:07 - loss: 0.1119 - sparse_categorical_accuracy: 0.9661\n",
            "388/469 [=======================>......] - ETA: 1:06 - loss: 0.1117 - sparse_categorical_accuracy: 0.9662\n",
            "389/469 [=======================>......] - ETA: 1:05 - loss: 0.1118 - sparse_categorical_accuracy: 0.9661\n",
            "390/469 [=======================>......] - ETA: 1:04 - loss: 0.1119 - sparse_categorical_accuracy: 0.9661\n",
            "391/469 [========================>.....] - ETA: 1:03 - loss: 0.1118 - sparse_categorical_accuracy: 0.9661\n",
            "392/469 [========================>.....] - ETA: 1:03 - loss: 0.1116 - sparse_categorical_accuracy: 0.9662\n",
            "393/469 [========================>.....] - ETA: 1:02 - loss: 0.1116 - sparse_categorical_accuracy: 0.9662\n",
            "394/469 [========================>.....] - ETA: 1:01 - loss: 0.1115 - sparse_categorical_accuracy: 0.9662\n",
            "395/469 [========================>.....] - ETA: 1:00 - loss: 0.1114 - sparse_categorical_accuracy: 0.9662\n",
            "396/469 [========================>.....] - ETA: 59s - loss: 0.1114 - sparse_categorical_accuracy: 0.9662 \n",
            "397/469 [========================>.....] - ETA: 58s - loss: 0.1113 - sparse_categorical_accuracy: 0.9662\n",
            "398/469 [========================>.....] - ETA: 58s - loss: 0.1113 - sparse_categorical_accuracy: 0.9663\n",
            "399/469 [========================>.....] - ETA: 57s - loss: 0.1112 - sparse_categorical_accuracy: 0.9663\n",
            "400/469 [========================>.....] - ETA: 56s - loss: 0.1111 - sparse_categorical_accuracy: 0.9663\n",
            "401/469 [========================>.....] - ETA: 55s - loss: 0.1110 - sparse_categorical_accuracy: 0.9663\n",
            "402/469 [========================>.....] - ETA: 54s - loss: 0.1109 - sparse_categorical_accuracy: 0.9663\n",
            "403/469 [========================>.....] - ETA: 54s - loss: 0.1109 - sparse_categorical_accuracy: 0.9664\n",
            "404/469 [========================>.....] - ETA: 53s - loss: 0.1108 - sparse_categorical_accuracy: 0.9664\n",
            "405/469 [========================>.....] - ETA: 52s - loss: 0.1110 - sparse_categorical_accuracy: 0.9664\n",
            "406/469 [========================>.....] - ETA: 51s - loss: 0.1110 - sparse_categorical_accuracy: 0.9664\n",
            "407/469 [=========================>....] - ETA: 50s - loss: 0.1112 - sparse_categorical_accuracy: 0.9664\n",
            "408/469 [=========================>....] - ETA: 49s - loss: 0.1110 - sparse_categorical_accuracy: 0.9665\n",
            "409/469 [=========================>....] - ETA: 49s - loss: 0.1108 - sparse_categorical_accuracy: 0.9665\n",
            "410/469 [=========================>....] - ETA: 48s - loss: 0.1107 - sparse_categorical_accuracy: 0.9666\n",
            "411/469 [=========================>....] - ETA: 47s - loss: 0.1106 - sparse_categorical_accuracy: 0.9666\n",
            "412/469 [=========================>....] - ETA: 46s - loss: 0.1105 - sparse_categorical_accuracy: 0.9666\n",
            "413/469 [=========================>....] - ETA: 45s - loss: 0.1105 - sparse_categorical_accuracy: 0.9666\n",
            "414/469 [=========================>....] - ETA: 44s - loss: 0.1103 - sparse_categorical_accuracy: 0.9666\n",
            "415/469 [=========================>....] - ETA: 44s - loss: 0.1107 - sparse_categorical_accuracy: 0.9666\n",
            "416/469 [=========================>....] - ETA: 43s - loss: 0.1107 - sparse_categorical_accuracy: 0.9665\n",
            "417/469 [=========================>....] - ETA: 42s - loss: 0.1106 - sparse_categorical_accuracy: 0.9665\n",
            "418/469 [=========================>....] - ETA: 41s - loss: 0.1106 - sparse_categorical_accuracy: 0.9665\n",
            "419/469 [=========================>....] - ETA: 40s - loss: 0.1106 - sparse_categorical_accuracy: 0.9665\n",
            "420/469 [=========================>....] - ETA: 40s - loss: 0.1105 - sparse_categorical_accuracy: 0.9665\n",
            "421/469 [=========================>....] - ETA: 39s - loss: 0.1104 - sparse_categorical_accuracy: 0.9665\n",
            "422/469 [=========================>....] - ETA: 38s - loss: 0.1105 - sparse_categorical_accuracy: 0.9665\n",
            "423/469 [==========================>...] - ETA: 37s - loss: 0.1102 - sparse_categorical_accuracy: 0.9666\n",
            "424/469 [==========================>...] - ETA: 36s - loss: 0.1102 - sparse_categorical_accuracy: 0.9666\n",
            "425/469 [==========================>...] - ETA: 35s - loss: 0.1100 - sparse_categorical_accuracy: 0.9666\n",
            "426/469 [==========================>...] - ETA: 35s - loss: 0.1103 - sparse_categorical_accuracy: 0.9666\n",
            "427/469 [==========================>...] - ETA: 34s - loss: 0.1102 - sparse_categorical_accuracy: 0.9667\n",
            "428/469 [==========================>...] - ETA: 33s - loss: 0.1100 - sparse_categorical_accuracy: 0.9667\n",
            "429/469 [==========================>...] - ETA: 32s - loss: 0.1102 - sparse_categorical_accuracy: 0.9666\n",
            "430/469 [==========================>...] - ETA: 31s - loss: 0.1101 - sparse_categorical_accuracy: 0.9667\n",
            "431/469 [==========================>...] - ETA: 31s - loss: 0.1101 - sparse_categorical_accuracy: 0.9666\n",
            "432/469 [==========================>...] - ETA: 30s - loss: 0.1103 - sparse_categorical_accuracy: 0.9666\n",
            "433/469 [==========================>...] - ETA: 29s - loss: 0.1102 - sparse_categorical_accuracy: 0.9666\n",
            "434/469 [==========================>...] - ETA: 28s - loss: 0.1100 - sparse_categorical_accuracy: 0.9666\n",
            "435/469 [==========================>...] - ETA: 27s - loss: 0.1099 - sparse_categorical_accuracy: 0.9667\n",
            "436/469 [==========================>...] - ETA: 26s - loss: 0.1099 - sparse_categorical_accuracy: 0.9667\n",
            "437/469 [==========================>...] - ETA: 26s - loss: 0.1098 - sparse_categorical_accuracy: 0.9667\n",
            "438/469 [===========================>..] - ETA: 25s - loss: 0.1099 - sparse_categorical_accuracy: 0.9666\n",
            "439/469 [===========================>..] - ETA: 24s - loss: 0.1098 - sparse_categorical_accuracy: 0.9667\n",
            "440/469 [===========================>..] - ETA: 23s - loss: 0.1098 - sparse_categorical_accuracy: 0.9666\n",
            "441/469 [===========================>..] - ETA: 22s - loss: 0.1098 - sparse_categorical_accuracy: 0.9667\n",
            "442/469 [===========================>..] - ETA: 22s - loss: 0.1099 - sparse_categorical_accuracy: 0.9666\n",
            "443/469 [===========================>..] - ETA: 21s - loss: 0.1098 - sparse_categorical_accuracy: 0.9666\n",
            "444/469 [===========================>..] - ETA: 20s - loss: 0.1097 - sparse_categorical_accuracy: 0.9667\n",
            "445/469 [===========================>..] - ETA: 19s - loss: 0.1096 - sparse_categorical_accuracy: 0.9667\n",
            "446/469 [===========================>..] - ETA: 18s - loss: 0.1097 - sparse_categorical_accuracy: 0.9667\n",
            "447/469 [===========================>..] - ETA: 17s - loss: 0.1098 - sparse_categorical_accuracy: 0.9667\n",
            "448/469 [===========================>..] - ETA: 17s - loss: 0.1097 - sparse_categorical_accuracy: 0.9667\n",
            "449/469 [===========================>..] - ETA: 16s - loss: 0.1096 - sparse_categorical_accuracy: 0.9667\n",
            "450/469 [===========================>..] - ETA: 15s - loss: 0.1095 - sparse_categorical_accuracy: 0.9667\n",
            "451/469 [===========================>..] - ETA: 14s - loss: 0.1094 - sparse_categorical_accuracy: 0.9668\n",
            "452/469 [===========================>..] - ETA: 13s - loss: 0.1094 - sparse_categorical_accuracy: 0.9667\n",
            "453/469 [===========================>..] - ETA: 13s - loss: 0.1094 - sparse_categorical_accuracy: 0.9667\n",
            "454/469 [============================>.] - ETA: 12s - loss: 0.1092 - sparse_categorical_accuracy: 0.9668\n",
            "455/469 [============================>.] - ETA: 11s - loss: 0.1092 - sparse_categorical_accuracy: 0.9668\n",
            "456/469 [============================>.] - ETA: 10s - loss: 0.1091 - sparse_categorical_accuracy: 0.9668\n",
            "457/469 [============================>.] - ETA: 9s - loss: 0.1091 - sparse_categorical_accuracy: 0.9669 \n",
            "458/469 [============================>.] - ETA: 8s - loss: 0.1090 - sparse_categorical_accuracy: 0.9668\n",
            "459/469 [============================>.] - ETA: 8s - loss: 0.1090 - sparse_categorical_accuracy: 0.9669\n",
            "460/469 [============================>.] - ETA: 7s - loss: 0.1091 - sparse_categorical_accuracy: 0.9669\n",
            "461/469 [============================>.] - ETA: 6s - loss: 0.1090 - sparse_categorical_accuracy: 0.9669\n",
            "462/469 [============================>.] - ETA: 5s - loss: 0.1089 - sparse_categorical_accuracy: 0.9669\n",
            "463/469 [============================>.] - ETA: 4s - loss: 0.1090 - sparse_categorical_accuracy: 0.9669\n",
            "464/469 [============================>.] - ETA: 4s - loss: 0.1090 - sparse_categorical_accuracy: 0.9669\n",
            "465/469 [============================>.] - ETA: 3s - loss: 0.1089 - sparse_categorical_accuracy: 0.9670\n",
            "466/469 [============================>.] - ETA: 2s - loss: 0.1088 - sparse_categorical_accuracy: 0.9670\n",
            "467/469 [============================>.] - ETA: 1s - loss: 0.1088 - sparse_categorical_accuracy: 0.9670\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.1089 - sparse_categorical_accuracy: 0.9670\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1089 - sparse_categorical_accuracy: 0.9669\n",
            "  0%|          | 0/5 [12:31<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/04/16 00:44:32 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 382s 816ms/step - loss: 0.1089 - sparse_categorical_accuracy: 0.9669\n",
            "\n",
            "Epoch 3/5\n",
            "\n",
            "  1/469 [..............................] - ETA: 5:40 - loss: 0.0588 - sparse_categorical_accuracy: 0.9844\n",
            "  2/469 [..............................] - ETA: 5:21 - loss: 0.1207 - sparse_categorical_accuracy: 0.9570\n",
            "  3/469 [..............................] - ETA: 5:20 - loss: 0.1191 - sparse_categorical_accuracy: 0.9609\n",
            "  4/469 [..............................] - ETA: 5:23 - loss: 0.1165 - sparse_categorical_accuracy: 0.9629\n",
            "  5/469 [..............................] - ETA: 5:21 - loss: 0.1089 - sparse_categorical_accuracy: 0.9672\n",
            "  6/469 [..............................] - ETA: 5:21 - loss: 0.1016 - sparse_categorical_accuracy: 0.9701\n",
            "  7/469 [..............................] - ETA: 5:19 - loss: 0.0987 - sparse_categorical_accuracy: 0.9699\n",
            "  8/469 [..............................] - ETA: 5:16 - loss: 0.1005 - sparse_categorical_accuracy: 0.9707\n",
            "  9/469 [..............................] - ETA: 5:15 - loss: 0.0978 - sparse_categorical_accuracy: 0.9714\n",
            " 10/469 [..............................] - ETA: 5:17 - loss: 0.0933 - sparse_categorical_accuracy: 0.9727\n",
            " 11/469 [..............................] - ETA: 5:17 - loss: 0.0981 - sparse_categorical_accuracy: 0.9730\n",
            " 12/469 [..............................] - ETA: 5:17 - loss: 0.0948 - sparse_categorical_accuracy: 0.9740\n",
            " 13/469 [..............................] - ETA: 5:16 - loss: 0.0927 - sparse_categorical_accuracy: 0.9742\n",
            " 14/469 [..............................] - ETA: 5:22 - loss: 0.0940 - sparse_categorical_accuracy: 0.9738\n",
            " 15/469 [..............................] - ETA: 5:35 - loss: 0.0903 - sparse_categorical_accuracy: 0.9750\n",
            " 16/469 [>.............................] - ETA: 5:46 - loss: 0.0871 - sparse_categorical_accuracy: 0.9761\n",
            " 17/469 [>.............................] - ETA: 5:51 - loss: 0.0846 - sparse_categorical_accuracy: 0.9761\n",
            " 18/469 [>.............................] - ETA: 5:48 - loss: 0.0855 - sparse_categorical_accuracy: 0.9753\n",
            " 19/469 [>.............................] - ETA: 5:46 - loss: 0.0838 - sparse_categorical_accuracy: 0.9762\n",
            " 20/469 [>.............................] - ETA: 5:43 - loss: 0.0847 - sparse_categorical_accuracy: 0.9758\n",
            " 21/469 [>.............................] - ETA: 5:41 - loss: 0.0835 - sparse_categorical_accuracy: 0.9754\n",
            " 22/469 [>.............................] - ETA: 5:40 - loss: 0.0837 - sparse_categorical_accuracy: 0.9759\n",
            " 23/469 [>.............................] - ETA: 5:38 - loss: 0.0829 - sparse_categorical_accuracy: 0.9759\n",
            " 24/469 [>.............................] - ETA: 5:36 - loss: 0.0817 - sparse_categorical_accuracy: 0.9762\n",
            " 25/469 [>.............................] - ETA: 5:34 - loss: 0.0806 - sparse_categorical_accuracy: 0.9766\n",
            " 26/469 [>.............................] - ETA: 5:33 - loss: 0.0829 - sparse_categorical_accuracy: 0.9754\n",
            " 27/469 [>.............................] - ETA: 5:31 - loss: 0.0856 - sparse_categorical_accuracy: 0.9745\n",
            " 28/469 [>.............................] - ETA: 5:30 - loss: 0.0839 - sparse_categorical_accuracy: 0.9749\n",
            " 29/469 [>.............................] - ETA: 5:29 - loss: 0.0865 - sparse_categorical_accuracy: 0.9739\n",
            " 30/469 [>.............................] - ETA: 5:27 - loss: 0.0881 - sparse_categorical_accuracy: 0.9734\n",
            " 31/469 [>.............................] - ETA: 5:27 - loss: 0.0883 - sparse_categorical_accuracy: 0.9730\n",
            " 32/469 [=>............................] - ETA: 5:32 - loss: 0.0882 - sparse_categorical_accuracy: 0.9731\n",
            " 33/469 [=>............................] - ETA: 5:37 - loss: 0.0883 - sparse_categorical_accuracy: 0.9728\n",
            " 34/469 [=>............................] - ETA: 5:40 - loss: 0.0881 - sparse_categorical_accuracy: 0.9722\n",
            " 35/469 [=>............................] - ETA: 5:39 - loss: 0.0869 - sparse_categorical_accuracy: 0.9723\n",
            " 36/469 [=>............................] - ETA: 5:37 - loss: 0.0872 - sparse_categorical_accuracy: 0.9722\n",
            " 37/469 [=>............................] - ETA: 5:35 - loss: 0.0860 - sparse_categorical_accuracy: 0.9730\n",
            " 38/469 [=>............................] - ETA: 5:34 - loss: 0.0868 - sparse_categorical_accuracy: 0.9727\n",
            " 39/469 [=>............................] - ETA: 5:33 - loss: 0.0863 - sparse_categorical_accuracy: 0.9728\n",
            " 40/469 [=>............................] - ETA: 5:31 - loss: 0.0853 - sparse_categorical_accuracy: 0.9730\n",
            " 41/469 [=>............................] - ETA: 5:29 - loss: 0.0847 - sparse_categorical_accuracy: 0.9729\n",
            " 42/469 [=>............................] - ETA: 5:28 - loss: 0.0842 - sparse_categorical_accuracy: 0.9734\n",
            " 43/469 [=>............................] - ETA: 5:26 - loss: 0.0843 - sparse_categorical_accuracy: 0.9733\n",
            " 44/469 [=>............................] - ETA: 5:25 - loss: 0.0845 - sparse_categorical_accuracy: 0.9734\n",
            " 45/469 [=>............................] - ETA: 5:23 - loss: 0.0838 - sparse_categorical_accuracy: 0.9738\n",
            " 46/469 [=>............................] - ETA: 5:22 - loss: 0.0828 - sparse_categorical_accuracy: 0.9742\n",
            " 47/469 [==>...........................] - ETA: 5:20 - loss: 0.0834 - sparse_categorical_accuracy: 0.9739\n",
            " 48/469 [==>...........................] - ETA: 5:19 - loss: 0.0840 - sparse_categorical_accuracy: 0.9738\n",
            " 49/469 [==>...........................] - ETA: 5:20 - loss: 0.0839 - sparse_categorical_accuracy: 0.9735\n",
            " 50/469 [==>...........................] - ETA: 5:23 - loss: 0.0842 - sparse_categorical_accuracy: 0.9736\n",
            " 51/469 [==>...........................] - ETA: 5:25 - loss: 0.0851 - sparse_categorical_accuracy: 0.9737\n",
            " 52/469 [==>...........................] - ETA: 5:24 - loss: 0.0840 - sparse_categorical_accuracy: 0.9742\n",
            " 53/469 [==>...........................] - ETA: 5:23 - loss: 0.0848 - sparse_categorical_accuracy: 0.9742\n",
            " 54/469 [==>...........................] - ETA: 5:21 - loss: 0.0847 - sparse_categorical_accuracy: 0.9741\n",
            " 55/469 [==>...........................] - ETA: 5:20 - loss: 0.0845 - sparse_categorical_accuracy: 0.9741\n",
            " 56/469 [==>...........................] - ETA: 5:18 - loss: 0.0845 - sparse_categorical_accuracy: 0.9741\n",
            " 57/469 [==>...........................] - ETA: 5:17 - loss: 0.0845 - sparse_categorical_accuracy: 0.9741\n",
            " 58/469 [==>...........................] - ETA: 5:15 - loss: 0.0837 - sparse_categorical_accuracy: 0.9744\n",
            " 59/469 [==>...........................] - ETA: 5:14 - loss: 0.0828 - sparse_categorical_accuracy: 0.9746\n",
            " 60/469 [==>...........................] - ETA: 5:13 - loss: 0.0829 - sparse_categorical_accuracy: 0.9746\n",
            " 61/469 [==>...........................] - ETA: 5:12 - loss: 0.0821 - sparse_categorical_accuracy: 0.9750\n",
            " 62/469 [==>...........................] - ETA: 5:11 - loss: 0.0822 - sparse_categorical_accuracy: 0.9751\n",
            " 63/469 [===>..........................] - ETA: 5:10 - loss: 0.0822 - sparse_categorical_accuracy: 0.9751\n",
            " 64/469 [===>..........................] - ETA: 5:09 - loss: 0.0825 - sparse_categorical_accuracy: 0.9750\n",
            " 65/469 [===>..........................] - ETA: 5:08 - loss: 0.0825 - sparse_categorical_accuracy: 0.9750\n",
            " 66/469 [===>..........................] - ETA: 5:08 - loss: 0.0825 - sparse_categorical_accuracy: 0.9749\n",
            " 67/469 [===>..........................] - ETA: 5:09 - loss: 0.0818 - sparse_categorical_accuracy: 0.9750\n",
            " 68/469 [===>..........................] - ETA: 5:11 - loss: 0.0820 - sparse_categorical_accuracy: 0.9752\n",
            " 69/469 [===>..........................] - ETA: 5:12 - loss: 0.0822 - sparse_categorical_accuracy: 0.9750\n",
            " 70/469 [===>..........................] - ETA: 5:11 - loss: 0.0825 - sparse_categorical_accuracy: 0.9749\n",
            " 71/469 [===>..........................] - ETA: 5:10 - loss: 0.0823 - sparse_categorical_accuracy: 0.9750\n",
            " 72/469 [===>..........................] - ETA: 5:09 - loss: 0.0817 - sparse_categorical_accuracy: 0.9752\n",
            " 73/469 [===>..........................] - ETA: 5:08 - loss: 0.0816 - sparse_categorical_accuracy: 0.9750\n",
            " 74/469 [===>..........................] - ETA: 5:07 - loss: 0.0820 - sparse_categorical_accuracy: 0.9748\n",
            " 75/469 [===>..........................] - ETA: 5:06 - loss: 0.0834 - sparse_categorical_accuracy: 0.9742\n",
            " 76/469 [===>..........................] - ETA: 5:04 - loss: 0.0836 - sparse_categorical_accuracy: 0.9739\n",
            " 77/469 [===>..........................] - ETA: 5:03 - loss: 0.0844 - sparse_categorical_accuracy: 0.9737\n",
            " 78/469 [===>..........................] - ETA: 5:02 - loss: 0.0856 - sparse_categorical_accuracy: 0.9736\n",
            " 79/469 [====>.........................] - ETA: 5:01 - loss: 0.0855 - sparse_categorical_accuracy: 0.9737\n",
            " 80/469 [====>.........................] - ETA: 5:00 - loss: 0.0858 - sparse_categorical_accuracy: 0.9737\n",
            " 81/469 [====>.........................] - ETA: 4:59 - loss: 0.0860 - sparse_categorical_accuracy: 0.9735\n",
            " 82/469 [====>.........................] - ETA: 4:58 - loss: 0.0858 - sparse_categorical_accuracy: 0.9736\n",
            " 83/469 [====>.........................] - ETA: 4:58 - loss: 0.0858 - sparse_categorical_accuracy: 0.9738\n",
            " 84/469 [====>.........................] - ETA: 4:59 - loss: 0.0874 - sparse_categorical_accuracy: 0.9733\n",
            " 85/469 [====>.........................] - ETA: 4:59 - loss: 0.0872 - sparse_categorical_accuracy: 0.9733\n",
            " 86/469 [====>.........................] - ETA: 5:00 - loss: 0.0871 - sparse_categorical_accuracy: 0.9733\n",
            " 87/469 [====>.........................] - ETA: 4:59 - loss: 0.0866 - sparse_categorical_accuracy: 0.9736\n",
            " 88/469 [====>.........................] - ETA: 4:58 - loss: 0.0862 - sparse_categorical_accuracy: 0.9736\n",
            " 89/469 [====>.........................] - ETA: 4:57 - loss: 0.0859 - sparse_categorical_accuracy: 0.9738\n",
            " 90/469 [====>.........................] - ETA: 4:55 - loss: 0.0858 - sparse_categorical_accuracy: 0.9738\n",
            " 91/469 [====>.........................] - ETA: 4:54 - loss: 0.0853 - sparse_categorical_accuracy: 0.9740\n",
            " 92/469 [====>.........................] - ETA: 4:53 - loss: 0.0851 - sparse_categorical_accuracy: 0.9739\n",
            " 93/469 [====>.........................] - ETA: 4:52 - loss: 0.0852 - sparse_categorical_accuracy: 0.9741\n",
            " 94/469 [=====>........................] - ETA: 4:51 - loss: 0.0850 - sparse_categorical_accuracy: 0.9742\n",
            " 95/469 [=====>........................] - ETA: 4:50 - loss: 0.0844 - sparse_categorical_accuracy: 0.9743\n",
            " 96/469 [=====>........................] - ETA: 4:49 - loss: 0.0842 - sparse_categorical_accuracy: 0.9743\n",
            " 97/469 [=====>........................] - ETA: 4:48 - loss: 0.0842 - sparse_categorical_accuracy: 0.9743\n",
            " 98/469 [=====>........................] - ETA: 4:47 - loss: 0.0839 - sparse_categorical_accuracy: 0.9743\n",
            " 99/469 [=====>........................] - ETA: 4:46 - loss: 0.0839 - sparse_categorical_accuracy: 0.9744\n",
            "100/469 [=====>........................] - ETA: 4:45 - loss: 0.0839 - sparse_categorical_accuracy: 0.9741\n",
            "101/469 [=====>........................] - ETA: 4:45 - loss: 0.0842 - sparse_categorical_accuracy: 0.9742\n",
            "102/469 [=====>........................] - ETA: 4:46 - loss: 0.0836 - sparse_categorical_accuracy: 0.9744\n",
            "103/469 [=====>........................] - ETA: 4:46 - loss: 0.0834 - sparse_categorical_accuracy: 0.9744\n",
            "104/469 [=====>........................] - ETA: 4:45 - loss: 0.0830 - sparse_categorical_accuracy: 0.9745\n",
            "105/469 [=====>........................] - ETA: 4:44 - loss: 0.0831 - sparse_categorical_accuracy: 0.9746\n",
            "106/469 [=====>........................] - ETA: 4:43 - loss: 0.0835 - sparse_categorical_accuracy: 0.9744\n",
            "107/469 [=====>........................] - ETA: 4:42 - loss: 0.0830 - sparse_categorical_accuracy: 0.9746\n",
            "108/469 [=====>........................] - ETA: 4:41 - loss: 0.0829 - sparse_categorical_accuracy: 0.9745\n",
            "109/469 [=====>........................] - ETA: 4:40 - loss: 0.0828 - sparse_categorical_accuracy: 0.9745\n",
            "110/469 [======>.......................] - ETA: 4:39 - loss: 0.0833 - sparse_categorical_accuracy: 0.9744\n",
            "111/469 [======>.......................] - ETA: 4:38 - loss: 0.0831 - sparse_categorical_accuracy: 0.9743\n",
            "112/469 [======>.......................] - ETA: 4:37 - loss: 0.0828 - sparse_categorical_accuracy: 0.9743\n",
            "113/469 [======>.......................] - ETA: 4:36 - loss: 0.0827 - sparse_categorical_accuracy: 0.9745\n",
            "114/469 [======>.......................] - ETA: 4:35 - loss: 0.0827 - sparse_categorical_accuracy: 0.9745\n",
            "115/469 [======>.......................] - ETA: 4:34 - loss: 0.0826 - sparse_categorical_accuracy: 0.9745\n",
            "116/469 [======>.......................] - ETA: 4:33 - loss: 0.0823 - sparse_categorical_accuracy: 0.9746\n",
            "117/469 [======>.......................] - ETA: 4:32 - loss: 0.0827 - sparse_categorical_accuracy: 0.9746\n",
            "118/469 [======>.......................] - ETA: 4:33 - loss: 0.0832 - sparse_categorical_accuracy: 0.9744\n",
            "119/469 [======>.......................] - ETA: 4:33 - loss: 0.0843 - sparse_categorical_accuracy: 0.9742\n",
            "120/469 [======>.......................] - ETA: 4:33 - loss: 0.0840 - sparse_categorical_accuracy: 0.9743\n",
            "121/469 [======>.......................] - ETA: 4:32 - loss: 0.0837 - sparse_categorical_accuracy: 0.9744\n",
            "122/469 [======>.......................] - ETA: 4:32 - loss: 0.0839 - sparse_categorical_accuracy: 0.9744\n",
            "123/469 [======>.......................] - ETA: 4:31 - loss: 0.0840 - sparse_categorical_accuracy: 0.9743\n",
            "124/469 [======>.......................] - ETA: 4:30 - loss: 0.0839 - sparse_categorical_accuracy: 0.9744\n",
            "125/469 [======>.......................] - ETA: 4:29 - loss: 0.0839 - sparse_categorical_accuracy: 0.9744\n",
            "126/469 [=======>......................] - ETA: 4:28 - loss: 0.0842 - sparse_categorical_accuracy: 0.9743\n",
            "127/469 [=======>......................] - ETA: 4:27 - loss: 0.0843 - sparse_categorical_accuracy: 0.9744\n",
            "128/469 [=======>......................] - ETA: 4:26 - loss: 0.0845 - sparse_categorical_accuracy: 0.9744\n",
            "129/469 [=======>......................] - ETA: 4:25 - loss: 0.0846 - sparse_categorical_accuracy: 0.9743\n",
            "130/469 [=======>......................] - ETA: 4:24 - loss: 0.0843 - sparse_categorical_accuracy: 0.9745\n",
            "131/469 [=======>......................] - ETA: 4:23 - loss: 0.0843 - sparse_categorical_accuracy: 0.9745\n",
            "132/469 [=======>......................] - ETA: 4:22 - loss: 0.0840 - sparse_categorical_accuracy: 0.9746\n",
            "133/469 [=======>......................] - ETA: 4:21 - loss: 0.0845 - sparse_categorical_accuracy: 0.9743\n",
            "134/469 [=======>......................] - ETA: 4:20 - loss: 0.0842 - sparse_categorical_accuracy: 0.9744\n",
            "135/469 [=======>......................] - ETA: 4:20 - loss: 0.0840 - sparse_categorical_accuracy: 0.9744\n",
            "136/469 [=======>......................] - ETA: 4:21 - loss: 0.0841 - sparse_categorical_accuracy: 0.9744\n",
            "137/469 [=======>......................] - ETA: 4:20 - loss: 0.0842 - sparse_categorical_accuracy: 0.9743\n",
            "138/469 [=======>......................] - ETA: 4:20 - loss: 0.0844 - sparse_categorical_accuracy: 0.9744\n",
            "139/469 [=======>......................] - ETA: 4:19 - loss: 0.0842 - sparse_categorical_accuracy: 0.9744\n",
            "140/469 [=======>......................] - ETA: 4:18 - loss: 0.0844 - sparse_categorical_accuracy: 0.9743\n",
            "141/469 [========>.....................] - ETA: 4:17 - loss: 0.0850 - sparse_categorical_accuracy: 0.9742\n",
            "142/469 [========>.....................] - ETA: 4:16 - loss: 0.0853 - sparse_categorical_accuracy: 0.9742\n",
            "143/469 [========>.....................] - ETA: 4:15 - loss: 0.0854 - sparse_categorical_accuracy: 0.9742\n",
            "144/469 [========>.....................] - ETA: 4:14 - loss: 0.0854 - sparse_categorical_accuracy: 0.9741\n",
            "145/469 [========>.....................] - ETA: 4:13 - loss: 0.0855 - sparse_categorical_accuracy: 0.9741\n",
            "146/469 [========>.....................] - ETA: 4:12 - loss: 0.0856 - sparse_categorical_accuracy: 0.9741\n",
            "147/469 [========>.....................] - ETA: 4:11 - loss: 0.0856 - sparse_categorical_accuracy: 0.9741\n",
            "148/469 [========>.....................] - ETA: 4:10 - loss: 0.0858 - sparse_categorical_accuracy: 0.9740\n",
            "149/469 [========>.....................] - ETA: 4:09 - loss: 0.0855 - sparse_categorical_accuracy: 0.9742\n",
            "150/469 [========>.....................] - ETA: 4:08 - loss: 0.0853 - sparse_categorical_accuracy: 0.9742\n",
            "151/469 [========>.....................] - ETA: 4:07 - loss: 0.0853 - sparse_categorical_accuracy: 0.9742\n",
            "152/469 [========>.....................] - ETA: 4:07 - loss: 0.0859 - sparse_categorical_accuracy: 0.9741\n",
            "153/469 [========>.....................] - ETA: 4:07 - loss: 0.0856 - sparse_categorical_accuracy: 0.9742\n",
            "154/469 [========>.....................] - ETA: 4:07 - loss: 0.0853 - sparse_categorical_accuracy: 0.9743\n",
            "155/469 [========>.....................] - ETA: 4:06 - loss: 0.0852 - sparse_categorical_accuracy: 0.9744\n",
            "156/469 [========>.....................] - ETA: 4:05 - loss: 0.0855 - sparse_categorical_accuracy: 0.9744\n",
            "157/469 [=========>....................] - ETA: 4:05 - loss: 0.0851 - sparse_categorical_accuracy: 0.9745\n",
            "158/469 [=========>....................] - ETA: 4:04 - loss: 0.0855 - sparse_categorical_accuracy: 0.9744\n",
            "159/469 [=========>....................] - ETA: 4:03 - loss: 0.0857 - sparse_categorical_accuracy: 0.9743\n",
            "160/469 [=========>....................] - ETA: 4:02 - loss: 0.0855 - sparse_categorical_accuracy: 0.9744\n",
            "161/469 [=========>....................] - ETA: 4:01 - loss: 0.0854 - sparse_categorical_accuracy: 0.9744\n",
            "162/469 [=========>....................] - ETA: 4:00 - loss: 0.0853 - sparse_categorical_accuracy: 0.9744\n",
            "163/469 [=========>....................] - ETA: 3:59 - loss: 0.0861 - sparse_categorical_accuracy: 0.9744\n",
            "164/469 [=========>....................] - ETA: 3:58 - loss: 0.0862 - sparse_categorical_accuracy: 0.9742\n",
            "165/469 [=========>....................] - ETA: 3:57 - loss: 0.0863 - sparse_categorical_accuracy: 0.9742\n",
            "166/469 [=========>....................] - ETA: 3:56 - loss: 0.0863 - sparse_categorical_accuracy: 0.9742\n",
            "167/469 [=========>....................] - ETA: 3:55 - loss: 0.0867 - sparse_categorical_accuracy: 0.9742\n",
            "168/469 [=========>....................] - ETA: 3:54 - loss: 0.0865 - sparse_categorical_accuracy: 0.9742\n",
            "169/469 [=========>....................] - ETA: 3:53 - loss: 0.0862 - sparse_categorical_accuracy: 0.9743\n",
            "170/469 [=========>....................] - ETA: 3:53 - loss: 0.0858 - sparse_categorical_accuracy: 0.9745\n",
            "171/469 [=========>....................] - ETA: 3:53 - loss: 0.0857 - sparse_categorical_accuracy: 0.9746\n",
            "172/469 [==========>...................] - ETA: 3:53 - loss: 0.0856 - sparse_categorical_accuracy: 0.9746\n",
            "173/469 [==========>...................] - ETA: 3:52 - loss: 0.0858 - sparse_categorical_accuracy: 0.9745\n",
            "174/469 [==========>...................] - ETA: 3:51 - loss: 0.0860 - sparse_categorical_accuracy: 0.9744\n",
            "175/469 [==========>...................] - ETA: 3:50 - loss: 0.0860 - sparse_categorical_accuracy: 0.9743\n",
            "176/469 [==========>...................] - ETA: 3:49 - loss: 0.0860 - sparse_categorical_accuracy: 0.9743\n",
            "177/469 [==========>...................] - ETA: 3:48 - loss: 0.0856 - sparse_categorical_accuracy: 0.9744\n",
            "178/469 [==========>...................] - ETA: 3:47 - loss: 0.0856 - sparse_categorical_accuracy: 0.9745\n",
            "179/469 [==========>...................] - ETA: 3:47 - loss: 0.0854 - sparse_categorical_accuracy: 0.9746\n",
            "180/469 [==========>...................] - ETA: 3:46 - loss: 0.0853 - sparse_categorical_accuracy: 0.9747\n",
            "181/469 [==========>...................] - ETA: 3:45 - loss: 0.0850 - sparse_categorical_accuracy: 0.9747\n",
            "182/469 [==========>...................] - ETA: 3:44 - loss: 0.0853 - sparse_categorical_accuracy: 0.9746\n",
            "183/469 [==========>...................] - ETA: 3:43 - loss: 0.0850 - sparse_categorical_accuracy: 0.9747\n",
            "184/469 [==========>...................] - ETA: 3:42 - loss: 0.0849 - sparse_categorical_accuracy: 0.9748\n",
            "185/469 [==========>...................] - ETA: 3:41 - loss: 0.0849 - sparse_categorical_accuracy: 0.9747\n",
            "186/469 [==========>...................] - ETA: 3:40 - loss: 0.0850 - sparse_categorical_accuracy: 0.9746\n",
            "187/469 [==========>...................] - ETA: 3:40 - loss: 0.0848 - sparse_categorical_accuracy: 0.9746\n",
            "188/469 [===========>..................] - ETA: 3:40 - loss: 0.0846 - sparse_categorical_accuracy: 0.9747\n",
            "189/469 [===========>..................] - ETA: 3:40 - loss: 0.0845 - sparse_categorical_accuracy: 0.9747\n",
            "190/469 [===========>..................] - ETA: 3:39 - loss: 0.0845 - sparse_categorical_accuracy: 0.9746\n",
            "191/469 [===========>..................] - ETA: 3:38 - loss: 0.0846 - sparse_categorical_accuracy: 0.9746\n",
            "192/469 [===========>..................] - ETA: 3:37 - loss: 0.0844 - sparse_categorical_accuracy: 0.9747\n",
            "193/469 [===========>..................] - ETA: 3:36 - loss: 0.0846 - sparse_categorical_accuracy: 0.9745\n",
            "194/469 [===========>..................] - ETA: 3:35 - loss: 0.0845 - sparse_categorical_accuracy: 0.9745\n",
            "195/469 [===========>..................] - ETA: 3:34 - loss: 0.0845 - sparse_categorical_accuracy: 0.9745\n",
            "196/469 [===========>..................] - ETA: 3:33 - loss: 0.0846 - sparse_categorical_accuracy: 0.9744\n",
            "197/469 [===========>..................] - ETA: 3:33 - loss: 0.0847 - sparse_categorical_accuracy: 0.9744\n",
            "198/469 [===========>..................] - ETA: 3:32 - loss: 0.0851 - sparse_categorical_accuracy: 0.9743\n",
            "199/469 [===========>..................] - ETA: 3:31 - loss: 0.0849 - sparse_categorical_accuracy: 0.9743\n",
            "200/469 [===========>..................] - ETA: 3:30 - loss: 0.0847 - sparse_categorical_accuracy: 0.9744\n",
            "201/469 [===========>..................] - ETA: 3:29 - loss: 0.0846 - sparse_categorical_accuracy: 0.9745\n",
            "202/469 [===========>..................] - ETA: 3:28 - loss: 0.0848 - sparse_categorical_accuracy: 0.9744\n",
            "203/469 [===========>..................] - ETA: 3:28 - loss: 0.0845 - sparse_categorical_accuracy: 0.9745\n",
            "204/469 [============>.................] - ETA: 3:27 - loss: 0.0844 - sparse_categorical_accuracy: 0.9746\n",
            "205/469 [============>.................] - ETA: 3:27 - loss: 0.0844 - sparse_categorical_accuracy: 0.9746\n",
            "206/469 [============>.................] - ETA: 3:26 - loss: 0.0845 - sparse_categorical_accuracy: 0.9745\n",
            "207/469 [============>.................] - ETA: 3:26 - loss: 0.0846 - sparse_categorical_accuracy: 0.9744\n",
            "208/469 [============>.................] - ETA: 3:25 - loss: 0.0844 - sparse_categorical_accuracy: 0.9745\n",
            "209/469 [============>.................] - ETA: 3:24 - loss: 0.0842 - sparse_categorical_accuracy: 0.9746\n",
            "210/469 [============>.................] - ETA: 3:23 - loss: 0.0840 - sparse_categorical_accuracy: 0.9747\n",
            "211/469 [============>.................] - ETA: 3:23 - loss: 0.0841 - sparse_categorical_accuracy: 0.9746\n",
            "212/469 [============>.................] - ETA: 3:22 - loss: 0.0840 - sparse_categorical_accuracy: 0.9747\n",
            "213/469 [============>.................] - ETA: 3:21 - loss: 0.0843 - sparse_categorical_accuracy: 0.9746\n",
            "214/469 [============>.................] - ETA: 3:20 - loss: 0.0842 - sparse_categorical_accuracy: 0.9747\n",
            "215/469 [============>.................] - ETA: 3:19 - loss: 0.0843 - sparse_categorical_accuracy: 0.9746\n",
            "216/469 [============>.................] - ETA: 3:18 - loss: 0.0846 - sparse_categorical_accuracy: 0.9746\n",
            "217/469 [============>.................] - ETA: 3:17 - loss: 0.0850 - sparse_categorical_accuracy: 0.9746\n",
            "218/469 [============>.................] - ETA: 3:17 - loss: 0.0850 - sparse_categorical_accuracy: 0.9746\n",
            "219/469 [=============>................] - ETA: 3:16 - loss: 0.0855 - sparse_categorical_accuracy: 0.9746\n",
            "220/469 [=============>................] - ETA: 3:15 - loss: 0.0858 - sparse_categorical_accuracy: 0.9745\n",
            "221/469 [=============>................] - ETA: 3:14 - loss: 0.0859 - sparse_categorical_accuracy: 0.9745\n",
            "222/469 [=============>................] - ETA: 3:14 - loss: 0.0864 - sparse_categorical_accuracy: 0.9744\n",
            "223/469 [=============>................] - ETA: 3:13 - loss: 0.0863 - sparse_categorical_accuracy: 0.9744\n",
            "224/469 [=============>................] - ETA: 3:13 - loss: 0.0860 - sparse_categorical_accuracy: 0.9745\n",
            "225/469 [=============>................] - ETA: 3:12 - loss: 0.0860 - sparse_categorical_accuracy: 0.9745\n",
            "226/469 [=============>................] - ETA: 3:11 - loss: 0.0858 - sparse_categorical_accuracy: 0.9746\n",
            "227/469 [=============>................] - ETA: 3:10 - loss: 0.0860 - sparse_categorical_accuracy: 0.9745\n",
            "228/469 [=============>................] - ETA: 3:09 - loss: 0.0859 - sparse_categorical_accuracy: 0.9745\n",
            "229/469 [=============>................] - ETA: 3:09 - loss: 0.0858 - sparse_categorical_accuracy: 0.9746\n",
            "230/469 [=============>................] - ETA: 3:08 - loss: 0.0857 - sparse_categorical_accuracy: 0.9746\n",
            "231/469 [=============>................] - ETA: 3:07 - loss: 0.0856 - sparse_categorical_accuracy: 0.9746\n",
            "232/469 [=============>................] - ETA: 3:06 - loss: 0.0857 - sparse_categorical_accuracy: 0.9746\n",
            "233/469 [=============>................] - ETA: 3:05 - loss: 0.0857 - sparse_categorical_accuracy: 0.9746\n",
            "234/469 [=============>................] - ETA: 3:04 - loss: 0.0856 - sparse_categorical_accuracy: 0.9746\n",
            "235/469 [==============>...............] - ETA: 3:04 - loss: 0.0855 - sparse_categorical_accuracy: 0.9747\n",
            "236/469 [==============>...............] - ETA: 3:03 - loss: 0.0853 - sparse_categorical_accuracy: 0.9747\n",
            "237/469 [==============>...............] - ETA: 3:02 - loss: 0.0856 - sparse_categorical_accuracy: 0.9747\n",
            "238/469 [==============>...............] - ETA: 3:01 - loss: 0.0855 - sparse_categorical_accuracy: 0.9747\n",
            "239/469 [==============>...............] - ETA: 3:01 - loss: 0.0854 - sparse_categorical_accuracy: 0.9747\n",
            "240/469 [==============>...............] - ETA: 3:00 - loss: 0.0855 - sparse_categorical_accuracy: 0.9747\n",
            "241/469 [==============>...............] - ETA: 3:00 - loss: 0.0857 - sparse_categorical_accuracy: 0.9747\n",
            "242/469 [==============>...............] - ETA: 2:59 - loss: 0.0859 - sparse_categorical_accuracy: 0.9746\n",
            "243/469 [==============>...............] - ETA: 2:58 - loss: 0.0859 - sparse_categorical_accuracy: 0.9746\n",
            "244/469 [==============>...............] - ETA: 2:57 - loss: 0.0857 - sparse_categorical_accuracy: 0.9747\n",
            "245/469 [==============>...............] - ETA: 2:56 - loss: 0.0856 - sparse_categorical_accuracy: 0.9747\n",
            "246/469 [==============>...............] - ETA: 2:55 - loss: 0.0854 - sparse_categorical_accuracy: 0.9748\n",
            "247/469 [==============>...............] - ETA: 2:55 - loss: 0.0854 - sparse_categorical_accuracy: 0.9748\n",
            "248/469 [==============>...............] - ETA: 2:54 - loss: 0.0856 - sparse_categorical_accuracy: 0.9747\n",
            "249/469 [==============>...............] - ETA: 2:53 - loss: 0.0854 - sparse_categorical_accuracy: 0.9748\n",
            "250/469 [==============>...............] - ETA: 2:52 - loss: 0.0852 - sparse_categorical_accuracy: 0.9748\n",
            "251/469 [===============>..............] - ETA: 2:51 - loss: 0.0853 - sparse_categorical_accuracy: 0.9748\n",
            "252/469 [===============>..............] - ETA: 2:50 - loss: 0.0851 - sparse_categorical_accuracy: 0.9749\n",
            "253/469 [===============>..............] - ETA: 2:49 - loss: 0.0852 - sparse_categorical_accuracy: 0.9749\n",
            "254/469 [===============>..............] - ETA: 2:49 - loss: 0.0853 - sparse_categorical_accuracy: 0.9749\n",
            "255/469 [===============>..............] - ETA: 2:48 - loss: 0.0852 - sparse_categorical_accuracy: 0.9749\n",
            "256/469 [===============>..............] - ETA: 2:47 - loss: 0.0852 - sparse_categorical_accuracy: 0.9749\n",
            "257/469 [===============>..............] - ETA: 2:47 - loss: 0.0853 - sparse_categorical_accuracy: 0.9749\n",
            "258/469 [===============>..............] - ETA: 2:46 - loss: 0.0851 - sparse_categorical_accuracy: 0.9749\n",
            "259/469 [===============>..............] - ETA: 2:45 - loss: 0.0850 - sparse_categorical_accuracy: 0.9750\n",
            "260/469 [===============>..............] - ETA: 2:45 - loss: 0.0850 - sparse_categorical_accuracy: 0.9750\n",
            "261/469 [===============>..............] - ETA: 2:44 - loss: 0.0849 - sparse_categorical_accuracy: 0.9750\n",
            "262/469 [===============>..............] - ETA: 2:43 - loss: 0.0851 - sparse_categorical_accuracy: 0.9749\n",
            "263/469 [===============>..............] - ETA: 2:42 - loss: 0.0849 - sparse_categorical_accuracy: 0.9749\n",
            "264/469 [===============>..............] - ETA: 2:41 - loss: 0.0848 - sparse_categorical_accuracy: 0.9750\n",
            "265/469 [===============>..............] - ETA: 2:40 - loss: 0.0847 - sparse_categorical_accuracy: 0.9750\n",
            "266/469 [================>.............] - ETA: 2:39 - loss: 0.0849 - sparse_categorical_accuracy: 0.9749\n",
            "267/469 [================>.............] - ETA: 2:39 - loss: 0.0849 - sparse_categorical_accuracy: 0.9749\n",
            "268/469 [================>.............] - ETA: 2:38 - loss: 0.0849 - sparse_categorical_accuracy: 0.9749\n",
            "269/469 [================>.............] - ETA: 2:37 - loss: 0.0847 - sparse_categorical_accuracy: 0.9750\n",
            "270/469 [================>.............] - ETA: 2:36 - loss: 0.0847 - sparse_categorical_accuracy: 0.9749\n",
            "271/469 [================>.............] - ETA: 2:35 - loss: 0.0847 - sparse_categorical_accuracy: 0.9749\n",
            "272/469 [================>.............] - ETA: 2:34 - loss: 0.0846 - sparse_categorical_accuracy: 0.9750\n",
            "273/469 [================>.............] - ETA: 2:34 - loss: 0.0845 - sparse_categorical_accuracy: 0.9749\n",
            "274/469 [================>.............] - ETA: 2:33 - loss: 0.0845 - sparse_categorical_accuracy: 0.9749\n",
            "275/469 [================>.............] - ETA: 2:33 - loss: 0.0846 - sparse_categorical_accuracy: 0.9749\n",
            "276/469 [================>.............] - ETA: 2:32 - loss: 0.0848 - sparse_categorical_accuracy: 0.9748\n",
            "277/469 [================>.............] - ETA: 2:31 - loss: 0.0850 - sparse_categorical_accuracy: 0.9748\n",
            "278/469 [================>.............] - ETA: 2:30 - loss: 0.0850 - sparse_categorical_accuracy: 0.9748\n",
            "279/469 [================>.............] - ETA: 2:29 - loss: 0.0849 - sparse_categorical_accuracy: 0.9748\n",
            "280/469 [================>.............] - ETA: 2:28 - loss: 0.0849 - sparse_categorical_accuracy: 0.9748\n",
            "281/469 [================>.............] - ETA: 2:28 - loss: 0.0849 - sparse_categorical_accuracy: 0.9748\n",
            "282/469 [=================>............] - ETA: 2:27 - loss: 0.0852 - sparse_categorical_accuracy: 0.9748\n",
            "283/469 [=================>............] - ETA: 2:26 - loss: 0.0851 - sparse_categorical_accuracy: 0.9748\n",
            "284/469 [=================>............] - ETA: 2:25 - loss: 0.0849 - sparse_categorical_accuracy: 0.9749\n",
            "285/469 [=================>............] - ETA: 2:24 - loss: 0.0848 - sparse_categorical_accuracy: 0.9748\n",
            "286/469 [=================>............] - ETA: 2:23 - loss: 0.0849 - sparse_categorical_accuracy: 0.9747\n",
            "287/469 [=================>............] - ETA: 2:23 - loss: 0.0850 - sparse_categorical_accuracy: 0.9747\n",
            "288/469 [=================>............] - ETA: 2:22 - loss: 0.0850 - sparse_categorical_accuracy: 0.9747\n",
            "289/469 [=================>............] - ETA: 2:21 - loss: 0.0849 - sparse_categorical_accuracy: 0.9747\n",
            "290/469 [=================>............] - ETA: 2:20 - loss: 0.0849 - sparse_categorical_accuracy: 0.9747\n",
            "291/469 [=================>............] - ETA: 2:20 - loss: 0.0847 - sparse_categorical_accuracy: 0.9748\n",
            "292/469 [=================>............] - ETA: 2:19 - loss: 0.0848 - sparse_categorical_accuracy: 0.9747\n",
            "293/469 [=================>............] - ETA: 2:18 - loss: 0.0850 - sparse_categorical_accuracy: 0.9747\n",
            "294/469 [=================>............] - ETA: 2:18 - loss: 0.0849 - sparse_categorical_accuracy: 0.9747\n",
            "295/469 [=================>............] - ETA: 2:17 - loss: 0.0848 - sparse_categorical_accuracy: 0.9748\n",
            "296/469 [=================>............] - ETA: 2:16 - loss: 0.0846 - sparse_categorical_accuracy: 0.9748\n",
            "297/469 [=================>............] - ETA: 2:15 - loss: 0.0845 - sparse_categorical_accuracy: 0.9749\n",
            "298/469 [==================>...........] - ETA: 2:14 - loss: 0.0846 - sparse_categorical_accuracy: 0.9748\n",
            "299/469 [==================>...........] - ETA: 2:14 - loss: 0.0845 - sparse_categorical_accuracy: 0.9748\n",
            "300/469 [==================>...........] - ETA: 2:13 - loss: 0.0846 - sparse_categorical_accuracy: 0.9748\n",
            "301/469 [==================>...........] - ETA: 2:12 - loss: 0.0846 - sparse_categorical_accuracy: 0.9748\n",
            "302/469 [==================>...........] - ETA: 2:11 - loss: 0.0845 - sparse_categorical_accuracy: 0.9749\n",
            "303/469 [==================>...........] - ETA: 2:10 - loss: 0.0844 - sparse_categorical_accuracy: 0.9748\n",
            "304/469 [==================>...........] - ETA: 2:09 - loss: 0.0844 - sparse_categorical_accuracy: 0.9748\n",
            "305/469 [==================>...........] - ETA: 2:09 - loss: 0.0844 - sparse_categorical_accuracy: 0.9747\n",
            "306/469 [==================>...........] - ETA: 2:08 - loss: 0.0843 - sparse_categorical_accuracy: 0.9748\n",
            "307/469 [==================>...........] - ETA: 2:07 - loss: 0.0842 - sparse_categorical_accuracy: 0.9748\n",
            "308/469 [==================>...........] - ETA: 2:07 - loss: 0.0841 - sparse_categorical_accuracy: 0.9749\n",
            "309/469 [==================>...........] - ETA: 2:06 - loss: 0.0840 - sparse_categorical_accuracy: 0.9749\n",
            "310/469 [==================>...........] - ETA: 2:05 - loss: 0.0838 - sparse_categorical_accuracy: 0.9749\n",
            "311/469 [==================>...........] - ETA: 2:04 - loss: 0.0838 - sparse_categorical_accuracy: 0.9749\n",
            "312/469 [==================>...........] - ETA: 2:04 - loss: 0.0838 - sparse_categorical_accuracy: 0.9749\n",
            "313/469 [===================>..........] - ETA: 2:03 - loss: 0.0839 - sparse_categorical_accuracy: 0.9749\n",
            "314/469 [===================>..........] - ETA: 2:02 - loss: 0.0839 - sparse_categorical_accuracy: 0.9749\n",
            "315/469 [===================>..........] - ETA: 2:01 - loss: 0.0840 - sparse_categorical_accuracy: 0.9749\n",
            "316/469 [===================>..........] - ETA: 2:00 - loss: 0.0839 - sparse_categorical_accuracy: 0.9748\n",
            "317/469 [===================>..........] - ETA: 1:59 - loss: 0.0839 - sparse_categorical_accuracy: 0.9748\n",
            "318/469 [===================>..........] - ETA: 1:59 - loss: 0.0838 - sparse_categorical_accuracy: 0.9749\n",
            "319/469 [===================>..........] - ETA: 1:58 - loss: 0.0837 - sparse_categorical_accuracy: 0.9749\n",
            "320/469 [===================>..........] - ETA: 1:57 - loss: 0.0837 - sparse_categorical_accuracy: 0.9749\n",
            "321/469 [===================>..........] - ETA: 1:56 - loss: 0.0836 - sparse_categorical_accuracy: 0.9749\n",
            "322/469 [===================>..........] - ETA: 1:55 - loss: 0.0837 - sparse_categorical_accuracy: 0.9749\n",
            "323/469 [===================>..........] - ETA: 1:55 - loss: 0.0835 - sparse_categorical_accuracy: 0.9749\n",
            "324/469 [===================>..........] - ETA: 1:54 - loss: 0.0834 - sparse_categorical_accuracy: 0.9749\n",
            "325/469 [===================>..........] - ETA: 1:53 - loss: 0.0834 - sparse_categorical_accuracy: 0.9750\n",
            "326/469 [===================>..........] - ETA: 1:53 - loss: 0.0834 - sparse_categorical_accuracy: 0.9749\n",
            "327/469 [===================>..........] - ETA: 1:52 - loss: 0.0833 - sparse_categorical_accuracy: 0.9750\n",
            "328/469 [===================>..........] - ETA: 1:51 - loss: 0.0833 - sparse_categorical_accuracy: 0.9749\n",
            "329/469 [====================>.........] - ETA: 1:50 - loss: 0.0832 - sparse_categorical_accuracy: 0.9750\n",
            "330/469 [====================>.........] - ETA: 1:49 - loss: 0.0834 - sparse_categorical_accuracy: 0.9749\n",
            "331/469 [====================>.........] - ETA: 1:48 - loss: 0.0833 - sparse_categorical_accuracy: 0.9749\n",
            "332/469 [====================>.........] - ETA: 1:48 - loss: 0.0833 - sparse_categorical_accuracy: 0.9749\n",
            "333/469 [====================>.........] - ETA: 1:47 - loss: 0.0834 - sparse_categorical_accuracy: 0.9749\n",
            "334/469 [====================>.........] - ETA: 1:46 - loss: 0.0833 - sparse_categorical_accuracy: 0.9749\n",
            "335/469 [====================>.........] - ETA: 1:45 - loss: 0.0835 - sparse_categorical_accuracy: 0.9749\n",
            "336/469 [====================>.........] - ETA: 1:44 - loss: 0.0834 - sparse_categorical_accuracy: 0.9750\n",
            "337/469 [====================>.........] - ETA: 1:44 - loss: 0.0832 - sparse_categorical_accuracy: 0.9750\n",
            "338/469 [====================>.........] - ETA: 1:43 - loss: 0.0834 - sparse_categorical_accuracy: 0.9750\n",
            "339/469 [====================>.........] - ETA: 1:42 - loss: 0.0834 - sparse_categorical_accuracy: 0.9749\n",
            "340/469 [====================>.........] - ETA: 1:41 - loss: 0.0834 - sparse_categorical_accuracy: 0.9749\n",
            "341/469 [====================>.........] - ETA: 1:40 - loss: 0.0833 - sparse_categorical_accuracy: 0.9750\n",
            "342/469 [====================>.........] - ETA: 1:40 - loss: 0.0832 - sparse_categorical_accuracy: 0.9750\n",
            "343/469 [====================>.........] - ETA: 1:39 - loss: 0.0831 - sparse_categorical_accuracy: 0.9750\n",
            "344/469 [=====================>........] - ETA: 1:38 - loss: 0.0830 - sparse_categorical_accuracy: 0.9750\n",
            "345/469 [=====================>........] - ETA: 1:38 - loss: 0.0830 - sparse_categorical_accuracy: 0.9750\n",
            "346/469 [=====================>........] - ETA: 1:37 - loss: 0.0832 - sparse_categorical_accuracy: 0.9750\n",
            "347/469 [=====================>........] - ETA: 1:36 - loss: 0.0832 - sparse_categorical_accuracy: 0.9749\n",
            "348/469 [=====================>........] - ETA: 1:35 - loss: 0.0837 - sparse_categorical_accuracy: 0.9749\n",
            "349/469 [=====================>........] - ETA: 1:34 - loss: 0.0837 - sparse_categorical_accuracy: 0.9749\n",
            "350/469 [=====================>........] - ETA: 1:33 - loss: 0.0837 - sparse_categorical_accuracy: 0.9749\n",
            "351/469 [=====================>........] - ETA: 1:33 - loss: 0.0837 - sparse_categorical_accuracy: 0.9748\n",
            "352/469 [=====================>........] - ETA: 1:32 - loss: 0.0836 - sparse_categorical_accuracy: 0.9749\n",
            "353/469 [=====================>........] - ETA: 1:31 - loss: 0.0837 - sparse_categorical_accuracy: 0.9748\n",
            "354/469 [=====================>........] - ETA: 1:30 - loss: 0.0836 - sparse_categorical_accuracy: 0.9748\n",
            "355/469 [=====================>........] - ETA: 1:29 - loss: 0.0836 - sparse_categorical_accuracy: 0.9748\n",
            "356/469 [=====================>........] - ETA: 1:29 - loss: 0.0835 - sparse_categorical_accuracy: 0.9749\n",
            "357/469 [=====================>........] - ETA: 1:28 - loss: 0.0834 - sparse_categorical_accuracy: 0.9749\n",
            "358/469 [=====================>........] - ETA: 1:27 - loss: 0.0834 - sparse_categorical_accuracy: 0.9749\n",
            "359/469 [=====================>........] - ETA: 1:26 - loss: 0.0837 - sparse_categorical_accuracy: 0.9748\n",
            "360/469 [======================>.......] - ETA: 1:25 - loss: 0.0836 - sparse_categorical_accuracy: 0.9748\n",
            "361/469 [======================>.......] - ETA: 1:25 - loss: 0.0839 - sparse_categorical_accuracy: 0.9748\n",
            "362/469 [======================>.......] - ETA: 1:24 - loss: 0.0837 - sparse_categorical_accuracy: 0.9749\n",
            "363/469 [======================>.......] - ETA: 1:23 - loss: 0.0838 - sparse_categorical_accuracy: 0.9748\n",
            "364/469 [======================>.......] - ETA: 1:22 - loss: 0.0837 - sparse_categorical_accuracy: 0.9748\n",
            "365/469 [======================>.......] - ETA: 1:22 - loss: 0.0838 - sparse_categorical_accuracy: 0.9748\n",
            "366/469 [======================>.......] - ETA: 1:21 - loss: 0.0838 - sparse_categorical_accuracy: 0.9748\n",
            "367/469 [======================>.......] - ETA: 1:20 - loss: 0.0838 - sparse_categorical_accuracy: 0.9748\n",
            "368/469 [======================>.......] - ETA: 1:19 - loss: 0.0837 - sparse_categorical_accuracy: 0.9748\n",
            "369/469 [======================>.......] - ETA: 1:18 - loss: 0.0837 - sparse_categorical_accuracy: 0.9749\n",
            "370/469 [======================>.......] - ETA: 1:18 - loss: 0.0836 - sparse_categorical_accuracy: 0.9749\n",
            "371/469 [======================>.......] - ETA: 1:17 - loss: 0.0834 - sparse_categorical_accuracy: 0.9749\n",
            "372/469 [======================>.......] - ETA: 1:16 - loss: 0.0833 - sparse_categorical_accuracy: 0.9750\n",
            "373/469 [======================>.......] - ETA: 1:15 - loss: 0.0833 - sparse_categorical_accuracy: 0.9750\n",
            "374/469 [======================>.......] - ETA: 1:14 - loss: 0.0834 - sparse_categorical_accuracy: 0.9750\n",
            "375/469 [======================>.......] - ETA: 1:14 - loss: 0.0834 - sparse_categorical_accuracy: 0.9750\n",
            "376/469 [=======================>......] - ETA: 1:13 - loss: 0.0834 - sparse_categorical_accuracy: 0.9750\n",
            "377/469 [=======================>......] - ETA: 1:12 - loss: 0.0833 - sparse_categorical_accuracy: 0.9750\n",
            "378/469 [=======================>......] - ETA: 1:11 - loss: 0.0833 - sparse_categorical_accuracy: 0.9750\n",
            "379/469 [=======================>......] - ETA: 1:11 - loss: 0.0832 - sparse_categorical_accuracy: 0.9750\n",
            "380/469 [=======================>......] - ETA: 1:10 - loss: 0.0831 - sparse_categorical_accuracy: 0.9751\n",
            "381/469 [=======================>......] - ETA: 1:09 - loss: 0.0829 - sparse_categorical_accuracy: 0.9751\n",
            "382/469 [=======================>......] - ETA: 1:08 - loss: 0.0828 - sparse_categorical_accuracy: 0.9752\n",
            "383/469 [=======================>......] - ETA: 1:07 - loss: 0.0829 - sparse_categorical_accuracy: 0.9751\n",
            "384/469 [=======================>......] - ETA: 1:07 - loss: 0.0828 - sparse_categorical_accuracy: 0.9751\n",
            "385/469 [=======================>......] - ETA: 1:06 - loss: 0.0828 - sparse_categorical_accuracy: 0.9751\n",
            "386/469 [=======================>......] - ETA: 1:05 - loss: 0.0827 - sparse_categorical_accuracy: 0.9752\n",
            "387/469 [=======================>......] - ETA: 1:04 - loss: 0.0826 - sparse_categorical_accuracy: 0.9752\n",
            "388/469 [=======================>......] - ETA: 1:03 - loss: 0.0827 - sparse_categorical_accuracy: 0.9752\n",
            "389/469 [=======================>......] - ETA: 1:03 - loss: 0.0826 - sparse_categorical_accuracy: 0.9752\n",
            "390/469 [=======================>......] - ETA: 1:02 - loss: 0.0827 - sparse_categorical_accuracy: 0.9752\n",
            "391/469 [========================>.....] - ETA: 1:01 - loss: 0.0826 - sparse_categorical_accuracy: 0.9752\n",
            "392/469 [========================>.....] - ETA: 1:00 - loss: 0.0826 - sparse_categorical_accuracy: 0.9752\n",
            "393/469 [========================>.....] - ETA: 59s - loss: 0.0826 - sparse_categorical_accuracy: 0.9752 \n",
            "394/469 [========================>.....] - ETA: 59s - loss: 0.0825 - sparse_categorical_accuracy: 0.9752\n",
            "395/469 [========================>.....] - ETA: 58s - loss: 0.0825 - sparse_categorical_accuracy: 0.9752\n",
            "396/469 [========================>.....] - ETA: 57s - loss: 0.0826 - sparse_categorical_accuracy: 0.9752\n",
            "397/469 [========================>.....] - ETA: 56s - loss: 0.0827 - sparse_categorical_accuracy: 0.9751\n",
            "398/469 [========================>.....] - ETA: 56s - loss: 0.0827 - sparse_categorical_accuracy: 0.9751\n",
            "399/469 [========================>.....] - ETA: 55s - loss: 0.0827 - sparse_categorical_accuracy: 0.9751\n",
            "400/469 [========================>.....] - ETA: 54s - loss: 0.0826 - sparse_categorical_accuracy: 0.9752\n",
            "401/469 [========================>.....] - ETA: 53s - loss: 0.0825 - sparse_categorical_accuracy: 0.9752\n",
            "402/469 [========================>.....] - ETA: 52s - loss: 0.0825 - sparse_categorical_accuracy: 0.9752\n",
            "403/469 [========================>.....] - ETA: 52s - loss: 0.0824 - sparse_categorical_accuracy: 0.9752\n",
            "404/469 [========================>.....] - ETA: 51s - loss: 0.0823 - sparse_categorical_accuracy: 0.9752\n",
            "405/469 [========================>.....] - ETA: 50s - loss: 0.0824 - sparse_categorical_accuracy: 0.9752\n",
            "406/469 [========================>.....] - ETA: 49s - loss: 0.0824 - sparse_categorical_accuracy: 0.9752\n",
            "407/469 [=========================>....] - ETA: 48s - loss: 0.0825 - sparse_categorical_accuracy: 0.9752\n",
            "408/469 [=========================>....] - ETA: 48s - loss: 0.0824 - sparse_categorical_accuracy: 0.9753\n",
            "409/469 [=========================>....] - ETA: 47s - loss: 0.0824 - sparse_categorical_accuracy: 0.9752\n",
            "410/469 [=========================>....] - ETA: 46s - loss: 0.0823 - sparse_categorical_accuracy: 0.9753\n",
            "411/469 [=========================>....] - ETA: 45s - loss: 0.0822 - sparse_categorical_accuracy: 0.9753\n",
            "412/469 [=========================>....] - ETA: 45s - loss: 0.0823 - sparse_categorical_accuracy: 0.9753\n",
            "413/469 [=========================>....] - ETA: 44s - loss: 0.0821 - sparse_categorical_accuracy: 0.9753\n",
            "414/469 [=========================>....] - ETA: 43s - loss: 0.0821 - sparse_categorical_accuracy: 0.9753\n",
            "415/469 [=========================>....] - ETA: 42s - loss: 0.0820 - sparse_categorical_accuracy: 0.9754\n",
            "416/469 [=========================>....] - ETA: 41s - loss: 0.0820 - sparse_categorical_accuracy: 0.9754\n",
            "417/469 [=========================>....] - ETA: 41s - loss: 0.0819 - sparse_categorical_accuracy: 0.9754\n",
            "418/469 [=========================>....] - ETA: 40s - loss: 0.0819 - sparse_categorical_accuracy: 0.9754\n",
            "419/469 [=========================>....] - ETA: 39s - loss: 0.0818 - sparse_categorical_accuracy: 0.9754\n",
            "420/469 [=========================>....] - ETA: 38s - loss: 0.0819 - sparse_categorical_accuracy: 0.9754\n",
            "421/469 [=========================>....] - ETA: 37s - loss: 0.0819 - sparse_categorical_accuracy: 0.9754\n",
            "422/469 [=========================>....] - ETA: 37s - loss: 0.0818 - sparse_categorical_accuracy: 0.9754\n",
            "423/469 [==========================>...] - ETA: 36s - loss: 0.0818 - sparse_categorical_accuracy: 0.9754\n",
            "424/469 [==========================>...] - ETA: 35s - loss: 0.0819 - sparse_categorical_accuracy: 0.9754\n",
            "425/469 [==========================>...] - ETA: 34s - loss: 0.0820 - sparse_categorical_accuracy: 0.9754\n",
            "426/469 [==========================>...] - ETA: 33s - loss: 0.0820 - sparse_categorical_accuracy: 0.9754\n",
            "427/469 [==========================>...] - ETA: 33s - loss: 0.0819 - sparse_categorical_accuracy: 0.9754\n",
            "428/469 [==========================>...] - ETA: 32s - loss: 0.0819 - sparse_categorical_accuracy: 0.9754\n",
            "429/469 [==========================>...] - ETA: 31s - loss: 0.0819 - sparse_categorical_accuracy: 0.9754\n",
            "430/469 [==========================>...] - ETA: 30s - loss: 0.0819 - sparse_categorical_accuracy: 0.9754\n",
            "431/469 [==========================>...] - ETA: 30s - loss: 0.0819 - sparse_categorical_accuracy: 0.9754\n",
            "432/469 [==========================>...] - ETA: 29s - loss: 0.0818 - sparse_categorical_accuracy: 0.9754\n",
            "433/469 [==========================>...] - ETA: 28s - loss: 0.0819 - sparse_categorical_accuracy: 0.9754\n",
            "434/469 [==========================>...] - ETA: 27s - loss: 0.0819 - sparse_categorical_accuracy: 0.9754\n",
            "435/469 [==========================>...] - ETA: 26s - loss: 0.0817 - sparse_categorical_accuracy: 0.9754\n",
            "436/469 [==========================>...] - ETA: 26s - loss: 0.0818 - sparse_categorical_accuracy: 0.9754\n",
            "437/469 [==========================>...] - ETA: 25s - loss: 0.0818 - sparse_categorical_accuracy: 0.9754\n",
            "438/469 [===========================>..] - ETA: 24s - loss: 0.0818 - sparse_categorical_accuracy: 0.9754\n",
            "439/469 [===========================>..] - ETA: 23s - loss: 0.0818 - sparse_categorical_accuracy: 0.9754\n",
            "440/469 [===========================>..] - ETA: 22s - loss: 0.0820 - sparse_categorical_accuracy: 0.9753\n",
            "441/469 [===========================>..] - ETA: 22s - loss: 0.0820 - sparse_categorical_accuracy: 0.9753\n",
            "442/469 [===========================>..] - ETA: 21s - loss: 0.0819 - sparse_categorical_accuracy: 0.9753\n",
            "443/469 [===========================>..] - ETA: 20s - loss: 0.0820 - sparse_categorical_accuracy: 0.9753\n",
            "444/469 [===========================>..] - ETA: 19s - loss: 0.0819 - sparse_categorical_accuracy: 0.9753\n",
            "445/469 [===========================>..] - ETA: 18s - loss: 0.0819 - sparse_categorical_accuracy: 0.9753\n",
            "446/469 [===========================>..] - ETA: 18s - loss: 0.0819 - sparse_categorical_accuracy: 0.9753\n",
            "447/469 [===========================>..] - ETA: 17s - loss: 0.0819 - sparse_categorical_accuracy: 0.9753\n",
            "448/469 [===========================>..] - ETA: 16s - loss: 0.0818 - sparse_categorical_accuracy: 0.9753\n",
            "449/469 [===========================>..] - ETA: 15s - loss: 0.0819 - sparse_categorical_accuracy: 0.9752\n",
            "450/469 [===========================>..] - ETA: 15s - loss: 0.0819 - sparse_categorical_accuracy: 0.9752\n",
            "451/469 [===========================>..] - ETA: 14s - loss: 0.0818 - sparse_categorical_accuracy: 0.9752\n",
            "452/469 [===========================>..] - ETA: 13s - loss: 0.0817 - sparse_categorical_accuracy: 0.9753\n",
            "453/469 [===========================>..] - ETA: 12s - loss: 0.0818 - sparse_categorical_accuracy: 0.9753\n",
            "454/469 [============================>.] - ETA: 11s - loss: 0.0817 - sparse_categorical_accuracy: 0.9753\n",
            "455/469 [============================>.] - ETA: 11s - loss: 0.0816 - sparse_categorical_accuracy: 0.9754\n",
            "456/469 [============================>.] - ETA: 10s - loss: 0.0816 - sparse_categorical_accuracy: 0.9754\n",
            "457/469 [============================>.] - ETA: 9s - loss: 0.0816 - sparse_categorical_accuracy: 0.9754 \n",
            "458/469 [============================>.] - ETA: 8s - loss: 0.0815 - sparse_categorical_accuracy: 0.9754\n",
            "459/469 [============================>.] - ETA: 7s - loss: 0.0814 - sparse_categorical_accuracy: 0.9754\n",
            "460/469 [============================>.] - ETA: 7s - loss: 0.0813 - sparse_categorical_accuracy: 0.9755\n",
            "461/469 [============================>.] - ETA: 6s - loss: 0.0813 - sparse_categorical_accuracy: 0.9755\n",
            "462/469 [============================>.] - ETA: 5s - loss: 0.0812 - sparse_categorical_accuracy: 0.9755\n",
            "463/469 [============================>.] - ETA: 4s - loss: 0.0811 - sparse_categorical_accuracy: 0.9756\n",
            "464/469 [============================>.] - ETA: 3s - loss: 0.0812 - sparse_categorical_accuracy: 0.9756\n",
            "465/469 [============================>.] - ETA: 3s - loss: 0.0812 - sparse_categorical_accuracy: 0.9756\n",
            "466/469 [============================>.] - ETA: 2s - loss: 0.0813 - sparse_categorical_accuracy: 0.9755\n",
            "467/469 [============================>.] - ETA: 1s - loss: 0.0812 - sparse_categorical_accuracy: 0.9755\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0813 - sparse_categorical_accuracy: 0.9755\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0812 - sparse_categorical_accuracy: 0.9755\n",
            "  0%|          | 0/5 [18:42<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/04/16 00:50:42 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 371s 791ms/step - loss: 0.0812 - sparse_categorical_accuracy: 0.9755\n",
            "\n",
            "Epoch 4/5\n",
            "\n",
            "  1/469 [..............................] - ETA: 5:50 - loss: 0.0354 - sparse_categorical_accuracy: 0.9766\n",
            "  2/469 [..............................] - ETA: 5:46 - loss: 0.0933 - sparse_categorical_accuracy: 0.9727\n",
            "  3/469 [..............................] - ETA: 5:35 - loss: 0.0766 - sparse_categorical_accuracy: 0.9766\n",
            "  4/469 [..............................] - ETA: 5:31 - loss: 0.0921 - sparse_categorical_accuracy: 0.9746\n",
            "  5/469 [..............................] - ETA: 5:33 - loss: 0.0804 - sparse_categorical_accuracy: 0.9781\n",
            "  6/469 [..............................] - ETA: 5:32 - loss: 0.0811 - sparse_categorical_accuracy: 0.9766\n",
            "  7/469 [..............................] - ETA: 5:33 - loss: 0.0798 - sparse_categorical_accuracy: 0.9777\n",
            "  8/469 [..............................] - ETA: 5:33 - loss: 0.0735 - sparse_categorical_accuracy: 0.9785\n",
            "  9/469 [..............................] - ETA: 5:31 - loss: 0.0766 - sparse_categorical_accuracy: 0.9792\n",
            " 10/469 [..............................] - ETA: 5:30 - loss: 0.0781 - sparse_categorical_accuracy: 0.9773\n",
            " 11/469 [..............................] - ETA: 5:51 - loss: 0.0758 - sparse_categorical_accuracy: 0.9766\n",
            " 12/469 [..............................] - ETA: 6:08 - loss: 0.0862 - sparse_categorical_accuracy: 0.9707\n",
            " 13/469 [..............................] - ETA: 6:18 - loss: 0.0835 - sparse_categorical_accuracy: 0.9724\n",
            " 14/469 [..............................] - ETA: 6:13 - loss: 0.0834 - sparse_categorical_accuracy: 0.9727\n",
            " 15/469 [..............................] - ETA: 6:08 - loss: 0.0823 - sparse_categorical_accuracy: 0.9724\n",
            " 16/469 [>.............................] - ETA: 6:05 - loss: 0.0806 - sparse_categorical_accuracy: 0.9731\n",
            " 17/469 [>.............................] - ETA: 6:00 - loss: 0.0769 - sparse_categorical_accuracy: 0.9747\n",
            " 18/469 [>.............................] - ETA: 5:57 - loss: 0.0738 - sparse_categorical_accuracy: 0.9761\n",
            " 19/469 [>.............................] - ETA: 5:54 - loss: 0.0721 - sparse_categorical_accuracy: 0.9766\n",
            " 20/469 [>.............................] - ETA: 5:51 - loss: 0.0703 - sparse_categorical_accuracy: 0.9770\n",
            " 21/469 [>.............................] - ETA: 5:49 - loss: 0.0680 - sparse_categorical_accuracy: 0.9781\n",
            " 22/469 [>.............................] - ETA: 5:47 - loss: 0.0685 - sparse_categorical_accuracy: 0.9773\n",
            " 23/469 [>.............................] - ETA: 5:44 - loss: 0.0673 - sparse_categorical_accuracy: 0.9779\n",
            " 24/469 [>.............................] - ETA: 5:42 - loss: 0.0689 - sparse_categorical_accuracy: 0.9775\n",
            " 25/469 [>.............................] - ETA: 5:41 - loss: 0.0677 - sparse_categorical_accuracy: 0.9781\n",
            " 26/469 [>.............................] - ETA: 5:39 - loss: 0.0660 - sparse_categorical_accuracy: 0.9787\n",
            " 27/469 [>.............................] - ETA: 5:38 - loss: 0.0654 - sparse_categorical_accuracy: 0.9786\n",
            " 28/469 [>.............................] - ETA: 5:42 - loss: 0.0670 - sparse_categorical_accuracy: 0.9780\n",
            " 29/469 [>.............................] - ETA: 5:47 - loss: 0.0671 - sparse_categorical_accuracy: 0.9776\n",
            " 30/469 [>.............................] - ETA: 5:52 - loss: 0.0674 - sparse_categorical_accuracy: 0.9776\n",
            " 31/469 [>.............................] - ETA: 5:52 - loss: 0.0680 - sparse_categorical_accuracy: 0.9776\n",
            " 32/469 [=>............................] - ETA: 5:50 - loss: 0.0669 - sparse_categorical_accuracy: 0.9780\n",
            " 33/469 [=>............................] - ETA: 5:49 - loss: 0.0654 - sparse_categorical_accuracy: 0.9785\n",
            " 34/469 [=>............................] - ETA: 5:47 - loss: 0.0650 - sparse_categorical_accuracy: 0.9786\n",
            " 35/469 [=>............................] - ETA: 5:46 - loss: 0.0649 - sparse_categorical_accuracy: 0.9790\n",
            " 36/469 [=>............................] - ETA: 5:44 - loss: 0.0652 - sparse_categorical_accuracy: 0.9789\n",
            " 37/469 [=>............................] - ETA: 5:43 - loss: 0.0642 - sparse_categorical_accuracy: 0.9793\n",
            " 38/469 [=>............................] - ETA: 5:42 - loss: 0.0636 - sparse_categorical_accuracy: 0.9794\n",
            " 39/469 [=>............................] - ETA: 5:41 - loss: 0.0639 - sparse_categorical_accuracy: 0.9794\n",
            " 40/469 [=>............................] - ETA: 5:40 - loss: 0.0636 - sparse_categorical_accuracy: 0.9791\n",
            " 41/469 [=>............................] - ETA: 5:39 - loss: 0.0641 - sparse_categorical_accuracy: 0.9790\n",
            " 42/469 [=>............................] - ETA: 5:38 - loss: 0.0642 - sparse_categorical_accuracy: 0.9788\n",
            " 43/469 [=>............................] - ETA: 5:37 - loss: 0.0645 - sparse_categorical_accuracy: 0.9789\n",
            " 44/469 [=>............................] - ETA: 5:38 - loss: 0.0670 - sparse_categorical_accuracy: 0.9782\n",
            " 45/469 [=>............................] - ETA: 5:41 - loss: 0.0664 - sparse_categorical_accuracy: 0.9786\n",
            " 46/469 [=>............................] - ETA: 5:43 - loss: 0.0660 - sparse_categorical_accuracy: 0.9786\n",
            " 47/469 [==>...........................] - ETA: 5:45 - loss: 0.0663 - sparse_categorical_accuracy: 0.9784\n",
            " 48/469 [==>...........................] - ETA: 5:43 - loss: 0.0661 - sparse_categorical_accuracy: 0.9784\n",
            " 49/469 [==>...........................] - ETA: 5:41 - loss: 0.0655 - sparse_categorical_accuracy: 0.9785\n",
            " 50/469 [==>...........................] - ETA: 5:40 - loss: 0.0661 - sparse_categorical_accuracy: 0.9784\n",
            " 51/469 [==>...........................] - ETA: 5:38 - loss: 0.0657 - sparse_categorical_accuracy: 0.9787\n",
            " 52/469 [==>...........................] - ETA: 5:37 - loss: 0.0668 - sparse_categorical_accuracy: 0.9785\n",
            " 53/469 [==>...........................] - ETA: 5:35 - loss: 0.0662 - sparse_categorical_accuracy: 0.9788\n",
            " 54/469 [==>...........................] - ETA: 5:34 - loss: 0.0664 - sparse_categorical_accuracy: 0.9786\n",
            " 55/469 [==>...........................] - ETA: 5:32 - loss: 0.0662 - sparse_categorical_accuracy: 0.9784\n",
            " 56/469 [==>...........................] - ETA: 5:31 - loss: 0.0660 - sparse_categorical_accuracy: 0.9784\n",
            " 57/469 [==>...........................] - ETA: 5:29 - loss: 0.0661 - sparse_categorical_accuracy: 0.9783\n",
            " 58/469 [==>...........................] - ETA: 5:28 - loss: 0.0662 - sparse_categorical_accuracy: 0.9783\n",
            " 59/469 [==>...........................] - ETA: 5:27 - loss: 0.0656 - sparse_categorical_accuracy: 0.9785\n",
            " 60/469 [==>...........................] - ETA: 5:25 - loss: 0.0658 - sparse_categorical_accuracy: 0.9785\n",
            " 61/469 [==>...........................] - ETA: 5:25 - loss: 0.0662 - sparse_categorical_accuracy: 0.9781\n",
            " 62/469 [==>...........................] - ETA: 5:28 - loss: 0.0672 - sparse_categorical_accuracy: 0.9774\n",
            " 63/469 [===>..........................] - ETA: 5:30 - loss: 0.0673 - sparse_categorical_accuracy: 0.9774\n",
            " 64/469 [===>..........................] - ETA: 5:30 - loss: 0.0673 - sparse_categorical_accuracy: 0.9775\n",
            " 65/469 [===>..........................] - ETA: 5:28 - loss: 0.0672 - sparse_categorical_accuracy: 0.9776\n",
            " 66/469 [===>..........................] - ETA: 5:27 - loss: 0.0664 - sparse_categorical_accuracy: 0.9780\n",
            " 67/469 [===>..........................] - ETA: 5:25 - loss: 0.0660 - sparse_categorical_accuracy: 0.9781\n",
            " 68/469 [===>..........................] - ETA: 5:24 - loss: 0.0659 - sparse_categorical_accuracy: 0.9782\n",
            " 69/469 [===>..........................] - ETA: 5:23 - loss: 0.0666 - sparse_categorical_accuracy: 0.9783\n",
            " 70/469 [===>..........................] - ETA: 5:22 - loss: 0.0663 - sparse_categorical_accuracy: 0.9785\n",
            " 71/469 [===>..........................] - ETA: 5:21 - loss: 0.0661 - sparse_categorical_accuracy: 0.9785\n",
            " 72/469 [===>..........................] - ETA: 5:19 - loss: 0.0659 - sparse_categorical_accuracy: 0.9786\n",
            " 73/469 [===>..........................] - ETA: 5:18 - loss: 0.0656 - sparse_categorical_accuracy: 0.9786\n",
            " 74/469 [===>..........................] - ETA: 5:17 - loss: 0.0658 - sparse_categorical_accuracy: 0.9787\n",
            " 75/469 [===>..........................] - ETA: 5:16 - loss: 0.0660 - sparse_categorical_accuracy: 0.9786\n",
            " 76/469 [===>..........................] - ETA: 5:15 - loss: 0.0657 - sparse_categorical_accuracy: 0.9787\n",
            " 77/469 [===>..........................] - ETA: 5:14 - loss: 0.0662 - sparse_categorical_accuracy: 0.9784\n",
            " 78/469 [===>..........................] - ETA: 5:15 - loss: 0.0660 - sparse_categorical_accuracy: 0.9784\n",
            " 79/469 [====>.........................] - ETA: 5:16 - loss: 0.0657 - sparse_categorical_accuracy: 0.9784\n",
            " 80/469 [====>.........................] - ETA: 5:17 - loss: 0.0659 - sparse_categorical_accuracy: 0.9785\n",
            " 81/469 [====>.........................] - ETA: 5:16 - loss: 0.0665 - sparse_categorical_accuracy: 0.9784\n",
            " 82/469 [====>.........................] - ETA: 5:15 - loss: 0.0670 - sparse_categorical_accuracy: 0.9782\n",
            " 83/469 [====>.........................] - ETA: 5:14 - loss: 0.0668 - sparse_categorical_accuracy: 0.9782\n",
            " 84/469 [====>.........................] - ETA: 5:13 - loss: 0.0667 - sparse_categorical_accuracy: 0.9782\n",
            " 85/469 [====>.........................] - ETA: 5:11 - loss: 0.0664 - sparse_categorical_accuracy: 0.9783\n",
            " 86/469 [====>.........................] - ETA: 5:10 - loss: 0.0659 - sparse_categorical_accuracy: 0.9786\n",
            " 87/469 [====>.........................] - ETA: 5:09 - loss: 0.0661 - sparse_categorical_accuracy: 0.9784\n",
            " 88/469 [====>.........................] - ETA: 5:08 - loss: 0.0659 - sparse_categorical_accuracy: 0.9785\n",
            " 89/469 [====>.........................] - ETA: 5:07 - loss: 0.0671 - sparse_categorical_accuracy: 0.9783\n",
            " 90/469 [====>.........................] - ETA: 5:06 - loss: 0.0666 - sparse_categorical_accuracy: 0.9785\n",
            " 91/469 [====>.........................] - ETA: 5:05 - loss: 0.0670 - sparse_categorical_accuracy: 0.9785\n",
            " 92/469 [====>.........................] - ETA: 5:04 - loss: 0.0675 - sparse_categorical_accuracy: 0.9782\n",
            " 93/469 [====>.........................] - ETA: 5:03 - loss: 0.0684 - sparse_categorical_accuracy: 0.9781\n",
            " 94/469 [=====>........................] - ETA: 5:02 - loss: 0.0682 - sparse_categorical_accuracy: 0.9781\n",
            " 95/469 [=====>........................] - ETA: 5:03 - loss: 0.0683 - sparse_categorical_accuracy: 0.9781\n",
            " 96/469 [=====>........................] - ETA: 5:03 - loss: 0.0683 - sparse_categorical_accuracy: 0.9782\n",
            " 97/469 [=====>........................] - ETA: 5:04 - loss: 0.0679 - sparse_categorical_accuracy: 0.9783\n",
            " 98/469 [=====>........................] - ETA: 5:02 - loss: 0.0681 - sparse_categorical_accuracy: 0.9784\n",
            " 99/469 [=====>........................] - ETA: 5:01 - loss: 0.0685 - sparse_categorical_accuracy: 0.9783\n",
            "100/469 [=====>........................] - ETA: 5:00 - loss: 0.0685 - sparse_categorical_accuracy: 0.9782\n",
            "101/469 [=====>........................] - ETA: 4:59 - loss: 0.0682 - sparse_categorical_accuracy: 0.9783\n",
            "102/469 [=====>........................] - ETA: 4:58 - loss: 0.0682 - sparse_categorical_accuracy: 0.9783\n",
            "103/469 [=====>........................] - ETA: 4:57 - loss: 0.0680 - sparse_categorical_accuracy: 0.9783\n",
            "104/469 [=====>........................] - ETA: 4:56 - loss: 0.0680 - sparse_categorical_accuracy: 0.9782\n",
            "105/469 [=====>........................] - ETA: 4:54 - loss: 0.0684 - sparse_categorical_accuracy: 0.9781\n",
            "106/469 [=====>........................] - ETA: 4:53 - loss: 0.0696 - sparse_categorical_accuracy: 0.9780\n",
            "107/469 [=====>........................] - ETA: 4:52 - loss: 0.0692 - sparse_categorical_accuracy: 0.9781\n",
            "108/469 [=====>........................] - ETA: 4:51 - loss: 0.0688 - sparse_categorical_accuracy: 0.9782\n",
            "109/469 [=====>........................] - ETA: 4:50 - loss: 0.0690 - sparse_categorical_accuracy: 0.9781\n",
            "110/469 [======>.......................] - ETA: 4:49 - loss: 0.0689 - sparse_categorical_accuracy: 0.9782\n",
            "111/469 [======>.......................] - ETA: 4:48 - loss: 0.0686 - sparse_categorical_accuracy: 0.9783\n",
            "112/469 [======>.......................] - ETA: 4:49 - loss: 0.0692 - sparse_categorical_accuracy: 0.9782\n",
            "113/469 [======>.......................] - ETA: 4:49 - loss: 0.0691 - sparse_categorical_accuracy: 0.9782\n",
            "114/469 [======>.......................] - ETA: 4:49 - loss: 0.0690 - sparse_categorical_accuracy: 0.9782\n",
            "115/469 [======>.......................] - ETA: 4:48 - loss: 0.0689 - sparse_categorical_accuracy: 0.9781\n",
            "116/469 [======>.......................] - ETA: 4:47 - loss: 0.0699 - sparse_categorical_accuracy: 0.9779\n",
            "117/469 [======>.......................] - ETA: 4:46 - loss: 0.0703 - sparse_categorical_accuracy: 0.9777\n",
            "118/469 [======>.......................] - ETA: 4:45 - loss: 0.0706 - sparse_categorical_accuracy: 0.9776\n",
            "119/469 [======>.......................] - ETA: 4:44 - loss: 0.0706 - sparse_categorical_accuracy: 0.9775\n",
            "120/469 [======>.......................] - ETA: 4:43 - loss: 0.0702 - sparse_categorical_accuracy: 0.9775\n",
            "121/469 [======>.......................] - ETA: 4:41 - loss: 0.0703 - sparse_categorical_accuracy: 0.9775\n",
            "122/469 [======>.......................] - ETA: 4:40 - loss: 0.0715 - sparse_categorical_accuracy: 0.9774\n",
            "123/469 [======>.......................] - ETA: 4:39 - loss: 0.0715 - sparse_categorical_accuracy: 0.9775\n",
            "124/469 [======>.......................] - ETA: 4:38 - loss: 0.0713 - sparse_categorical_accuracy: 0.9776\n",
            "125/469 [======>.......................] - ETA: 4:37 - loss: 0.0709 - sparse_categorical_accuracy: 0.9777\n",
            "126/469 [=======>......................] - ETA: 4:36 - loss: 0.0706 - sparse_categorical_accuracy: 0.9777\n",
            "127/469 [=======>......................] - ETA: 4:35 - loss: 0.0706 - sparse_categorical_accuracy: 0.9777\n",
            "128/469 [=======>......................] - ETA: 4:34 - loss: 0.0704 - sparse_categorical_accuracy: 0.9778\n",
            "129/469 [=======>......................] - ETA: 4:34 - loss: 0.0702 - sparse_categorical_accuracy: 0.9778\n",
            "130/469 [=======>......................] - ETA: 4:34 - loss: 0.0700 - sparse_categorical_accuracy: 0.9779\n",
            "131/469 [=======>......................] - ETA: 4:34 - loss: 0.0704 - sparse_categorical_accuracy: 0.9779\n",
            "132/469 [=======>......................] - ETA: 4:34 - loss: 0.0707 - sparse_categorical_accuracy: 0.9779\n",
            "133/469 [=======>......................] - ETA: 4:33 - loss: 0.0709 - sparse_categorical_accuracy: 0.9778\n",
            "134/469 [=======>......................] - ETA: 4:32 - loss: 0.0705 - sparse_categorical_accuracy: 0.9779\n",
            "135/469 [=======>......................] - ETA: 4:30 - loss: 0.0703 - sparse_categorical_accuracy: 0.9780\n",
            "136/469 [=======>......................] - ETA: 4:30 - loss: 0.0704 - sparse_categorical_accuracy: 0.9780\n",
            "137/469 [=======>......................] - ETA: 4:28 - loss: 0.0705 - sparse_categorical_accuracy: 0.9779\n",
            "138/469 [=======>......................] - ETA: 4:27 - loss: 0.0703 - sparse_categorical_accuracy: 0.9781\n",
            "139/469 [=======>......................] - ETA: 4:27 - loss: 0.0708 - sparse_categorical_accuracy: 0.9779\n",
            "140/469 [=======>......................] - ETA: 4:26 - loss: 0.0707 - sparse_categorical_accuracy: 0.9779\n",
            "141/469 [========>.....................] - ETA: 4:25 - loss: 0.0705 - sparse_categorical_accuracy: 0.9779\n",
            "142/469 [========>.....................] - ETA: 4:24 - loss: 0.0703 - sparse_categorical_accuracy: 0.9781\n",
            "143/469 [========>.....................] - ETA: 4:23 - loss: 0.0706 - sparse_categorical_accuracy: 0.9779\n",
            "144/469 [========>.....................] - ETA: 4:22 - loss: 0.0711 - sparse_categorical_accuracy: 0.9778\n",
            "145/469 [========>.....................] - ETA: 4:21 - loss: 0.0711 - sparse_categorical_accuracy: 0.9777\n",
            "146/469 [========>.....................] - ETA: 4:21 - loss: 0.0708 - sparse_categorical_accuracy: 0.9778\n",
            "147/469 [========>.....................] - ETA: 4:21 - loss: 0.0706 - sparse_categorical_accuracy: 0.9778\n",
            "148/469 [========>.....................] - ETA: 4:21 - loss: 0.0704 - sparse_categorical_accuracy: 0.9778\n",
            "149/469 [========>.....................] - ETA: 4:20 - loss: 0.0703 - sparse_categorical_accuracy: 0.9778\n",
            "150/469 [========>.....................] - ETA: 4:19 - loss: 0.0702 - sparse_categorical_accuracy: 0.9779\n",
            "151/469 [========>.....................] - ETA: 4:18 - loss: 0.0710 - sparse_categorical_accuracy: 0.9778\n",
            "152/469 [========>.....................] - ETA: 4:17 - loss: 0.0707 - sparse_categorical_accuracy: 0.9778\n",
            "153/469 [========>.....................] - ETA: 4:16 - loss: 0.0709 - sparse_categorical_accuracy: 0.9778\n",
            "154/469 [========>.....................] - ETA: 4:15 - loss: 0.0713 - sparse_categorical_accuracy: 0.9777\n",
            "155/469 [========>.....................] - ETA: 4:14 - loss: 0.0712 - sparse_categorical_accuracy: 0.9778\n",
            "156/469 [========>.....................] - ETA: 4:13 - loss: 0.0713 - sparse_categorical_accuracy: 0.9778\n",
            "157/469 [=========>....................] - ETA: 4:12 - loss: 0.0712 - sparse_categorical_accuracy: 0.9778\n",
            "158/469 [=========>....................] - ETA: 4:11 - loss: 0.0718 - sparse_categorical_accuracy: 0.9776\n",
            "159/469 [=========>....................] - ETA: 4:10 - loss: 0.0721 - sparse_categorical_accuracy: 0.9776\n",
            "160/469 [=========>....................] - ETA: 4:09 - loss: 0.0721 - sparse_categorical_accuracy: 0.9775\n",
            "161/469 [=========>....................] - ETA: 4:08 - loss: 0.0722 - sparse_categorical_accuracy: 0.9775\n",
            "162/469 [=========>....................] - ETA: 4:08 - loss: 0.0726 - sparse_categorical_accuracy: 0.9775\n",
            "163/469 [=========>....................] - ETA: 4:07 - loss: 0.0731 - sparse_categorical_accuracy: 0.9773\n",
            "164/469 [=========>....................] - ETA: 4:07 - loss: 0.0728 - sparse_categorical_accuracy: 0.9774\n",
            "165/469 [=========>....................] - ETA: 4:07 - loss: 0.0729 - sparse_categorical_accuracy: 0.9774\n",
            "166/469 [=========>....................] - ETA: 4:06 - loss: 0.0728 - sparse_categorical_accuracy: 0.9774\n",
            "167/469 [=========>....................] - ETA: 4:05 - loss: 0.0725 - sparse_categorical_accuracy: 0.9775\n",
            "168/469 [=========>....................] - ETA: 4:04 - loss: 0.0726 - sparse_categorical_accuracy: 0.9775\n",
            "169/469 [=========>....................] - ETA: 4:03 - loss: 0.0723 - sparse_categorical_accuracy: 0.9775\n",
            "170/469 [=========>....................] - ETA: 4:02 - loss: 0.0721 - sparse_categorical_accuracy: 0.9776\n",
            "171/469 [=========>....................] - ETA: 4:01 - loss: 0.0722 - sparse_categorical_accuracy: 0.9776\n",
            "172/469 [==========>...................] - ETA: 4:00 - loss: 0.0726 - sparse_categorical_accuracy: 0.9775\n",
            "173/469 [==========>...................] - ETA: 3:59 - loss: 0.0724 - sparse_categorical_accuracy: 0.9775\n",
            "174/469 [==========>...................] - ETA: 3:58 - loss: 0.0722 - sparse_categorical_accuracy: 0.9776\n",
            "175/469 [==========>...................] - ETA: 3:57 - loss: 0.0721 - sparse_categorical_accuracy: 0.9776\n",
            "176/469 [==========>...................] - ETA: 3:56 - loss: 0.0725 - sparse_categorical_accuracy: 0.9775\n",
            "177/469 [==========>...................] - ETA: 3:55 - loss: 0.0724 - sparse_categorical_accuracy: 0.9775\n",
            "178/469 [==========>...................] - ETA: 3:54 - loss: 0.0725 - sparse_categorical_accuracy: 0.9773\n",
            "179/469 [==========>...................] - ETA: 3:54 - loss: 0.0725 - sparse_categorical_accuracy: 0.9773\n",
            "180/469 [==========>...................] - ETA: 3:54 - loss: 0.0723 - sparse_categorical_accuracy: 0.9774\n",
            "181/469 [==========>...................] - ETA: 3:53 - loss: 0.0722 - sparse_categorical_accuracy: 0.9773\n",
            "182/469 [==========>...................] - ETA: 3:53 - loss: 0.0721 - sparse_categorical_accuracy: 0.9773\n",
            "183/469 [==========>...................] - ETA: 3:52 - loss: 0.0722 - sparse_categorical_accuracy: 0.9773\n",
            "184/469 [==========>...................] - ETA: 3:51 - loss: 0.0720 - sparse_categorical_accuracy: 0.9774\n",
            "185/469 [==========>...................] - ETA: 3:50 - loss: 0.0721 - sparse_categorical_accuracy: 0.9774\n",
            "186/469 [==========>...................] - ETA: 3:49 - loss: 0.0720 - sparse_categorical_accuracy: 0.9774\n",
            "187/469 [==========>...................] - ETA: 3:48 - loss: 0.0722 - sparse_categorical_accuracy: 0.9774\n",
            "188/469 [===========>..................] - ETA: 3:47 - loss: 0.0719 - sparse_categorical_accuracy: 0.9774\n",
            "189/469 [===========>..................] - ETA: 3:46 - loss: 0.0718 - sparse_categorical_accuracy: 0.9774\n",
            "190/469 [===========>..................] - ETA: 3:45 - loss: 0.0718 - sparse_categorical_accuracy: 0.9775\n",
            "191/469 [===========>..................] - ETA: 3:44 - loss: 0.0719 - sparse_categorical_accuracy: 0.9774\n",
            "192/469 [===========>..................] - ETA: 3:44 - loss: 0.0720 - sparse_categorical_accuracy: 0.9773\n",
            "193/469 [===========>..................] - ETA: 3:43 - loss: 0.0718 - sparse_categorical_accuracy: 0.9774\n",
            "194/469 [===========>..................] - ETA: 3:42 - loss: 0.0718 - sparse_categorical_accuracy: 0.9774\n",
            "195/469 [===========>..................] - ETA: 3:41 - loss: 0.0717 - sparse_categorical_accuracy: 0.9774\n",
            "196/469 [===========>..................] - ETA: 3:40 - loss: 0.0720 - sparse_categorical_accuracy: 0.9774\n",
            "197/469 [===========>..................] - ETA: 3:40 - loss: 0.0719 - sparse_categorical_accuracy: 0.9775\n",
            "198/469 [===========>..................] - ETA: 3:40 - loss: 0.0718 - sparse_categorical_accuracy: 0.9775\n",
            "199/469 [===========>..................] - ETA: 3:39 - loss: 0.0719 - sparse_categorical_accuracy: 0.9774\n",
            "200/469 [===========>..................] - ETA: 3:38 - loss: 0.0718 - sparse_categorical_accuracy: 0.9774\n",
            "201/469 [===========>..................] - ETA: 3:37 - loss: 0.0716 - sparse_categorical_accuracy: 0.9775\n",
            "202/469 [===========>..................] - ETA: 3:36 - loss: 0.0714 - sparse_categorical_accuracy: 0.9776\n",
            "203/469 [===========>..................] - ETA: 3:35 - loss: 0.0713 - sparse_categorical_accuracy: 0.9776\n",
            "204/469 [============>.................] - ETA: 3:34 - loss: 0.0712 - sparse_categorical_accuracy: 0.9777\n",
            "205/469 [============>.................] - ETA: 3:33 - loss: 0.0711 - sparse_categorical_accuracy: 0.9777\n",
            "206/469 [============>.................] - ETA: 3:32 - loss: 0.0712 - sparse_categorical_accuracy: 0.9776\n",
            "207/469 [============>.................] - ETA: 3:31 - loss: 0.0710 - sparse_categorical_accuracy: 0.9777\n",
            "208/469 [============>.................] - ETA: 3:31 - loss: 0.0709 - sparse_categorical_accuracy: 0.9777\n",
            "209/469 [============>.................] - ETA: 3:30 - loss: 0.0713 - sparse_categorical_accuracy: 0.9777\n",
            "210/469 [============>.................] - ETA: 3:29 - loss: 0.0713 - sparse_categorical_accuracy: 0.9778\n",
            "211/469 [============>.................] - ETA: 3:28 - loss: 0.0711 - sparse_categorical_accuracy: 0.9778\n",
            "212/469 [============>.................] - ETA: 3:27 - loss: 0.0709 - sparse_categorical_accuracy: 0.9779\n",
            "213/469 [============>.................] - ETA: 3:26 - loss: 0.0706 - sparse_categorical_accuracy: 0.9779\n",
            "214/469 [============>.................] - ETA: 3:26 - loss: 0.0708 - sparse_categorical_accuracy: 0.9779\n",
            "215/469 [============>.................] - ETA: 3:25 - loss: 0.0706 - sparse_categorical_accuracy: 0.9779\n",
            "216/469 [============>.................] - ETA: 3:25 - loss: 0.0705 - sparse_categorical_accuracy: 0.9780\n",
            "217/469 [============>.................] - ETA: 3:24 - loss: 0.0704 - sparse_categorical_accuracy: 0.9780\n",
            "218/469 [============>.................] - ETA: 3:23 - loss: 0.0704 - sparse_categorical_accuracy: 0.9779\n",
            "219/469 [=============>................] - ETA: 3:22 - loss: 0.0706 - sparse_categorical_accuracy: 0.9778\n",
            "220/469 [=============>................] - ETA: 3:21 - loss: 0.0703 - sparse_categorical_accuracy: 0.9779\n",
            "221/469 [=============>................] - ETA: 3:20 - loss: 0.0706 - sparse_categorical_accuracy: 0.9779\n",
            "222/469 [=============>................] - ETA: 3:19 - loss: 0.0707 - sparse_categorical_accuracy: 0.9777\n",
            "223/469 [=============>................] - ETA: 3:19 - loss: 0.0714 - sparse_categorical_accuracy: 0.9778\n",
            "224/469 [=============>................] - ETA: 3:18 - loss: 0.0715 - sparse_categorical_accuracy: 0.9777\n",
            "225/469 [=============>................] - ETA: 3:17 - loss: 0.0713 - sparse_categorical_accuracy: 0.9778\n",
            "226/469 [=============>................] - ETA: 3:16 - loss: 0.0715 - sparse_categorical_accuracy: 0.9777\n",
            "227/469 [=============>................] - ETA: 3:15 - loss: 0.0715 - sparse_categorical_accuracy: 0.9776\n",
            "228/469 [=============>................] - ETA: 3:14 - loss: 0.0713 - sparse_categorical_accuracy: 0.9777\n",
            "229/469 [=============>................] - ETA: 3:13 - loss: 0.0714 - sparse_categorical_accuracy: 0.9777\n",
            "230/469 [=============>................] - ETA: 3:13 - loss: 0.0716 - sparse_categorical_accuracy: 0.9776\n",
            "231/469 [=============>................] - ETA: 3:12 - loss: 0.0715 - sparse_categorical_accuracy: 0.9776\n",
            "232/469 [=============>................] - ETA: 3:12 - loss: 0.0714 - sparse_categorical_accuracy: 0.9776\n",
            "233/469 [=============>................] - ETA: 3:11 - loss: 0.0712 - sparse_categorical_accuracy: 0.9777\n",
            "234/469 [=============>................] - ETA: 3:10 - loss: 0.0713 - sparse_categorical_accuracy: 0.9777\n",
            "235/469 [==============>...............] - ETA: 3:09 - loss: 0.0714 - sparse_categorical_accuracy: 0.9776\n",
            "236/469 [==============>...............] - ETA: 3:08 - loss: 0.0714 - sparse_categorical_accuracy: 0.9776\n",
            "237/469 [==============>...............] - ETA: 3:07 - loss: 0.0715 - sparse_categorical_accuracy: 0.9777\n",
            "238/469 [==============>...............] - ETA: 3:07 - loss: 0.0717 - sparse_categorical_accuracy: 0.9776\n",
            "239/469 [==============>...............] - ETA: 3:06 - loss: 0.0715 - sparse_categorical_accuracy: 0.9776\n",
            "240/469 [==============>...............] - ETA: 3:05 - loss: 0.0715 - sparse_categorical_accuracy: 0.9776\n",
            "241/469 [==============>...............] - ETA: 3:04 - loss: 0.0713 - sparse_categorical_accuracy: 0.9777\n",
            "242/469 [==============>...............] - ETA: 3:03 - loss: 0.0714 - sparse_categorical_accuracy: 0.9777\n",
            "243/469 [==============>...............] - ETA: 3:02 - loss: 0.0712 - sparse_categorical_accuracy: 0.9778\n",
            "244/469 [==============>...............] - ETA: 3:01 - loss: 0.0711 - sparse_categorical_accuracy: 0.9778\n",
            "245/469 [==============>...............] - ETA: 3:00 - loss: 0.0709 - sparse_categorical_accuracy: 0.9779\n",
            "246/469 [==============>...............] - ETA: 2:59 - loss: 0.0711 - sparse_categorical_accuracy: 0.9778\n",
            "247/469 [==============>...............] - ETA: 2:59 - loss: 0.0711 - sparse_categorical_accuracy: 0.9778\n",
            "248/469 [==============>...............] - ETA: 2:58 - loss: 0.0709 - sparse_categorical_accuracy: 0.9779\n",
            "249/469 [==============>...............] - ETA: 2:58 - loss: 0.0714 - sparse_categorical_accuracy: 0.9778\n",
            "250/469 [==============>...............] - ETA: 2:57 - loss: 0.0713 - sparse_categorical_accuracy: 0.9778\n",
            "251/469 [===============>..............] - ETA: 2:56 - loss: 0.0712 - sparse_categorical_accuracy: 0.9778\n",
            "252/469 [===============>..............] - ETA: 2:55 - loss: 0.0711 - sparse_categorical_accuracy: 0.9779\n",
            "253/469 [===============>..............] - ETA: 2:54 - loss: 0.0710 - sparse_categorical_accuracy: 0.9779\n",
            "254/469 [===============>..............] - ETA: 2:54 - loss: 0.0711 - sparse_categorical_accuracy: 0.9779\n",
            "255/469 [===============>..............] - ETA: 2:53 - loss: 0.0711 - sparse_categorical_accuracy: 0.9779\n",
            "256/469 [===============>..............] - ETA: 2:52 - loss: 0.0711 - sparse_categorical_accuracy: 0.9779\n",
            "257/469 [===============>..............] - ETA: 2:51 - loss: 0.0711 - sparse_categorical_accuracy: 0.9779\n",
            "258/469 [===============>..............] - ETA: 2:50 - loss: 0.0710 - sparse_categorical_accuracy: 0.9779\n",
            "259/469 [===============>..............] - ETA: 2:49 - loss: 0.0709 - sparse_categorical_accuracy: 0.9780\n",
            "260/469 [===============>..............] - ETA: 2:48 - loss: 0.0709 - sparse_categorical_accuracy: 0.9779\n",
            "261/469 [===============>..............] - ETA: 2:47 - loss: 0.0707 - sparse_categorical_accuracy: 0.9780\n",
            "262/469 [===============>..............] - ETA: 2:47 - loss: 0.0708 - sparse_categorical_accuracy: 0.9779\n",
            "263/469 [===============>..............] - ETA: 2:46 - loss: 0.0710 - sparse_categorical_accuracy: 0.9779\n",
            "264/469 [===============>..............] - ETA: 2:45 - loss: 0.0710 - sparse_categorical_accuracy: 0.9779\n",
            "265/469 [===============>..............] - ETA: 2:44 - loss: 0.0709 - sparse_categorical_accuracy: 0.9779\n",
            "266/469 [================>.............] - ETA: 2:44 - loss: 0.0707 - sparse_categorical_accuracy: 0.9779\n",
            "267/469 [================>.............] - ETA: 2:43 - loss: 0.0707 - sparse_categorical_accuracy: 0.9779\n",
            "268/469 [================>.............] - ETA: 2:42 - loss: 0.0705 - sparse_categorical_accuracy: 0.9780\n",
            "269/469 [================>.............] - ETA: 2:41 - loss: 0.0705 - sparse_categorical_accuracy: 0.9780\n",
            "270/469 [================>.............] - ETA: 2:41 - loss: 0.0705 - sparse_categorical_accuracy: 0.9780\n",
            "271/469 [================>.............] - ETA: 2:40 - loss: 0.0709 - sparse_categorical_accuracy: 0.9780\n",
            "272/469 [================>.............] - ETA: 2:39 - loss: 0.0709 - sparse_categorical_accuracy: 0.9780\n",
            "273/469 [================>.............] - ETA: 2:38 - loss: 0.0710 - sparse_categorical_accuracy: 0.9780\n",
            "274/469 [================>.............] - ETA: 2:37 - loss: 0.0709 - sparse_categorical_accuracy: 0.9780\n",
            "275/469 [================>.............] - ETA: 2:36 - loss: 0.0707 - sparse_categorical_accuracy: 0.9780\n",
            "276/469 [================>.............] - ETA: 2:35 - loss: 0.0707 - sparse_categorical_accuracy: 0.9780\n",
            "277/469 [================>.............] - ETA: 2:34 - loss: 0.0708 - sparse_categorical_accuracy: 0.9780\n",
            "278/469 [================>.............] - ETA: 2:34 - loss: 0.0710 - sparse_categorical_accuracy: 0.9779\n",
            "279/469 [================>.............] - ETA: 2:33 - loss: 0.0713 - sparse_categorical_accuracy: 0.9779\n",
            "280/469 [================>.............] - ETA: 2:32 - loss: 0.0712 - sparse_categorical_accuracy: 0.9780\n",
            "281/469 [================>.............] - ETA: 2:31 - loss: 0.0711 - sparse_categorical_accuracy: 0.9780\n",
            "282/469 [=================>............] - ETA: 2:30 - loss: 0.0712 - sparse_categorical_accuracy: 0.9780\n",
            "283/469 [=================>............] - ETA: 2:30 - loss: 0.0714 - sparse_categorical_accuracy: 0.9780\n",
            "284/469 [=================>............] - ETA: 2:29 - loss: 0.0713 - sparse_categorical_accuracy: 0.9779\n",
            "285/469 [=================>............] - ETA: 2:28 - loss: 0.0712 - sparse_categorical_accuracy: 0.9780\n",
            "286/469 [=================>............] - ETA: 2:28 - loss: 0.0712 - sparse_categorical_accuracy: 0.9780\n",
            "287/469 [=================>............] - ETA: 2:27 - loss: 0.0711 - sparse_categorical_accuracy: 0.9780\n",
            "288/469 [=================>............] - ETA: 2:26 - loss: 0.0709 - sparse_categorical_accuracy: 0.9781\n",
            "289/469 [=================>............] - ETA: 2:25 - loss: 0.0708 - sparse_categorical_accuracy: 0.9781\n",
            "290/469 [=================>............] - ETA: 2:24 - loss: 0.0709 - sparse_categorical_accuracy: 0.9781\n",
            "291/469 [=================>............] - ETA: 2:23 - loss: 0.0712 - sparse_categorical_accuracy: 0.9780\n",
            "292/469 [=================>............] - ETA: 2:22 - loss: 0.0712 - sparse_categorical_accuracy: 0.9780\n",
            "293/469 [=================>............] - ETA: 2:22 - loss: 0.0712 - sparse_categorical_accuracy: 0.9780\n",
            "294/469 [=================>............] - ETA: 2:21 - loss: 0.0716 - sparse_categorical_accuracy: 0.9780\n",
            "295/469 [=================>............] - ETA: 2:20 - loss: 0.0716 - sparse_categorical_accuracy: 0.9780\n",
            "296/469 [=================>............] - ETA: 2:19 - loss: 0.0716 - sparse_categorical_accuracy: 0.9780\n",
            "297/469 [=================>............] - ETA: 2:18 - loss: 0.0715 - sparse_categorical_accuracy: 0.9780\n",
            "298/469 [==================>...........] - ETA: 2:17 - loss: 0.0716 - sparse_categorical_accuracy: 0.9779\n",
            "299/469 [==================>...........] - ETA: 2:17 - loss: 0.0715 - sparse_categorical_accuracy: 0.9780\n",
            "300/469 [==================>...........] - ETA: 2:16 - loss: 0.0714 - sparse_categorical_accuracy: 0.9780\n",
            "301/469 [==================>...........] - ETA: 2:15 - loss: 0.0716 - sparse_categorical_accuracy: 0.9779\n",
            "302/469 [==================>...........] - ETA: 2:15 - loss: 0.0717 - sparse_categorical_accuracy: 0.9779\n",
            "303/469 [==================>...........] - ETA: 2:14 - loss: 0.0717 - sparse_categorical_accuracy: 0.9779\n",
            "304/469 [==================>...........] - ETA: 2:13 - loss: 0.0716 - sparse_categorical_accuracy: 0.9780\n",
            "305/469 [==================>...........] - ETA: 2:12 - loss: 0.0717 - sparse_categorical_accuracy: 0.9779\n",
            "306/469 [==================>...........] - ETA: 2:11 - loss: 0.0716 - sparse_categorical_accuracy: 0.9780\n",
            "307/469 [==================>...........] - ETA: 2:10 - loss: 0.0716 - sparse_categorical_accuracy: 0.9780\n",
            "308/469 [==================>...........] - ETA: 2:10 - loss: 0.0717 - sparse_categorical_accuracy: 0.9780\n",
            "309/469 [==================>...........] - ETA: 2:09 - loss: 0.0716 - sparse_categorical_accuracy: 0.9780\n",
            "310/469 [==================>...........] - ETA: 2:08 - loss: 0.0717 - sparse_categorical_accuracy: 0.9779\n",
            "311/469 [==================>...........] - ETA: 2:07 - loss: 0.0718 - sparse_categorical_accuracy: 0.9778\n",
            "312/469 [==================>...........] - ETA: 2:06 - loss: 0.0718 - sparse_categorical_accuracy: 0.9778\n",
            "313/469 [===================>..........] - ETA: 2:05 - loss: 0.0717 - sparse_categorical_accuracy: 0.9778\n",
            "314/469 [===================>..........] - ETA: 2:04 - loss: 0.0716 - sparse_categorical_accuracy: 0.9779\n",
            "315/469 [===================>..........] - ETA: 2:04 - loss: 0.0717 - sparse_categorical_accuracy: 0.9779\n",
            "316/469 [===================>..........] - ETA: 2:03 - loss: 0.0718 - sparse_categorical_accuracy: 0.9778\n",
            "317/469 [===================>..........] - ETA: 2:02 - loss: 0.0718 - sparse_categorical_accuracy: 0.9778\n",
            "318/469 [===================>..........] - ETA: 2:02 - loss: 0.0717 - sparse_categorical_accuracy: 0.9779\n",
            "319/469 [===================>..........] - ETA: 2:01 - loss: 0.0717 - sparse_categorical_accuracy: 0.9779\n",
            "320/469 [===================>..........] - ETA: 2:00 - loss: 0.0716 - sparse_categorical_accuracy: 0.9779\n",
            "321/469 [===================>..........] - ETA: 1:59 - loss: 0.0717 - sparse_categorical_accuracy: 0.9778\n",
            "322/469 [===================>..........] - ETA: 1:58 - loss: 0.0716 - sparse_categorical_accuracy: 0.9778\n",
            "323/469 [===================>..........] - ETA: 1:58 - loss: 0.0717 - sparse_categorical_accuracy: 0.9778\n",
            "324/469 [===================>..........] - ETA: 1:57 - loss: 0.0716 - sparse_categorical_accuracy: 0.9778\n",
            "325/469 [===================>..........] - ETA: 1:56 - loss: 0.0717 - sparse_categorical_accuracy: 0.9778\n",
            "326/469 [===================>..........] - ETA: 1:55 - loss: 0.0716 - sparse_categorical_accuracy: 0.9778\n",
            "327/469 [===================>..........] - ETA: 1:54 - loss: 0.0715 - sparse_categorical_accuracy: 0.9779\n",
            "328/469 [===================>..........] - ETA: 1:53 - loss: 0.0715 - sparse_categorical_accuracy: 0.9779\n",
            "329/469 [====================>.........] - ETA: 1:53 - loss: 0.0716 - sparse_categorical_accuracy: 0.9778\n",
            "330/469 [====================>.........] - ETA: 1:52 - loss: 0.0714 - sparse_categorical_accuracy: 0.9779\n",
            "331/469 [====================>.........] - ETA: 1:51 - loss: 0.0714 - sparse_categorical_accuracy: 0.9779\n",
            "332/469 [====================>.........] - ETA: 1:50 - loss: 0.0713 - sparse_categorical_accuracy: 0.9780\n",
            "333/469 [====================>.........] - ETA: 1:50 - loss: 0.0714 - sparse_categorical_accuracy: 0.9779\n",
            "334/469 [====================>.........] - ETA: 1:49 - loss: 0.0713 - sparse_categorical_accuracy: 0.9779\n",
            "335/469 [====================>.........] - ETA: 1:48 - loss: 0.0712 - sparse_categorical_accuracy: 0.9780\n",
            "336/469 [====================>.........] - ETA: 1:47 - loss: 0.0711 - sparse_categorical_accuracy: 0.9780\n",
            "337/469 [====================>.........] - ETA: 1:47 - loss: 0.0711 - sparse_categorical_accuracy: 0.9780\n",
            "338/469 [====================>.........] - ETA: 1:46 - loss: 0.0711 - sparse_categorical_accuracy: 0.9781\n",
            "339/469 [====================>.........] - ETA: 1:45 - loss: 0.0710 - sparse_categorical_accuracy: 0.9781\n",
            "340/469 [====================>.........] - ETA: 1:44 - loss: 0.0709 - sparse_categorical_accuracy: 0.9781\n",
            "341/469 [====================>.........] - ETA: 1:43 - loss: 0.0709 - sparse_categorical_accuracy: 0.9782\n",
            "342/469 [====================>.........] - ETA: 1:42 - loss: 0.0709 - sparse_categorical_accuracy: 0.9781\n",
            "343/469 [====================>.........] - ETA: 1:42 - loss: 0.0709 - sparse_categorical_accuracy: 0.9781\n",
            "344/469 [=====================>........] - ETA: 1:41 - loss: 0.0707 - sparse_categorical_accuracy: 0.9782\n",
            "345/469 [=====================>........] - ETA: 1:40 - loss: 0.0707 - sparse_categorical_accuracy: 0.9782\n",
            "346/469 [=====================>........] - ETA: 1:39 - loss: 0.0706 - sparse_categorical_accuracy: 0.9782\n",
            "347/469 [=====================>........] - ETA: 1:38 - loss: 0.0705 - sparse_categorical_accuracy: 0.9782\n",
            "348/469 [=====================>........] - ETA: 1:37 - loss: 0.0705 - sparse_categorical_accuracy: 0.9782\n",
            "349/469 [=====================>........] - ETA: 1:37 - loss: 0.0706 - sparse_categorical_accuracy: 0.9782\n",
            "350/469 [=====================>........] - ETA: 1:36 - loss: 0.0705 - sparse_categorical_accuracy: 0.9782\n",
            "351/469 [=====================>........] - ETA: 1:35 - loss: 0.0704 - sparse_categorical_accuracy: 0.9782\n",
            "352/469 [=====================>........] - ETA: 1:34 - loss: 0.0704 - sparse_categorical_accuracy: 0.9782\n",
            "353/469 [=====================>........] - ETA: 1:34 - loss: 0.0704 - sparse_categorical_accuracy: 0.9782\n",
            "354/469 [=====================>........] - ETA: 1:33 - loss: 0.0703 - sparse_categorical_accuracy: 0.9783\n",
            "355/469 [=====================>........] - ETA: 1:32 - loss: 0.0704 - sparse_categorical_accuracy: 0.9782\n",
            "356/469 [=====================>........] - ETA: 1:31 - loss: 0.0707 - sparse_categorical_accuracy: 0.9781\n",
            "357/469 [=====================>........] - ETA: 1:30 - loss: 0.0708 - sparse_categorical_accuracy: 0.9780\n",
            "358/469 [=====================>........] - ETA: 1:29 - loss: 0.0709 - sparse_categorical_accuracy: 0.9780\n",
            "359/469 [=====================>........] - ETA: 1:29 - loss: 0.0710 - sparse_categorical_accuracy: 0.9780\n",
            "360/469 [======================>.......] - ETA: 1:28 - loss: 0.0710 - sparse_categorical_accuracy: 0.9780\n",
            "361/469 [======================>.......] - ETA: 1:27 - loss: 0.0709 - sparse_categorical_accuracy: 0.9780\n",
            "362/469 [======================>.......] - ETA: 1:26 - loss: 0.0710 - sparse_categorical_accuracy: 0.9780\n",
            "363/469 [======================>.......] - ETA: 1:25 - loss: 0.0709 - sparse_categorical_accuracy: 0.9780\n",
            "364/469 [======================>.......] - ETA: 1:24 - loss: 0.0709 - sparse_categorical_accuracy: 0.9780\n",
            "365/469 [======================>.......] - ETA: 1:24 - loss: 0.0708 - sparse_categorical_accuracy: 0.9780\n",
            "366/469 [======================>.......] - ETA: 1:23 - loss: 0.0710 - sparse_categorical_accuracy: 0.9779\n",
            "367/469 [======================>.......] - ETA: 1:22 - loss: 0.0709 - sparse_categorical_accuracy: 0.9780\n",
            "368/469 [======================>.......] - ETA: 1:21 - loss: 0.0710 - sparse_categorical_accuracy: 0.9780\n",
            "369/469 [======================>.......] - ETA: 1:21 - loss: 0.0709 - sparse_categorical_accuracy: 0.9780\n",
            "370/469 [======================>.......] - ETA: 1:20 - loss: 0.0707 - sparse_categorical_accuracy: 0.9781\n",
            "371/469 [======================>.......] - ETA: 1:19 - loss: 0.0706 - sparse_categorical_accuracy: 0.9781\n",
            "372/469 [======================>.......] - ETA: 1:18 - loss: 0.0707 - sparse_categorical_accuracy: 0.9781\n",
            "373/469 [======================>.......] - ETA: 1:17 - loss: 0.0706 - sparse_categorical_accuracy: 0.9781\n",
            "374/469 [======================>.......] - ETA: 1:16 - loss: 0.0706 - sparse_categorical_accuracy: 0.9780\n",
            "375/469 [======================>.......] - ETA: 1:16 - loss: 0.0705 - sparse_categorical_accuracy: 0.9781\n",
            "376/469 [=======================>......] - ETA: 1:15 - loss: 0.0706 - sparse_categorical_accuracy: 0.9781\n",
            "377/469 [=======================>......] - ETA: 1:14 - loss: 0.0707 - sparse_categorical_accuracy: 0.9781\n",
            "378/469 [=======================>......] - ETA: 1:13 - loss: 0.0706 - sparse_categorical_accuracy: 0.9781\n",
            "379/469 [=======================>......] - ETA: 1:12 - loss: 0.0705 - sparse_categorical_accuracy: 0.9781\n",
            "380/469 [=======================>......] - ETA: 1:12 - loss: 0.0706 - sparse_categorical_accuracy: 0.9781\n",
            "381/469 [=======================>......] - ETA: 1:11 - loss: 0.0707 - sparse_categorical_accuracy: 0.9781\n",
            "382/469 [=======================>......] - ETA: 1:10 - loss: 0.0707 - sparse_categorical_accuracy: 0.9782\n",
            "383/469 [=======================>......] - ETA: 1:09 - loss: 0.0707 - sparse_categorical_accuracy: 0.9782\n",
            "384/469 [=======================>......] - ETA: 1:09 - loss: 0.0708 - sparse_categorical_accuracy: 0.9781\n",
            "385/469 [=======================>......] - ETA: 1:08 - loss: 0.0709 - sparse_categorical_accuracy: 0.9781\n",
            "386/469 [=======================>......] - ETA: 1:07 - loss: 0.0710 - sparse_categorical_accuracy: 0.9781\n",
            "387/469 [=======================>......] - ETA: 1:06 - loss: 0.0710 - sparse_categorical_accuracy: 0.9781\n",
            "388/469 [=======================>......] - ETA: 1:05 - loss: 0.0708 - sparse_categorical_accuracy: 0.9781\n",
            "389/469 [=======================>......] - ETA: 1:04 - loss: 0.0707 - sparse_categorical_accuracy: 0.9782\n",
            "390/469 [=======================>......] - ETA: 1:04 - loss: 0.0706 - sparse_categorical_accuracy: 0.9782\n",
            "391/469 [========================>.....] - ETA: 1:03 - loss: 0.0705 - sparse_categorical_accuracy: 0.9782\n",
            "392/469 [========================>.....] - ETA: 1:02 - loss: 0.0705 - sparse_categorical_accuracy: 0.9782\n",
            "393/469 [========================>.....] - ETA: 1:01 - loss: 0.0706 - sparse_categorical_accuracy: 0.9782\n",
            "394/469 [========================>.....] - ETA: 1:00 - loss: 0.0706 - sparse_categorical_accuracy: 0.9782\n",
            "395/469 [========================>.....] - ETA: 59s - loss: 0.0707 - sparse_categorical_accuracy: 0.9781 \n",
            "396/469 [========================>.....] - ETA: 59s - loss: 0.0707 - sparse_categorical_accuracy: 0.9781\n",
            "397/469 [========================>.....] - ETA: 58s - loss: 0.0707 - sparse_categorical_accuracy: 0.9781\n",
            "398/469 [========================>.....] - ETA: 57s - loss: 0.0706 - sparse_categorical_accuracy: 0.9781\n",
            "399/469 [========================>.....] - ETA: 56s - loss: 0.0706 - sparse_categorical_accuracy: 0.9781\n",
            "400/469 [========================>.....] - ETA: 56s - loss: 0.0704 - sparse_categorical_accuracy: 0.9781\n",
            "401/469 [========================>.....] - ETA: 55s - loss: 0.0704 - sparse_categorical_accuracy: 0.9781\n",
            "402/469 [========================>.....] - ETA: 54s - loss: 0.0704 - sparse_categorical_accuracy: 0.9782\n",
            "403/469 [========================>.....] - ETA: 53s - loss: 0.0705 - sparse_categorical_accuracy: 0.9782\n",
            "404/469 [========================>.....] - ETA: 52s - loss: 0.0704 - sparse_categorical_accuracy: 0.9782\n",
            "405/469 [========================>.....] - ETA: 51s - loss: 0.0705 - sparse_categorical_accuracy: 0.9782\n",
            "406/469 [========================>.....] - ETA: 51s - loss: 0.0705 - sparse_categorical_accuracy: 0.9782\n",
            "407/469 [=========================>....] - ETA: 50s - loss: 0.0706 - sparse_categorical_accuracy: 0.9781\n",
            "408/469 [=========================>....] - ETA: 49s - loss: 0.0705 - sparse_categorical_accuracy: 0.9781\n",
            "409/469 [=========================>....] - ETA: 48s - loss: 0.0705 - sparse_categorical_accuracy: 0.9782\n",
            "410/469 [=========================>....] - ETA: 47s - loss: 0.0706 - sparse_categorical_accuracy: 0.9781\n",
            "411/469 [=========================>....] - ETA: 47s - loss: 0.0705 - sparse_categorical_accuracy: 0.9782\n",
            "412/469 [=========================>....] - ETA: 46s - loss: 0.0704 - sparse_categorical_accuracy: 0.9782\n",
            "413/469 [=========================>....] - ETA: 45s - loss: 0.0703 - sparse_categorical_accuracy: 0.9782\n",
            "414/469 [=========================>....] - ETA: 44s - loss: 0.0703 - sparse_categorical_accuracy: 0.9783\n",
            "415/469 [=========================>....] - ETA: 43s - loss: 0.0704 - sparse_categorical_accuracy: 0.9783\n",
            "416/469 [=========================>....] - ETA: 43s - loss: 0.0706 - sparse_categorical_accuracy: 0.9782\n",
            "417/469 [=========================>....] - ETA: 42s - loss: 0.0707 - sparse_categorical_accuracy: 0.9781\n",
            "418/469 [=========================>....] - ETA: 41s - loss: 0.0707 - sparse_categorical_accuracy: 0.9781\n",
            "419/469 [=========================>....] - ETA: 40s - loss: 0.0707 - sparse_categorical_accuracy: 0.9781\n",
            "420/469 [=========================>....] - ETA: 39s - loss: 0.0707 - sparse_categorical_accuracy: 0.9781\n",
            "421/469 [=========================>....] - ETA: 38s - loss: 0.0706 - sparse_categorical_accuracy: 0.9781\n",
            "422/469 [=========================>....] - ETA: 38s - loss: 0.0705 - sparse_categorical_accuracy: 0.9782\n",
            "423/469 [==========================>...] - ETA: 37s - loss: 0.0705 - sparse_categorical_accuracy: 0.9782\n",
            "424/469 [==========================>...] - ETA: 36s - loss: 0.0704 - sparse_categorical_accuracy: 0.9782\n",
            "425/469 [==========================>...] - ETA: 35s - loss: 0.0703 - sparse_categorical_accuracy: 0.9782\n",
            "426/469 [==========================>...] - ETA: 34s - loss: 0.0703 - sparse_categorical_accuracy: 0.9782\n",
            "427/469 [==========================>...] - ETA: 34s - loss: 0.0702 - sparse_categorical_accuracy: 0.9782\n",
            "428/469 [==========================>...] - ETA: 33s - loss: 0.0702 - sparse_categorical_accuracy: 0.9782\n",
            "429/469 [==========================>...] - ETA: 32s - loss: 0.0702 - sparse_categorical_accuracy: 0.9782\n",
            "430/469 [==========================>...] - ETA: 31s - loss: 0.0701 - sparse_categorical_accuracy: 0.9783\n",
            "431/469 [==========================>...] - ETA: 30s - loss: 0.0701 - sparse_categorical_accuracy: 0.9782\n",
            "432/469 [==========================>...] - ETA: 29s - loss: 0.0702 - sparse_categorical_accuracy: 0.9782\n",
            "433/469 [==========================>...] - ETA: 29s - loss: 0.0701 - sparse_categorical_accuracy: 0.9782\n",
            "434/469 [==========================>...] - ETA: 28s - loss: 0.0702 - sparse_categorical_accuracy: 0.9782\n",
            "435/469 [==========================>...] - ETA: 27s - loss: 0.0702 - sparse_categorical_accuracy: 0.9782\n",
            "436/469 [==========================>...] - ETA: 26s - loss: 0.0702 - sparse_categorical_accuracy: 0.9782\n",
            "437/469 [==========================>...] - ETA: 25s - loss: 0.0701 - sparse_categorical_accuracy: 0.9782\n",
            "438/469 [===========================>..] - ETA: 25s - loss: 0.0701 - sparse_categorical_accuracy: 0.9783\n",
            "439/469 [===========================>..] - ETA: 24s - loss: 0.0700 - sparse_categorical_accuracy: 0.9783\n",
            "440/469 [===========================>..] - ETA: 23s - loss: 0.0700 - sparse_categorical_accuracy: 0.9783\n",
            "441/469 [===========================>..] - ETA: 22s - loss: 0.0701 - sparse_categorical_accuracy: 0.9782\n",
            "442/469 [===========================>..] - ETA: 21s - loss: 0.0700 - sparse_categorical_accuracy: 0.9783\n",
            "443/469 [===========================>..] - ETA: 21s - loss: 0.0699 - sparse_categorical_accuracy: 0.9783\n",
            "444/469 [===========================>..] - ETA: 20s - loss: 0.0700 - sparse_categorical_accuracy: 0.9783\n",
            "445/469 [===========================>..] - ETA: 19s - loss: 0.0700 - sparse_categorical_accuracy: 0.9783\n",
            "446/469 [===========================>..] - ETA: 18s - loss: 0.0700 - sparse_categorical_accuracy: 0.9783\n",
            "447/469 [===========================>..] - ETA: 17s - loss: 0.0700 - sparse_categorical_accuracy: 0.9783\n",
            "448/469 [===========================>..] - ETA: 17s - loss: 0.0700 - sparse_categorical_accuracy: 0.9783\n",
            "449/469 [===========================>..] - ETA: 16s - loss: 0.0701 - sparse_categorical_accuracy: 0.9783\n",
            "450/469 [===========================>..] - ETA: 15s - loss: 0.0700 - sparse_categorical_accuracy: 0.9784\n",
            "451/469 [===========================>..] - ETA: 14s - loss: 0.0700 - sparse_categorical_accuracy: 0.9784\n",
            "452/469 [===========================>..] - ETA: 13s - loss: 0.0699 - sparse_categorical_accuracy: 0.9784\n",
            "453/469 [===========================>..] - ETA: 12s - loss: 0.0698 - sparse_categorical_accuracy: 0.9784\n",
            "454/469 [============================>.] - ETA: 12s - loss: 0.0699 - sparse_categorical_accuracy: 0.9784\n",
            "455/469 [============================>.] - ETA: 11s - loss: 0.0700 - sparse_categorical_accuracy: 0.9784\n",
            "456/469 [============================>.] - ETA: 10s - loss: 0.0699 - sparse_categorical_accuracy: 0.9784\n",
            "457/469 [============================>.] - ETA: 9s - loss: 0.0699 - sparse_categorical_accuracy: 0.9784 \n",
            "458/469 [============================>.] - ETA: 8s - loss: 0.0699 - sparse_categorical_accuracy: 0.9784\n",
            "459/469 [============================>.] - ETA: 8s - loss: 0.0699 - sparse_categorical_accuracy: 0.9784\n",
            "460/469 [============================>.] - ETA: 7s - loss: 0.0700 - sparse_categorical_accuracy: 0.9784\n",
            "461/469 [============================>.] - ETA: 6s - loss: 0.0699 - sparse_categorical_accuracy: 0.9785\n",
            "462/469 [============================>.] - ETA: 5s - loss: 0.0698 - sparse_categorical_accuracy: 0.9785\n",
            "463/469 [============================>.] - ETA: 4s - loss: 0.0698 - sparse_categorical_accuracy: 0.9785\n",
            "464/469 [============================>.] - ETA: 4s - loss: 0.0698 - sparse_categorical_accuracy: 0.9785\n",
            "465/469 [============================>.] - ETA: 3s - loss: 0.0698 - sparse_categorical_accuracy: 0.9785\n",
            "466/469 [============================>.] - ETA: 2s - loss: 0.0698 - sparse_categorical_accuracy: 0.9785\n",
            "467/469 [============================>.] - ETA: 1s - loss: 0.0697 - sparse_categorical_accuracy: 0.9785\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0698 - sparse_categorical_accuracy: 0.9785\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0697 - sparse_categorical_accuracy: 0.9785\n",
            "  0%|          | 0/5 [25:03<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/04/16 00:57:04 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 381s 813ms/step - loss: 0.0697 - sparse_categorical_accuracy: 0.9785\n",
            "\n",
            "Epoch 5/5\n",
            "\n",
            "  1/469 [..............................] - ETA: 5:57 - loss: 0.0502 - sparse_categorical_accuracy: 0.9766\n",
            "  2/469 [..............................] - ETA: 5:45 - loss: 0.0789 - sparse_categorical_accuracy: 0.9805\n",
            "  3/469 [..............................] - ETA: 5:49 - loss: 0.0638 - sparse_categorical_accuracy: 0.9818\n",
            "  4/469 [..............................] - ETA: 5:44 - loss: 0.0612 - sparse_categorical_accuracy: 0.9824\n",
            "  5/469 [..............................] - ETA: 5:44 - loss: 0.0610 - sparse_categorical_accuracy: 0.9828\n",
            "  6/469 [..............................] - ETA: 5:40 - loss: 0.0592 - sparse_categorical_accuracy: 0.9844\n",
            "  7/469 [..............................] - ETA: 5:37 - loss: 0.0592 - sparse_categorical_accuracy: 0.9844\n",
            "  8/469 [..............................] - ETA: 5:37 - loss: 0.0574 - sparse_categorical_accuracy: 0.9854\n",
            "  9/469 [..............................] - ETA: 5:36 - loss: 0.0626 - sparse_categorical_accuracy: 0.9835\n",
            " 10/469 [..............................] - ETA: 5:33 - loss: 0.0599 - sparse_categorical_accuracy: 0.9844\n",
            " 11/469 [..............................] - ETA: 5:33 - loss: 0.0561 - sparse_categorical_accuracy: 0.9851\n",
            " 12/469 [..............................] - ETA: 5:33 - loss: 0.0561 - sparse_categorical_accuracy: 0.9837\n",
            " 13/469 [..............................] - ETA: 5:31 - loss: 0.0538 - sparse_categorical_accuracy: 0.9850\n",
            " 14/469 [..............................] - ETA: 5:36 - loss: 0.0524 - sparse_categorical_accuracy: 0.9849\n",
            " 15/469 [..............................] - ETA: 5:52 - loss: 0.0532 - sparse_categorical_accuracy: 0.9839\n",
            " 16/469 [>.............................] - ETA: 6:03 - loss: 0.0535 - sparse_categorical_accuracy: 0.9829\n",
            " 17/469 [>.............................] - ETA: 6:06 - loss: 0.0554 - sparse_categorical_accuracy: 0.9821\n",
            " 18/469 [>.............................] - ETA: 6:02 - loss: 0.0560 - sparse_categorical_accuracy: 0.9822\n",
            " 19/469 [>.............................] - ETA: 6:00 - loss: 0.0572 - sparse_categorical_accuracy: 0.9819\n",
            " 20/469 [>.............................] - ETA: 5:57 - loss: 0.0586 - sparse_categorical_accuracy: 0.9812\n",
            " 21/469 [>.............................] - ETA: 5:54 - loss: 0.0585 - sparse_categorical_accuracy: 0.9814\n",
            " 22/469 [>.............................] - ETA: 5:52 - loss: 0.0571 - sparse_categorical_accuracy: 0.9815\n",
            " 23/469 [>.............................] - ETA: 5:50 - loss: 0.0564 - sparse_categorical_accuracy: 0.9817\n",
            " 24/469 [>.............................] - ETA: 5:47 - loss: 0.0549 - sparse_categorical_accuracy: 0.9821\n",
            " 25/469 [>.............................] - ETA: 5:45 - loss: 0.0578 - sparse_categorical_accuracy: 0.9809\n",
            " 26/469 [>.............................] - ETA: 5:44 - loss: 0.0572 - sparse_categorical_accuracy: 0.9811\n",
            " 27/469 [>.............................] - ETA: 5:42 - loss: 0.0573 - sparse_categorical_accuracy: 0.9806\n",
            " 28/469 [>.............................] - ETA: 5:41 - loss: 0.0561 - sparse_categorical_accuracy: 0.9813\n",
            " 29/469 [>.............................] - ETA: 5:40 - loss: 0.0572 - sparse_categorical_accuracy: 0.9811\n",
            " 30/469 [>.............................] - ETA: 5:39 - loss: 0.0580 - sparse_categorical_accuracy: 0.9812\n",
            " 31/469 [>.............................] - ETA: 5:41 - loss: 0.0586 - sparse_categorical_accuracy: 0.9811\n",
            " 32/469 [=>............................] - ETA: 5:47 - loss: 0.0575 - sparse_categorical_accuracy: 0.9817\n",
            " 33/469 [=>............................] - ETA: 5:51 - loss: 0.0569 - sparse_categorical_accuracy: 0.9820\n",
            " 34/469 [=>............................] - ETA: 5:51 - loss: 0.0559 - sparse_categorical_accuracy: 0.9825\n",
            " 35/469 [=>............................] - ETA: 5:49 - loss: 0.0582 - sparse_categorical_accuracy: 0.9821\n",
            " 36/469 [=>............................] - ETA: 5:47 - loss: 0.0574 - sparse_categorical_accuracy: 0.9824\n",
            " 37/469 [=>............................] - ETA: 5:45 - loss: 0.0571 - sparse_categorical_accuracy: 0.9827\n",
            " 38/469 [=>............................] - ETA: 5:44 - loss: 0.0579 - sparse_categorical_accuracy: 0.9825\n",
            " 39/469 [=>............................] - ETA: 5:42 - loss: 0.0577 - sparse_categorical_accuracy: 0.9826\n",
            " 40/469 [=>............................] - ETA: 5:40 - loss: 0.0569 - sparse_categorical_accuracy: 0.9830\n",
            " 41/469 [=>............................] - ETA: 5:38 - loss: 0.0558 - sparse_categorical_accuracy: 0.9834\n",
            " 42/469 [=>............................] - ETA: 5:37 - loss: 0.0577 - sparse_categorical_accuracy: 0.9833\n",
            " 43/469 [=>............................] - ETA: 5:35 - loss: 0.0574 - sparse_categorical_accuracy: 0.9835\n",
            " 44/469 [=>............................] - ETA: 5:33 - loss: 0.0564 - sparse_categorical_accuracy: 0.9838\n",
            " 45/469 [=>............................] - ETA: 5:32 - loss: 0.0559 - sparse_categorical_accuracy: 0.9840\n",
            " 46/469 [=>............................] - ETA: 5:31 - loss: 0.0556 - sparse_categorical_accuracy: 0.9840\n",
            " 47/469 [==>...........................] - ETA: 5:29 - loss: 0.0554 - sparse_categorical_accuracy: 0.9839\n",
            " 48/469 [==>...........................] - ETA: 5:30 - loss: 0.0564 - sparse_categorical_accuracy: 0.9837\n",
            " 49/469 [==>...........................] - ETA: 5:33 - loss: 0.0562 - sparse_categorical_accuracy: 0.9836\n",
            " 50/469 [==>...........................] - ETA: 5:35 - loss: 0.0556 - sparse_categorical_accuracy: 0.9839\n",
            " 51/469 [==>...........................] - ETA: 5:36 - loss: 0.0573 - sparse_categorical_accuracy: 0.9835\n",
            " 52/469 [==>...........................] - ETA: 5:34 - loss: 0.0571 - sparse_categorical_accuracy: 0.9835\n",
            " 53/469 [==>...........................] - ETA: 5:33 - loss: 0.0580 - sparse_categorical_accuracy: 0.9830\n",
            " 54/469 [==>...........................] - ETA: 5:31 - loss: 0.0575 - sparse_categorical_accuracy: 0.9832\n",
            " 55/469 [==>...........................] - ETA: 5:30 - loss: 0.0573 - sparse_categorical_accuracy: 0.9834\n",
            " 56/469 [==>...........................] - ETA: 5:28 - loss: 0.0577 - sparse_categorical_accuracy: 0.9831\n",
            " 57/469 [==>...........................] - ETA: 5:27 - loss: 0.0572 - sparse_categorical_accuracy: 0.9833\n",
            " 58/469 [==>...........................] - ETA: 5:26 - loss: 0.0577 - sparse_categorical_accuracy: 0.9833\n",
            " 59/469 [==>...........................] - ETA: 5:24 - loss: 0.0581 - sparse_categorical_accuracy: 0.9833\n",
            " 60/469 [==>...........................] - ETA: 5:23 - loss: 0.0583 - sparse_categorical_accuracy: 0.9831\n",
            " 61/469 [==>...........................] - ETA: 5:22 - loss: 0.0584 - sparse_categorical_accuracy: 0.9831\n",
            " 62/469 [==>...........................] - ETA: 5:21 - loss: 0.0582 - sparse_categorical_accuracy: 0.9830\n",
            " 63/469 [===>..........................] - ETA: 5:20 - loss: 0.0577 - sparse_categorical_accuracy: 0.9831\n",
            " 64/469 [===>..........................] - ETA: 5:19 - loss: 0.0571 - sparse_categorical_accuracy: 0.9834\n",
            " 65/469 [===>..........................] - ETA: 5:19 - loss: 0.0567 - sparse_categorical_accuracy: 0.9834\n",
            " 66/469 [===>..........................] - ETA: 5:21 - loss: 0.0563 - sparse_categorical_accuracy: 0.9835\n",
            " 67/469 [===>..........................] - ETA: 5:22 - loss: 0.0567 - sparse_categorical_accuracy: 0.9834\n",
            " 68/469 [===>..........................] - ETA: 5:23 - loss: 0.0566 - sparse_categorical_accuracy: 0.9835\n",
            " 69/469 [===>..........................] - ETA: 5:21 - loss: 0.0572 - sparse_categorical_accuracy: 0.9832\n",
            " 70/469 [===>..........................] - ETA: 5:20 - loss: 0.0577 - sparse_categorical_accuracy: 0.9831\n",
            " 71/469 [===>..........................] - ETA: 5:19 - loss: 0.0571 - sparse_categorical_accuracy: 0.9834\n",
            " 72/469 [===>..........................] - ETA: 5:18 - loss: 0.0565 - sparse_categorical_accuracy: 0.9835\n",
            " 73/469 [===>..........................] - ETA: 5:16 - loss: 0.0563 - sparse_categorical_accuracy: 0.9836\n",
            " 74/469 [===>..........................] - ETA: 5:15 - loss: 0.0560 - sparse_categorical_accuracy: 0.9836\n",
            " 75/469 [===>..........................] - ETA: 5:14 - loss: 0.0555 - sparse_categorical_accuracy: 0.9837\n",
            " 76/469 [===>..........................] - ETA: 5:13 - loss: 0.0568 - sparse_categorical_accuracy: 0.9833\n",
            " 77/469 [===>..........................] - ETA: 5:12 - loss: 0.0567 - sparse_categorical_accuracy: 0.9834\n",
            " 78/469 [===>..........................] - ETA: 5:11 - loss: 0.0575 - sparse_categorical_accuracy: 0.9832\n",
            " 79/469 [====>.........................] - ETA: 5:09 - loss: 0.0576 - sparse_categorical_accuracy: 0.9831\n",
            " 80/469 [====>.........................] - ETA: 5:08 - loss: 0.0571 - sparse_categorical_accuracy: 0.9833\n",
            " 81/469 [====>.........................] - ETA: 5:07 - loss: 0.0573 - sparse_categorical_accuracy: 0.9832\n",
            " 82/469 [====>.........................] - ETA: 5:07 - loss: 0.0571 - sparse_categorical_accuracy: 0.9833\n",
            " 83/469 [====>.........................] - ETA: 5:08 - loss: 0.0585 - sparse_categorical_accuracy: 0.9834\n",
            " 84/469 [====>.........................] - ETA: 5:08 - loss: 0.0583 - sparse_categorical_accuracy: 0.9835\n",
            " 85/469 [====>.........................] - ETA: 5:09 - loss: 0.0581 - sparse_categorical_accuracy: 0.9837\n",
            " 86/469 [====>.........................] - ETA: 5:07 - loss: 0.0581 - sparse_categorical_accuracy: 0.9837\n",
            " 87/469 [====>.........................] - ETA: 5:06 - loss: 0.0577 - sparse_categorical_accuracy: 0.9838\n",
            " 88/469 [====>.........................] - ETA: 5:05 - loss: 0.0574 - sparse_categorical_accuracy: 0.9838\n",
            " 89/469 [====>.........................] - ETA: 5:04 - loss: 0.0571 - sparse_categorical_accuracy: 0.9839\n",
            " 90/469 [====>.........................] - ETA: 5:03 - loss: 0.0571 - sparse_categorical_accuracy: 0.9839\n",
            " 91/469 [====>.........................] - ETA: 5:02 - loss: 0.0571 - sparse_categorical_accuracy: 0.9839\n",
            " 92/469 [====>.........................] - ETA: 5:01 - loss: 0.0574 - sparse_categorical_accuracy: 0.9840\n",
            " 93/469 [====>.........................] - ETA: 4:59 - loss: 0.0577 - sparse_categorical_accuracy: 0.9838\n",
            " 94/469 [=====>........................] - ETA: 4:58 - loss: 0.0576 - sparse_categorical_accuracy: 0.9838\n",
            " 95/469 [=====>........................] - ETA: 4:57 - loss: 0.0575 - sparse_categorical_accuracy: 0.9838\n",
            " 96/469 [=====>........................] - ETA: 4:56 - loss: 0.0573 - sparse_categorical_accuracy: 0.9838\n",
            " 97/469 [=====>........................] - ETA: 4:55 - loss: 0.0572 - sparse_categorical_accuracy: 0.9838\n",
            " 98/469 [=====>........................] - ETA: 4:54 - loss: 0.0572 - sparse_categorical_accuracy: 0.9837\n",
            " 99/469 [=====>........................] - ETA: 4:54 - loss: 0.0575 - sparse_categorical_accuracy: 0.9836\n",
            "100/469 [=====>........................] - ETA: 4:54 - loss: 0.0581 - sparse_categorical_accuracy: 0.9835\n",
            "101/469 [=====>........................] - ETA: 4:55 - loss: 0.0582 - sparse_categorical_accuracy: 0.9834\n",
            "102/469 [=====>........................] - ETA: 4:55 - loss: 0.0582 - sparse_categorical_accuracy: 0.9833\n",
            "103/469 [=====>........................] - ETA: 4:54 - loss: 0.0583 - sparse_categorical_accuracy: 0.9832\n",
            "104/469 [=====>........................] - ETA: 4:53 - loss: 0.0585 - sparse_categorical_accuracy: 0.9832\n",
            "105/469 [=====>........................] - ETA: 4:52 - loss: 0.0583 - sparse_categorical_accuracy: 0.9833\n",
            "106/469 [=====>........................] - ETA: 4:51 - loss: 0.0584 - sparse_categorical_accuracy: 0.9832\n",
            "107/469 [=====>........................] - ETA: 4:49 - loss: 0.0581 - sparse_categorical_accuracy: 0.9833\n",
            "108/469 [=====>........................] - ETA: 4:48 - loss: 0.0579 - sparse_categorical_accuracy: 0.9833\n",
            "109/469 [=====>........................] - ETA: 4:47 - loss: 0.0581 - sparse_categorical_accuracy: 0.9832\n",
            "110/469 [======>.......................] - ETA: 4:46 - loss: 0.0583 - sparse_categorical_accuracy: 0.9830\n",
            "111/469 [======>.......................] - ETA: 4:45 - loss: 0.0580 - sparse_categorical_accuracy: 0.9831\n",
            "112/469 [======>.......................] - ETA: 4:44 - loss: 0.0581 - sparse_categorical_accuracy: 0.9830\n",
            "113/469 [======>.......................] - ETA: 4:43 - loss: 0.0585 - sparse_categorical_accuracy: 0.9829\n",
            "114/469 [======>.......................] - ETA: 4:42 - loss: 0.0584 - sparse_categorical_accuracy: 0.9829\n",
            "115/469 [======>.......................] - ETA: 4:41 - loss: 0.0587 - sparse_categorical_accuracy: 0.9827\n",
            "116/469 [======>.......................] - ETA: 4:40 - loss: 0.0582 - sparse_categorical_accuracy: 0.9828\n",
            "117/469 [======>.......................] - ETA: 4:40 - loss: 0.0585 - sparse_categorical_accuracy: 0.9828\n",
            "118/469 [======>.......................] - ETA: 4:41 - loss: 0.0587 - sparse_categorical_accuracy: 0.9826\n",
            "119/469 [======>.......................] - ETA: 4:41 - loss: 0.0589 - sparse_categorical_accuracy: 0.9826\n",
            "120/469 [======>.......................] - ETA: 4:40 - loss: 0.0592 - sparse_categorical_accuracy: 0.9825\n",
            "121/469 [======>.......................] - ETA: 4:39 - loss: 0.0593 - sparse_categorical_accuracy: 0.9824\n",
            "122/469 [======>.......................] - ETA: 4:38 - loss: 0.0595 - sparse_categorical_accuracy: 0.9823\n",
            "123/469 [======>.......................] - ETA: 4:37 - loss: 0.0593 - sparse_categorical_accuracy: 0.9823\n",
            "124/469 [======>.......................] - ETA: 4:36 - loss: 0.0593 - sparse_categorical_accuracy: 0.9822\n",
            "125/469 [======>.......................] - ETA: 4:35 - loss: 0.0595 - sparse_categorical_accuracy: 0.9822\n",
            "126/469 [=======>......................] - ETA: 4:34 - loss: 0.0598 - sparse_categorical_accuracy: 0.9821\n",
            "127/469 [=======>......................] - ETA: 4:33 - loss: 0.0599 - sparse_categorical_accuracy: 0.9820\n",
            "128/469 [=======>......................] - ETA: 4:32 - loss: 0.0600 - sparse_categorical_accuracy: 0.9820\n",
            "129/469 [=======>......................] - ETA: 4:31 - loss: 0.0599 - sparse_categorical_accuracy: 0.9820\n",
            "130/469 [=======>......................] - ETA: 4:30 - loss: 0.0599 - sparse_categorical_accuracy: 0.9820\n",
            "131/469 [=======>......................] - ETA: 4:29 - loss: 0.0598 - sparse_categorical_accuracy: 0.9820\n",
            "132/469 [=======>......................] - ETA: 4:28 - loss: 0.0596 - sparse_categorical_accuracy: 0.9821\n",
            "133/469 [=======>......................] - ETA: 4:27 - loss: 0.0600 - sparse_categorical_accuracy: 0.9820\n",
            "134/469 [=======>......................] - ETA: 4:27 - loss: 0.0597 - sparse_categorical_accuracy: 0.9821\n",
            "135/469 [=======>......................] - ETA: 4:27 - loss: 0.0600 - sparse_categorical_accuracy: 0.9821\n",
            "136/469 [=======>......................] - ETA: 4:27 - loss: 0.0602 - sparse_categorical_accuracy: 0.9820\n",
            "137/469 [=======>......................] - ETA: 4:26 - loss: 0.0600 - sparse_categorical_accuracy: 0.9821\n",
            "138/469 [=======>......................] - ETA: 4:25 - loss: 0.0603 - sparse_categorical_accuracy: 0.9821\n",
            "139/469 [=======>......................] - ETA: 4:24 - loss: 0.0600 - sparse_categorical_accuracy: 0.9822\n",
            "140/469 [=======>......................] - ETA: 4:23 - loss: 0.0600 - sparse_categorical_accuracy: 0.9822\n",
            "141/469 [========>.....................] - ETA: 4:22 - loss: 0.0597 - sparse_categorical_accuracy: 0.9823\n",
            "142/469 [========>.....................] - ETA: 4:21 - loss: 0.0594 - sparse_categorical_accuracy: 0.9824\n",
            "143/469 [========>.....................] - ETA: 4:20 - loss: 0.0597 - sparse_categorical_accuracy: 0.9824\n",
            "144/469 [========>.....................] - ETA: 4:20 - loss: 0.0599 - sparse_categorical_accuracy: 0.9824\n",
            "145/469 [========>.....................] - ETA: 4:19 - loss: 0.0597 - sparse_categorical_accuracy: 0.9824\n",
            "146/469 [========>.....................] - ETA: 4:18 - loss: 0.0595 - sparse_categorical_accuracy: 0.9825\n",
            "147/469 [========>.....................] - ETA: 4:17 - loss: 0.0595 - sparse_categorical_accuracy: 0.9825\n",
            "148/469 [========>.....................] - ETA: 4:16 - loss: 0.0594 - sparse_categorical_accuracy: 0.9825\n",
            "149/469 [========>.....................] - ETA: 4:15 - loss: 0.0594 - sparse_categorical_accuracy: 0.9825\n",
            "150/469 [========>.....................] - ETA: 4:14 - loss: 0.0594 - sparse_categorical_accuracy: 0.9824\n",
            "151/469 [========>.....................] - ETA: 4:14 - loss: 0.0597 - sparse_categorical_accuracy: 0.9824\n",
            "152/469 [========>.....................] - ETA: 4:14 - loss: 0.0604 - sparse_categorical_accuracy: 0.9821\n",
            "153/469 [========>.....................] - ETA: 4:14 - loss: 0.0604 - sparse_categorical_accuracy: 0.9821\n",
            "154/469 [========>.....................] - ETA: 4:13 - loss: 0.0606 - sparse_categorical_accuracy: 0.9820\n",
            "155/469 [========>.....................] - ETA: 4:12 - loss: 0.0604 - sparse_categorical_accuracy: 0.9821\n",
            "156/469 [========>.....................] - ETA: 4:11 - loss: 0.0610 - sparse_categorical_accuracy: 0.9820\n",
            "157/469 [=========>....................] - ETA: 4:10 - loss: 0.0607 - sparse_categorical_accuracy: 0.9821\n",
            "158/469 [=========>....................] - ETA: 4:09 - loss: 0.0607 - sparse_categorical_accuracy: 0.9821\n",
            "159/469 [=========>....................] - ETA: 4:08 - loss: 0.0608 - sparse_categorical_accuracy: 0.9820\n",
            "160/469 [=========>....................] - ETA: 4:07 - loss: 0.0607 - sparse_categorical_accuracy: 0.9820\n",
            "161/469 [=========>....................] - ETA: 4:06 - loss: 0.0608 - sparse_categorical_accuracy: 0.9819\n",
            "162/469 [=========>....................] - ETA: 4:05 - loss: 0.0609 - sparse_categorical_accuracy: 0.9819\n",
            "163/469 [=========>....................] - ETA: 4:04 - loss: 0.0615 - sparse_categorical_accuracy: 0.9818\n",
            "164/469 [=========>....................] - ETA: 4:03 - loss: 0.0614 - sparse_categorical_accuracy: 0.9819\n",
            "165/469 [=========>....................] - ETA: 4:03 - loss: 0.0614 - sparse_categorical_accuracy: 0.9819\n",
            "166/469 [=========>....................] - ETA: 4:02 - loss: 0.0613 - sparse_categorical_accuracy: 0.9819\n",
            "167/469 [=========>....................] - ETA: 4:02 - loss: 0.0612 - sparse_categorical_accuracy: 0.9818\n",
            "168/469 [=========>....................] - ETA: 4:01 - loss: 0.0610 - sparse_categorical_accuracy: 0.9819\n",
            "169/469 [=========>....................] - ETA: 4:01 - loss: 0.0614 - sparse_categorical_accuracy: 0.9817\n",
            "170/469 [=========>....................] - ETA: 4:01 - loss: 0.0615 - sparse_categorical_accuracy: 0.9817\n",
            "171/469 [=========>....................] - ETA: 4:00 - loss: 0.0616 - sparse_categorical_accuracy: 0.9817\n",
            "172/469 [==========>...................] - ETA: 3:59 - loss: 0.0614 - sparse_categorical_accuracy: 0.9818\n",
            "173/469 [==========>...................] - ETA: 3:58 - loss: 0.0617 - sparse_categorical_accuracy: 0.9817\n",
            "174/469 [==========>...................] - ETA: 3:57 - loss: 0.0615 - sparse_categorical_accuracy: 0.9817\n",
            "175/469 [==========>...................] - ETA: 3:56 - loss: 0.0616 - sparse_categorical_accuracy: 0.9817\n",
            "176/469 [==========>...................] - ETA: 3:55 - loss: 0.0618 - sparse_categorical_accuracy: 0.9816\n",
            "177/469 [==========>...................] - ETA: 3:54 - loss: 0.0617 - sparse_categorical_accuracy: 0.9816\n",
            "178/469 [==========>...................] - ETA: 3:53 - loss: 0.0615 - sparse_categorical_accuracy: 0.9817\n",
            "179/469 [==========>...................] - ETA: 3:52 - loss: 0.0615 - sparse_categorical_accuracy: 0.9817\n",
            "180/469 [==========>...................] - ETA: 3:51 - loss: 0.0616 - sparse_categorical_accuracy: 0.9816\n",
            "181/469 [==========>...................] - ETA: 3:50 - loss: 0.0616 - sparse_categorical_accuracy: 0.9815\n",
            "182/469 [==========>...................] - ETA: 3:49 - loss: 0.0618 - sparse_categorical_accuracy: 0.9815\n",
            "183/469 [==========>...................] - ETA: 3:48 - loss: 0.0617 - sparse_categorical_accuracy: 0.9815\n",
            "184/469 [==========>...................] - ETA: 3:48 - loss: 0.0617 - sparse_categorical_accuracy: 0.9815\n",
            "185/469 [==========>...................] - ETA: 3:48 - loss: 0.0618 - sparse_categorical_accuracy: 0.9814\n",
            "186/469 [==========>...................] - ETA: 3:47 - loss: 0.0621 - sparse_categorical_accuracy: 0.9813\n",
            "187/469 [==========>...................] - ETA: 3:47 - loss: 0.0620 - sparse_categorical_accuracy: 0.9813\n",
            "188/469 [===========>..................] - ETA: 3:46 - loss: 0.0620 - sparse_categorical_accuracy: 0.9813\n",
            "189/469 [===========>..................] - ETA: 3:45 - loss: 0.0619 - sparse_categorical_accuracy: 0.9813\n",
            "190/469 [===========>..................] - ETA: 3:44 - loss: 0.0618 - sparse_categorical_accuracy: 0.9814\n",
            "191/469 [===========>..................] - ETA: 3:43 - loss: 0.0618 - sparse_categorical_accuracy: 0.9814\n",
            "192/469 [===========>..................] - ETA: 3:42 - loss: 0.0620 - sparse_categorical_accuracy: 0.9813\n",
            "193/469 [===========>..................] - ETA: 3:41 - loss: 0.0621 - sparse_categorical_accuracy: 0.9812\n",
            "194/469 [===========>..................] - ETA: 3:40 - loss: 0.0621 - sparse_categorical_accuracy: 0.9813\n",
            "195/469 [===========>..................] - ETA: 3:40 - loss: 0.0624 - sparse_categorical_accuracy: 0.9812\n",
            "196/469 [===========>..................] - ETA: 3:39 - loss: 0.0623 - sparse_categorical_accuracy: 0.9813\n",
            "197/469 [===========>..................] - ETA: 3:38 - loss: 0.0624 - sparse_categorical_accuracy: 0.9812\n",
            "198/469 [===========>..................] - ETA: 3:37 - loss: 0.0621 - sparse_categorical_accuracy: 0.9813\n",
            "199/469 [===========>..................] - ETA: 3:36 - loss: 0.0620 - sparse_categorical_accuracy: 0.9813\n",
            "200/469 [===========>..................] - ETA: 3:35 - loss: 0.0618 - sparse_categorical_accuracy: 0.9813\n",
            "201/469 [===========>..................] - ETA: 3:35 - loss: 0.0616 - sparse_categorical_accuracy: 0.9814\n",
            "202/469 [===========>..................] - ETA: 3:34 - loss: 0.0614 - sparse_categorical_accuracy: 0.9815\n",
            "203/469 [===========>..................] - ETA: 3:34 - loss: 0.0614 - sparse_categorical_accuracy: 0.9815\n",
            "204/469 [============>.................] - ETA: 3:33 - loss: 0.0613 - sparse_categorical_accuracy: 0.9814\n",
            "205/469 [============>.................] - ETA: 3:32 - loss: 0.0612 - sparse_categorical_accuracy: 0.9815\n",
            "206/469 [============>.................] - ETA: 3:31 - loss: 0.0611 - sparse_categorical_accuracy: 0.9815\n",
            "207/469 [============>.................] - ETA: 3:31 - loss: 0.0612 - sparse_categorical_accuracy: 0.9814\n",
            "208/469 [============>.................] - ETA: 3:30 - loss: 0.0612 - sparse_categorical_accuracy: 0.9814\n",
            "209/469 [============>.................] - ETA: 3:29 - loss: 0.0611 - sparse_categorical_accuracy: 0.9814\n",
            "210/469 [============>.................] - ETA: 3:28 - loss: 0.0612 - sparse_categorical_accuracy: 0.9814\n",
            "211/469 [============>.................] - ETA: 3:27 - loss: 0.0611 - sparse_categorical_accuracy: 0.9814\n",
            "212/469 [============>.................] - ETA: 3:26 - loss: 0.0610 - sparse_categorical_accuracy: 0.9814\n",
            "213/469 [============>.................] - ETA: 3:25 - loss: 0.0609 - sparse_categorical_accuracy: 0.9814\n",
            "214/469 [============>.................] - ETA: 3:24 - loss: 0.0611 - sparse_categorical_accuracy: 0.9813\n",
            "215/469 [============>.................] - ETA: 3:23 - loss: 0.0609 - sparse_categorical_accuracy: 0.9814\n",
            "216/469 [============>.................] - ETA: 3:22 - loss: 0.0608 - sparse_categorical_accuracy: 0.9814\n",
            "217/469 [============>.................] - ETA: 3:21 - loss: 0.0610 - sparse_categorical_accuracy: 0.9813\n",
            "218/469 [============>.................] - ETA: 3:21 - loss: 0.0610 - sparse_categorical_accuracy: 0.9813\n",
            "219/469 [=============>................] - ETA: 3:21 - loss: 0.0609 - sparse_categorical_accuracy: 0.9814\n",
            "220/469 [=============>................] - ETA: 3:20 - loss: 0.0608 - sparse_categorical_accuracy: 0.9814\n",
            "221/469 [=============>................] - ETA: 3:19 - loss: 0.0608 - sparse_categorical_accuracy: 0.9814\n",
            "222/469 [=============>................] - ETA: 3:19 - loss: 0.0610 - sparse_categorical_accuracy: 0.9813\n",
            "223/469 [=============>................] - ETA: 3:18 - loss: 0.0610 - sparse_categorical_accuracy: 0.9813\n",
            "224/469 [=============>................] - ETA: 3:17 - loss: 0.0610 - sparse_categorical_accuracy: 0.9812\n",
            "225/469 [=============>................] - ETA: 3:16 - loss: 0.0610 - sparse_categorical_accuracy: 0.9812\n",
            "226/469 [=============>................] - ETA: 3:15 - loss: 0.0612 - sparse_categorical_accuracy: 0.9812\n",
            "227/469 [=============>................] - ETA: 3:14 - loss: 0.0612 - sparse_categorical_accuracy: 0.9811\n",
            "228/469 [=============>................] - ETA: 3:13 - loss: 0.0610 - sparse_categorical_accuracy: 0.9812\n",
            "229/469 [=============>................] - ETA: 3:12 - loss: 0.0611 - sparse_categorical_accuracy: 0.9811\n",
            "230/469 [=============>................] - ETA: 3:11 - loss: 0.0611 - sparse_categorical_accuracy: 0.9811\n",
            "231/469 [=============>................] - ETA: 3:11 - loss: 0.0610 - sparse_categorical_accuracy: 0.9811\n",
            "232/469 [=============>................] - ETA: 3:10 - loss: 0.0610 - sparse_categorical_accuracy: 0.9811\n",
            "233/469 [=============>................] - ETA: 3:09 - loss: 0.0611 - sparse_categorical_accuracy: 0.9811\n",
            "234/469 [=============>................] - ETA: 3:08 - loss: 0.0611 - sparse_categorical_accuracy: 0.9811\n",
            "235/469 [==============>...............] - ETA: 3:08 - loss: 0.0610 - sparse_categorical_accuracy: 0.9811\n",
            "236/469 [==============>...............] - ETA: 3:07 - loss: 0.0609 - sparse_categorical_accuracy: 0.9811\n",
            "237/469 [==============>...............] - ETA: 3:07 - loss: 0.0610 - sparse_categorical_accuracy: 0.9811\n",
            "238/469 [==============>...............] - ETA: 3:06 - loss: 0.0608 - sparse_categorical_accuracy: 0.9812\n",
            "239/469 [==============>...............] - ETA: 3:05 - loss: 0.0607 - sparse_categorical_accuracy: 0.9812\n",
            "240/469 [==============>...............] - ETA: 3:04 - loss: 0.0607 - sparse_categorical_accuracy: 0.9812\n",
            "241/469 [==============>...............] - ETA: 3:03 - loss: 0.0605 - sparse_categorical_accuracy: 0.9813\n",
            "242/469 [==============>...............] - ETA: 3:02 - loss: 0.0604 - sparse_categorical_accuracy: 0.9813\n",
            "243/469 [==============>...............] - ETA: 3:01 - loss: 0.0603 - sparse_categorical_accuracy: 0.9814\n",
            "244/469 [==============>...............] - ETA: 3:00 - loss: 0.0603 - sparse_categorical_accuracy: 0.9813\n",
            "245/469 [==============>...............] - ETA: 3:00 - loss: 0.0602 - sparse_categorical_accuracy: 0.9813\n",
            "246/469 [==============>...............] - ETA: 2:59 - loss: 0.0604 - sparse_categorical_accuracy: 0.9813\n",
            "247/469 [==============>...............] - ETA: 2:58 - loss: 0.0604 - sparse_categorical_accuracy: 0.9813\n",
            "248/469 [==============>...............] - ETA: 2:57 - loss: 0.0603 - sparse_categorical_accuracy: 0.9814\n",
            "249/469 [==============>...............] - ETA: 2:56 - loss: 0.0602 - sparse_categorical_accuracy: 0.9814\n",
            "250/469 [==============>...............] - ETA: 2:55 - loss: 0.0602 - sparse_categorical_accuracy: 0.9814\n",
            "251/469 [===============>..............] - ETA: 2:54 - loss: 0.0605 - sparse_categorical_accuracy: 0.9814\n",
            "252/469 [===============>..............] - ETA: 2:54 - loss: 0.0603 - sparse_categorical_accuracy: 0.9814\n",
            "253/469 [===============>..............] - ETA: 2:53 - loss: 0.0602 - sparse_categorical_accuracy: 0.9814\n",
            "254/469 [===============>..............] - ETA: 2:53 - loss: 0.0602 - sparse_categorical_accuracy: 0.9814\n",
            "255/469 [===============>..............] - ETA: 2:52 - loss: 0.0601 - sparse_categorical_accuracy: 0.9814\n",
            "256/469 [===============>..............] - ETA: 2:51 - loss: 0.0601 - sparse_categorical_accuracy: 0.9814\n",
            "257/469 [===============>..............] - ETA: 2:50 - loss: 0.0600 - sparse_categorical_accuracy: 0.9814\n",
            "258/469 [===============>..............] - ETA: 2:49 - loss: 0.0600 - sparse_categorical_accuracy: 0.9814\n",
            "259/469 [===============>..............] - ETA: 2:49 - loss: 0.0600 - sparse_categorical_accuracy: 0.9814\n",
            "260/469 [===============>..............] - ETA: 2:48 - loss: 0.0599 - sparse_categorical_accuracy: 0.9813\n",
            "261/469 [===============>..............] - ETA: 2:47 - loss: 0.0599 - sparse_categorical_accuracy: 0.9813\n",
            "262/469 [===============>..............] - ETA: 2:46 - loss: 0.0600 - sparse_categorical_accuracy: 0.9813\n",
            "263/469 [===============>..............] - ETA: 2:45 - loss: 0.0601 - sparse_categorical_accuracy: 0.9812\n",
            "264/469 [===============>..............] - ETA: 2:44 - loss: 0.0601 - sparse_categorical_accuracy: 0.9812\n",
            "265/469 [===============>..............] - ETA: 2:43 - loss: 0.0604 - sparse_categorical_accuracy: 0.9812\n",
            "266/469 [================>.............] - ETA: 2:42 - loss: 0.0603 - sparse_categorical_accuracy: 0.9813\n",
            "267/469 [================>.............] - ETA: 2:42 - loss: 0.0603 - sparse_categorical_accuracy: 0.9813\n",
            "268/469 [================>.............] - ETA: 2:41 - loss: 0.0605 - sparse_categorical_accuracy: 0.9813\n",
            "269/469 [================>.............] - ETA: 2:40 - loss: 0.0607 - sparse_categorical_accuracy: 0.9812\n",
            "270/469 [================>.............] - ETA: 2:40 - loss: 0.0605 - sparse_categorical_accuracy: 0.9813\n",
            "271/469 [================>.............] - ETA: 2:39 - loss: 0.0605 - sparse_categorical_accuracy: 0.9813\n",
            "272/469 [================>.............] - ETA: 2:38 - loss: 0.0604 - sparse_categorical_accuracy: 0.9814\n",
            "273/469 [================>.............] - ETA: 2:38 - loss: 0.0604 - sparse_categorical_accuracy: 0.9813\n",
            "274/469 [================>.............] - ETA: 2:37 - loss: 0.0604 - sparse_categorical_accuracy: 0.9814\n",
            "275/469 [================>.............] - ETA: 2:36 - loss: 0.0603 - sparse_categorical_accuracy: 0.9814\n",
            "276/469 [================>.............] - ETA: 2:35 - loss: 0.0602 - sparse_categorical_accuracy: 0.9815\n",
            "277/469 [================>.............] - ETA: 2:34 - loss: 0.0601 - sparse_categorical_accuracy: 0.9815\n",
            "278/469 [================>.............] - ETA: 2:33 - loss: 0.0600 - sparse_categorical_accuracy: 0.9815\n",
            "279/469 [================>.............] - ETA: 2:32 - loss: 0.0599 - sparse_categorical_accuracy: 0.9816\n",
            "280/469 [================>.............] - ETA: 2:32 - loss: 0.0597 - sparse_categorical_accuracy: 0.9816\n",
            "281/469 [================>.............] - ETA: 2:31 - loss: 0.0597 - sparse_categorical_accuracy: 0.9816\n",
            "282/469 [=================>............] - ETA: 2:30 - loss: 0.0597 - sparse_categorical_accuracy: 0.9816\n",
            "283/469 [=================>............] - ETA: 2:29 - loss: 0.0598 - sparse_categorical_accuracy: 0.9816\n",
            "284/469 [=================>............] - ETA: 2:28 - loss: 0.0596 - sparse_categorical_accuracy: 0.9816\n",
            "285/469 [=================>............] - ETA: 2:27 - loss: 0.0599 - sparse_categorical_accuracy: 0.9816\n",
            "286/469 [=================>............] - ETA: 2:27 - loss: 0.0599 - sparse_categorical_accuracy: 0.9816\n",
            "287/469 [=================>............] - ETA: 2:26 - loss: 0.0598 - sparse_categorical_accuracy: 0.9816\n",
            "288/469 [=================>............] - ETA: 2:26 - loss: 0.0598 - sparse_categorical_accuracy: 0.9816\n",
            "289/469 [=================>............] - ETA: 2:25 - loss: 0.0600 - sparse_categorical_accuracy: 0.9815\n",
            "290/469 [=================>............] - ETA: 2:24 - loss: 0.0603 - sparse_categorical_accuracy: 0.9814\n",
            "291/469 [=================>............] - ETA: 2:23 - loss: 0.0603 - sparse_categorical_accuracy: 0.9814\n",
            "292/469 [=================>............] - ETA: 2:22 - loss: 0.0602 - sparse_categorical_accuracy: 0.9815\n",
            "293/469 [=================>............] - ETA: 2:21 - loss: 0.0602 - sparse_categorical_accuracy: 0.9815\n",
            "294/469 [=================>............] - ETA: 2:21 - loss: 0.0601 - sparse_categorical_accuracy: 0.9815\n",
            "295/469 [=================>............] - ETA: 2:20 - loss: 0.0600 - sparse_categorical_accuracy: 0.9815\n",
            "296/469 [=================>............] - ETA: 2:19 - loss: 0.0603 - sparse_categorical_accuracy: 0.9815\n",
            "297/469 [=================>............] - ETA: 2:18 - loss: 0.0603 - sparse_categorical_accuracy: 0.9814\n",
            "298/469 [==================>...........] - ETA: 2:17 - loss: 0.0603 - sparse_categorical_accuracy: 0.9814\n",
            "299/469 [==================>...........] - ETA: 2:16 - loss: 0.0603 - sparse_categorical_accuracy: 0.9814\n",
            "300/469 [==================>...........] - ETA: 2:16 - loss: 0.0603 - sparse_categorical_accuracy: 0.9814\n",
            "301/469 [==================>...........] - ETA: 2:15 - loss: 0.0603 - sparse_categorical_accuracy: 0.9814\n",
            "302/469 [==================>...........] - ETA: 2:14 - loss: 0.0604 - sparse_categorical_accuracy: 0.9815\n",
            "303/469 [==================>...........] - ETA: 2:13 - loss: 0.0604 - sparse_categorical_accuracy: 0.9814\n",
            "304/469 [==================>...........] - ETA: 2:13 - loss: 0.0604 - sparse_categorical_accuracy: 0.9814\n",
            "305/469 [==================>...........] - ETA: 2:12 - loss: 0.0603 - sparse_categorical_accuracy: 0.9815\n",
            "306/469 [==================>...........] - ETA: 2:11 - loss: 0.0603 - sparse_categorical_accuracy: 0.9815\n",
            "307/469 [==================>...........] - ETA: 2:10 - loss: 0.0604 - sparse_categorical_accuracy: 0.9815\n",
            "308/469 [==================>...........] - ETA: 2:09 - loss: 0.0604 - sparse_categorical_accuracy: 0.9815\n",
            "309/469 [==================>...........] - ETA: 2:08 - loss: 0.0605 - sparse_categorical_accuracy: 0.9814\n",
            "310/469 [==================>...........] - ETA: 2:08 - loss: 0.0605 - sparse_categorical_accuracy: 0.9814\n",
            "311/469 [==================>...........] - ETA: 2:07 - loss: 0.0604 - sparse_categorical_accuracy: 0.9814\n",
            "312/469 [==================>...........] - ETA: 2:06 - loss: 0.0606 - sparse_categorical_accuracy: 0.9813\n",
            "313/469 [===================>..........] - ETA: 2:05 - loss: 0.0606 - sparse_categorical_accuracy: 0.9813\n",
            "314/469 [===================>..........] - ETA: 2:04 - loss: 0.0605 - sparse_categorical_accuracy: 0.9813\n",
            "315/469 [===================>..........] - ETA: 2:03 - loss: 0.0604 - sparse_categorical_accuracy: 0.9813\n",
            "316/469 [===================>..........] - ETA: 2:02 - loss: 0.0603 - sparse_categorical_accuracy: 0.9813\n",
            "317/469 [===================>..........] - ETA: 2:02 - loss: 0.0605 - sparse_categorical_accuracy: 0.9813\n",
            "318/469 [===================>..........] - ETA: 2:01 - loss: 0.0606 - sparse_categorical_accuracy: 0.9813\n",
            "319/469 [===================>..........] - ETA: 2:00 - loss: 0.0606 - sparse_categorical_accuracy: 0.9813\n",
            "320/469 [===================>..........] - ETA: 1:59 - loss: 0.0608 - sparse_categorical_accuracy: 0.9812\n",
            "321/469 [===================>..........] - ETA: 1:59 - loss: 0.0606 - sparse_categorical_accuracy: 0.9813\n",
            "322/469 [===================>..........] - ETA: 1:58 - loss: 0.0606 - sparse_categorical_accuracy: 0.9813\n",
            "323/469 [===================>..........] - ETA: 1:57 - loss: 0.0605 - sparse_categorical_accuracy: 0.9813\n",
            "324/469 [===================>..........] - ETA: 1:56 - loss: 0.0606 - sparse_categorical_accuracy: 0.9813\n",
            "325/469 [===================>..........] - ETA: 1:55 - loss: 0.0608 - sparse_categorical_accuracy: 0.9812\n",
            "326/469 [===================>..........] - ETA: 1:55 - loss: 0.0607 - sparse_categorical_accuracy: 0.9813\n",
            "327/469 [===================>..........] - ETA: 1:54 - loss: 0.0606 - sparse_categorical_accuracy: 0.9813\n",
            "328/469 [===================>..........] - ETA: 1:53 - loss: 0.0606 - sparse_categorical_accuracy: 0.9813\n",
            "329/469 [====================>.........] - ETA: 1:52 - loss: 0.0607 - sparse_categorical_accuracy: 0.9813\n",
            "330/469 [====================>.........] - ETA: 1:51 - loss: 0.0608 - sparse_categorical_accuracy: 0.9813\n",
            "331/469 [====================>.........] - ETA: 1:50 - loss: 0.0608 - sparse_categorical_accuracy: 0.9813\n",
            "332/469 [====================>.........] - ETA: 1:50 - loss: 0.0607 - sparse_categorical_accuracy: 0.9813\n",
            "333/469 [====================>.........] - ETA: 1:49 - loss: 0.0607 - sparse_categorical_accuracy: 0.9813\n",
            "334/469 [====================>.........] - ETA: 1:48 - loss: 0.0607 - sparse_categorical_accuracy: 0.9813\n",
            "335/469 [====================>.........] - ETA: 1:47 - loss: 0.0610 - sparse_categorical_accuracy: 0.9813\n",
            "336/469 [====================>.........] - ETA: 1:46 - loss: 0.0610 - sparse_categorical_accuracy: 0.9812\n",
            "337/469 [====================>.........] - ETA: 1:46 - loss: 0.0611 - sparse_categorical_accuracy: 0.9812\n",
            "338/469 [====================>.........] - ETA: 1:45 - loss: 0.0612 - sparse_categorical_accuracy: 0.9812\n",
            "339/469 [====================>.........] - ETA: 1:44 - loss: 0.0612 - sparse_categorical_accuracy: 0.9812\n",
            "340/469 [====================>.........] - ETA: 1:43 - loss: 0.0617 - sparse_categorical_accuracy: 0.9810\n",
            "341/469 [====================>.........] - ETA: 1:42 - loss: 0.0616 - sparse_categorical_accuracy: 0.9811\n",
            "342/469 [====================>.........] - ETA: 1:42 - loss: 0.0615 - sparse_categorical_accuracy: 0.9811\n",
            "343/469 [====================>.........] - ETA: 1:41 - loss: 0.0615 - sparse_categorical_accuracy: 0.9811\n",
            "344/469 [=====================>........] - ETA: 1:40 - loss: 0.0615 - sparse_categorical_accuracy: 0.9811\n",
            "345/469 [=====================>........] - ETA: 1:39 - loss: 0.0614 - sparse_categorical_accuracy: 0.9811\n",
            "346/469 [=====================>........] - ETA: 1:38 - loss: 0.0613 - sparse_categorical_accuracy: 0.9812\n",
            "347/469 [=====================>........] - ETA: 1:37 - loss: 0.0613 - sparse_categorical_accuracy: 0.9812\n",
            "348/469 [=====================>........] - ETA: 1:37 - loss: 0.0613 - sparse_categorical_accuracy: 0.9811\n",
            "349/469 [=====================>........] - ETA: 1:36 - loss: 0.0613 - sparse_categorical_accuracy: 0.9812\n",
            "350/469 [=====================>........] - ETA: 1:35 - loss: 0.0613 - sparse_categorical_accuracy: 0.9812\n",
            "351/469 [=====================>........] - ETA: 1:34 - loss: 0.0612 - sparse_categorical_accuracy: 0.9812\n",
            "352/469 [=====================>........] - ETA: 1:33 - loss: 0.0611 - sparse_categorical_accuracy: 0.9812\n",
            "353/469 [=====================>........] - ETA: 1:33 - loss: 0.0609 - sparse_categorical_accuracy: 0.9813\n",
            "354/469 [=====================>........] - ETA: 1:32 - loss: 0.0610 - sparse_categorical_accuracy: 0.9813\n",
            "355/469 [=====================>........] - ETA: 1:31 - loss: 0.0608 - sparse_categorical_accuracy: 0.9813\n",
            "356/469 [=====================>........] - ETA: 1:30 - loss: 0.0608 - sparse_categorical_accuracy: 0.9813\n",
            "357/469 [=====================>........] - ETA: 1:30 - loss: 0.0608 - sparse_categorical_accuracy: 0.9813\n",
            "358/469 [=====================>........] - ETA: 1:29 - loss: 0.0607 - sparse_categorical_accuracy: 0.9813\n",
            "359/469 [=====================>........] - ETA: 1:28 - loss: 0.0610 - sparse_categorical_accuracy: 0.9813\n",
            "360/469 [======================>.......] - ETA: 1:27 - loss: 0.0609 - sparse_categorical_accuracy: 0.9813\n",
            "361/469 [======================>.......] - ETA: 1:26 - loss: 0.0610 - sparse_categorical_accuracy: 0.9813\n",
            "362/469 [======================>.......] - ETA: 1:25 - loss: 0.0610 - sparse_categorical_accuracy: 0.9813\n",
            "363/469 [======================>.......] - ETA: 1:25 - loss: 0.0610 - sparse_categorical_accuracy: 0.9813\n",
            "364/469 [======================>.......] - ETA: 1:24 - loss: 0.0610 - sparse_categorical_accuracy: 0.9813\n",
            "365/469 [======================>.......] - ETA: 1:23 - loss: 0.0609 - sparse_categorical_accuracy: 0.9814\n",
            "366/469 [======================>.......] - ETA: 1:22 - loss: 0.0609 - sparse_categorical_accuracy: 0.9814\n",
            "367/469 [======================>.......] - ETA: 1:21 - loss: 0.0609 - sparse_categorical_accuracy: 0.9814\n",
            "368/469 [======================>.......] - ETA: 1:20 - loss: 0.0609 - sparse_categorical_accuracy: 0.9814\n",
            "369/469 [======================>.......] - ETA: 1:20 - loss: 0.0609 - sparse_categorical_accuracy: 0.9814\n",
            "370/469 [======================>.......] - ETA: 1:19 - loss: 0.0608 - sparse_categorical_accuracy: 0.9814\n",
            "371/469 [======================>.......] - ETA: 1:18 - loss: 0.0608 - sparse_categorical_accuracy: 0.9814\n",
            "372/469 [======================>.......] - ETA: 1:17 - loss: 0.0609 - sparse_categorical_accuracy: 0.9814\n",
            "373/469 [======================>.......] - ETA: 1:17 - loss: 0.0609 - sparse_categorical_accuracy: 0.9813\n",
            "374/469 [======================>.......] - ETA: 1:16 - loss: 0.0608 - sparse_categorical_accuracy: 0.9814\n",
            "375/469 [======================>.......] - ETA: 1:15 - loss: 0.0607 - sparse_categorical_accuracy: 0.9814\n",
            "376/469 [=======================>......] - ETA: 1:14 - loss: 0.0607 - sparse_categorical_accuracy: 0.9814\n",
            "377/469 [=======================>......] - ETA: 1:13 - loss: 0.0606 - sparse_categorical_accuracy: 0.9814\n",
            "378/469 [=======================>......] - ETA: 1:12 - loss: 0.0606 - sparse_categorical_accuracy: 0.9814\n",
            "379/469 [=======================>......] - ETA: 1:12 - loss: 0.0607 - sparse_categorical_accuracy: 0.9814\n",
            "380/469 [=======================>......] - ETA: 1:11 - loss: 0.0606 - sparse_categorical_accuracy: 0.9814\n",
            "381/469 [=======================>......] - ETA: 1:10 - loss: 0.0605 - sparse_categorical_accuracy: 0.9815\n",
            "382/469 [=======================>......] - ETA: 1:09 - loss: 0.0605 - sparse_categorical_accuracy: 0.9815\n",
            "383/469 [=======================>......] - ETA: 1:08 - loss: 0.0606 - sparse_categorical_accuracy: 0.9814\n",
            "384/469 [=======================>......] - ETA: 1:08 - loss: 0.0605 - sparse_categorical_accuracy: 0.9815\n",
            "385/469 [=======================>......] - ETA: 1:07 - loss: 0.0605 - sparse_categorical_accuracy: 0.9815\n",
            "386/469 [=======================>......] - ETA: 1:06 - loss: 0.0603 - sparse_categorical_accuracy: 0.9815\n",
            "387/469 [=======================>......] - ETA: 1:05 - loss: 0.0604 - sparse_categorical_accuracy: 0.9815\n",
            "388/469 [=======================>......] - ETA: 1:04 - loss: 0.0603 - sparse_categorical_accuracy: 0.9815\n",
            "389/469 [=======================>......] - ETA: 1:04 - loss: 0.0603 - sparse_categorical_accuracy: 0.9815\n",
            "390/469 [=======================>......] - ETA: 1:03 - loss: 0.0603 - sparse_categorical_accuracy: 0.9816\n",
            "391/469 [========================>.....] - ETA: 1:02 - loss: 0.0603 - sparse_categorical_accuracy: 0.9816\n",
            "392/469 [========================>.....] - ETA: 1:01 - loss: 0.0603 - sparse_categorical_accuracy: 0.9816\n",
            "393/469 [========================>.....] - ETA: 1:00 - loss: 0.0602 - sparse_categorical_accuracy: 0.9816\n",
            "394/469 [========================>.....] - ETA: 1:00 - loss: 0.0602 - sparse_categorical_accuracy: 0.9816\n",
            "395/469 [========================>.....] - ETA: 59s - loss: 0.0601 - sparse_categorical_accuracy: 0.9816 \n",
            "396/469 [========================>.....] - ETA: 58s - loss: 0.0601 - sparse_categorical_accuracy: 0.9816\n",
            "397/469 [========================>.....] - ETA: 57s - loss: 0.0600 - sparse_categorical_accuracy: 0.9816\n",
            "398/469 [========================>.....] - ETA: 56s - loss: 0.0600 - sparse_categorical_accuracy: 0.9816\n",
            "399/469 [========================>.....] - ETA: 56s - loss: 0.0599 - sparse_categorical_accuracy: 0.9817\n",
            "400/469 [========================>.....] - ETA: 55s - loss: 0.0599 - sparse_categorical_accuracy: 0.9817\n",
            "401/469 [========================>.....] - ETA: 54s - loss: 0.0598 - sparse_categorical_accuracy: 0.9817\n",
            "402/469 [========================>.....] - ETA: 53s - loss: 0.0599 - sparse_categorical_accuracy: 0.9817\n",
            "403/469 [========================>.....] - ETA: 52s - loss: 0.0598 - sparse_categorical_accuracy: 0.9817\n",
            "404/469 [========================>.....] - ETA: 51s - loss: 0.0601 - sparse_categorical_accuracy: 0.9816\n",
            "405/469 [========================>.....] - ETA: 51s - loss: 0.0601 - sparse_categorical_accuracy: 0.9816\n",
            "406/469 [========================>.....] - ETA: 50s - loss: 0.0602 - sparse_categorical_accuracy: 0.9816\n",
            "407/469 [=========================>....] - ETA: 49s - loss: 0.0603 - sparse_categorical_accuracy: 0.9816\n",
            "408/469 [=========================>....] - ETA: 48s - loss: 0.0603 - sparse_categorical_accuracy: 0.9816\n",
            "409/469 [=========================>....] - ETA: 48s - loss: 0.0603 - sparse_categorical_accuracy: 0.9816\n",
            "410/469 [=========================>....] - ETA: 47s - loss: 0.0603 - sparse_categorical_accuracy: 0.9816\n",
            "411/469 [=========================>....] - ETA: 46s - loss: 0.0603 - sparse_categorical_accuracy: 0.9816\n",
            "412/469 [=========================>....] - ETA: 45s - loss: 0.0604 - sparse_categorical_accuracy: 0.9816\n",
            "413/469 [=========================>....] - ETA: 44s - loss: 0.0603 - sparse_categorical_accuracy: 0.9816\n",
            "414/469 [=========================>....] - ETA: 43s - loss: 0.0602 - sparse_categorical_accuracy: 0.9816\n",
            "415/469 [=========================>....] - ETA: 43s - loss: 0.0603 - sparse_categorical_accuracy: 0.9816\n",
            "416/469 [=========================>....] - ETA: 42s - loss: 0.0605 - sparse_categorical_accuracy: 0.9816\n",
            "417/469 [=========================>....] - ETA: 41s - loss: 0.0604 - sparse_categorical_accuracy: 0.9817\n",
            "418/469 [=========================>....] - ETA: 40s - loss: 0.0603 - sparse_categorical_accuracy: 0.9817\n",
            "419/469 [=========================>....] - ETA: 39s - loss: 0.0604 - sparse_categorical_accuracy: 0.9816\n",
            "420/469 [=========================>....] - ETA: 39s - loss: 0.0605 - sparse_categorical_accuracy: 0.9816\n",
            "421/469 [=========================>....] - ETA: 38s - loss: 0.0605 - sparse_categorical_accuracy: 0.9816\n",
            "422/469 [=========================>....] - ETA: 37s - loss: 0.0604 - sparse_categorical_accuracy: 0.9816\n",
            "423/469 [==========================>...] - ETA: 36s - loss: 0.0603 - sparse_categorical_accuracy: 0.9816\n",
            "424/469 [==========================>...] - ETA: 36s - loss: 0.0603 - sparse_categorical_accuracy: 0.9816\n",
            "425/469 [==========================>...] - ETA: 35s - loss: 0.0604 - sparse_categorical_accuracy: 0.9816\n",
            "426/469 [==========================>...] - ETA: 34s - loss: 0.0604 - sparse_categorical_accuracy: 0.9816\n",
            "427/469 [==========================>...] - ETA: 33s - loss: 0.0607 - sparse_categorical_accuracy: 0.9816\n",
            "428/469 [==========================>...] - ETA: 32s - loss: 0.0607 - sparse_categorical_accuracy: 0.9816\n",
            "429/469 [==========================>...] - ETA: 32s - loss: 0.0607 - sparse_categorical_accuracy: 0.9816\n",
            "430/469 [==========================>...] - ETA: 31s - loss: 0.0607 - sparse_categorical_accuracy: 0.9815\n",
            "431/469 [==========================>...] - ETA: 30s - loss: 0.0606 - sparse_categorical_accuracy: 0.9816\n",
            "432/469 [==========================>...] - ETA: 29s - loss: 0.0606 - sparse_categorical_accuracy: 0.9816\n",
            "433/469 [==========================>...] - ETA: 28s - loss: 0.0606 - sparse_categorical_accuracy: 0.9816\n",
            "434/469 [==========================>...] - ETA: 27s - loss: 0.0606 - sparse_categorical_accuracy: 0.9816\n",
            "435/469 [==========================>...] - ETA: 27s - loss: 0.0606 - sparse_categorical_accuracy: 0.9816\n",
            "436/469 [==========================>...] - ETA: 26s - loss: 0.0605 - sparse_categorical_accuracy: 0.9816\n",
            "437/469 [==========================>...] - ETA: 25s - loss: 0.0605 - sparse_categorical_accuracy: 0.9816\n",
            "438/469 [===========================>..] - ETA: 24s - loss: 0.0606 - sparse_categorical_accuracy: 0.9816\n",
            "439/469 [===========================>..] - ETA: 23s - loss: 0.0607 - sparse_categorical_accuracy: 0.9815\n",
            "440/469 [===========================>..] - ETA: 23s - loss: 0.0607 - sparse_categorical_accuracy: 0.9815\n",
            "441/469 [===========================>..] - ETA: 22s - loss: 0.0606 - sparse_categorical_accuracy: 0.9815\n",
            "442/469 [===========================>..] - ETA: 21s - loss: 0.0605 - sparse_categorical_accuracy: 0.9816\n",
            "443/469 [===========================>..] - ETA: 20s - loss: 0.0604 - sparse_categorical_accuracy: 0.9816\n",
            "444/469 [===========================>..] - ETA: 20s - loss: 0.0604 - sparse_categorical_accuracy: 0.9816\n",
            "445/469 [===========================>..] - ETA: 19s - loss: 0.0604 - sparse_categorical_accuracy: 0.9816\n",
            "446/469 [===========================>..] - ETA: 18s - loss: 0.0603 - sparse_categorical_accuracy: 0.9816\n",
            "447/469 [===========================>..] - ETA: 17s - loss: 0.0603 - sparse_categorical_accuracy: 0.9816\n",
            "448/469 [===========================>..] - ETA: 16s - loss: 0.0602 - sparse_categorical_accuracy: 0.9817\n",
            "449/469 [===========================>..] - ETA: 15s - loss: 0.0602 - sparse_categorical_accuracy: 0.9817\n",
            "450/469 [===========================>..] - ETA: 15s - loss: 0.0602 - sparse_categorical_accuracy: 0.9817\n",
            "451/469 [===========================>..] - ETA: 14s - loss: 0.0602 - sparse_categorical_accuracy: 0.9817\n",
            "452/469 [===========================>..] - ETA: 13s - loss: 0.0602 - sparse_categorical_accuracy: 0.9817\n",
            "453/469 [===========================>..] - ETA: 12s - loss: 0.0602 - sparse_categorical_accuracy: 0.9817\n",
            "454/469 [============================>.] - ETA: 11s - loss: 0.0602 - sparse_categorical_accuracy: 0.9817\n",
            "455/469 [============================>.] - ETA: 11s - loss: 0.0603 - sparse_categorical_accuracy: 0.9817\n",
            "456/469 [============================>.] - ETA: 10s - loss: 0.0603 - sparse_categorical_accuracy: 0.9817\n",
            "457/469 [============================>.] - ETA: 9s - loss: 0.0603 - sparse_categorical_accuracy: 0.9817 \n",
            "458/469 [============================>.] - ETA: 8s - loss: 0.0604 - sparse_categorical_accuracy: 0.9817\n",
            "459/469 [============================>.] - ETA: 8s - loss: 0.0604 - sparse_categorical_accuracy: 0.9817\n",
            "460/469 [============================>.] - ETA: 7s - loss: 0.0603 - sparse_categorical_accuracy: 0.9817\n",
            "461/469 [============================>.] - ETA: 6s - loss: 0.0603 - sparse_categorical_accuracy: 0.9817\n",
            "462/469 [============================>.] - ETA: 5s - loss: 0.0602 - sparse_categorical_accuracy: 0.9817\n",
            "463/469 [============================>.] - ETA: 4s - loss: 0.0601 - sparse_categorical_accuracy: 0.9817\n",
            "464/469 [============================>.] - ETA: 3s - loss: 0.0602 - sparse_categorical_accuracy: 0.9817\n",
            "465/469 [============================>.] - ETA: 3s - loss: 0.0602 - sparse_categorical_accuracy: 0.9818\n",
            "466/469 [============================>.] - ETA: 2s - loss: 0.0602 - sparse_categorical_accuracy: 0.9817\n",
            "467/469 [============================>.] - ETA: 1s - loss: 0.0601 - sparse_categorical_accuracy: 0.9818\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0602 - sparse_categorical_accuracy: 0.9818\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0601 - sparse_categorical_accuracy: 0.9818\n",
            "  0%|          | 0/5 [31:18<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/04/16 01:03:18 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 375s 799ms/step - loss: 0.0601 - sparse_categorical_accuracy: 0.9818\n",
            "\n",
            "1/1 [==============================] - ETA: 0s\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "\n",
            "  0%|          | 0/5 [31:24<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "2024/04/16 01:03:37 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpgp1e_hyv/model, flavor: tensorflow). Fall back to return ['tensorflow==2.12.0', 'cloudpickle==2.2.1']. Set logging level to DEBUG to see the full traceback. \n",
            "\n",
            "2024/04/16 01:03:37 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\n",
            "  1/469 [..............................] - ETA: 5:00 - loss: 4.1432 - sparse_categorical_accuracy: 0.0391\n",
            "  2/469 [..............................] - ETA: 1:21 - loss: 4.1205 - sparse_categorical_accuracy: 0.0508\n",
            "  3/469 [..............................] - ETA: 1:23 - loss: 4.1230 - sparse_categorical_accuracy: 0.0573\n",
            "  4/469 [..............................] - ETA: 1:22 - loss: 4.1030 - sparse_categorical_accuracy: 0.0664\n",
            "  5/469 [..............................] - ETA: 1:22 - loss: 4.0831 - sparse_categorical_accuracy: 0.0781\n",
            "  6/469 [..............................] - ETA: 1:22 - loss: 4.0588 - sparse_categorical_accuracy: 0.0924\n",
            "  7/469 [..............................] - ETA: 1:23 - loss: 4.0382 - sparse_categorical_accuracy: 0.0915\n",
            "  8/469 [..............................] - ETA: 1:23 - loss: 4.0073 - sparse_categorical_accuracy: 0.1016\n",
            "  9/469 [..............................] - ETA: 1:22 - loss: 3.9683 - sparse_categorical_accuracy: 0.1042\n",
            " 10/469 [..............................] - ETA: 1:21 - loss: 3.9257 - sparse_categorical_accuracy: 0.1094\n",
            " 11/469 [..............................] - ETA: 1:21 - loss: 3.8756 - sparse_categorical_accuracy: 0.1122\n",
            " 12/469 [..............................] - ETA: 1:21 - loss: 3.8133 - sparse_categorical_accuracy: 0.1191\n",
            " 13/469 [..............................] - ETA: 1:22 - loss: 3.7331 - sparse_categorical_accuracy: 0.1256\n",
            " 14/469 [..............................] - ETA: 1:21 - loss: 3.6479 - sparse_categorical_accuracy: 0.1289\n",
            " 15/469 [..............................] - ETA: 1:21 - loss: 3.5692 - sparse_categorical_accuracy: 0.1312\n",
            " 16/469 [>.............................] - ETA: 1:21 - loss: 3.4848 - sparse_categorical_accuracy: 0.1406\n",
            " 17/469 [>.............................] - ETA: 1:20 - loss: 3.4003 - sparse_categorical_accuracy: 0.1498\n",
            " 18/469 [>.............................] - ETA: 1:20 - loss: 3.3264 - sparse_categorical_accuracy: 0.1567\n",
            " 19/469 [>.............................] - ETA: 1:20 - loss: 3.2578 - sparse_categorical_accuracy: 0.1616\n",
            " 20/469 [>.............................] - ETA: 1:20 - loss: 3.1923 - sparse_categorical_accuracy: 0.1695\n",
            " 21/469 [>.............................] - ETA: 1:19 - loss: 3.1336 - sparse_categorical_accuracy: 0.1760\n",
            " 22/469 [>.............................] - ETA: 1:19 - loss: 3.0747 - sparse_categorical_accuracy: 0.1843\n",
            " 23/469 [>.............................] - ETA: 1:19 - loss: 3.0109 - sparse_categorical_accuracy: 0.1967\n",
            " 24/469 [>.............................] - ETA: 1:21 - loss: 2.9584 - sparse_categorical_accuracy: 0.2035\n",
            " 25/469 [>.............................] - ETA: 1:22 - loss: 2.9022 - sparse_categorical_accuracy: 0.2153\n",
            " 26/469 [>.............................] - ETA: 1:23 - loss: 2.8463 - sparse_categorical_accuracy: 0.2269\n",
            " 27/469 [>.............................] - ETA: 1:24 - loss: 2.7952 - sparse_categorical_accuracy: 0.2370\n",
            " 28/469 [>.............................] - ETA: 1:26 - loss: 2.7461 - sparse_categorical_accuracy: 0.2464\n",
            " 29/469 [>.............................] - ETA: 1:27 - loss: 2.6925 - sparse_categorical_accuracy: 0.2597\n",
            " 30/469 [>.............................] - ETA: 1:28 - loss: 2.6472 - sparse_categorical_accuracy: 0.2693\n",
            " 31/469 [>.............................] - ETA: 1:29 - loss: 2.6007 - sparse_categorical_accuracy: 0.2785\n",
            " 32/469 [=>............................] - ETA: 1:30 - loss: 2.5563 - sparse_categorical_accuracy: 0.2886\n",
            " 33/469 [=>............................] - ETA: 1:31 - loss: 2.5131 - sparse_categorical_accuracy: 0.2983\n",
            " 34/469 [=>............................] - ETA: 1:31 - loss: 2.4710 - sparse_categorical_accuracy: 0.3084\n",
            " 35/469 [=>............................] - ETA: 1:32 - loss: 2.4322 - sparse_categorical_accuracy: 0.3176\n",
            " 36/469 [=>............................] - ETA: 1:33 - loss: 2.3940 - sparse_categorical_accuracy: 0.3268\n",
            " 37/469 [=>............................] - ETA: 1:32 - loss: 2.3598 - sparse_categorical_accuracy: 0.3353\n",
            " 38/469 [=>............................] - ETA: 1:31 - loss: 2.3287 - sparse_categorical_accuracy: 0.3433\n",
            " 39/469 [=>............................] - ETA: 1:31 - loss: 2.2889 - sparse_categorical_accuracy: 0.3536\n",
            " 40/469 [=>............................] - ETA: 1:30 - loss: 2.2550 - sparse_categorical_accuracy: 0.3625\n",
            " 41/469 [=>............................] - ETA: 1:30 - loss: 2.2235 - sparse_categorical_accuracy: 0.3702\n",
            " 42/469 [=>............................] - ETA: 1:29 - loss: 2.1896 - sparse_categorical_accuracy: 0.3783\n",
            " 43/469 [=>............................] - ETA: 1:28 - loss: 2.1572 - sparse_categorical_accuracy: 0.3877\n",
            " 44/469 [=>............................] - ETA: 1:28 - loss: 2.1264 - sparse_categorical_accuracy: 0.3965\n",
            " 45/469 [=>............................] - ETA: 1:27 - loss: 2.0947 - sparse_categorical_accuracy: 0.4056\n",
            " 46/469 [=>............................] - ETA: 1:27 - loss: 2.0634 - sparse_categorical_accuracy: 0.4134\n",
            " 47/469 [==>...........................] - ETA: 1:27 - loss: 2.0346 - sparse_categorical_accuracy: 0.4220\n",
            " 48/469 [==>...........................] - ETA: 1:26 - loss: 2.0159 - sparse_categorical_accuracy: 0.4269\n",
            " 49/469 [==>...........................] - ETA: 1:26 - loss: 1.9897 - sparse_categorical_accuracy: 0.4330\n",
            " 50/469 [==>...........................] - ETA: 1:25 - loss: 1.9641 - sparse_categorical_accuracy: 0.4408\n",
            " 51/469 [==>...........................] - ETA: 1:25 - loss: 1.9406 - sparse_categorical_accuracy: 0.4470\n",
            " 52/469 [==>...........................] - ETA: 1:24 - loss: 1.9124 - sparse_categorical_accuracy: 0.4549\n",
            " 53/469 [==>...........................] - ETA: 1:24 - loss: 1.8884 - sparse_categorical_accuracy: 0.4606\n",
            " 54/469 [==>...........................] - ETA: 1:24 - loss: 1.8711 - sparse_categorical_accuracy: 0.4653\n",
            " 55/469 [==>...........................] - ETA: 1:23 - loss: 1.8509 - sparse_categorical_accuracy: 0.4707\n",
            " 56/469 [==>...........................] - ETA: 1:23 - loss: 1.8273 - sparse_categorical_accuracy: 0.4766\n",
            " 57/469 [==>...........................] - ETA: 1:23 - loss: 1.8059 - sparse_categorical_accuracy: 0.4823\n",
            " 58/469 [==>...........................] - ETA: 1:22 - loss: 1.7864 - sparse_categorical_accuracy: 0.4879\n",
            " 59/469 [==>...........................] - ETA: 1:22 - loss: 1.7673 - sparse_categorical_accuracy: 0.4931\n",
            " 60/469 [==>...........................] - ETA: 1:22 - loss: 1.7467 - sparse_categorical_accuracy: 0.4986\n",
            " 61/469 [==>...........................] - ETA: 1:21 - loss: 1.7314 - sparse_categorical_accuracy: 0.5020\n",
            " 62/469 [==>...........................] - ETA: 1:21 - loss: 1.7139 - sparse_categorical_accuracy: 0.5068\n",
            " 63/469 [===>..........................] - ETA: 1:21 - loss: 1.6984 - sparse_categorical_accuracy: 0.5112\n",
            " 64/469 [===>..........................] - ETA: 1:20 - loss: 1.6805 - sparse_categorical_accuracy: 0.5160\n",
            " 65/469 [===>..........................] - ETA: 1:20 - loss: 1.6640 - sparse_categorical_accuracy: 0.5207\n",
            " 66/469 [===>..........................] - ETA: 1:20 - loss: 1.6475 - sparse_categorical_accuracy: 0.5252\n",
            " 67/469 [===>..........................] - ETA: 1:19 - loss: 1.6340 - sparse_categorical_accuracy: 0.5286\n",
            " 68/469 [===>..........................] - ETA: 1:19 - loss: 1.6204 - sparse_categorical_accuracy: 0.5324\n",
            " 69/469 [===>..........................] - ETA: 1:19 - loss: 1.6055 - sparse_categorical_accuracy: 0.5368\n",
            " 70/469 [===>..........................] - ETA: 1:18 - loss: 1.5907 - sparse_categorical_accuracy: 0.5406\n",
            " 71/469 [===>..........................] - ETA: 1:18 - loss: 1.5758 - sparse_categorical_accuracy: 0.5452\n",
            " 72/469 [===>..........................] - ETA: 1:18 - loss: 1.5622 - sparse_categorical_accuracy: 0.5484\n",
            " 73/469 [===>..........................] - ETA: 1:17 - loss: 1.5481 - sparse_categorical_accuracy: 0.5518\n",
            " 74/469 [===>..........................] - ETA: 1:17 - loss: 1.5363 - sparse_categorical_accuracy: 0.5552\n",
            " 75/469 [===>..........................] - ETA: 1:17 - loss: 1.5230 - sparse_categorical_accuracy: 0.5593\n",
            " 76/469 [===>..........................] - ETA: 1:17 - loss: 1.5101 - sparse_categorical_accuracy: 0.5632\n",
            " 77/469 [===>..........................] - ETA: 1:16 - loss: 1.4987 - sparse_categorical_accuracy: 0.5663\n",
            " 78/469 [===>..........................] - ETA: 1:16 - loss: 1.4852 - sparse_categorical_accuracy: 0.5700\n",
            " 79/469 [====>.........................] - ETA: 1:16 - loss: 1.4730 - sparse_categorical_accuracy: 0.5728\n",
            " 80/469 [====>.........................] - ETA: 1:16 - loss: 1.4615 - sparse_categorical_accuracy: 0.5765\n",
            " 81/469 [====>.........................] - ETA: 1:15 - loss: 1.4494 - sparse_categorical_accuracy: 0.5798\n",
            " 82/469 [====>.........................] - ETA: 1:15 - loss: 1.4379 - sparse_categorical_accuracy: 0.5829\n",
            " 83/469 [====>.........................] - ETA: 1:15 - loss: 1.4285 - sparse_categorical_accuracy: 0.5854\n",
            " 84/469 [====>.........................] - ETA: 1:15 - loss: 1.4177 - sparse_categorical_accuracy: 0.5883\n",
            " 85/469 [====>.........................] - ETA: 1:14 - loss: 1.4070 - sparse_categorical_accuracy: 0.5910\n",
            " 86/469 [====>.........................] - ETA: 1:14 - loss: 1.3943 - sparse_categorical_accuracy: 0.5946\n",
            " 87/469 [====>.........................] - ETA: 1:14 - loss: 1.3849 - sparse_categorical_accuracy: 0.5973\n",
            " 88/469 [====>.........................] - ETA: 1:14 - loss: 1.3768 - sparse_categorical_accuracy: 0.5996\n",
            " 89/469 [====>.........................] - ETA: 1:13 - loss: 1.3679 - sparse_categorical_accuracy: 0.6022\n",
            " 90/469 [====>.........................] - ETA: 1:13 - loss: 1.3574 - sparse_categorical_accuracy: 0.6049\n",
            " 91/469 [====>.........................] - ETA: 1:13 - loss: 1.3482 - sparse_categorical_accuracy: 0.6076\n",
            " 92/469 [====>.........................] - ETA: 1:13 - loss: 1.3385 - sparse_categorical_accuracy: 0.6102\n",
            " 93/469 [====>.........................] - ETA: 1:13 - loss: 1.3304 - sparse_categorical_accuracy: 0.6125\n",
            " 94/469 [=====>........................] - ETA: 1:13 - loss: 1.3218 - sparse_categorical_accuracy: 0.6145\n",
            " 95/469 [=====>........................] - ETA: 1:13 - loss: 1.3128 - sparse_categorical_accuracy: 0.6172\n",
            " 96/469 [=====>........................] - ETA: 1:13 - loss: 1.3038 - sparse_categorical_accuracy: 0.6195\n",
            " 97/469 [=====>........................] - ETA: 1:14 - loss: 1.2960 - sparse_categorical_accuracy: 0.6217\n",
            " 98/469 [=====>........................] - ETA: 1:14 - loss: 1.2889 - sparse_categorical_accuracy: 0.6238\n",
            " 99/469 [=====>........................] - ETA: 1:14 - loss: 1.2800 - sparse_categorical_accuracy: 0.6265\n",
            "100/469 [=====>........................] - ETA: 1:14 - loss: 1.2709 - sparse_categorical_accuracy: 0.6288\n",
            "101/469 [=====>........................] - ETA: 1:14 - loss: 1.2649 - sparse_categorical_accuracy: 0.6304\n",
            "102/469 [=====>........................] - ETA: 1:14 - loss: 1.2561 - sparse_categorical_accuracy: 0.6329\n",
            "103/469 [=====>........................] - ETA: 1:14 - loss: 1.2478 - sparse_categorical_accuracy: 0.6353\n",
            "104/469 [=====>........................] - ETA: 1:14 - loss: 1.2397 - sparse_categorical_accuracy: 0.6378\n",
            "105/469 [=====>........................] - ETA: 1:14 - loss: 1.2321 - sparse_categorical_accuracy: 0.6399\n",
            "106/469 [=====>........................] - ETA: 1:14 - loss: 1.2247 - sparse_categorical_accuracy: 0.6422\n",
            "107/469 [=====>........................] - ETA: 1:13 - loss: 1.2171 - sparse_categorical_accuracy: 0.6445\n",
            "108/469 [=====>........................] - ETA: 1:13 - loss: 1.2098 - sparse_categorical_accuracy: 0.6466\n",
            "109/469 [=====>........................] - ETA: 1:13 - loss: 1.2030 - sparse_categorical_accuracy: 0.6485\n",
            "110/469 [======>.......................] - ETA: 1:12 - loss: 1.1955 - sparse_categorical_accuracy: 0.6508\n",
            "111/469 [======>.......................] - ETA: 1:12 - loss: 1.1888 - sparse_categorical_accuracy: 0.6528\n",
            "112/469 [======>.......................] - ETA: 1:12 - loss: 1.1821 - sparse_categorical_accuracy: 0.6547\n",
            "113/469 [======>.......................] - ETA: 1:12 - loss: 1.1757 - sparse_categorical_accuracy: 0.6565\n",
            "114/469 [======>.......................] - ETA: 1:11 - loss: 1.1697 - sparse_categorical_accuracy: 0.6582\n",
            "115/469 [======>.......................] - ETA: 1:11 - loss: 1.1629 - sparse_categorical_accuracy: 0.6602\n",
            "116/469 [======>.......................] - ETA: 1:11 - loss: 1.1566 - sparse_categorical_accuracy: 0.6619\n",
            "117/469 [======>.......................] - ETA: 1:10 - loss: 1.1495 - sparse_categorical_accuracy: 0.6640\n",
            "118/469 [======>.......................] - ETA: 1:10 - loss: 1.1440 - sparse_categorical_accuracy: 0.6651\n",
            "119/469 [======>.......................] - ETA: 1:10 - loss: 1.1372 - sparse_categorical_accuracy: 0.6670\n",
            "120/469 [======>.......................] - ETA: 1:10 - loss: 1.1317 - sparse_categorical_accuracy: 0.6682\n",
            "121/469 [======>.......................] - ETA: 1:09 - loss: 1.1266 - sparse_categorical_accuracy: 0.6696\n",
            "122/469 [======>.......................] - ETA: 1:09 - loss: 1.1203 - sparse_categorical_accuracy: 0.6712\n",
            "123/469 [======>.......................] - ETA: 1:09 - loss: 1.1158 - sparse_categorical_accuracy: 0.6726\n",
            "124/469 [======>.......................] - ETA: 1:09 - loss: 1.1104 - sparse_categorical_accuracy: 0.6740\n",
            "125/469 [======>.......................] - ETA: 1:08 - loss: 1.1038 - sparse_categorical_accuracy: 0.6758\n",
            "126/469 [=======>......................] - ETA: 1:08 - loss: 1.0984 - sparse_categorical_accuracy: 0.6773\n",
            "127/469 [=======>......................] - ETA: 1:08 - loss: 1.0929 - sparse_categorical_accuracy: 0.6791\n",
            "128/469 [=======>......................] - ETA: 1:08 - loss: 1.0869 - sparse_categorical_accuracy: 0.6809\n",
            "129/469 [=======>......................] - ETA: 1:07 - loss: 1.0810 - sparse_categorical_accuracy: 0.6826\n",
            "130/469 [=======>......................] - ETA: 1:07 - loss: 1.0756 - sparse_categorical_accuracy: 0.6841\n",
            "131/469 [=======>......................] - ETA: 1:07 - loss: 1.0699 - sparse_categorical_accuracy: 0.6855\n",
            "132/469 [=======>......................] - ETA: 1:06 - loss: 1.0641 - sparse_categorical_accuracy: 0.6873\n",
            "133/469 [=======>......................] - ETA: 1:06 - loss: 1.0582 - sparse_categorical_accuracy: 0.6890\n",
            "134/469 [=======>......................] - ETA: 1:06 - loss: 1.0533 - sparse_categorical_accuracy: 0.6905\n",
            "135/469 [=======>......................] - ETA: 1:06 - loss: 1.0479 - sparse_categorical_accuracy: 0.6920\n",
            "136/469 [=======>......................] - ETA: 1:05 - loss: 1.0430 - sparse_categorical_accuracy: 0.6934\n",
            "137/469 [=======>......................] - ETA: 1:05 - loss: 1.0380 - sparse_categorical_accuracy: 0.6946\n",
            "138/469 [=======>......................] - ETA: 1:05 - loss: 1.0334 - sparse_categorical_accuracy: 0.6962\n",
            "139/469 [=======>......................] - ETA: 1:05 - loss: 1.0283 - sparse_categorical_accuracy: 0.6976\n",
            "140/469 [=======>......................] - ETA: 1:04 - loss: 1.0238 - sparse_categorical_accuracy: 0.6989\n",
            "141/469 [========>.....................] - ETA: 1:04 - loss: 1.0185 - sparse_categorical_accuracy: 0.7004\n",
            "142/469 [========>.....................] - ETA: 1:04 - loss: 1.0133 - sparse_categorical_accuracy: 0.7019\n",
            "143/469 [========>.....................] - ETA: 1:04 - loss: 1.0090 - sparse_categorical_accuracy: 0.7033\n",
            "144/469 [========>.....................] - ETA: 1:03 - loss: 1.0048 - sparse_categorical_accuracy: 0.7045\n",
            "145/469 [========>.....................] - ETA: 1:03 - loss: 0.9992 - sparse_categorical_accuracy: 0.7062\n",
            "146/469 [========>.....................] - ETA: 1:03 - loss: 0.9958 - sparse_categorical_accuracy: 0.7075\n",
            "147/469 [========>.....................] - ETA: 1:03 - loss: 0.9912 - sparse_categorical_accuracy: 0.7088\n",
            "148/469 [========>.....................] - ETA: 1:02 - loss: 0.9862 - sparse_categorical_accuracy: 0.7103\n",
            "149/469 [========>.....................] - ETA: 1:02 - loss: 0.9817 - sparse_categorical_accuracy: 0.7114\n",
            "150/469 [========>.....................] - ETA: 1:02 - loss: 0.9773 - sparse_categorical_accuracy: 0.7126\n",
            "151/469 [========>.....................] - ETA: 1:02 - loss: 0.9729 - sparse_categorical_accuracy: 0.7140\n",
            "152/469 [========>.....................] - ETA: 1:02 - loss: 0.9688 - sparse_categorical_accuracy: 0.7152\n",
            "153/469 [========>.....................] - ETA: 1:01 - loss: 0.9651 - sparse_categorical_accuracy: 0.7164\n",
            "154/469 [========>.....................] - ETA: 1:01 - loss: 0.9613 - sparse_categorical_accuracy: 0.7174\n",
            "155/469 [========>.....................] - ETA: 1:01 - loss: 0.9578 - sparse_categorical_accuracy: 0.7185\n",
            "156/469 [========>.....................] - ETA: 1:01 - loss: 0.9538 - sparse_categorical_accuracy: 0.7197\n",
            "157/469 [=========>....................] - ETA: 1:00 - loss: 0.9494 - sparse_categorical_accuracy: 0.7211\n",
            "158/469 [=========>....................] - ETA: 1:00 - loss: 0.9446 - sparse_categorical_accuracy: 0.7225\n",
            "159/469 [=========>....................] - ETA: 1:00 - loss: 0.9405 - sparse_categorical_accuracy: 0.7237\n",
            "160/469 [=========>....................] - ETA: 1:00 - loss: 0.9368 - sparse_categorical_accuracy: 0.7246\n",
            "161/469 [=========>....................] - ETA: 59s - loss: 0.9335 - sparse_categorical_accuracy: 0.7254 \n",
            "162/469 [=========>....................] - ETA: 59s - loss: 0.9291 - sparse_categorical_accuracy: 0.7267\n",
            "163/469 [=========>....................] - ETA: 59s - loss: 0.9254 - sparse_categorical_accuracy: 0.7278\n",
            "164/469 [=========>....................] - ETA: 59s - loss: 0.9216 - sparse_categorical_accuracy: 0.7288\n",
            "165/469 [=========>....................] - ETA: 59s - loss: 0.9188 - sparse_categorical_accuracy: 0.7297\n",
            "166/469 [=========>....................] - ETA: 59s - loss: 0.9152 - sparse_categorical_accuracy: 0.7307\n",
            "167/469 [=========>....................] - ETA: 59s - loss: 0.9117 - sparse_categorical_accuracy: 0.7317\n",
            "168/469 [=========>....................] - ETA: 59s - loss: 0.9078 - sparse_categorical_accuracy: 0.7328\n",
            "169/469 [=========>....................] - ETA: 59s - loss: 0.9047 - sparse_categorical_accuracy: 0.7338\n",
            "170/469 [=========>....................] - ETA: 59s - loss: 0.9018 - sparse_categorical_accuracy: 0.7346\n",
            "171/469 [=========>....................] - ETA: 59s - loss: 0.8990 - sparse_categorical_accuracy: 0.7352\n",
            "172/469 [==========>...................] - ETA: 59s - loss: 0.8954 - sparse_categorical_accuracy: 0.7362\n",
            "173/469 [==========>...................] - ETA: 59s - loss: 0.8917 - sparse_categorical_accuracy: 0.7372\n",
            "174/469 [==========>...................] - ETA: 59s - loss: 0.8880 - sparse_categorical_accuracy: 0.7384\n",
            "175/469 [==========>...................] - ETA: 58s - loss: 0.8855 - sparse_categorical_accuracy: 0.7393\n",
            "176/469 [==========>...................] - ETA: 58s - loss: 0.8830 - sparse_categorical_accuracy: 0.7400\n",
            "177/469 [==========>...................] - ETA: 58s - loss: 0.8797 - sparse_categorical_accuracy: 0.7411\n",
            "178/469 [==========>...................] - ETA: 58s - loss: 0.8766 - sparse_categorical_accuracy: 0.7419\n",
            "179/469 [==========>...................] - ETA: 57s - loss: 0.8737 - sparse_categorical_accuracy: 0.7428\n",
            "180/469 [==========>...................] - ETA: 57s - loss: 0.8707 - sparse_categorical_accuracy: 0.7438\n",
            "181/469 [==========>...................] - ETA: 57s - loss: 0.8680 - sparse_categorical_accuracy: 0.7446\n",
            "182/469 [==========>...................] - ETA: 57s - loss: 0.8645 - sparse_categorical_accuracy: 0.7454\n",
            "183/469 [==========>...................] - ETA: 57s - loss: 0.8613 - sparse_categorical_accuracy: 0.7463\n",
            "184/469 [==========>...................] - ETA: 56s - loss: 0.8581 - sparse_categorical_accuracy: 0.7473\n",
            "185/469 [==========>...................] - ETA: 56s - loss: 0.8553 - sparse_categorical_accuracy: 0.7481\n",
            "186/469 [==========>...................] - ETA: 56s - loss: 0.8531 - sparse_categorical_accuracy: 0.7485\n",
            "187/469 [==========>...................] - ETA: 56s - loss: 0.8502 - sparse_categorical_accuracy: 0.7495\n",
            "188/469 [===========>..................] - ETA: 55s - loss: 0.8472 - sparse_categorical_accuracy: 0.7503\n",
            "189/469 [===========>..................] - ETA: 55s - loss: 0.8441 - sparse_categorical_accuracy: 0.7514\n",
            "190/469 [===========>..................] - ETA: 55s - loss: 0.8416 - sparse_categorical_accuracy: 0.7522\n",
            "191/469 [===========>..................] - ETA: 55s - loss: 0.8388 - sparse_categorical_accuracy: 0.7527\n",
            "192/469 [===========>..................] - ETA: 54s - loss: 0.8364 - sparse_categorical_accuracy: 0.7536\n",
            "193/469 [===========>..................] - ETA: 54s - loss: 0.8345 - sparse_categorical_accuracy: 0.7541\n",
            "194/469 [===========>..................] - ETA: 54s - loss: 0.8319 - sparse_categorical_accuracy: 0.7550\n",
            "195/469 [===========>..................] - ETA: 54s - loss: 0.8295 - sparse_categorical_accuracy: 0.7558\n",
            "196/469 [===========>..................] - ETA: 53s - loss: 0.8268 - sparse_categorical_accuracy: 0.7566\n",
            "197/469 [===========>..................] - ETA: 53s - loss: 0.8239 - sparse_categorical_accuracy: 0.7575\n",
            "198/469 [===========>..................] - ETA: 53s - loss: 0.8213 - sparse_categorical_accuracy: 0.7583\n",
            "199/469 [===========>..................] - ETA: 53s - loss: 0.8184 - sparse_categorical_accuracy: 0.7591\n",
            "200/469 [===========>..................] - ETA: 53s - loss: 0.8157 - sparse_categorical_accuracy: 0.7597\n",
            "201/469 [===========>..................] - ETA: 52s - loss: 0.8125 - sparse_categorical_accuracy: 0.7608\n",
            "202/469 [===========>..................] - ETA: 52s - loss: 0.8096 - sparse_categorical_accuracy: 0.7616\n",
            "203/469 [===========>..................] - ETA: 52s - loss: 0.8065 - sparse_categorical_accuracy: 0.7626\n",
            "204/469 [============>.................] - ETA: 52s - loss: 0.8041 - sparse_categorical_accuracy: 0.7633\n",
            "205/469 [============>.................] - ETA: 51s - loss: 0.8017 - sparse_categorical_accuracy: 0.7641\n",
            "206/469 [============>.................] - ETA: 51s - loss: 0.7990 - sparse_categorical_accuracy: 0.7649\n",
            "207/469 [============>.................] - ETA: 51s - loss: 0.7968 - sparse_categorical_accuracy: 0.7658\n",
            "208/469 [============>.................] - ETA: 51s - loss: 0.7941 - sparse_categorical_accuracy: 0.7667\n",
            "209/469 [============>.................] - ETA: 51s - loss: 0.7921 - sparse_categorical_accuracy: 0.7672\n",
            "210/469 [============>.................] - ETA: 50s - loss: 0.7897 - sparse_categorical_accuracy: 0.7679\n",
            "211/469 [============>.................] - ETA: 50s - loss: 0.7870 - sparse_categorical_accuracy: 0.7687\n",
            "212/469 [============>.................] - ETA: 50s - loss: 0.7840 - sparse_categorical_accuracy: 0.7696\n",
            "213/469 [============>.................] - ETA: 50s - loss: 0.7813 - sparse_categorical_accuracy: 0.7703\n",
            "214/469 [============>.................] - ETA: 49s - loss: 0.7794 - sparse_categorical_accuracy: 0.7709\n",
            "215/469 [============>.................] - ETA: 49s - loss: 0.7772 - sparse_categorical_accuracy: 0.7717\n",
            "216/469 [============>.................] - ETA: 49s - loss: 0.7749 - sparse_categorical_accuracy: 0.7724\n",
            "217/469 [============>.................] - ETA: 49s - loss: 0.7729 - sparse_categorical_accuracy: 0.7730\n",
            "218/469 [============>.................] - ETA: 49s - loss: 0.7703 - sparse_categorical_accuracy: 0.7738\n",
            "219/469 [=============>................] - ETA: 48s - loss: 0.7679 - sparse_categorical_accuracy: 0.7744\n",
            "220/469 [=============>................] - ETA: 48s - loss: 0.7656 - sparse_categorical_accuracy: 0.7751\n",
            "221/469 [=============>................] - ETA: 48s - loss: 0.7631 - sparse_categorical_accuracy: 0.7757\n",
            "222/469 [=============>................] - ETA: 48s - loss: 0.7607 - sparse_categorical_accuracy: 0.7765\n",
            "223/469 [=============>................] - ETA: 48s - loss: 0.7588 - sparse_categorical_accuracy: 0.7771\n",
            "224/469 [=============>................] - ETA: 47s - loss: 0.7562 - sparse_categorical_accuracy: 0.7779\n",
            "225/469 [=============>................] - ETA: 47s - loss: 0.7537 - sparse_categorical_accuracy: 0.7786\n",
            "226/469 [=============>................] - ETA: 47s - loss: 0.7514 - sparse_categorical_accuracy: 0.7792\n",
            "227/469 [=============>................] - ETA: 47s - loss: 0.7495 - sparse_categorical_accuracy: 0.7798\n",
            "228/469 [=============>................] - ETA: 47s - loss: 0.7475 - sparse_categorical_accuracy: 0.7803\n",
            "229/469 [=============>................] - ETA: 46s - loss: 0.7455 - sparse_categorical_accuracy: 0.7809\n",
            "230/469 [=============>................] - ETA: 46s - loss: 0.7430 - sparse_categorical_accuracy: 0.7816\n",
            "231/469 [=============>................] - ETA: 46s - loss: 0.7408 - sparse_categorical_accuracy: 0.7822\n",
            "232/469 [=============>................] - ETA: 46s - loss: 0.7386 - sparse_categorical_accuracy: 0.7829\n",
            "233/469 [=============>................] - ETA: 46s - loss: 0.7367 - sparse_categorical_accuracy: 0.7835\n",
            "234/469 [=============>................] - ETA: 46s - loss: 0.7350 - sparse_categorical_accuracy: 0.7839\n",
            "235/469 [==============>...............] - ETA: 46s - loss: 0.7330 - sparse_categorical_accuracy: 0.7845\n",
            "236/469 [==============>...............] - ETA: 46s - loss: 0.7309 - sparse_categorical_accuracy: 0.7851\n",
            "237/469 [==============>...............] - ETA: 45s - loss: 0.7293 - sparse_categorical_accuracy: 0.7854\n",
            "238/469 [==============>...............] - ETA: 45s - loss: 0.7269 - sparse_categorical_accuracy: 0.7861\n",
            "239/469 [==============>...............] - ETA: 45s - loss: 0.7245 - sparse_categorical_accuracy: 0.7869\n",
            "240/469 [==============>...............] - ETA: 45s - loss: 0.7229 - sparse_categorical_accuracy: 0.7872\n",
            "241/469 [==============>...............] - ETA: 45s - loss: 0.7205 - sparse_categorical_accuracy: 0.7879\n",
            "242/469 [==============>...............] - ETA: 45s - loss: 0.7183 - sparse_categorical_accuracy: 0.7886\n",
            "243/469 [==============>...............] - ETA: 45s - loss: 0.7166 - sparse_categorical_accuracy: 0.7891\n",
            "244/469 [==============>...............] - ETA: 44s - loss: 0.7143 - sparse_categorical_accuracy: 0.7897\n",
            "245/469 [==============>...............] - ETA: 44s - loss: 0.7127 - sparse_categorical_accuracy: 0.7901\n",
            "246/469 [==============>...............] - ETA: 44s - loss: 0.7106 - sparse_categorical_accuracy: 0.7907\n",
            "247/469 [==============>...............] - ETA: 44s - loss: 0.7092 - sparse_categorical_accuracy: 0.7912\n",
            "248/469 [==============>...............] - ETA: 43s - loss: 0.7070 - sparse_categorical_accuracy: 0.7919\n",
            "249/469 [==============>...............] - ETA: 43s - loss: 0.7047 - sparse_categorical_accuracy: 0.7926\n",
            "250/469 [==============>...............] - ETA: 43s - loss: 0.7028 - sparse_categorical_accuracy: 0.7932\n",
            "251/469 [===============>..............] - ETA: 43s - loss: 0.7008 - sparse_categorical_accuracy: 0.7937\n",
            "252/469 [===============>..............] - ETA: 43s - loss: 0.6990 - sparse_categorical_accuracy: 0.7941\n",
            "253/469 [===============>..............] - ETA: 42s - loss: 0.6973 - sparse_categorical_accuracy: 0.7946\n",
            "254/469 [===============>..............] - ETA: 42s - loss: 0.6953 - sparse_categorical_accuracy: 0.7952\n",
            "255/469 [===============>..............] - ETA: 42s - loss: 0.6935 - sparse_categorical_accuracy: 0.7956\n",
            "256/469 [===============>..............] - ETA: 42s - loss: 0.6920 - sparse_categorical_accuracy: 0.7961\n",
            "257/469 [===============>..............] - ETA: 42s - loss: 0.6900 - sparse_categorical_accuracy: 0.7967\n",
            "258/469 [===============>..............] - ETA: 41s - loss: 0.6881 - sparse_categorical_accuracy: 0.7973\n",
            "259/469 [===============>..............] - ETA: 41s - loss: 0.6863 - sparse_categorical_accuracy: 0.7978\n",
            "260/469 [===============>..............] - ETA: 41s - loss: 0.6846 - sparse_categorical_accuracy: 0.7982\n",
            "261/469 [===============>..............] - ETA: 41s - loss: 0.6830 - sparse_categorical_accuracy: 0.7987\n",
            "262/469 [===============>..............] - ETA: 40s - loss: 0.6813 - sparse_categorical_accuracy: 0.7993\n",
            "263/469 [===============>..............] - ETA: 40s - loss: 0.6795 - sparse_categorical_accuracy: 0.7998\n",
            "264/469 [===============>..............] - ETA: 40s - loss: 0.6781 - sparse_categorical_accuracy: 0.8002\n",
            "265/469 [===============>..............] - ETA: 40s - loss: 0.6761 - sparse_categorical_accuracy: 0.8008\n",
            "266/469 [================>.............] - ETA: 40s - loss: 0.6741 - sparse_categorical_accuracy: 0.8014\n",
            "267/469 [================>.............] - ETA: 39s - loss: 0.6722 - sparse_categorical_accuracy: 0.8020\n",
            "268/469 [================>.............] - ETA: 39s - loss: 0.6707 - sparse_categorical_accuracy: 0.8023\n",
            "269/469 [================>.............] - ETA: 39s - loss: 0.6689 - sparse_categorical_accuracy: 0.8028\n",
            "270/469 [================>.............] - ETA: 39s - loss: 0.6670 - sparse_categorical_accuracy: 0.8033\n",
            "271/469 [================>.............] - ETA: 39s - loss: 0.6652 - sparse_categorical_accuracy: 0.8038\n",
            "272/469 [================>.............] - ETA: 38s - loss: 0.6632 - sparse_categorical_accuracy: 0.8045\n",
            "273/469 [================>.............] - ETA: 38s - loss: 0.6615 - sparse_categorical_accuracy: 0.8049\n",
            "274/469 [================>.............] - ETA: 38s - loss: 0.6598 - sparse_categorical_accuracy: 0.8054\n",
            "275/469 [================>.............] - ETA: 38s - loss: 0.6584 - sparse_categorical_accuracy: 0.8060\n",
            "276/469 [================>.............] - ETA: 38s - loss: 0.6568 - sparse_categorical_accuracy: 0.8065\n",
            "277/469 [================>.............] - ETA: 37s - loss: 0.6552 - sparse_categorical_accuracy: 0.8070\n",
            "278/469 [================>.............] - ETA: 37s - loss: 0.6536 - sparse_categorical_accuracy: 0.8075\n",
            "279/469 [================>.............] - ETA: 37s - loss: 0.6519 - sparse_categorical_accuracy: 0.8080\n",
            "280/469 [================>.............] - ETA: 37s - loss: 0.6502 - sparse_categorical_accuracy: 0.8085\n",
            "281/469 [================>.............] - ETA: 36s - loss: 0.6491 - sparse_categorical_accuracy: 0.8089\n",
            "282/469 [=================>............] - ETA: 36s - loss: 0.6479 - sparse_categorical_accuracy: 0.8093\n",
            "283/469 [=================>............] - ETA: 36s - loss: 0.6462 - sparse_categorical_accuracy: 0.8098\n",
            "284/469 [=================>............] - ETA: 36s - loss: 0.6448 - sparse_categorical_accuracy: 0.8103\n",
            "285/469 [=================>............] - ETA: 36s - loss: 0.6431 - sparse_categorical_accuracy: 0.8107\n",
            "286/469 [=================>............] - ETA: 35s - loss: 0.6417 - sparse_categorical_accuracy: 0.8111\n",
            "287/469 [=================>............] - ETA: 35s - loss: 0.6403 - sparse_categorical_accuracy: 0.8115\n",
            "288/469 [=================>............] - ETA: 35s - loss: 0.6387 - sparse_categorical_accuracy: 0.8120\n",
            "289/469 [=================>............] - ETA: 35s - loss: 0.6370 - sparse_categorical_accuracy: 0.8126\n",
            "290/469 [=================>............] - ETA: 35s - loss: 0.6358 - sparse_categorical_accuracy: 0.8130\n",
            "291/469 [=================>............] - ETA: 34s - loss: 0.6343 - sparse_categorical_accuracy: 0.8134\n",
            "292/469 [=================>............] - ETA: 34s - loss: 0.6330 - sparse_categorical_accuracy: 0.8138\n",
            "293/469 [=================>............] - ETA: 34s - loss: 0.6314 - sparse_categorical_accuracy: 0.8142\n",
            "294/469 [=================>............] - ETA: 34s - loss: 0.6303 - sparse_categorical_accuracy: 0.8144\n",
            "295/469 [=================>............] - ETA: 34s - loss: 0.6286 - sparse_categorical_accuracy: 0.8149\n",
            "296/469 [=================>............] - ETA: 33s - loss: 0.6273 - sparse_categorical_accuracy: 0.8153\n",
            "297/469 [=================>............] - ETA: 33s - loss: 0.6261 - sparse_categorical_accuracy: 0.8157\n",
            "298/469 [==================>...........] - ETA: 33s - loss: 0.6251 - sparse_categorical_accuracy: 0.8160\n",
            "299/469 [==================>...........] - ETA: 33s - loss: 0.6237 - sparse_categorical_accuracy: 0.8165\n",
            "300/469 [==================>...........] - ETA: 33s - loss: 0.6224 - sparse_categorical_accuracy: 0.8169\n",
            "301/469 [==================>...........] - ETA: 33s - loss: 0.6209 - sparse_categorical_accuracy: 0.8174\n",
            "302/469 [==================>...........] - ETA: 32s - loss: 0.6197 - sparse_categorical_accuracy: 0.8176\n",
            "303/469 [==================>...........] - ETA: 32s - loss: 0.6183 - sparse_categorical_accuracy: 0.8180\n",
            "304/469 [==================>...........] - ETA: 32s - loss: 0.6172 - sparse_categorical_accuracy: 0.8183\n",
            "305/469 [==================>...........] - ETA: 32s - loss: 0.6159 - sparse_categorical_accuracy: 0.8187\n",
            "306/469 [==================>...........] - ETA: 32s - loss: 0.6145 - sparse_categorical_accuracy: 0.8191\n",
            "307/469 [==================>...........] - ETA: 32s - loss: 0.6131 - sparse_categorical_accuracy: 0.8194\n",
            "308/469 [==================>...........] - ETA: 32s - loss: 0.6115 - sparse_categorical_accuracy: 0.8198\n",
            "309/469 [==================>...........] - ETA: 31s - loss: 0.6104 - sparse_categorical_accuracy: 0.8202\n",
            "310/469 [==================>...........] - ETA: 31s - loss: 0.6091 - sparse_categorical_accuracy: 0.8206\n",
            "311/469 [==================>...........] - ETA: 31s - loss: 0.6079 - sparse_categorical_accuracy: 0.8209\n",
            "312/469 [==================>...........] - ETA: 31s - loss: 0.6070 - sparse_categorical_accuracy: 0.8212\n",
            "313/469 [===================>..........] - ETA: 31s - loss: 0.6057 - sparse_categorical_accuracy: 0.8216\n",
            "314/469 [===================>..........] - ETA: 30s - loss: 0.6047 - sparse_categorical_accuracy: 0.8219\n",
            "315/469 [===================>..........] - ETA: 30s - loss: 0.6037 - sparse_categorical_accuracy: 0.8221\n",
            "316/469 [===================>..........] - ETA: 30s - loss: 0.6025 - sparse_categorical_accuracy: 0.8225\n",
            "317/469 [===================>..........] - ETA: 30s - loss: 0.6016 - sparse_categorical_accuracy: 0.8227\n",
            "318/469 [===================>..........] - ETA: 30s - loss: 0.6005 - sparse_categorical_accuracy: 0.8230\n",
            "319/469 [===================>..........] - ETA: 29s - loss: 0.5991 - sparse_categorical_accuracy: 0.8235\n",
            "320/469 [===================>..........] - ETA: 29s - loss: 0.5978 - sparse_categorical_accuracy: 0.8239\n",
            "321/469 [===================>..........] - ETA: 29s - loss: 0.5963 - sparse_categorical_accuracy: 0.8243\n",
            "322/469 [===================>..........] - ETA: 29s - loss: 0.5950 - sparse_categorical_accuracy: 0.8247\n",
            "323/469 [===================>..........] - ETA: 29s - loss: 0.5937 - sparse_categorical_accuracy: 0.8251\n",
            "324/469 [===================>..........] - ETA: 28s - loss: 0.5924 - sparse_categorical_accuracy: 0.8254\n",
            "325/469 [===================>..........] - ETA: 28s - loss: 0.5915 - sparse_categorical_accuracy: 0.8256\n",
            "326/469 [===================>..........] - ETA: 28s - loss: 0.5901 - sparse_categorical_accuracy: 0.8260\n",
            "327/469 [===================>..........] - ETA: 28s - loss: 0.5887 - sparse_categorical_accuracy: 0.8264\n",
            "328/469 [===================>..........] - ETA: 28s - loss: 0.5876 - sparse_categorical_accuracy: 0.8266\n",
            "329/469 [====================>.........] - ETA: 27s - loss: 0.5864 - sparse_categorical_accuracy: 0.8271\n",
            "330/469 [====================>.........] - ETA: 27s - loss: 0.5852 - sparse_categorical_accuracy: 0.8274\n",
            "331/469 [====================>.........] - ETA: 27s - loss: 0.5840 - sparse_categorical_accuracy: 0.8278\n",
            "332/469 [====================>.........] - ETA: 27s - loss: 0.5827 - sparse_categorical_accuracy: 0.8282\n",
            "333/469 [====================>.........] - ETA: 26s - loss: 0.5816 - sparse_categorical_accuracy: 0.8285\n",
            "334/469 [====================>.........] - ETA: 26s - loss: 0.5803 - sparse_categorical_accuracy: 0.8289\n",
            "335/469 [====================>.........] - ETA: 26s - loss: 0.5795 - sparse_categorical_accuracy: 0.8292\n",
            "336/469 [====================>.........] - ETA: 26s - loss: 0.5783 - sparse_categorical_accuracy: 0.8296\n",
            "337/469 [====================>.........] - ETA: 26s - loss: 0.5774 - sparse_categorical_accuracy: 0.8298\n",
            "338/469 [====================>.........] - ETA: 25s - loss: 0.5762 - sparse_categorical_accuracy: 0.8302\n",
            "339/469 [====================>.........] - ETA: 25s - loss: 0.5750 - sparse_categorical_accuracy: 0.8306\n",
            "340/469 [====================>.........] - ETA: 25s - loss: 0.5738 - sparse_categorical_accuracy: 0.8309\n",
            "341/469 [====================>.........] - ETA: 25s - loss: 0.5728 - sparse_categorical_accuracy: 0.8313\n",
            "342/469 [====================>.........] - ETA: 25s - loss: 0.5715 - sparse_categorical_accuracy: 0.8316\n",
            "343/469 [====================>.........] - ETA: 24s - loss: 0.5705 - sparse_categorical_accuracy: 0.8320\n",
            "344/469 [=====================>........] - ETA: 24s - loss: 0.5693 - sparse_categorical_accuracy: 0.8323\n",
            "345/469 [=====================>........] - ETA: 24s - loss: 0.5684 - sparse_categorical_accuracy: 0.8326\n",
            "346/469 [=====================>........] - ETA: 24s - loss: 0.5673 - sparse_categorical_accuracy: 0.8329\n",
            "347/469 [=====================>........] - ETA: 24s - loss: 0.5661 - sparse_categorical_accuracy: 0.8333\n",
            "348/469 [=====================>........] - ETA: 23s - loss: 0.5651 - sparse_categorical_accuracy: 0.8336\n",
            "349/469 [=====================>........] - ETA: 23s - loss: 0.5639 - sparse_categorical_accuracy: 0.8340\n",
            "350/469 [=====================>........] - ETA: 23s - loss: 0.5629 - sparse_categorical_accuracy: 0.8342\n",
            "351/469 [=====================>........] - ETA: 23s - loss: 0.5618 - sparse_categorical_accuracy: 0.8345\n",
            "352/469 [=====================>........] - ETA: 23s - loss: 0.5613 - sparse_categorical_accuracy: 0.8347\n",
            "353/469 [=====================>........] - ETA: 22s - loss: 0.5606 - sparse_categorical_accuracy: 0.8349\n",
            "354/469 [=====================>........] - ETA: 22s - loss: 0.5598 - sparse_categorical_accuracy: 0.8351\n",
            "355/469 [=====================>........] - ETA: 22s - loss: 0.5589 - sparse_categorical_accuracy: 0.8355\n",
            "356/469 [=====================>........] - ETA: 22s - loss: 0.5577 - sparse_categorical_accuracy: 0.8358\n",
            "357/469 [=====================>........] - ETA: 22s - loss: 0.5565 - sparse_categorical_accuracy: 0.8362\n",
            "358/469 [=====================>........] - ETA: 21s - loss: 0.5557 - sparse_categorical_accuracy: 0.8364\n",
            "359/469 [=====================>........] - ETA: 21s - loss: 0.5548 - sparse_categorical_accuracy: 0.8367\n",
            "360/469 [======================>.......] - ETA: 21s - loss: 0.5543 - sparse_categorical_accuracy: 0.8368\n",
            "361/469 [======================>.......] - ETA: 21s - loss: 0.5531 - sparse_categorical_accuracy: 0.8371\n",
            "362/469 [======================>.......] - ETA: 21s - loss: 0.5520 - sparse_categorical_accuracy: 0.8375\n",
            "363/469 [======================>.......] - ETA: 20s - loss: 0.5509 - sparse_categorical_accuracy: 0.8378\n",
            "364/469 [======================>.......] - ETA: 20s - loss: 0.5500 - sparse_categorical_accuracy: 0.8381\n",
            "365/469 [======================>.......] - ETA: 20s - loss: 0.5489 - sparse_categorical_accuracy: 0.8384\n",
            "366/469 [======================>.......] - ETA: 20s - loss: 0.5478 - sparse_categorical_accuracy: 0.8388\n",
            "367/469 [======================>.......] - ETA: 20s - loss: 0.5468 - sparse_categorical_accuracy: 0.8390\n",
            "368/469 [======================>.......] - ETA: 20s - loss: 0.5458 - sparse_categorical_accuracy: 0.8393\n",
            "369/469 [======================>.......] - ETA: 19s - loss: 0.5448 - sparse_categorical_accuracy: 0.8396\n",
            "370/469 [======================>.......] - ETA: 19s - loss: 0.5441 - sparse_categorical_accuracy: 0.8399\n",
            "371/469 [======================>.......] - ETA: 19s - loss: 0.5433 - sparse_categorical_accuracy: 0.8402\n",
            "372/469 [======================>.......] - ETA: 19s - loss: 0.5423 - sparse_categorical_accuracy: 0.8405\n",
            "373/469 [======================>.......] - ETA: 19s - loss: 0.5414 - sparse_categorical_accuracy: 0.8407\n",
            "374/469 [======================>.......] - ETA: 18s - loss: 0.5404 - sparse_categorical_accuracy: 0.8411\n",
            "375/469 [======================>.......] - ETA: 18s - loss: 0.5393 - sparse_categorical_accuracy: 0.8414\n",
            "376/469 [=======================>......] - ETA: 18s - loss: 0.5385 - sparse_categorical_accuracy: 0.8416\n",
            "377/469 [=======================>......] - ETA: 18s - loss: 0.5377 - sparse_categorical_accuracy: 0.8418\n",
            "378/469 [=======================>......] - ETA: 18s - loss: 0.5366 - sparse_categorical_accuracy: 0.8421\n",
            "379/469 [=======================>......] - ETA: 18s - loss: 0.5359 - sparse_categorical_accuracy: 0.8424\n",
            "380/469 [=======================>......] - ETA: 17s - loss: 0.5349 - sparse_categorical_accuracy: 0.8427\n",
            "381/469 [=======================>......] - ETA: 17s - loss: 0.5344 - sparse_categorical_accuracy: 0.8429\n",
            "382/469 [=======================>......] - ETA: 17s - loss: 0.5336 - sparse_categorical_accuracy: 0.8431\n",
            "383/469 [=======================>......] - ETA: 17s - loss: 0.5327 - sparse_categorical_accuracy: 0.8433\n",
            "384/469 [=======================>......] - ETA: 16s - loss: 0.5318 - sparse_categorical_accuracy: 0.8435\n",
            "385/469 [=======================>......] - ETA: 16s - loss: 0.5308 - sparse_categorical_accuracy: 0.8438\n",
            "386/469 [=======================>......] - ETA: 16s - loss: 0.5298 - sparse_categorical_accuracy: 0.8441\n",
            "387/469 [=======================>......] - ETA: 16s - loss: 0.5289 - sparse_categorical_accuracy: 0.8443\n",
            "388/469 [=======================>......] - ETA: 16s - loss: 0.5281 - sparse_categorical_accuracy: 0.8446\n",
            "389/469 [=======================>......] - ETA: 15s - loss: 0.5273 - sparse_categorical_accuracy: 0.8448\n",
            "390/469 [=======================>......] - ETA: 15s - loss: 0.5262 - sparse_categorical_accuracy: 0.8451\n",
            "391/469 [========================>.....] - ETA: 15s - loss: 0.5252 - sparse_categorical_accuracy: 0.8453\n",
            "392/469 [========================>.....] - ETA: 15s - loss: 0.5242 - sparse_categorical_accuracy: 0.8456\n",
            "393/469 [========================>.....] - ETA: 15s - loss: 0.5233 - sparse_categorical_accuracy: 0.8459\n",
            "394/469 [========================>.....] - ETA: 14s - loss: 0.5225 - sparse_categorical_accuracy: 0.8461\n",
            "395/469 [========================>.....] - ETA: 14s - loss: 0.5219 - sparse_categorical_accuracy: 0.8463\n",
            "396/469 [========================>.....] - ETA: 14s - loss: 0.5210 - sparse_categorical_accuracy: 0.8467\n",
            "397/469 [========================>.....] - ETA: 14s - loss: 0.5201 - sparse_categorical_accuracy: 0.8469\n",
            "398/469 [========================>.....] - ETA: 14s - loss: 0.5191 - sparse_categorical_accuracy: 0.8473\n",
            "399/469 [========================>.....] - ETA: 13s - loss: 0.5184 - sparse_categorical_accuracy: 0.8475\n",
            "400/469 [========================>.....] - ETA: 13s - loss: 0.5174 - sparse_categorical_accuracy: 0.8478\n",
            "401/469 [========================>.....] - ETA: 13s - loss: 0.5164 - sparse_categorical_accuracy: 0.8481\n",
            "402/469 [========================>.....] - ETA: 13s - loss: 0.5156 - sparse_categorical_accuracy: 0.8483\n",
            "403/469 [========================>.....] - ETA: 13s - loss: 0.5148 - sparse_categorical_accuracy: 0.8485\n",
            "404/469 [========================>.....] - ETA: 12s - loss: 0.5140 - sparse_categorical_accuracy: 0.8488\n",
            "405/469 [========================>.....] - ETA: 12s - loss: 0.5132 - sparse_categorical_accuracy: 0.8490\n",
            "406/469 [========================>.....] - ETA: 12s - loss: 0.5124 - sparse_categorical_accuracy: 0.8493\n",
            "407/469 [=========================>....] - ETA: 12s - loss: 0.5116 - sparse_categorical_accuracy: 0.8495\n",
            "408/469 [=========================>....] - ETA: 12s - loss: 0.5106 - sparse_categorical_accuracy: 0.8498\n",
            "409/469 [=========================>....] - ETA: 11s - loss: 0.5098 - sparse_categorical_accuracy: 0.8501\n",
            "410/469 [=========================>....] - ETA: 11s - loss: 0.5089 - sparse_categorical_accuracy: 0.8504\n",
            "411/469 [=========================>....] - ETA: 11s - loss: 0.5080 - sparse_categorical_accuracy: 0.8506\n",
            "412/469 [=========================>....] - ETA: 11s - loss: 0.5074 - sparse_categorical_accuracy: 0.8508\n",
            "413/469 [=========================>....] - ETA: 11s - loss: 0.5065 - sparse_categorical_accuracy: 0.8511\n",
            "414/469 [=========================>....] - ETA: 10s - loss: 0.5055 - sparse_categorical_accuracy: 0.8514\n",
            "415/469 [=========================>....] - ETA: 10s - loss: 0.5048 - sparse_categorical_accuracy: 0.8515\n",
            "416/469 [=========================>....] - ETA: 10s - loss: 0.5039 - sparse_categorical_accuracy: 0.8518\n",
            "417/469 [=========================>....] - ETA: 10s - loss: 0.5031 - sparse_categorical_accuracy: 0.8521\n",
            "418/469 [=========================>....] - ETA: 10s - loss: 0.5022 - sparse_categorical_accuracy: 0.8523\n",
            "419/469 [=========================>....] - ETA: 9s - loss: 0.5015 - sparse_categorical_accuracy: 0.8525 \n",
            "420/469 [=========================>....] - ETA: 9s - loss: 0.5006 - sparse_categorical_accuracy: 0.8528\n",
            "421/469 [=========================>....] - ETA: 9s - loss: 0.4999 - sparse_categorical_accuracy: 0.8530\n",
            "422/469 [=========================>....] - ETA: 9s - loss: 0.4991 - sparse_categorical_accuracy: 0.8532\n",
            "423/469 [==========================>...] - ETA: 9s - loss: 0.4982 - sparse_categorical_accuracy: 0.8534\n",
            "424/469 [==========================>...] - ETA: 8s - loss: 0.4974 - sparse_categorical_accuracy: 0.8537\n",
            "425/469 [==========================>...] - ETA: 8s - loss: 0.4965 - sparse_categorical_accuracy: 0.8540\n",
            "426/469 [==========================>...] - ETA: 8s - loss: 0.4957 - sparse_categorical_accuracy: 0.8542\n",
            "427/469 [==========================>...] - ETA: 8s - loss: 0.4949 - sparse_categorical_accuracy: 0.8544\n",
            "428/469 [==========================>...] - ETA: 8s - loss: 0.4942 - sparse_categorical_accuracy: 0.8546\n",
            "429/469 [==========================>...] - ETA: 7s - loss: 0.4932 - sparse_categorical_accuracy: 0.8548\n",
            "430/469 [==========================>...] - ETA: 7s - loss: 0.4922 - sparse_categorical_accuracy: 0.8552\n",
            "431/469 [==========================>...] - ETA: 7s - loss: 0.4916 - sparse_categorical_accuracy: 0.8554\n",
            "432/469 [==========================>...] - ETA: 7s - loss: 0.4906 - sparse_categorical_accuracy: 0.8557\n",
            "433/469 [==========================>...] - ETA: 7s - loss: 0.4897 - sparse_categorical_accuracy: 0.8559\n",
            "434/469 [==========================>...] - ETA: 6s - loss: 0.4888 - sparse_categorical_accuracy: 0.8562\n",
            "435/469 [==========================>...] - ETA: 6s - loss: 0.4881 - sparse_categorical_accuracy: 0.8564\n",
            "436/469 [==========================>...] - ETA: 6s - loss: 0.4874 - sparse_categorical_accuracy: 0.8566\n",
            "437/469 [==========================>...] - ETA: 6s - loss: 0.4866 - sparse_categorical_accuracy: 0.8569\n",
            "438/469 [===========================>..] - ETA: 6s - loss: 0.4859 - sparse_categorical_accuracy: 0.8571\n",
            "439/469 [===========================>..] - ETA: 6s - loss: 0.4850 - sparse_categorical_accuracy: 0.8573\n",
            "440/469 [===========================>..] - ETA: 5s - loss: 0.4841 - sparse_categorical_accuracy: 0.8575\n",
            "441/469 [===========================>..] - ETA: 5s - loss: 0.4832 - sparse_categorical_accuracy: 0.8578\n",
            "442/469 [===========================>..] - ETA: 5s - loss: 0.4827 - sparse_categorical_accuracy: 0.8580\n",
            "443/469 [===========================>..] - ETA: 5s - loss: 0.4821 - sparse_categorical_accuracy: 0.8582\n",
            "444/469 [===========================>..] - ETA: 5s - loss: 0.4816 - sparse_categorical_accuracy: 0.8584\n",
            "445/469 [===========================>..] - ETA: 4s - loss: 0.4807 - sparse_categorical_accuracy: 0.8586\n",
            "446/469 [===========================>..] - ETA: 4s - loss: 0.4802 - sparse_categorical_accuracy: 0.8588\n",
            "447/469 [===========================>..] - ETA: 4s - loss: 0.4796 - sparse_categorical_accuracy: 0.8589\n",
            "448/469 [===========================>..] - ETA: 4s - loss: 0.4790 - sparse_categorical_accuracy: 0.8591\n",
            "449/469 [===========================>..] - ETA: 4s - loss: 0.4782 - sparse_categorical_accuracy: 0.8593\n",
            "450/469 [===========================>..] - ETA: 3s - loss: 0.4774 - sparse_categorical_accuracy: 0.8595\n",
            "451/469 [===========================>..] - ETA: 3s - loss: 0.4767 - sparse_categorical_accuracy: 0.8598\n",
            "452/469 [===========================>..] - ETA: 3s - loss: 0.4760 - sparse_categorical_accuracy: 0.8600\n",
            "453/469 [===========================>..] - ETA: 3s - loss: 0.4753 - sparse_categorical_accuracy: 0.8602\n",
            "454/469 [============================>.] - ETA: 3s - loss: 0.4746 - sparse_categorical_accuracy: 0.8604\n",
            "455/469 [============================>.] - ETA: 2s - loss: 0.4741 - sparse_categorical_accuracy: 0.8606\n",
            "456/469 [============================>.] - ETA: 2s - loss: 0.4735 - sparse_categorical_accuracy: 0.8608\n",
            "457/469 [============================>.] - ETA: 2s - loss: 0.4727 - sparse_categorical_accuracy: 0.8610\n",
            "458/469 [============================>.] - ETA: 2s - loss: 0.4723 - sparse_categorical_accuracy: 0.8612\n",
            "459/469 [============================>.] - ETA: 2s - loss: 0.4715 - sparse_categorical_accuracy: 0.8613\n",
            "460/469 [============================>.] - ETA: 1s - loss: 0.4709 - sparse_categorical_accuracy: 0.8615\n",
            "461/469 [============================>.] - ETA: 1s - loss: 0.4702 - sparse_categorical_accuracy: 0.8617\n",
            "462/469 [============================>.] - ETA: 1s - loss: 0.4695 - sparse_categorical_accuracy: 0.8619\n",
            "463/469 [============================>.] - ETA: 1s - loss: 0.4688 - sparse_categorical_accuracy: 0.8621\n",
            "464/469 [============================>.] - ETA: 1s - loss: 0.4681 - sparse_categorical_accuracy: 0.8624\n",
            "465/469 [============================>.] - ETA: 0s - loss: 0.4674 - sparse_categorical_accuracy: 0.8625\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.4665 - sparse_categorical_accuracy: 0.8628\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.4658 - sparse_categorical_accuracy: 0.8630\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.4651 - sparse_categorical_accuracy: 0.8632\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.4645 - sparse_categorical_accuracy: 0.8634\n",
            " 20%|██        | 1/5 [33:26<2:07:25, 1911.46s/trial, best loss: -0.9830999970436096]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/04/16 01:05:27 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 94s 200ms/step - loss: 0.4645 - sparse_categorical_accuracy: 0.8634\n",
            "\n",
            "Epoch 2/5\n",
            "\n",
            "  1/469 [..............................] - ETA: 1:24 - loss: 0.2726 - sparse_categorical_accuracy: 0.9062\n",
            "  2/469 [..............................] - ETA: 1:18 - loss: 0.1881 - sparse_categorical_accuracy: 0.9336\n",
            "  3/469 [..............................] - ETA: 1:23 - loss: 0.1647 - sparse_categorical_accuracy: 0.9453\n",
            "  4/469 [..............................] - ETA: 1:22 - loss: 0.1605 - sparse_categorical_accuracy: 0.9473\n",
            "  5/469 [..............................] - ETA: 1:22 - loss: 0.1498 - sparse_categorical_accuracy: 0.9500\n",
            "  6/469 [..............................] - ETA: 1:22 - loss: 0.1403 - sparse_categorical_accuracy: 0.9531\n",
            "  7/469 [..............................] - ETA: 1:22 - loss: 0.1378 - sparse_categorical_accuracy: 0.9542\n",
            "  8/469 [..............................] - ETA: 1:21 - loss: 0.1465 - sparse_categorical_accuracy: 0.9531\n",
            "  9/469 [..............................] - ETA: 1:22 - loss: 0.1513 - sparse_categorical_accuracy: 0.9523\n",
            " 10/469 [..............................] - ETA: 1:21 - loss: 0.1509 - sparse_categorical_accuracy: 0.9516\n",
            " 11/469 [..............................] - ETA: 1:20 - loss: 0.1637 - sparse_categorical_accuracy: 0.9503\n",
            " 12/469 [..............................] - ETA: 1:20 - loss: 0.1600 - sparse_categorical_accuracy: 0.9512\n",
            " 13/469 [..............................] - ETA: 1:20 - loss: 0.1618 - sparse_categorical_accuracy: 0.9513\n",
            " 14/469 [..............................] - ETA: 1:20 - loss: 0.1558 - sparse_categorical_accuracy: 0.9537\n",
            " 15/469 [..............................] - ETA: 1:20 - loss: 0.1582 - sparse_categorical_accuracy: 0.9521\n",
            " 16/469 [>.............................] - ETA: 1:20 - loss: 0.1543 - sparse_categorical_accuracy: 0.9536\n",
            " 17/469 [>.............................] - ETA: 1:20 - loss: 0.1549 - sparse_categorical_accuracy: 0.9531\n",
            " 18/469 [>.............................] - ETA: 1:19 - loss: 0.1537 - sparse_categorical_accuracy: 0.9531\n",
            " 19/469 [>.............................] - ETA: 1:19 - loss: 0.1496 - sparse_categorical_accuracy: 0.9548\n",
            " 20/469 [>.............................] - ETA: 1:19 - loss: 0.1497 - sparse_categorical_accuracy: 0.9555\n",
            " 21/469 [>.............................] - ETA: 1:19 - loss: 0.1458 - sparse_categorical_accuracy: 0.9568\n",
            " 22/469 [>.............................] - ETA: 1:18 - loss: 0.1457 - sparse_categorical_accuracy: 0.9567\n",
            " 23/469 [>.............................] - ETA: 1:18 - loss: 0.1429 - sparse_categorical_accuracy: 0.9569\n",
            " 24/469 [>.............................] - ETA: 1:18 - loss: 0.1459 - sparse_categorical_accuracy: 0.9561\n",
            " 25/469 [>.............................] - ETA: 1:17 - loss: 0.1482 - sparse_categorical_accuracy: 0.9556\n",
            " 26/469 [>.............................] - ETA: 1:17 - loss: 0.1481 - sparse_categorical_accuracy: 0.9549\n",
            " 27/469 [>.............................] - ETA: 1:17 - loss: 0.1518 - sparse_categorical_accuracy: 0.9534\n",
            " 28/469 [>.............................] - ETA: 1:17 - loss: 0.1502 - sparse_categorical_accuracy: 0.9534\n",
            " 29/469 [>.............................] - ETA: 1:17 - loss: 0.1522 - sparse_categorical_accuracy: 0.9531\n",
            " 30/469 [>.............................] - ETA: 1:17 - loss: 0.1518 - sparse_categorical_accuracy: 0.9534\n",
            " 31/469 [>.............................] - ETA: 1:18 - loss: 0.1496 - sparse_categorical_accuracy: 0.9541\n",
            " 32/469 [=>............................] - ETA: 1:20 - loss: 0.1518 - sparse_categorical_accuracy: 0.9534\n",
            " 33/469 [=>............................] - ETA: 1:21 - loss: 0.1523 - sparse_categorical_accuracy: 0.9538\n",
            " 34/469 [=>............................] - ETA: 1:22 - loss: 0.1525 - sparse_categorical_accuracy: 0.9538\n",
            " 35/469 [=>............................] - ETA: 1:23 - loss: 0.1515 - sparse_categorical_accuracy: 0.9540\n",
            " 36/469 [=>............................] - ETA: 1:24 - loss: 0.1493 - sparse_categorical_accuracy: 0.9546\n",
            " 37/469 [=>............................] - ETA: 1:24 - loss: 0.1496 - sparse_categorical_accuracy: 0.9552\n",
            " 38/469 [=>............................] - ETA: 1:25 - loss: 0.1507 - sparse_categorical_accuracy: 0.9548\n",
            " 39/469 [=>............................] - ETA: 1:26 - loss: 0.1512 - sparse_categorical_accuracy: 0.9545\n",
            " 40/469 [=>............................] - ETA: 1:26 - loss: 0.1528 - sparse_categorical_accuracy: 0.9537\n",
            " 41/469 [=>............................] - ETA: 1:27 - loss: 0.1532 - sparse_categorical_accuracy: 0.9535\n",
            " 42/469 [=>............................] - ETA: 1:28 - loss: 0.1537 - sparse_categorical_accuracy: 0.9533\n",
            " 43/469 [=>............................] - ETA: 1:27 - loss: 0.1532 - sparse_categorical_accuracy: 0.9531\n",
            " 44/469 [=>............................] - ETA: 1:27 - loss: 0.1532 - sparse_categorical_accuracy: 0.9533\n",
            " 45/469 [=>............................] - ETA: 1:26 - loss: 0.1527 - sparse_categorical_accuracy: 0.9535\n",
            " 46/469 [=>............................] - ETA: 1:26 - loss: 0.1509 - sparse_categorical_accuracy: 0.9541\n",
            " 47/469 [==>...........................] - ETA: 1:25 - loss: 0.1499 - sparse_categorical_accuracy: 0.9543\n",
            " 48/469 [==>...........................] - ETA: 1:25 - loss: 0.1505 - sparse_categorical_accuracy: 0.9539\n",
            " 49/469 [==>...........................] - ETA: 1:24 - loss: 0.1509 - sparse_categorical_accuracy: 0.9539\n",
            " 50/469 [==>...........................] - ETA: 1:24 - loss: 0.1497 - sparse_categorical_accuracy: 0.9542\n",
            " 51/469 [==>...........................] - ETA: 1:24 - loss: 0.1492 - sparse_categorical_accuracy: 0.9545\n",
            " 52/469 [==>...........................] - ETA: 1:23 - loss: 0.1479 - sparse_categorical_accuracy: 0.9548\n",
            " 53/469 [==>...........................] - ETA: 1:23 - loss: 0.1486 - sparse_categorical_accuracy: 0.9546\n",
            " 54/469 [==>...........................] - ETA: 1:22 - loss: 0.1470 - sparse_categorical_accuracy: 0.9552\n",
            " 55/469 [==>...........................] - ETA: 1:22 - loss: 0.1475 - sparse_categorical_accuracy: 0.9548\n",
            " 56/469 [==>...........................] - ETA: 1:22 - loss: 0.1472 - sparse_categorical_accuracy: 0.9547\n",
            " 57/469 [==>...........................] - ETA: 1:21 - loss: 0.1491 - sparse_categorical_accuracy: 0.9545\n",
            " 58/469 [==>...........................] - ETA: 1:21 - loss: 0.1485 - sparse_categorical_accuracy: 0.9547\n",
            " 59/469 [==>...........................] - ETA: 1:21 - loss: 0.1487 - sparse_categorical_accuracy: 0.9544\n",
            " 60/469 [==>...........................] - ETA: 1:20 - loss: 0.1478 - sparse_categorical_accuracy: 0.9547\n",
            " 61/469 [==>...........................] - ETA: 1:20 - loss: 0.1479 - sparse_categorical_accuracy: 0.9545\n",
            " 62/469 [==>...........................] - ETA: 1:20 - loss: 0.1481 - sparse_categorical_accuracy: 0.9544\n",
            " 63/469 [===>..........................] - ETA: 1:19 - loss: 0.1472 - sparse_categorical_accuracy: 0.9545\n",
            " 64/469 [===>..........................] - ETA: 1:19 - loss: 0.1465 - sparse_categorical_accuracy: 0.9545\n",
            " 65/469 [===>..........................] - ETA: 1:19 - loss: 0.1462 - sparse_categorical_accuracy: 0.9546\n",
            " 66/469 [===>..........................] - ETA: 1:18 - loss: 0.1452 - sparse_categorical_accuracy: 0.9549\n",
            " 67/469 [===>..........................] - ETA: 1:18 - loss: 0.1457 - sparse_categorical_accuracy: 0.9549\n",
            " 68/469 [===>..........................] - ETA: 1:18 - loss: 0.1456 - sparse_categorical_accuracy: 0.9547\n",
            " 69/469 [===>..........................] - ETA: 1:17 - loss: 0.1488 - sparse_categorical_accuracy: 0.9540\n",
            " 70/469 [===>..........................] - ETA: 1:17 - loss: 0.1490 - sparse_categorical_accuracy: 0.9541\n",
            " 71/469 [===>..........................] - ETA: 1:17 - loss: 0.1491 - sparse_categorical_accuracy: 0.9541\n",
            " 72/469 [===>..........................] - ETA: 1:16 - loss: 0.1495 - sparse_categorical_accuracy: 0.9538\n",
            " 73/469 [===>..........................] - ETA: 1:16 - loss: 0.1493 - sparse_categorical_accuracy: 0.9538\n",
            " 74/469 [===>..........................] - ETA: 1:16 - loss: 0.1512 - sparse_categorical_accuracy: 0.9535\n",
            " 75/469 [===>..........................] - ETA: 1:16 - loss: 0.1514 - sparse_categorical_accuracy: 0.9532\n",
            " 76/469 [===>..........................] - ETA: 1:15 - loss: 0.1511 - sparse_categorical_accuracy: 0.9532\n",
            " 77/469 [===>..........................] - ETA: 1:15 - loss: 0.1508 - sparse_categorical_accuracy: 0.9534\n",
            " 78/469 [===>..........................] - ETA: 1:15 - loss: 0.1504 - sparse_categorical_accuracy: 0.9536\n",
            " 79/469 [====>.........................] - ETA: 1:15 - loss: 0.1515 - sparse_categorical_accuracy: 0.9534\n",
            " 80/469 [====>.........................] - ETA: 1:14 - loss: 0.1516 - sparse_categorical_accuracy: 0.9534\n",
            " 81/469 [====>.........................] - ETA: 1:14 - loss: 0.1514 - sparse_categorical_accuracy: 0.9535\n",
            " 82/469 [====>.........................] - ETA: 1:14 - loss: 0.1510 - sparse_categorical_accuracy: 0.9539\n",
            " 83/469 [====>.........................] - ETA: 1:13 - loss: 0.1506 - sparse_categorical_accuracy: 0.9540\n",
            " 84/469 [====>.........................] - ETA: 1:13 - loss: 0.1516 - sparse_categorical_accuracy: 0.9536\n",
            " 85/469 [====>.........................] - ETA: 1:13 - loss: 0.1523 - sparse_categorical_accuracy: 0.9535\n",
            " 86/469 [====>.........................] - ETA: 1:13 - loss: 0.1518 - sparse_categorical_accuracy: 0.9536\n",
            " 87/469 [====>.........................] - ETA: 1:12 - loss: 0.1530 - sparse_categorical_accuracy: 0.9534\n",
            " 88/469 [====>.........................] - ETA: 1:12 - loss: 0.1522 - sparse_categorical_accuracy: 0.9537\n",
            " 89/469 [====>.........................] - ETA: 1:12 - loss: 0.1538 - sparse_categorical_accuracy: 0.9531\n",
            " 90/469 [====>.........................] - ETA: 1:12 - loss: 0.1543 - sparse_categorical_accuracy: 0.9530\n",
            " 91/469 [====>.........................] - ETA: 1:11 - loss: 0.1541 - sparse_categorical_accuracy: 0.9530\n",
            " 92/469 [====>.........................] - ETA: 1:11 - loss: 0.1536 - sparse_categorical_accuracy: 0.9533\n",
            " 93/469 [====>.........................] - ETA: 1:11 - loss: 0.1553 - sparse_categorical_accuracy: 0.9530\n",
            " 94/469 [=====>........................] - ETA: 1:11 - loss: 0.1548 - sparse_categorical_accuracy: 0.9530\n",
            " 95/469 [=====>........................] - ETA: 1:10 - loss: 0.1543 - sparse_categorical_accuracy: 0.9531\n",
            " 96/469 [=====>........................] - ETA: 1:10 - loss: 0.1534 - sparse_categorical_accuracy: 0.9533\n",
            " 97/469 [=====>........................] - ETA: 1:10 - loss: 0.1534 - sparse_categorical_accuracy: 0.9532\n",
            " 98/469 [=====>........................] - ETA: 1:10 - loss: 0.1525 - sparse_categorical_accuracy: 0.9535\n",
            " 99/469 [=====>........................] - ETA: 1:10 - loss: 0.1529 - sparse_categorical_accuracy: 0.9536\n",
            "100/469 [=====>........................] - ETA: 1:10 - loss: 0.1526 - sparse_categorical_accuracy: 0.9536\n",
            "101/469 [=====>........................] - ETA: 1:10 - loss: 0.1525 - sparse_categorical_accuracy: 0.9536\n",
            "102/469 [=====>........................] - ETA: 1:10 - loss: 0.1526 - sparse_categorical_accuracy: 0.9536\n",
            "103/469 [=====>........................] - ETA: 1:10 - loss: 0.1520 - sparse_categorical_accuracy: 0.9538\n",
            "104/469 [=====>........................] - ETA: 1:10 - loss: 0.1516 - sparse_categorical_accuracy: 0.9540\n",
            "105/469 [=====>........................] - ETA: 1:11 - loss: 0.1512 - sparse_categorical_accuracy: 0.9541\n",
            "106/469 [=====>........................] - ETA: 1:11 - loss: 0.1509 - sparse_categorical_accuracy: 0.9542\n",
            "107/469 [=====>........................] - ETA: 1:11 - loss: 0.1522 - sparse_categorical_accuracy: 0.9539\n",
            "108/469 [=====>........................] - ETA: 1:11 - loss: 0.1521 - sparse_categorical_accuracy: 0.9541\n",
            "109/469 [=====>........................] - ETA: 1:11 - loss: 0.1519 - sparse_categorical_accuracy: 0.9541\n",
            "110/469 [======>.......................] - ETA: 1:11 - loss: 0.1521 - sparse_categorical_accuracy: 0.9541\n",
            "111/469 [======>.......................] - ETA: 1:11 - loss: 0.1534 - sparse_categorical_accuracy: 0.9535\n",
            "112/469 [======>.......................] - ETA: 1:11 - loss: 0.1544 - sparse_categorical_accuracy: 0.9534\n",
            "113/469 [======>.......................] - ETA: 1:10 - loss: 0.1543 - sparse_categorical_accuracy: 0.9535\n",
            "114/469 [======>.......................] - ETA: 1:10 - loss: 0.1540 - sparse_categorical_accuracy: 0.9535\n",
            "115/469 [======>.......................] - ETA: 1:10 - loss: 0.1543 - sparse_categorical_accuracy: 0.9535\n",
            "116/469 [======>.......................] - ETA: 1:10 - loss: 0.1541 - sparse_categorical_accuracy: 0.9536\n",
            "117/469 [======>.......................] - ETA: 1:09 - loss: 0.1542 - sparse_categorical_accuracy: 0.9537\n",
            "118/469 [======>.......................] - ETA: 1:09 - loss: 0.1545 - sparse_categorical_accuracy: 0.9535\n",
            "119/469 [======>.......................] - ETA: 1:09 - loss: 0.1549 - sparse_categorical_accuracy: 0.9535\n",
            "120/469 [======>.......................] - ETA: 1:09 - loss: 0.1543 - sparse_categorical_accuracy: 0.9535\n",
            "121/469 [======>.......................] - ETA: 1:08 - loss: 0.1550 - sparse_categorical_accuracy: 0.9531\n",
            "122/469 [======>.......................] - ETA: 1:08 - loss: 0.1553 - sparse_categorical_accuracy: 0.9531\n",
            "123/469 [======>.......................] - ETA: 1:08 - loss: 0.1551 - sparse_categorical_accuracy: 0.9531\n",
            "124/469 [======>.......................] - ETA: 1:08 - loss: 0.1555 - sparse_categorical_accuracy: 0.9530\n",
            "125/469 [======>.......................] - ETA: 1:07 - loss: 0.1551 - sparse_categorical_accuracy: 0.9530\n",
            "126/469 [=======>......................] - ETA: 1:07 - loss: 0.1551 - sparse_categorical_accuracy: 0.9530\n",
            "127/469 [=======>......................] - ETA: 1:07 - loss: 0.1545 - sparse_categorical_accuracy: 0.9530\n",
            "128/469 [=======>......................] - ETA: 1:07 - loss: 0.1543 - sparse_categorical_accuracy: 0.9530\n",
            "129/469 [=======>......................] - ETA: 1:06 - loss: 0.1545 - sparse_categorical_accuracy: 0.9529\n",
            "130/469 [=======>......................] - ETA: 1:06 - loss: 0.1545 - sparse_categorical_accuracy: 0.9530\n",
            "131/469 [=======>......................] - ETA: 1:06 - loss: 0.1545 - sparse_categorical_accuracy: 0.9530\n",
            "132/469 [=======>......................] - ETA: 1:06 - loss: 0.1541 - sparse_categorical_accuracy: 0.9531\n",
            "133/469 [=======>......................] - ETA: 1:05 - loss: 0.1547 - sparse_categorical_accuracy: 0.9529\n",
            "134/469 [=======>......................] - ETA: 1:05 - loss: 0.1548 - sparse_categorical_accuracy: 0.9529\n",
            "135/469 [=======>......................] - ETA: 1:05 - loss: 0.1549 - sparse_categorical_accuracy: 0.9528\n",
            "136/469 [=======>......................] - ETA: 1:05 - loss: 0.1549 - sparse_categorical_accuracy: 0.9529\n",
            "137/469 [=======>......................] - ETA: 1:05 - loss: 0.1546 - sparse_categorical_accuracy: 0.9529\n",
            "138/469 [=======>......................] - ETA: 1:04 - loss: 0.1550 - sparse_categorical_accuracy: 0.9528\n",
            "139/469 [=======>......................] - ETA: 1:04 - loss: 0.1548 - sparse_categorical_accuracy: 0.9528\n",
            "140/469 [=======>......................] - ETA: 1:04 - loss: 0.1547 - sparse_categorical_accuracy: 0.9530\n",
            "141/469 [========>.....................] - ETA: 1:04 - loss: 0.1557 - sparse_categorical_accuracy: 0.9527\n",
            "142/469 [========>.....................] - ETA: 1:03 - loss: 0.1553 - sparse_categorical_accuracy: 0.9528\n",
            "143/469 [========>.....................] - ETA: 1:03 - loss: 0.1555 - sparse_categorical_accuracy: 0.9527\n",
            "144/469 [========>.....................] - ETA: 1:03 - loss: 0.1549 - sparse_categorical_accuracy: 0.9530\n",
            "145/469 [========>.....................] - ETA: 1:03 - loss: 0.1544 - sparse_categorical_accuracy: 0.9532\n",
            "146/469 [========>.....................] - ETA: 1:02 - loss: 0.1541 - sparse_categorical_accuracy: 0.9533\n",
            "147/469 [========>.....................] - ETA: 1:02 - loss: 0.1542 - sparse_categorical_accuracy: 0.9532\n",
            "148/469 [========>.....................] - ETA: 1:02 - loss: 0.1539 - sparse_categorical_accuracy: 0.9533\n",
            "149/469 [========>.....................] - ETA: 1:02 - loss: 0.1542 - sparse_categorical_accuracy: 0.9533\n",
            "150/469 [========>.....................] - ETA: 1:02 - loss: 0.1535 - sparse_categorical_accuracy: 0.9535\n",
            "151/469 [========>.....................] - ETA: 1:01 - loss: 0.1537 - sparse_categorical_accuracy: 0.9535\n",
            "152/469 [========>.....................] - ETA: 1:01 - loss: 0.1535 - sparse_categorical_accuracy: 0.9536\n",
            "153/469 [========>.....................] - ETA: 1:01 - loss: 0.1531 - sparse_categorical_accuracy: 0.9537\n",
            "154/469 [========>.....................] - ETA: 1:01 - loss: 0.1542 - sparse_categorical_accuracy: 0.9535\n",
            "155/469 [========>.....................] - ETA: 1:00 - loss: 0.1543 - sparse_categorical_accuracy: 0.9534\n",
            "156/469 [========>.....................] - ETA: 1:00 - loss: 0.1545 - sparse_categorical_accuracy: 0.9534\n",
            "157/469 [=========>....................] - ETA: 1:00 - loss: 0.1540 - sparse_categorical_accuracy: 0.9536\n",
            "158/469 [=========>....................] - ETA: 1:00 - loss: 0.1540 - sparse_categorical_accuracy: 0.9536\n",
            "159/469 [=========>....................] - ETA: 1:00 - loss: 0.1536 - sparse_categorical_accuracy: 0.9538\n",
            "160/469 [=========>....................] - ETA: 59s - loss: 0.1534 - sparse_categorical_accuracy: 0.9538 \n",
            "161/469 [=========>....................] - ETA: 59s - loss: 0.1529 - sparse_categorical_accuracy: 0.9539\n",
            "162/469 [=========>....................] - ETA: 59s - loss: 0.1531 - sparse_categorical_accuracy: 0.9538\n",
            "163/469 [=========>....................] - ETA: 59s - loss: 0.1533 - sparse_categorical_accuracy: 0.9537\n",
            "164/469 [=========>....................] - ETA: 59s - loss: 0.1533 - sparse_categorical_accuracy: 0.9537\n",
            "165/469 [=========>....................] - ETA: 58s - loss: 0.1531 - sparse_categorical_accuracy: 0.9538\n",
            "166/469 [=========>....................] - ETA: 58s - loss: 0.1528 - sparse_categorical_accuracy: 0.9538\n",
            "167/469 [=========>....................] - ETA: 58s - loss: 0.1531 - sparse_categorical_accuracy: 0.9538\n",
            "168/469 [=========>....................] - ETA: 58s - loss: 0.1525 - sparse_categorical_accuracy: 0.9540\n",
            "169/469 [=========>....................] - ETA: 58s - loss: 0.1522 - sparse_categorical_accuracy: 0.9541\n",
            "170/469 [=========>....................] - ETA: 58s - loss: 0.1518 - sparse_categorical_accuracy: 0.9542\n",
            "171/469 [=========>....................] - ETA: 58s - loss: 0.1515 - sparse_categorical_accuracy: 0.9543\n",
            "172/469 [==========>...................] - ETA: 58s - loss: 0.1514 - sparse_categorical_accuracy: 0.9543\n",
            "173/469 [==========>...................] - ETA: 58s - loss: 0.1510 - sparse_categorical_accuracy: 0.9544\n",
            "174/469 [==========>...................] - ETA: 58s - loss: 0.1508 - sparse_categorical_accuracy: 0.9544\n",
            "175/469 [==========>...................] - ETA: 58s - loss: 0.1506 - sparse_categorical_accuracy: 0.9544\n",
            "176/469 [==========>...................] - ETA: 58s - loss: 0.1507 - sparse_categorical_accuracy: 0.9545\n",
            "177/469 [==========>...................] - ETA: 58s - loss: 0.1502 - sparse_categorical_accuracy: 0.9545\n",
            "178/469 [==========>...................] - ETA: 58s - loss: 0.1498 - sparse_categorical_accuracy: 0.9546\n",
            "179/469 [==========>...................] - ETA: 57s - loss: 0.1496 - sparse_categorical_accuracy: 0.9547\n",
            "180/469 [==========>...................] - ETA: 57s - loss: 0.1497 - sparse_categorical_accuracy: 0.9546\n",
            "181/469 [==========>...................] - ETA: 57s - loss: 0.1493 - sparse_categorical_accuracy: 0.9548\n",
            "182/469 [==========>...................] - ETA: 57s - loss: 0.1495 - sparse_categorical_accuracy: 0.9548\n",
            "183/469 [==========>...................] - ETA: 57s - loss: 0.1494 - sparse_categorical_accuracy: 0.9547\n",
            "184/469 [==========>...................] - ETA: 56s - loss: 0.1497 - sparse_categorical_accuracy: 0.9547\n",
            "185/469 [==========>...................] - ETA: 56s - loss: 0.1492 - sparse_categorical_accuracy: 0.9548\n",
            "186/469 [==========>...................] - ETA: 56s - loss: 0.1490 - sparse_categorical_accuracy: 0.9548\n",
            "187/469 [==========>...................] - ETA: 56s - loss: 0.1492 - sparse_categorical_accuracy: 0.9548\n",
            "188/469 [===========>..................] - ETA: 55s - loss: 0.1491 - sparse_categorical_accuracy: 0.9548\n",
            "189/469 [===========>..................] - ETA: 55s - loss: 0.1489 - sparse_categorical_accuracy: 0.9549\n",
            "190/469 [===========>..................] - ETA: 55s - loss: 0.1488 - sparse_categorical_accuracy: 0.9550\n",
            "191/469 [===========>..................] - ETA: 55s - loss: 0.1488 - sparse_categorical_accuracy: 0.9550\n",
            "192/469 [===========>..................] - ETA: 54s - loss: 0.1491 - sparse_categorical_accuracy: 0.9549\n",
            "193/469 [===========>..................] - ETA: 54s - loss: 0.1490 - sparse_categorical_accuracy: 0.9549\n",
            "194/469 [===========>..................] - ETA: 54s - loss: 0.1491 - sparse_categorical_accuracy: 0.9548\n",
            "195/469 [===========>..................] - ETA: 54s - loss: 0.1488 - sparse_categorical_accuracy: 0.9549\n",
            "196/469 [===========>..................] - ETA: 54s - loss: 0.1487 - sparse_categorical_accuracy: 0.9550\n",
            "197/469 [===========>..................] - ETA: 53s - loss: 0.1485 - sparse_categorical_accuracy: 0.9551\n",
            "198/469 [===========>..................] - ETA: 53s - loss: 0.1484 - sparse_categorical_accuracy: 0.9550\n",
            "199/469 [===========>..................] - ETA: 53s - loss: 0.1484 - sparse_categorical_accuracy: 0.9549\n",
            "200/469 [===========>..................] - ETA: 53s - loss: 0.1483 - sparse_categorical_accuracy: 0.9550\n",
            "201/469 [===========>..................] - ETA: 52s - loss: 0.1481 - sparse_categorical_accuracy: 0.9550\n",
            "202/469 [===========>..................] - ETA: 52s - loss: 0.1479 - sparse_categorical_accuracy: 0.9550\n",
            "203/469 [===========>..................] - ETA: 52s - loss: 0.1479 - sparse_categorical_accuracy: 0.9551\n",
            "204/469 [============>.................] - ETA: 52s - loss: 0.1478 - sparse_categorical_accuracy: 0.9550\n",
            "205/469 [============>.................] - ETA: 52s - loss: 0.1479 - sparse_categorical_accuracy: 0.9549\n",
            "206/469 [============>.................] - ETA: 51s - loss: 0.1478 - sparse_categorical_accuracy: 0.9548\n",
            "207/469 [============>.................] - ETA: 51s - loss: 0.1476 - sparse_categorical_accuracy: 0.9549\n",
            "208/469 [============>.................] - ETA: 51s - loss: 0.1477 - sparse_categorical_accuracy: 0.9549\n",
            "209/469 [============>.................] - ETA: 51s - loss: 0.1472 - sparse_categorical_accuracy: 0.9551\n",
            "210/469 [============>.................] - ETA: 51s - loss: 0.1473 - sparse_categorical_accuracy: 0.9551\n",
            "211/469 [============>.................] - ETA: 50s - loss: 0.1473 - sparse_categorical_accuracy: 0.9551\n",
            "212/469 [============>.................] - ETA: 50s - loss: 0.1469 - sparse_categorical_accuracy: 0.9552\n",
            "213/469 [============>.................] - ETA: 50s - loss: 0.1468 - sparse_categorical_accuracy: 0.9552\n",
            "214/469 [============>.................] - ETA: 50s - loss: 0.1467 - sparse_categorical_accuracy: 0.9552\n",
            "215/469 [============>.................] - ETA: 49s - loss: 0.1463 - sparse_categorical_accuracy: 0.9553\n",
            "216/469 [============>.................] - ETA: 49s - loss: 0.1465 - sparse_categorical_accuracy: 0.9552\n",
            "217/469 [============>.................] - ETA: 49s - loss: 0.1464 - sparse_categorical_accuracy: 0.9551\n",
            "218/469 [============>.................] - ETA: 49s - loss: 0.1468 - sparse_categorical_accuracy: 0.9551\n",
            "219/469 [=============>................] - ETA: 49s - loss: 0.1466 - sparse_categorical_accuracy: 0.9551\n",
            "220/469 [=============>................] - ETA: 48s - loss: 0.1466 - sparse_categorical_accuracy: 0.9551\n",
            "221/469 [=============>................] - ETA: 48s - loss: 0.1467 - sparse_categorical_accuracy: 0.9551\n",
            "222/469 [=============>................] - ETA: 48s - loss: 0.1464 - sparse_categorical_accuracy: 0.9552\n",
            "223/469 [=============>................] - ETA: 48s - loss: 0.1461 - sparse_categorical_accuracy: 0.9553\n",
            "224/469 [=============>................] - ETA: 48s - loss: 0.1462 - sparse_categorical_accuracy: 0.9553\n",
            "225/469 [=============>................] - ETA: 47s - loss: 0.1461 - sparse_categorical_accuracy: 0.9553\n",
            "226/469 [=============>................] - ETA: 47s - loss: 0.1460 - sparse_categorical_accuracy: 0.9554\n",
            "227/469 [=============>................] - ETA: 47s - loss: 0.1458 - sparse_categorical_accuracy: 0.9555\n",
            "228/469 [=============>................] - ETA: 47s - loss: 0.1456 - sparse_categorical_accuracy: 0.9556\n",
            "229/469 [=============>................] - ETA: 47s - loss: 0.1456 - sparse_categorical_accuracy: 0.9556\n",
            "230/469 [=============>................] - ETA: 46s - loss: 0.1456 - sparse_categorical_accuracy: 0.9557\n",
            "231/469 [=============>................] - ETA: 46s - loss: 0.1457 - sparse_categorical_accuracy: 0.9557\n",
            "232/469 [=============>................] - ETA: 46s - loss: 0.1457 - sparse_categorical_accuracy: 0.9557\n",
            "233/469 [=============>................] - ETA: 46s - loss: 0.1455 - sparse_categorical_accuracy: 0.9557\n",
            "234/469 [=============>................] - ETA: 45s - loss: 0.1454 - sparse_categorical_accuracy: 0.9558\n",
            "235/469 [==============>...............] - ETA: 45s - loss: 0.1452 - sparse_categorical_accuracy: 0.9559\n",
            "236/469 [==============>...............] - ETA: 45s - loss: 0.1450 - sparse_categorical_accuracy: 0.9559\n",
            "237/469 [==============>...............] - ETA: 45s - loss: 0.1453 - sparse_categorical_accuracy: 0.9558\n",
            "238/469 [==============>...............] - ETA: 45s - loss: 0.1453 - sparse_categorical_accuracy: 0.9558\n",
            "239/469 [==============>...............] - ETA: 45s - loss: 0.1456 - sparse_categorical_accuracy: 0.9557\n",
            "240/469 [==============>...............] - ETA: 45s - loss: 0.1454 - sparse_categorical_accuracy: 0.9558\n",
            "241/469 [==============>...............] - ETA: 45s - loss: 0.1453 - sparse_categorical_accuracy: 0.9558\n",
            "242/469 [==============>...............] - ETA: 45s - loss: 0.1451 - sparse_categorical_accuracy: 0.9559\n",
            "243/469 [==============>...............] - ETA: 45s - loss: 0.1450 - sparse_categorical_accuracy: 0.9559\n",
            "244/469 [==============>...............] - ETA: 44s - loss: 0.1450 - sparse_categorical_accuracy: 0.9559\n",
            "245/469 [==============>...............] - ETA: 44s - loss: 0.1448 - sparse_categorical_accuracy: 0.9560\n",
            "246/469 [==============>...............] - ETA: 44s - loss: 0.1449 - sparse_categorical_accuracy: 0.9559\n",
            "247/469 [==============>...............] - ETA: 44s - loss: 0.1446 - sparse_categorical_accuracy: 0.9559\n",
            "248/469 [==============>...............] - ETA: 44s - loss: 0.1446 - sparse_categorical_accuracy: 0.9560\n",
            "249/469 [==============>...............] - ETA: 43s - loss: 0.1443 - sparse_categorical_accuracy: 0.9561\n",
            "250/469 [==============>...............] - ETA: 43s - loss: 0.1440 - sparse_categorical_accuracy: 0.9562\n",
            "251/469 [===============>..............] - ETA: 43s - loss: 0.1436 - sparse_categorical_accuracy: 0.9563\n",
            "252/469 [===============>..............] - ETA: 43s - loss: 0.1433 - sparse_categorical_accuracy: 0.9565\n",
            "253/469 [===============>..............] - ETA: 43s - loss: 0.1431 - sparse_categorical_accuracy: 0.9566\n",
            "254/469 [===============>..............] - ETA: 42s - loss: 0.1432 - sparse_categorical_accuracy: 0.9564\n",
            "255/469 [===============>..............] - ETA: 42s - loss: 0.1430 - sparse_categorical_accuracy: 0.9565\n",
            "256/469 [===============>..............] - ETA: 42s - loss: 0.1431 - sparse_categorical_accuracy: 0.9565\n",
            "257/469 [===============>..............] - ETA: 42s - loss: 0.1431 - sparse_categorical_accuracy: 0.9565\n",
            "258/469 [===============>..............] - ETA: 42s - loss: 0.1433 - sparse_categorical_accuracy: 0.9565\n",
            "259/469 [===============>..............] - ETA: 41s - loss: 0.1435 - sparse_categorical_accuracy: 0.9564\n",
            "260/469 [===============>..............] - ETA: 41s - loss: 0.1435 - sparse_categorical_accuracy: 0.9564\n",
            "261/469 [===============>..............] - ETA: 41s - loss: 0.1435 - sparse_categorical_accuracy: 0.9563\n",
            "262/469 [===============>..............] - ETA: 41s - loss: 0.1432 - sparse_categorical_accuracy: 0.9564\n",
            "263/469 [===============>..............] - ETA: 40s - loss: 0.1429 - sparse_categorical_accuracy: 0.9564\n",
            "264/469 [===============>..............] - ETA: 40s - loss: 0.1429 - sparse_categorical_accuracy: 0.9564\n",
            "265/469 [===============>..............] - ETA: 40s - loss: 0.1426 - sparse_categorical_accuracy: 0.9565\n",
            "266/469 [================>.............] - ETA: 40s - loss: 0.1427 - sparse_categorical_accuracy: 0.9565\n",
            "267/469 [================>.............] - ETA: 40s - loss: 0.1426 - sparse_categorical_accuracy: 0.9566\n",
            "268/469 [================>.............] - ETA: 39s - loss: 0.1427 - sparse_categorical_accuracy: 0.9566\n",
            "269/469 [================>.............] - ETA: 39s - loss: 0.1425 - sparse_categorical_accuracy: 0.9567\n",
            "270/469 [================>.............] - ETA: 39s - loss: 0.1424 - sparse_categorical_accuracy: 0.9567\n",
            "271/469 [================>.............] - ETA: 39s - loss: 0.1420 - sparse_categorical_accuracy: 0.9568\n",
            "272/469 [================>.............] - ETA: 39s - loss: 0.1420 - sparse_categorical_accuracy: 0.9568\n",
            "273/469 [================>.............] - ETA: 38s - loss: 0.1418 - sparse_categorical_accuracy: 0.9569\n",
            "274/469 [================>.............] - ETA: 38s - loss: 0.1420 - sparse_categorical_accuracy: 0.9569\n",
            "275/469 [================>.............] - ETA: 38s - loss: 0.1421 - sparse_categorical_accuracy: 0.9568\n",
            "276/469 [================>.............] - ETA: 38s - loss: 0.1419 - sparse_categorical_accuracy: 0.9569\n",
            "277/469 [================>.............] - ETA: 37s - loss: 0.1416 - sparse_categorical_accuracy: 0.9570\n",
            "278/469 [================>.............] - ETA: 37s - loss: 0.1415 - sparse_categorical_accuracy: 0.9570\n",
            "279/469 [================>.............] - ETA: 37s - loss: 0.1412 - sparse_categorical_accuracy: 0.9571\n",
            "280/469 [================>.............] - ETA: 37s - loss: 0.1410 - sparse_categorical_accuracy: 0.9572\n",
            "281/469 [================>.............] - ETA: 37s - loss: 0.1408 - sparse_categorical_accuracy: 0.9572\n",
            "282/469 [=================>............] - ETA: 36s - loss: 0.1406 - sparse_categorical_accuracy: 0.9573\n",
            "283/469 [=================>............] - ETA: 36s - loss: 0.1404 - sparse_categorical_accuracy: 0.9573\n",
            "284/469 [=================>............] - ETA: 36s - loss: 0.1407 - sparse_categorical_accuracy: 0.9572\n",
            "285/469 [=================>............] - ETA: 36s - loss: 0.1406 - sparse_categorical_accuracy: 0.9571\n",
            "286/469 [=================>............] - ETA: 36s - loss: 0.1406 - sparse_categorical_accuracy: 0.9572\n",
            "287/469 [=================>............] - ETA: 35s - loss: 0.1405 - sparse_categorical_accuracy: 0.9572\n",
            "288/469 [=================>............] - ETA: 35s - loss: 0.1404 - sparse_categorical_accuracy: 0.9572\n",
            "289/469 [=================>............] - ETA: 35s - loss: 0.1402 - sparse_categorical_accuracy: 0.9573\n",
            "290/469 [=================>............] - ETA: 35s - loss: 0.1400 - sparse_categorical_accuracy: 0.9573\n",
            "291/469 [=================>............] - ETA: 35s - loss: 0.1399 - sparse_categorical_accuracy: 0.9573\n",
            "292/469 [=================>............] - ETA: 34s - loss: 0.1396 - sparse_categorical_accuracy: 0.9575\n",
            "293/469 [=================>............] - ETA: 34s - loss: 0.1396 - sparse_categorical_accuracy: 0.9575\n",
            "294/469 [=================>............] - ETA: 34s - loss: 0.1396 - sparse_categorical_accuracy: 0.9575\n",
            "295/469 [=================>............] - ETA: 34s - loss: 0.1394 - sparse_categorical_accuracy: 0.9575\n",
            "296/469 [=================>............] - ETA: 34s - loss: 0.1392 - sparse_categorical_accuracy: 0.9576\n",
            "297/469 [=================>............] - ETA: 33s - loss: 0.1392 - sparse_categorical_accuracy: 0.9576\n",
            "298/469 [==================>...........] - ETA: 33s - loss: 0.1390 - sparse_categorical_accuracy: 0.9577\n",
            "299/469 [==================>...........] - ETA: 33s - loss: 0.1388 - sparse_categorical_accuracy: 0.9579\n",
            "300/469 [==================>...........] - ETA: 33s - loss: 0.1385 - sparse_categorical_accuracy: 0.9579\n",
            "301/469 [==================>...........] - ETA: 32s - loss: 0.1384 - sparse_categorical_accuracy: 0.9579\n",
            "302/469 [==================>...........] - ETA: 32s - loss: 0.1383 - sparse_categorical_accuracy: 0.9579\n",
            "303/469 [==================>...........] - ETA: 32s - loss: 0.1381 - sparse_categorical_accuracy: 0.9579\n",
            "304/469 [==================>...........] - ETA: 32s - loss: 0.1386 - sparse_categorical_accuracy: 0.9579\n",
            "305/469 [==================>...........] - ETA: 32s - loss: 0.1389 - sparse_categorical_accuracy: 0.9578\n",
            "306/469 [==================>...........] - ETA: 32s - loss: 0.1388 - sparse_categorical_accuracy: 0.9578\n",
            "307/469 [==================>...........] - ETA: 32s - loss: 0.1387 - sparse_categorical_accuracy: 0.9578\n",
            "308/469 [==================>...........] - ETA: 31s - loss: 0.1384 - sparse_categorical_accuracy: 0.9579\n",
            "309/469 [==================>...........] - ETA: 31s - loss: 0.1385 - sparse_categorical_accuracy: 0.9578\n",
            "310/469 [==================>...........] - ETA: 31s - loss: 0.1385 - sparse_categorical_accuracy: 0.9578\n",
            "311/469 [==================>...........] - ETA: 31s - loss: 0.1383 - sparse_categorical_accuracy: 0.9579\n",
            "312/469 [==================>...........] - ETA: 31s - loss: 0.1380 - sparse_categorical_accuracy: 0.9580\n",
            "313/469 [===================>..........] - ETA: 31s - loss: 0.1382 - sparse_categorical_accuracy: 0.9580\n",
            "314/469 [===================>..........] - ETA: 30s - loss: 0.1382 - sparse_categorical_accuracy: 0.9580\n",
            "315/469 [===================>..........] - ETA: 30s - loss: 0.1383 - sparse_categorical_accuracy: 0.9580\n",
            "316/469 [===================>..........] - ETA: 30s - loss: 0.1385 - sparse_categorical_accuracy: 0.9580\n",
            "317/469 [===================>..........] - ETA: 30s - loss: 0.1382 - sparse_categorical_accuracy: 0.9581\n",
            "318/469 [===================>..........] - ETA: 30s - loss: 0.1380 - sparse_categorical_accuracy: 0.9581\n",
            "319/469 [===================>..........] - ETA: 29s - loss: 0.1380 - sparse_categorical_accuracy: 0.9581\n",
            "320/469 [===================>..........] - ETA: 29s - loss: 0.1379 - sparse_categorical_accuracy: 0.9582\n",
            "321/469 [===================>..........] - ETA: 29s - loss: 0.1378 - sparse_categorical_accuracy: 0.9582\n",
            "322/469 [===================>..........] - ETA: 29s - loss: 0.1379 - sparse_categorical_accuracy: 0.9582\n",
            "323/469 [===================>..........] - ETA: 29s - loss: 0.1378 - sparse_categorical_accuracy: 0.9581\n",
            "324/469 [===================>..........] - ETA: 28s - loss: 0.1381 - sparse_categorical_accuracy: 0.9581\n",
            "325/469 [===================>..........] - ETA: 28s - loss: 0.1379 - sparse_categorical_accuracy: 0.9581\n",
            "326/469 [===================>..........] - ETA: 28s - loss: 0.1379 - sparse_categorical_accuracy: 0.9581\n",
            "327/469 [===================>..........] - ETA: 28s - loss: 0.1381 - sparse_categorical_accuracy: 0.9581\n",
            "328/469 [===================>..........] - ETA: 28s - loss: 0.1380 - sparse_categorical_accuracy: 0.9581\n",
            "329/469 [====================>.........] - ETA: 27s - loss: 0.1379 - sparse_categorical_accuracy: 0.9581\n",
            "330/469 [====================>.........] - ETA: 27s - loss: 0.1380 - sparse_categorical_accuracy: 0.9580\n",
            "331/469 [====================>.........] - ETA: 27s - loss: 0.1382 - sparse_categorical_accuracy: 0.9580\n",
            "332/469 [====================>.........] - ETA: 27s - loss: 0.1383 - sparse_categorical_accuracy: 0.9580\n",
            "333/469 [====================>.........] - ETA: 26s - loss: 0.1381 - sparse_categorical_accuracy: 0.9580\n",
            "334/469 [====================>.........] - ETA: 26s - loss: 0.1382 - sparse_categorical_accuracy: 0.9579\n",
            "335/469 [====================>.........] - ETA: 26s - loss: 0.1381 - sparse_categorical_accuracy: 0.9580\n",
            "336/469 [====================>.........] - ETA: 26s - loss: 0.1380 - sparse_categorical_accuracy: 0.9580\n",
            "337/469 [====================>.........] - ETA: 26s - loss: 0.1377 - sparse_categorical_accuracy: 0.9581\n",
            "338/469 [====================>.........] - ETA: 25s - loss: 0.1376 - sparse_categorical_accuracy: 0.9581\n",
            "339/469 [====================>.........] - ETA: 25s - loss: 0.1378 - sparse_categorical_accuracy: 0.9581\n",
            "340/469 [====================>.........] - ETA: 25s - loss: 0.1377 - sparse_categorical_accuracy: 0.9581\n",
            "341/469 [====================>.........] - ETA: 25s - loss: 0.1376 - sparse_categorical_accuracy: 0.9582\n",
            "342/469 [====================>.........] - ETA: 25s - loss: 0.1377 - sparse_categorical_accuracy: 0.9581\n",
            "343/469 [====================>.........] - ETA: 24s - loss: 0.1378 - sparse_categorical_accuracy: 0.9581\n",
            "344/469 [=====================>........] - ETA: 24s - loss: 0.1381 - sparse_categorical_accuracy: 0.9580\n",
            "345/469 [=====================>........] - ETA: 24s - loss: 0.1380 - sparse_categorical_accuracy: 0.9580\n",
            "346/469 [=====================>........] - ETA: 24s - loss: 0.1378 - sparse_categorical_accuracy: 0.9581\n",
            "347/469 [=====================>........] - ETA: 24s - loss: 0.1380 - sparse_categorical_accuracy: 0.9580\n",
            "348/469 [=====================>........] - ETA: 23s - loss: 0.1383 - sparse_categorical_accuracy: 0.9580\n",
            "349/469 [=====================>........] - ETA: 23s - loss: 0.1384 - sparse_categorical_accuracy: 0.9580\n",
            "350/469 [=====================>........] - ETA: 23s - loss: 0.1382 - sparse_categorical_accuracy: 0.9581\n",
            "351/469 [=====================>........] - ETA: 23s - loss: 0.1381 - sparse_categorical_accuracy: 0.9581\n",
            "352/469 [=====================>........] - ETA: 23s - loss: 0.1382 - sparse_categorical_accuracy: 0.9581\n",
            "353/469 [=====================>........] - ETA: 22s - loss: 0.1381 - sparse_categorical_accuracy: 0.9581\n",
            "354/469 [=====================>........] - ETA: 22s - loss: 0.1380 - sparse_categorical_accuracy: 0.9582\n",
            "355/469 [=====================>........] - ETA: 22s - loss: 0.1383 - sparse_categorical_accuracy: 0.9581\n",
            "356/469 [=====================>........] - ETA: 22s - loss: 0.1380 - sparse_categorical_accuracy: 0.9582\n",
            "357/469 [=====================>........] - ETA: 22s - loss: 0.1379 - sparse_categorical_accuracy: 0.9582\n",
            "358/469 [=====================>........] - ETA: 21s - loss: 0.1380 - sparse_categorical_accuracy: 0.9582\n",
            "359/469 [=====================>........] - ETA: 21s - loss: 0.1381 - sparse_categorical_accuracy: 0.9582\n",
            "360/469 [======================>.......] - ETA: 21s - loss: 0.1379 - sparse_categorical_accuracy: 0.9582\n",
            "361/469 [======================>.......] - ETA: 21s - loss: 0.1379 - sparse_categorical_accuracy: 0.9583\n",
            "362/469 [======================>.......] - ETA: 21s - loss: 0.1378 - sparse_categorical_accuracy: 0.9582\n",
            "363/469 [======================>.......] - ETA: 20s - loss: 0.1379 - sparse_categorical_accuracy: 0.9582\n",
            "364/469 [======================>.......] - ETA: 20s - loss: 0.1380 - sparse_categorical_accuracy: 0.9583\n",
            "365/469 [======================>.......] - ETA: 20s - loss: 0.1380 - sparse_categorical_accuracy: 0.9583\n",
            "366/469 [======================>.......] - ETA: 20s - loss: 0.1380 - sparse_categorical_accuracy: 0.9583\n",
            "367/469 [======================>.......] - ETA: 20s - loss: 0.1378 - sparse_categorical_accuracy: 0.9583\n",
            "368/469 [======================>.......] - ETA: 19s - loss: 0.1377 - sparse_categorical_accuracy: 0.9584\n",
            "369/469 [======================>.......] - ETA: 19s - loss: 0.1377 - sparse_categorical_accuracy: 0.9584\n",
            "370/469 [======================>.......] - ETA: 19s - loss: 0.1376 - sparse_categorical_accuracy: 0.9584\n",
            "371/469 [======================>.......] - ETA: 19s - loss: 0.1375 - sparse_categorical_accuracy: 0.9584\n",
            "372/469 [======================>.......] - ETA: 19s - loss: 0.1374 - sparse_categorical_accuracy: 0.9585\n",
            "373/469 [======================>.......] - ETA: 18s - loss: 0.1374 - sparse_categorical_accuracy: 0.9585\n",
            "374/469 [======================>.......] - ETA: 18s - loss: 0.1373 - sparse_categorical_accuracy: 0.9585\n",
            "375/469 [======================>.......] - ETA: 18s - loss: 0.1373 - sparse_categorical_accuracy: 0.9585\n",
            "376/469 [=======================>......] - ETA: 18s - loss: 0.1371 - sparse_categorical_accuracy: 0.9586\n",
            "377/469 [=======================>......] - ETA: 18s - loss: 0.1373 - sparse_categorical_accuracy: 0.9585\n",
            "378/469 [=======================>......] - ETA: 18s - loss: 0.1376 - sparse_categorical_accuracy: 0.9584\n",
            "379/469 [=======================>......] - ETA: 17s - loss: 0.1376 - sparse_categorical_accuracy: 0.9584\n",
            "380/469 [=======================>......] - ETA: 17s - loss: 0.1375 - sparse_categorical_accuracy: 0.9584\n",
            "381/469 [=======================>......] - ETA: 17s - loss: 0.1374 - sparse_categorical_accuracy: 0.9584\n",
            "382/469 [=======================>......] - ETA: 17s - loss: 0.1373 - sparse_categorical_accuracy: 0.9585\n",
            "383/469 [=======================>......] - ETA: 17s - loss: 0.1373 - sparse_categorical_accuracy: 0.9584\n",
            "384/469 [=======================>......] - ETA: 16s - loss: 0.1372 - sparse_categorical_accuracy: 0.9585\n",
            "385/469 [=======================>......] - ETA: 16s - loss: 0.1370 - sparse_categorical_accuracy: 0.9585\n",
            "386/469 [=======================>......] - ETA: 16s - loss: 0.1370 - sparse_categorical_accuracy: 0.9585\n",
            "387/469 [=======================>......] - ETA: 16s - loss: 0.1369 - sparse_categorical_accuracy: 0.9585\n",
            "388/469 [=======================>......] - ETA: 16s - loss: 0.1367 - sparse_categorical_accuracy: 0.9586\n",
            "389/469 [=======================>......] - ETA: 15s - loss: 0.1368 - sparse_categorical_accuracy: 0.9585\n",
            "390/469 [=======================>......] - ETA: 15s - loss: 0.1368 - sparse_categorical_accuracy: 0.9586\n",
            "391/469 [========================>.....] - ETA: 15s - loss: 0.1366 - sparse_categorical_accuracy: 0.9586\n",
            "392/469 [========================>.....] - ETA: 15s - loss: 0.1365 - sparse_categorical_accuracy: 0.9586\n",
            "393/469 [========================>.....] - ETA: 15s - loss: 0.1365 - sparse_categorical_accuracy: 0.9586\n",
            "394/469 [========================>.....] - ETA: 14s - loss: 0.1364 - sparse_categorical_accuracy: 0.9587\n",
            "395/469 [========================>.....] - ETA: 14s - loss: 0.1363 - sparse_categorical_accuracy: 0.9587\n",
            "396/469 [========================>.....] - ETA: 14s - loss: 0.1362 - sparse_categorical_accuracy: 0.9587\n",
            "397/469 [========================>.....] - ETA: 14s - loss: 0.1362 - sparse_categorical_accuracy: 0.9587\n",
            "398/469 [========================>.....] - ETA: 14s - loss: 0.1363 - sparse_categorical_accuracy: 0.9586\n",
            "399/469 [========================>.....] - ETA: 13s - loss: 0.1361 - sparse_categorical_accuracy: 0.9586\n",
            "400/469 [========================>.....] - ETA: 13s - loss: 0.1361 - sparse_categorical_accuracy: 0.9587\n",
            "401/469 [========================>.....] - ETA: 13s - loss: 0.1361 - sparse_categorical_accuracy: 0.9587\n",
            "402/469 [========================>.....] - ETA: 13s - loss: 0.1360 - sparse_categorical_accuracy: 0.9587\n",
            "403/469 [========================>.....] - ETA: 13s - loss: 0.1359 - sparse_categorical_accuracy: 0.9587\n",
            "404/469 [========================>.....] - ETA: 12s - loss: 0.1359 - sparse_categorical_accuracy: 0.9588\n",
            "405/469 [========================>.....] - ETA: 12s - loss: 0.1359 - sparse_categorical_accuracy: 0.9587\n",
            "406/469 [========================>.....] - ETA: 12s - loss: 0.1359 - sparse_categorical_accuracy: 0.9587\n",
            "407/469 [=========================>....] - ETA: 12s - loss: 0.1359 - sparse_categorical_accuracy: 0.9588\n",
            "408/469 [=========================>....] - ETA: 12s - loss: 0.1357 - sparse_categorical_accuracy: 0.9589\n",
            "409/469 [=========================>....] - ETA: 11s - loss: 0.1356 - sparse_categorical_accuracy: 0.9589\n",
            "410/469 [=========================>....] - ETA: 11s - loss: 0.1354 - sparse_categorical_accuracy: 0.9589\n",
            "411/469 [=========================>....] - ETA: 11s - loss: 0.1353 - sparse_categorical_accuracy: 0.9589\n",
            "412/469 [=========================>....] - ETA: 11s - loss: 0.1351 - sparse_categorical_accuracy: 0.9590\n",
            "413/469 [=========================>....] - ETA: 11s - loss: 0.1351 - sparse_categorical_accuracy: 0.9590\n",
            "414/469 [=========================>....] - ETA: 10s - loss: 0.1350 - sparse_categorical_accuracy: 0.9590\n",
            "415/469 [=========================>....] - ETA: 10s - loss: 0.1352 - sparse_categorical_accuracy: 0.9590\n",
            "416/469 [=========================>....] - ETA: 10s - loss: 0.1351 - sparse_categorical_accuracy: 0.9590\n",
            "417/469 [=========================>....] - ETA: 10s - loss: 0.1350 - sparse_categorical_accuracy: 0.9590\n",
            "418/469 [=========================>....] - ETA: 10s - loss: 0.1349 - sparse_categorical_accuracy: 0.9591\n",
            "419/469 [=========================>....] - ETA: 9s - loss: 0.1349 - sparse_categorical_accuracy: 0.9591 \n",
            "420/469 [=========================>....] - ETA: 9s - loss: 0.1348 - sparse_categorical_accuracy: 0.9591\n",
            "421/469 [=========================>....] - ETA: 9s - loss: 0.1348 - sparse_categorical_accuracy: 0.9591\n",
            "422/469 [=========================>....] - ETA: 9s - loss: 0.1349 - sparse_categorical_accuracy: 0.9591\n",
            "423/469 [==========================>...] - ETA: 9s - loss: 0.1346 - sparse_categorical_accuracy: 0.9592\n",
            "424/469 [==========================>...] - ETA: 8s - loss: 0.1345 - sparse_categorical_accuracy: 0.9592\n",
            "425/469 [==========================>...] - ETA: 8s - loss: 0.1344 - sparse_categorical_accuracy: 0.9593\n",
            "426/469 [==========================>...] - ETA: 8s - loss: 0.1346 - sparse_categorical_accuracy: 0.9592\n",
            "427/469 [==========================>...] - ETA: 8s - loss: 0.1345 - sparse_categorical_accuracy: 0.9593\n",
            "428/469 [==========================>...] - ETA: 8s - loss: 0.1343 - sparse_categorical_accuracy: 0.9593\n",
            "429/469 [==========================>...] - ETA: 7s - loss: 0.1346 - sparse_categorical_accuracy: 0.9593\n",
            "430/469 [==========================>...] - ETA: 7s - loss: 0.1344 - sparse_categorical_accuracy: 0.9593\n",
            "431/469 [==========================>...] - ETA: 7s - loss: 0.1345 - sparse_categorical_accuracy: 0.9593\n",
            "432/469 [==========================>...] - ETA: 7s - loss: 0.1345 - sparse_categorical_accuracy: 0.9593\n",
            "433/469 [==========================>...] - ETA: 7s - loss: 0.1344 - sparse_categorical_accuracy: 0.9593\n",
            "434/469 [==========================>...] - ETA: 6s - loss: 0.1342 - sparse_categorical_accuracy: 0.9594\n",
            "435/469 [==========================>...] - ETA: 6s - loss: 0.1341 - sparse_categorical_accuracy: 0.9595\n",
            "436/469 [==========================>...] - ETA: 6s - loss: 0.1341 - sparse_categorical_accuracy: 0.9595\n",
            "437/469 [==========================>...] - ETA: 6s - loss: 0.1339 - sparse_categorical_accuracy: 0.9596\n",
            "438/469 [===========================>..] - ETA: 6s - loss: 0.1341 - sparse_categorical_accuracy: 0.9595\n",
            "439/469 [===========================>..] - ETA: 5s - loss: 0.1339 - sparse_categorical_accuracy: 0.9595\n",
            "440/469 [===========================>..] - ETA: 5s - loss: 0.1339 - sparse_categorical_accuracy: 0.9596\n",
            "441/469 [===========================>..] - ETA: 5s - loss: 0.1337 - sparse_categorical_accuracy: 0.9596\n",
            "442/469 [===========================>..] - ETA: 5s - loss: 0.1338 - sparse_categorical_accuracy: 0.9596\n",
            "443/469 [===========================>..] - ETA: 5s - loss: 0.1337 - sparse_categorical_accuracy: 0.9596\n",
            "444/469 [===========================>..] - ETA: 4s - loss: 0.1335 - sparse_categorical_accuracy: 0.9597\n",
            "445/469 [===========================>..] - ETA: 4s - loss: 0.1334 - sparse_categorical_accuracy: 0.9597\n",
            "446/469 [===========================>..] - ETA: 4s - loss: 0.1334 - sparse_categorical_accuracy: 0.9598\n",
            "447/469 [===========================>..] - ETA: 4s - loss: 0.1335 - sparse_categorical_accuracy: 0.9598\n",
            "448/469 [===========================>..] - ETA: 4s - loss: 0.1334 - sparse_categorical_accuracy: 0.9598\n",
            "449/469 [===========================>..] - ETA: 4s - loss: 0.1334 - sparse_categorical_accuracy: 0.9598\n",
            "450/469 [===========================>..] - ETA: 3s - loss: 0.1334 - sparse_categorical_accuracy: 0.9598\n",
            "451/469 [===========================>..] - ETA: 3s - loss: 0.1333 - sparse_categorical_accuracy: 0.9599\n",
            "452/469 [===========================>..] - ETA: 3s - loss: 0.1332 - sparse_categorical_accuracy: 0.9599\n",
            "453/469 [===========================>..] - ETA: 3s - loss: 0.1331 - sparse_categorical_accuracy: 0.9599\n",
            "454/469 [============================>.] - ETA: 3s - loss: 0.1330 - sparse_categorical_accuracy: 0.9600\n",
            "455/469 [============================>.] - ETA: 2s - loss: 0.1329 - sparse_categorical_accuracy: 0.9600\n",
            "456/469 [============================>.] - ETA: 2s - loss: 0.1328 - sparse_categorical_accuracy: 0.9600\n",
            "457/469 [============================>.] - ETA: 2s - loss: 0.1327 - sparse_categorical_accuracy: 0.9600\n",
            "458/469 [============================>.] - ETA: 2s - loss: 0.1326 - sparse_categorical_accuracy: 0.9600\n",
            "459/469 [============================>.] - ETA: 2s - loss: 0.1325 - sparse_categorical_accuracy: 0.9600\n",
            "460/469 [============================>.] - ETA: 1s - loss: 0.1326 - sparse_categorical_accuracy: 0.9601\n",
            "461/469 [============================>.] - ETA: 1s - loss: 0.1325 - sparse_categorical_accuracy: 0.9601\n",
            "462/469 [============================>.] - ETA: 1s - loss: 0.1325 - sparse_categorical_accuracy: 0.9601\n",
            "463/469 [============================>.] - ETA: 1s - loss: 0.1327 - sparse_categorical_accuracy: 0.9600\n",
            "464/469 [============================>.] - ETA: 1s - loss: 0.1328 - sparse_categorical_accuracy: 0.9600\n",
            "465/469 [============================>.] - ETA: 0s - loss: 0.1326 - sparse_categorical_accuracy: 0.9601\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.1325 - sparse_categorical_accuracy: 0.9601\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.1326 - sparse_categorical_accuracy: 0.9601\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.1327 - sparse_categorical_accuracy: 0.9601\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1328 - sparse_categorical_accuracy: 0.9600\n",
            " 20%|██        | 1/5 [35:00<2:07:25, 1911.46s/trial, best loss: -0.9830999970436096]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/04/16 01:07:01 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 94s 200ms/step - loss: 0.1328 - sparse_categorical_accuracy: 0.9600\n",
            "\n",
            "Epoch 3/5\n",
            "\n",
            "  1/469 [..............................] - ETA: 1:37 - loss: 0.1277 - sparse_categorical_accuracy: 0.9453\n",
            "  2/469 [..............................] - ETA: 1:24 - loss: 0.1884 - sparse_categorical_accuracy: 0.9258\n",
            "  3/469 [..............................] - ETA: 1:22 - loss: 0.1825 - sparse_categorical_accuracy: 0.9375\n",
            "  4/469 [..............................] - ETA: 1:24 - loss: 0.1734 - sparse_categorical_accuracy: 0.9414\n",
            "  5/469 [..............................] - ETA: 1:23 - loss: 0.1687 - sparse_categorical_accuracy: 0.9438\n",
            "  6/469 [..............................] - ETA: 1:22 - loss: 0.1587 - sparse_categorical_accuracy: 0.9453\n",
            "  7/469 [..............................] - ETA: 1:21 - loss: 0.1508 - sparse_categorical_accuracy: 0.9475\n",
            "  8/469 [..............................] - ETA: 1:21 - loss: 0.1458 - sparse_categorical_accuracy: 0.9512\n",
            "  9/469 [..............................] - ETA: 1:21 - loss: 0.1376 - sparse_categorical_accuracy: 0.9549\n",
            " 10/469 [..............................] - ETA: 1:21 - loss: 0.1320 - sparse_categorical_accuracy: 0.9570\n",
            " 11/469 [..............................] - ETA: 1:21 - loss: 0.1368 - sparse_categorical_accuracy: 0.9567\n",
            " 12/469 [..............................] - ETA: 1:21 - loss: 0.1298 - sparse_categorical_accuracy: 0.9596\n",
            " 13/469 [..............................] - ETA: 1:20 - loss: 0.1304 - sparse_categorical_accuracy: 0.9603\n",
            " 14/469 [..............................] - ETA: 1:20 - loss: 0.1329 - sparse_categorical_accuracy: 0.9604\n",
            " 15/469 [..............................] - ETA: 1:20 - loss: 0.1282 - sparse_categorical_accuracy: 0.9630\n",
            " 16/469 [>.............................] - ETA: 1:20 - loss: 0.1257 - sparse_categorical_accuracy: 0.9634\n",
            " 17/469 [>.............................] - ETA: 1:20 - loss: 0.1219 - sparse_categorical_accuracy: 0.9646\n",
            " 18/469 [>.............................] - ETA: 1:19 - loss: 0.1250 - sparse_categorical_accuracy: 0.9635\n",
            " 19/469 [>.............................] - ETA: 1:19 - loss: 0.1219 - sparse_categorical_accuracy: 0.9646\n",
            " 20/469 [>.............................] - ETA: 1:19 - loss: 0.1238 - sparse_categorical_accuracy: 0.9645\n",
            " 21/469 [>.............................] - ETA: 1:19 - loss: 0.1215 - sparse_categorical_accuracy: 0.9647\n",
            " 22/469 [>.............................] - ETA: 1:19 - loss: 0.1218 - sparse_categorical_accuracy: 0.9645\n",
            " 23/469 [>.............................] - ETA: 1:19 - loss: 0.1199 - sparse_categorical_accuracy: 0.9643\n",
            " 24/469 [>.............................] - ETA: 1:19 - loss: 0.1178 - sparse_categorical_accuracy: 0.9648\n",
            " 25/469 [>.............................] - ETA: 1:18 - loss: 0.1165 - sparse_categorical_accuracy: 0.9653\n",
            " 26/469 [>.............................] - ETA: 1:18 - loss: 0.1174 - sparse_categorical_accuracy: 0.9642\n",
            " 27/469 [>.............................] - ETA: 1:18 - loss: 0.1193 - sparse_categorical_accuracy: 0.9641\n",
            " 28/469 [>.............................] - ETA: 1:18 - loss: 0.1174 - sparse_categorical_accuracy: 0.9640\n",
            " 29/469 [>.............................] - ETA: 1:18 - loss: 0.1203 - sparse_categorical_accuracy: 0.9631\n",
            " 30/469 [>.............................] - ETA: 1:18 - loss: 0.1220 - sparse_categorical_accuracy: 0.9630\n",
            " 31/469 [>.............................] - ETA: 1:18 - loss: 0.1229 - sparse_categorical_accuracy: 0.9627\n",
            " 32/469 [=>............................] - ETA: 1:17 - loss: 0.1215 - sparse_categorical_accuracy: 0.9631\n",
            " 33/469 [=>............................] - ETA: 1:17 - loss: 0.1214 - sparse_categorical_accuracy: 0.9633\n",
            " 34/469 [=>............................] - ETA: 1:18 - loss: 0.1209 - sparse_categorical_accuracy: 0.9628\n",
            " 35/469 [=>............................] - ETA: 1:19 - loss: 0.1193 - sparse_categorical_accuracy: 0.9632\n",
            " 36/469 [=>............................] - ETA: 1:20 - loss: 0.1188 - sparse_categorical_accuracy: 0.9631\n",
            " 37/469 [=>............................] - ETA: 1:21 - loss: 0.1176 - sparse_categorical_accuracy: 0.9635\n",
            " 38/469 [=>............................] - ETA: 1:22 - loss: 0.1181 - sparse_categorical_accuracy: 0.9638\n",
            " 39/469 [=>............................] - ETA: 1:23 - loss: 0.1170 - sparse_categorical_accuracy: 0.9641\n",
            " 40/469 [=>............................] - ETA: 1:23 - loss: 0.1157 - sparse_categorical_accuracy: 0.9643\n",
            " 41/469 [=>............................] - ETA: 1:24 - loss: 0.1149 - sparse_categorical_accuracy: 0.9646\n",
            " 42/469 [=>............................] - ETA: 1:25 - loss: 0.1147 - sparse_categorical_accuracy: 0.9648\n",
            " 43/469 [=>............................] - ETA: 1:26 - loss: 0.1143 - sparse_categorical_accuracy: 0.9649\n",
            " 44/469 [=>............................] - ETA: 1:26 - loss: 0.1152 - sparse_categorical_accuracy: 0.9650\n",
            " 45/469 [=>............................] - ETA: 1:27 - loss: 0.1143 - sparse_categorical_accuracy: 0.9651\n",
            " 46/469 [=>............................] - ETA: 1:27 - loss: 0.1130 - sparse_categorical_accuracy: 0.9654\n",
            " 47/469 [==>...........................] - ETA: 1:27 - loss: 0.1139 - sparse_categorical_accuracy: 0.9651\n",
            " 48/469 [==>...........................] - ETA: 1:26 - loss: 0.1141 - sparse_categorical_accuracy: 0.9650\n",
            " 49/469 [==>...........................] - ETA: 1:26 - loss: 0.1147 - sparse_categorical_accuracy: 0.9648\n",
            " 50/469 [==>...........................] - ETA: 1:25 - loss: 0.1149 - sparse_categorical_accuracy: 0.9647\n",
            " 51/469 [==>...........................] - ETA: 1:25 - loss: 0.1163 - sparse_categorical_accuracy: 0.9645\n",
            " 52/469 [==>...........................] - ETA: 1:24 - loss: 0.1150 - sparse_categorical_accuracy: 0.9650\n",
            " 53/469 [==>...........................] - ETA: 1:24 - loss: 0.1159 - sparse_categorical_accuracy: 0.9649\n",
            " 54/469 [==>...........................] - ETA: 1:24 - loss: 0.1160 - sparse_categorical_accuracy: 0.9647\n",
            " 55/469 [==>...........................] - ETA: 1:23 - loss: 0.1152 - sparse_categorical_accuracy: 0.9648\n",
            " 56/469 [==>...........................] - ETA: 1:23 - loss: 0.1154 - sparse_categorical_accuracy: 0.9650\n",
            " 57/469 [==>...........................] - ETA: 1:23 - loss: 0.1148 - sparse_categorical_accuracy: 0.9650\n",
            " 58/469 [==>...........................] - ETA: 1:22 - loss: 0.1136 - sparse_categorical_accuracy: 0.9655\n",
            " 59/469 [==>...........................] - ETA: 1:22 - loss: 0.1130 - sparse_categorical_accuracy: 0.9656\n",
            " 60/469 [==>...........................] - ETA: 1:21 - loss: 0.1123 - sparse_categorical_accuracy: 0.9655\n",
            " 61/469 [==>...........................] - ETA: 1:21 - loss: 0.1116 - sparse_categorical_accuracy: 0.9657\n",
            " 62/469 [==>...........................] - ETA: 1:21 - loss: 0.1114 - sparse_categorical_accuracy: 0.9656\n",
            " 63/469 [===>..........................] - ETA: 1:20 - loss: 0.1116 - sparse_categorical_accuracy: 0.9656\n",
            " 64/469 [===>..........................] - ETA: 1:20 - loss: 0.1115 - sparse_categorical_accuracy: 0.9657\n",
            " 65/469 [===>..........................] - ETA: 1:20 - loss: 0.1114 - sparse_categorical_accuracy: 0.9656\n",
            " 66/469 [===>..........................] - ETA: 1:19 - loss: 0.1104 - sparse_categorical_accuracy: 0.9660\n",
            " 67/469 [===>..........................] - ETA: 1:19 - loss: 0.1099 - sparse_categorical_accuracy: 0.9662\n",
            " 68/469 [===>..........................] - ETA: 1:19 - loss: 0.1093 - sparse_categorical_accuracy: 0.9663\n",
            " 69/469 [===>..........................] - ETA: 1:19 - loss: 0.1096 - sparse_categorical_accuracy: 0.9664\n",
            " 70/469 [===>..........................] - ETA: 1:18 - loss: 0.1099 - sparse_categorical_accuracy: 0.9663\n",
            " 71/469 [===>..........................] - ETA: 1:18 - loss: 0.1093 - sparse_categorical_accuracy: 0.9664\n",
            " 72/469 [===>..........................] - ETA: 1:18 - loss: 0.1086 - sparse_categorical_accuracy: 0.9668\n",
            " 73/469 [===>..........................] - ETA: 1:17 - loss: 0.1088 - sparse_categorical_accuracy: 0.9668\n",
            " 74/469 [===>..........................] - ETA: 1:17 - loss: 0.1093 - sparse_categorical_accuracy: 0.9666\n",
            " 75/469 [===>..........................] - ETA: 1:17 - loss: 0.1103 - sparse_categorical_accuracy: 0.9663\n",
            " 76/469 [===>..........................] - ETA: 1:16 - loss: 0.1104 - sparse_categorical_accuracy: 0.9662\n",
            " 77/469 [===>..........................] - ETA: 1:16 - loss: 0.1110 - sparse_categorical_accuracy: 0.9661\n",
            " 78/469 [===>..........................] - ETA: 1:16 - loss: 0.1121 - sparse_categorical_accuracy: 0.9661\n",
            " 79/469 [====>.........................] - ETA: 1:16 - loss: 0.1117 - sparse_categorical_accuracy: 0.9662\n",
            " 80/469 [====>.........................] - ETA: 1:16 - loss: 0.1120 - sparse_categorical_accuracy: 0.9660\n",
            " 81/469 [====>.........................] - ETA: 1:15 - loss: 0.1124 - sparse_categorical_accuracy: 0.9660\n",
            " 82/469 [====>.........................] - ETA: 1:15 - loss: 0.1121 - sparse_categorical_accuracy: 0.9661\n",
            " 83/469 [====>.........................] - ETA: 1:15 - loss: 0.1124 - sparse_categorical_accuracy: 0.9659\n",
            " 84/469 [====>.........................] - ETA: 1:14 - loss: 0.1133 - sparse_categorical_accuracy: 0.9658\n",
            " 85/469 [====>.........................] - ETA: 1:14 - loss: 0.1130 - sparse_categorical_accuracy: 0.9659\n",
            " 86/469 [====>.........................] - ETA: 1:14 - loss: 0.1129 - sparse_categorical_accuracy: 0.9659\n",
            " 87/469 [====>.........................] - ETA: 1:14 - loss: 0.1122 - sparse_categorical_accuracy: 0.9662\n",
            " 88/469 [====>.........................] - ETA: 1:13 - loss: 0.1117 - sparse_categorical_accuracy: 0.9664\n",
            " 89/469 [====>.........................] - ETA: 1:13 - loss: 0.1111 - sparse_categorical_accuracy: 0.9666\n",
            " 90/469 [====>.........................] - ETA: 1:13 - loss: 0.1110 - sparse_categorical_accuracy: 0.9665\n",
            " 91/469 [====>.........................] - ETA: 1:13 - loss: 0.1103 - sparse_categorical_accuracy: 0.9666\n",
            " 92/469 [====>.........................] - ETA: 1:12 - loss: 0.1101 - sparse_categorical_accuracy: 0.9667\n",
            " 93/469 [====>.........................] - ETA: 1:12 - loss: 0.1100 - sparse_categorical_accuracy: 0.9668\n",
            " 94/469 [=====>........................] - ETA: 1:12 - loss: 0.1095 - sparse_categorical_accuracy: 0.9669\n",
            " 95/469 [=====>........................] - ETA: 1:12 - loss: 0.1090 - sparse_categorical_accuracy: 0.9672\n",
            " 96/469 [=====>........................] - ETA: 1:11 - loss: 0.1084 - sparse_categorical_accuracy: 0.9674\n",
            " 97/469 [=====>........................] - ETA: 1:11 - loss: 0.1084 - sparse_categorical_accuracy: 0.9676\n",
            " 98/469 [=====>........................] - ETA: 1:11 - loss: 0.1083 - sparse_categorical_accuracy: 0.9677\n",
            " 99/469 [=====>........................] - ETA: 1:11 - loss: 0.1083 - sparse_categorical_accuracy: 0.9678\n",
            "100/469 [=====>........................] - ETA: 1:10 - loss: 0.1081 - sparse_categorical_accuracy: 0.9677\n",
            "101/469 [=====>........................] - ETA: 1:10 - loss: 0.1083 - sparse_categorical_accuracy: 0.9676\n",
            "102/469 [=====>........................] - ETA: 1:10 - loss: 0.1078 - sparse_categorical_accuracy: 0.9678\n",
            "103/469 [=====>........................] - ETA: 1:10 - loss: 0.1078 - sparse_categorical_accuracy: 0.9678\n",
            "104/469 [=====>........................] - ETA: 1:10 - loss: 0.1076 - sparse_categorical_accuracy: 0.9678\n",
            "105/469 [=====>........................] - ETA: 1:10 - loss: 0.1074 - sparse_categorical_accuracy: 0.9680\n",
            "106/469 [=====>........................] - ETA: 1:11 - loss: 0.1080 - sparse_categorical_accuracy: 0.9678\n",
            "107/469 [=====>........................] - ETA: 1:11 - loss: 0.1076 - sparse_categorical_accuracy: 0.9679\n",
            "108/469 [=====>........................] - ETA: 1:11 - loss: 0.1070 - sparse_categorical_accuracy: 0.9681\n",
            "109/469 [=====>........................] - ETA: 1:11 - loss: 0.1070 - sparse_categorical_accuracy: 0.9680\n",
            "110/469 [======>.......................] - ETA: 1:11 - loss: 0.1076 - sparse_categorical_accuracy: 0.9679\n",
            "111/469 [======>.......................] - ETA: 1:11 - loss: 0.1074 - sparse_categorical_accuracy: 0.9679\n",
            "112/469 [======>.......................] - ETA: 1:11 - loss: 0.1070 - sparse_categorical_accuracy: 0.9680\n",
            "113/469 [======>.......................] - ETA: 1:11 - loss: 0.1070 - sparse_categorical_accuracy: 0.9680\n",
            "114/469 [======>.......................] - ETA: 1:11 - loss: 0.1067 - sparse_categorical_accuracy: 0.9681\n",
            "115/469 [======>.......................] - ETA: 1:11 - loss: 0.1063 - sparse_categorical_accuracy: 0.9681\n",
            "116/469 [======>.......................] - ETA: 1:10 - loss: 0.1059 - sparse_categorical_accuracy: 0.9683\n",
            "117/469 [======>.......................] - ETA: 1:10 - loss: 0.1065 - sparse_categorical_accuracy: 0.9681\n",
            "118/469 [======>.......................] - ETA: 1:10 - loss: 0.1074 - sparse_categorical_accuracy: 0.9677\n",
            "119/469 [======>.......................] - ETA: 1:10 - loss: 0.1082 - sparse_categorical_accuracy: 0.9674\n",
            "120/469 [======>.......................] - ETA: 1:09 - loss: 0.1080 - sparse_categorical_accuracy: 0.9675\n",
            "121/469 [======>.......................] - ETA: 1:09 - loss: 0.1078 - sparse_categorical_accuracy: 0.9675\n",
            "122/469 [======>.......................] - ETA: 1:09 - loss: 0.1082 - sparse_categorical_accuracy: 0.9673\n",
            "123/469 [======>.......................] - ETA: 1:09 - loss: 0.1084 - sparse_categorical_accuracy: 0.9672\n",
            "124/469 [======>.......................] - ETA: 1:08 - loss: 0.1083 - sparse_categorical_accuracy: 0.9672\n",
            "125/469 [======>.......................] - ETA: 1:08 - loss: 0.1083 - sparse_categorical_accuracy: 0.9672\n",
            "126/469 [=======>......................] - ETA: 1:08 - loss: 0.1086 - sparse_categorical_accuracy: 0.9671\n",
            "127/469 [=======>......................] - ETA: 1:07 - loss: 0.1088 - sparse_categorical_accuracy: 0.9670\n",
            "128/469 [=======>......................] - ETA: 1:07 - loss: 0.1089 - sparse_categorical_accuracy: 0.9670\n",
            "129/469 [=======>......................] - ETA: 1:07 - loss: 0.1093 - sparse_categorical_accuracy: 0.9668\n",
            "130/469 [=======>......................] - ETA: 1:07 - loss: 0.1089 - sparse_categorical_accuracy: 0.9669\n",
            "131/469 [=======>......................] - ETA: 1:06 - loss: 0.1092 - sparse_categorical_accuracy: 0.9668\n",
            "132/469 [=======>......................] - ETA: 1:06 - loss: 0.1088 - sparse_categorical_accuracy: 0.9669\n",
            "133/469 [=======>......................] - ETA: 1:06 - loss: 0.1093 - sparse_categorical_accuracy: 0.9668\n",
            "134/469 [=======>......................] - ETA: 1:06 - loss: 0.1088 - sparse_categorical_accuracy: 0.9670\n",
            "135/469 [=======>......................] - ETA: 1:05 - loss: 0.1085 - sparse_categorical_accuracy: 0.9671\n",
            "136/469 [=======>......................] - ETA: 1:05 - loss: 0.1085 - sparse_categorical_accuracy: 0.9671\n",
            "137/469 [=======>......................] - ETA: 1:05 - loss: 0.1086 - sparse_categorical_accuracy: 0.9672\n",
            "138/469 [=======>......................] - ETA: 1:05 - loss: 0.1091 - sparse_categorical_accuracy: 0.9672\n",
            "139/469 [=======>......................] - ETA: 1:04 - loss: 0.1088 - sparse_categorical_accuracy: 0.9673\n",
            "140/469 [=======>......................] - ETA: 1:04 - loss: 0.1091 - sparse_categorical_accuracy: 0.9672\n",
            "141/469 [========>.....................] - ETA: 1:04 - loss: 0.1094 - sparse_categorical_accuracy: 0.9671\n",
            "142/469 [========>.....................] - ETA: 1:04 - loss: 0.1096 - sparse_categorical_accuracy: 0.9671\n",
            "143/469 [========>.....................] - ETA: 1:04 - loss: 0.1098 - sparse_categorical_accuracy: 0.9672\n",
            "144/469 [========>.....................] - ETA: 1:03 - loss: 0.1096 - sparse_categorical_accuracy: 0.9672\n",
            "145/469 [========>.....................] - ETA: 1:03 - loss: 0.1098 - sparse_categorical_accuracy: 0.9671\n",
            "146/469 [========>.....................] - ETA: 1:03 - loss: 0.1100 - sparse_categorical_accuracy: 0.9671\n",
            "147/469 [========>.....................] - ETA: 1:03 - loss: 0.1102 - sparse_categorical_accuracy: 0.9670\n",
            "148/469 [========>.....................] - ETA: 1:02 - loss: 0.1108 - sparse_categorical_accuracy: 0.9670\n",
            "149/469 [========>.....................] - ETA: 1:02 - loss: 0.1105 - sparse_categorical_accuracy: 0.9670\n",
            "150/469 [========>.....................] - ETA: 1:02 - loss: 0.1103 - sparse_categorical_accuracy: 0.9671\n",
            "151/469 [========>.....................] - ETA: 1:02 - loss: 0.1103 - sparse_categorical_accuracy: 0.9670\n",
            "152/469 [========>.....................] - ETA: 1:02 - loss: 0.1107 - sparse_categorical_accuracy: 0.9671\n",
            "153/469 [========>.....................] - ETA: 1:01 - loss: 0.1104 - sparse_categorical_accuracy: 0.9672\n",
            "154/469 [========>.....................] - ETA: 1:01 - loss: 0.1099 - sparse_categorical_accuracy: 0.9674\n",
            "155/469 [========>.....................] - ETA: 1:01 - loss: 0.1098 - sparse_categorical_accuracy: 0.9675\n",
            "156/469 [========>.....................] - ETA: 1:01 - loss: 0.1100 - sparse_categorical_accuracy: 0.9674\n",
            "157/469 [=========>....................] - ETA: 1:00 - loss: 0.1097 - sparse_categorical_accuracy: 0.9675\n",
            "158/469 [=========>....................] - ETA: 1:00 - loss: 0.1099 - sparse_categorical_accuracy: 0.9675\n",
            "159/469 [=========>....................] - ETA: 1:00 - loss: 0.1102 - sparse_categorical_accuracy: 0.9674\n",
            "160/469 [=========>....................] - ETA: 1:00 - loss: 0.1099 - sparse_categorical_accuracy: 0.9675\n",
            "161/469 [=========>....................] - ETA: 59s - loss: 0.1099 - sparse_categorical_accuracy: 0.9674 \n",
            "162/469 [=========>....................] - ETA: 59s - loss: 0.1099 - sparse_categorical_accuracy: 0.9674\n",
            "163/469 [=========>....................] - ETA: 59s - loss: 0.1105 - sparse_categorical_accuracy: 0.9674\n",
            "164/469 [=========>....................] - ETA: 59s - loss: 0.1105 - sparse_categorical_accuracy: 0.9674\n",
            "165/469 [=========>....................] - ETA: 59s - loss: 0.1107 - sparse_categorical_accuracy: 0.9673\n",
            "166/469 [=========>....................] - ETA: 58s - loss: 0.1106 - sparse_categorical_accuracy: 0.9673\n",
            "167/469 [=========>....................] - ETA: 58s - loss: 0.1112 - sparse_categorical_accuracy: 0.9672\n",
            "168/469 [=========>....................] - ETA: 58s - loss: 0.1110 - sparse_categorical_accuracy: 0.9672\n",
            "169/469 [=========>....................] - ETA: 58s - loss: 0.1106 - sparse_categorical_accuracy: 0.9674\n",
            "170/469 [=========>....................] - ETA: 57s - loss: 0.1101 - sparse_categorical_accuracy: 0.9676\n",
            "171/469 [=========>....................] - ETA: 57s - loss: 0.1101 - sparse_categorical_accuracy: 0.9675\n",
            "172/469 [==========>...................] - ETA: 57s - loss: 0.1097 - sparse_categorical_accuracy: 0.9677\n",
            "173/469 [==========>...................] - ETA: 57s - loss: 0.1098 - sparse_categorical_accuracy: 0.9676\n",
            "174/469 [==========>...................] - ETA: 57s - loss: 0.1099 - sparse_categorical_accuracy: 0.9676\n",
            "175/469 [==========>...................] - ETA: 57s - loss: 0.1098 - sparse_categorical_accuracy: 0.9675\n",
            "176/469 [==========>...................] - ETA: 57s - loss: 0.1098 - sparse_categorical_accuracy: 0.9675\n",
            "177/469 [==========>...................] - ETA: 57s - loss: 0.1093 - sparse_categorical_accuracy: 0.9676\n",
            "178/469 [==========>...................] - ETA: 57s - loss: 0.1091 - sparse_categorical_accuracy: 0.9677\n",
            "179/469 [==========>...................] - ETA: 57s - loss: 0.1088 - sparse_categorical_accuracy: 0.9678\n",
            "180/469 [==========>...................] - ETA: 57s - loss: 0.1086 - sparse_categorical_accuracy: 0.9679\n",
            "181/469 [==========>...................] - ETA: 57s - loss: 0.1083 - sparse_categorical_accuracy: 0.9680\n",
            "182/469 [==========>...................] - ETA: 57s - loss: 0.1083 - sparse_categorical_accuracy: 0.9681\n",
            "183/469 [==========>...................] - ETA: 57s - loss: 0.1081 - sparse_categorical_accuracy: 0.9682\n",
            "184/469 [==========>...................] - ETA: 56s - loss: 0.1081 - sparse_categorical_accuracy: 0.9682\n",
            "185/469 [==========>...................] - ETA: 56s - loss: 0.1079 - sparse_categorical_accuracy: 0.9683\n",
            "186/469 [==========>...................] - ETA: 56s - loss: 0.1081 - sparse_categorical_accuracy: 0.9682\n",
            "187/469 [==========>...................] - ETA: 56s - loss: 0.1077 - sparse_categorical_accuracy: 0.9683\n",
            "188/469 [===========>..................] - ETA: 55s - loss: 0.1075 - sparse_categorical_accuracy: 0.9684\n",
            "189/469 [===========>..................] - ETA: 55s - loss: 0.1076 - sparse_categorical_accuracy: 0.9683\n",
            "190/469 [===========>..................] - ETA: 55s - loss: 0.1075 - sparse_categorical_accuracy: 0.9682\n",
            "191/469 [===========>..................] - ETA: 55s - loss: 0.1074 - sparse_categorical_accuracy: 0.9682\n",
            "192/469 [===========>..................] - ETA: 55s - loss: 0.1070 - sparse_categorical_accuracy: 0.9683\n",
            "193/469 [===========>..................] - ETA: 54s - loss: 0.1075 - sparse_categorical_accuracy: 0.9681\n",
            "194/469 [===========>..................] - ETA: 54s - loss: 0.1073 - sparse_categorical_accuracy: 0.9683\n",
            "195/469 [===========>..................] - ETA: 54s - loss: 0.1071 - sparse_categorical_accuracy: 0.9683\n",
            "196/469 [===========>..................] - ETA: 54s - loss: 0.1072 - sparse_categorical_accuracy: 0.9682\n",
            "197/469 [===========>..................] - ETA: 53s - loss: 0.1073 - sparse_categorical_accuracy: 0.9682\n",
            "198/469 [===========>..................] - ETA: 53s - loss: 0.1076 - sparse_categorical_accuracy: 0.9680\n",
            "199/469 [===========>..................] - ETA: 53s - loss: 0.1075 - sparse_categorical_accuracy: 0.9680\n",
            "200/469 [===========>..................] - ETA: 53s - loss: 0.1072 - sparse_categorical_accuracy: 0.9680\n",
            "201/469 [===========>..................] - ETA: 52s - loss: 0.1072 - sparse_categorical_accuracy: 0.9680\n",
            "202/469 [===========>..................] - ETA: 52s - loss: 0.1075 - sparse_categorical_accuracy: 0.9679\n",
            "203/469 [===========>..................] - ETA: 52s - loss: 0.1072 - sparse_categorical_accuracy: 0.9679\n",
            "204/469 [============>.................] - ETA: 52s - loss: 0.1071 - sparse_categorical_accuracy: 0.9680\n",
            "205/469 [============>.................] - ETA: 52s - loss: 0.1072 - sparse_categorical_accuracy: 0.9680\n",
            "206/469 [============>.................] - ETA: 51s - loss: 0.1074 - sparse_categorical_accuracy: 0.9680\n",
            "207/469 [============>.................] - ETA: 51s - loss: 0.1075 - sparse_categorical_accuracy: 0.9680\n",
            "208/469 [============>.................] - ETA: 51s - loss: 0.1072 - sparse_categorical_accuracy: 0.9681\n",
            "209/469 [============>.................] - ETA: 51s - loss: 0.1070 - sparse_categorical_accuracy: 0.9682\n",
            "210/469 [============>.................] - ETA: 51s - loss: 0.1067 - sparse_categorical_accuracy: 0.9683\n",
            "211/469 [============>.................] - ETA: 50s - loss: 0.1069 - sparse_categorical_accuracy: 0.9683\n",
            "212/469 [============>.................] - ETA: 50s - loss: 0.1069 - sparse_categorical_accuracy: 0.9683\n",
            "213/469 [============>.................] - ETA: 50s - loss: 0.1072 - sparse_categorical_accuracy: 0.9683\n",
            "214/469 [============>.................] - ETA: 50s - loss: 0.1070 - sparse_categorical_accuracy: 0.9683\n",
            "215/469 [============>.................] - ETA: 49s - loss: 0.1072 - sparse_categorical_accuracy: 0.9683\n",
            "216/469 [============>.................] - ETA: 49s - loss: 0.1075 - sparse_categorical_accuracy: 0.9681\n",
            "217/469 [============>.................] - ETA: 49s - loss: 0.1079 - sparse_categorical_accuracy: 0.9681\n",
            "218/469 [============>.................] - ETA: 49s - loss: 0.1079 - sparse_categorical_accuracy: 0.9681\n",
            "219/469 [=============>................] - ETA: 49s - loss: 0.1084 - sparse_categorical_accuracy: 0.9681\n",
            "220/469 [=============>................] - ETA: 48s - loss: 0.1083 - sparse_categorical_accuracy: 0.9682\n",
            "221/469 [=============>................] - ETA: 48s - loss: 0.1084 - sparse_categorical_accuracy: 0.9682\n",
            "222/469 [=============>................] - ETA: 48s - loss: 0.1087 - sparse_categorical_accuracy: 0.9681\n",
            "223/469 [=============>................] - ETA: 48s - loss: 0.1085 - sparse_categorical_accuracy: 0.9682\n",
            "224/469 [=============>................] - ETA: 48s - loss: 0.1082 - sparse_categorical_accuracy: 0.9683\n",
            "225/469 [=============>................] - ETA: 47s - loss: 0.1081 - sparse_categorical_accuracy: 0.9684\n",
            "226/469 [=============>................] - ETA: 47s - loss: 0.1079 - sparse_categorical_accuracy: 0.9684\n",
            "227/469 [=============>................] - ETA: 47s - loss: 0.1080 - sparse_categorical_accuracy: 0.9684\n",
            "228/469 [=============>................] - ETA: 47s - loss: 0.1078 - sparse_categorical_accuracy: 0.9685\n",
            "229/469 [=============>................] - ETA: 46s - loss: 0.1077 - sparse_categorical_accuracy: 0.9686\n",
            "230/469 [=============>................] - ETA: 46s - loss: 0.1076 - sparse_categorical_accuracy: 0.9686\n",
            "231/469 [=============>................] - ETA: 46s - loss: 0.1075 - sparse_categorical_accuracy: 0.9686\n",
            "232/469 [=============>................] - ETA: 46s - loss: 0.1078 - sparse_categorical_accuracy: 0.9685\n",
            "233/469 [=============>................] - ETA: 46s - loss: 0.1078 - sparse_categorical_accuracy: 0.9685\n",
            "234/469 [=============>................] - ETA: 45s - loss: 0.1077 - sparse_categorical_accuracy: 0.9685\n",
            "235/469 [==============>...............] - ETA: 45s - loss: 0.1076 - sparse_categorical_accuracy: 0.9686\n",
            "236/469 [==============>...............] - ETA: 45s - loss: 0.1074 - sparse_categorical_accuracy: 0.9686\n",
            "237/469 [==============>...............] - ETA: 45s - loss: 0.1076 - sparse_categorical_accuracy: 0.9686\n",
            "238/469 [==============>...............] - ETA: 45s - loss: 0.1075 - sparse_categorical_accuracy: 0.9686\n",
            "239/469 [==============>...............] - ETA: 44s - loss: 0.1074 - sparse_categorical_accuracy: 0.9686\n",
            "240/469 [==============>...............] - ETA: 44s - loss: 0.1074 - sparse_categorical_accuracy: 0.9686\n",
            "241/469 [==============>...............] - ETA: 44s - loss: 0.1075 - sparse_categorical_accuracy: 0.9686\n",
            "242/469 [==============>...............] - ETA: 44s - loss: 0.1078 - sparse_categorical_accuracy: 0.9686\n",
            "243/469 [==============>...............] - ETA: 44s - loss: 0.1077 - sparse_categorical_accuracy: 0.9685\n",
            "244/469 [==============>...............] - ETA: 44s - loss: 0.1076 - sparse_categorical_accuracy: 0.9685\n",
            "245/469 [==============>...............] - ETA: 44s - loss: 0.1075 - sparse_categorical_accuracy: 0.9685\n",
            "246/469 [==============>...............] - ETA: 43s - loss: 0.1072 - sparse_categorical_accuracy: 0.9686\n",
            "247/469 [==============>...............] - ETA: 43s - loss: 0.1073 - sparse_categorical_accuracy: 0.9685\n",
            "248/469 [==============>...............] - ETA: 43s - loss: 0.1073 - sparse_categorical_accuracy: 0.9685\n",
            "249/469 [==============>...............] - ETA: 43s - loss: 0.1070 - sparse_categorical_accuracy: 0.9686\n",
            "250/469 [==============>...............] - ETA: 43s - loss: 0.1068 - sparse_categorical_accuracy: 0.9687\n",
            "251/469 [===============>..............] - ETA: 43s - loss: 0.1068 - sparse_categorical_accuracy: 0.9686\n",
            "252/469 [===============>..............] - ETA: 43s - loss: 0.1066 - sparse_categorical_accuracy: 0.9687\n",
            "253/469 [===============>..............] - ETA: 43s - loss: 0.1066 - sparse_categorical_accuracy: 0.9686\n",
            "254/469 [===============>..............] - ETA: 42s - loss: 0.1066 - sparse_categorical_accuracy: 0.9686\n",
            "255/469 [===============>..............] - ETA: 42s - loss: 0.1065 - sparse_categorical_accuracy: 0.9686\n",
            "256/469 [===============>..............] - ETA: 42s - loss: 0.1064 - sparse_categorical_accuracy: 0.9687\n",
            "257/469 [===============>..............] - ETA: 42s - loss: 0.1065 - sparse_categorical_accuracy: 0.9686\n",
            "258/469 [===============>..............] - ETA: 41s - loss: 0.1065 - sparse_categorical_accuracy: 0.9686\n",
            "259/469 [===============>..............] - ETA: 41s - loss: 0.1064 - sparse_categorical_accuracy: 0.9686\n",
            "260/469 [===============>..............] - ETA: 41s - loss: 0.1064 - sparse_categorical_accuracy: 0.9686\n",
            "261/469 [===============>..............] - ETA: 41s - loss: 0.1063 - sparse_categorical_accuracy: 0.9686\n",
            "262/469 [===============>..............] - ETA: 41s - loss: 0.1064 - sparse_categorical_accuracy: 0.9686\n",
            "263/469 [===============>..............] - ETA: 40s - loss: 0.1063 - sparse_categorical_accuracy: 0.9685\n",
            "264/469 [===============>..............] - ETA: 40s - loss: 0.1061 - sparse_categorical_accuracy: 0.9685\n",
            "265/469 [===============>..............] - ETA: 40s - loss: 0.1061 - sparse_categorical_accuracy: 0.9685\n",
            "266/469 [================>.............] - ETA: 40s - loss: 0.1062 - sparse_categorical_accuracy: 0.9684\n",
            "267/469 [================>.............] - ETA: 40s - loss: 0.1063 - sparse_categorical_accuracy: 0.9683\n",
            "268/469 [================>.............] - ETA: 39s - loss: 0.1061 - sparse_categorical_accuracy: 0.9683\n",
            "269/469 [================>.............] - ETA: 39s - loss: 0.1059 - sparse_categorical_accuracy: 0.9684\n",
            "270/469 [================>.............] - ETA: 39s - loss: 0.1057 - sparse_categorical_accuracy: 0.9685\n",
            "271/469 [================>.............] - ETA: 39s - loss: 0.1057 - sparse_categorical_accuracy: 0.9684\n",
            "272/469 [================>.............] - ETA: 39s - loss: 0.1055 - sparse_categorical_accuracy: 0.9685\n",
            "273/469 [================>.............] - ETA: 38s - loss: 0.1053 - sparse_categorical_accuracy: 0.9685\n",
            "274/469 [================>.............] - ETA: 38s - loss: 0.1052 - sparse_categorical_accuracy: 0.9686\n",
            "275/469 [================>.............] - ETA: 38s - loss: 0.1053 - sparse_categorical_accuracy: 0.9685\n",
            "276/469 [================>.............] - ETA: 38s - loss: 0.1054 - sparse_categorical_accuracy: 0.9685\n",
            "277/469 [================>.............] - ETA: 37s - loss: 0.1057 - sparse_categorical_accuracy: 0.9685\n",
            "278/469 [================>.............] - ETA: 37s - loss: 0.1057 - sparse_categorical_accuracy: 0.9685\n",
            "279/469 [================>.............] - ETA: 37s - loss: 0.1056 - sparse_categorical_accuracy: 0.9686\n",
            "280/469 [================>.............] - ETA: 37s - loss: 0.1054 - sparse_categorical_accuracy: 0.9686\n",
            "281/469 [================>.............] - ETA: 37s - loss: 0.1054 - sparse_categorical_accuracy: 0.9687\n",
            "282/469 [=================>............] - ETA: 36s - loss: 0.1056 - sparse_categorical_accuracy: 0.9687\n",
            "283/469 [=================>............] - ETA: 36s - loss: 0.1055 - sparse_categorical_accuracy: 0.9687\n",
            "284/469 [=================>............] - ETA: 36s - loss: 0.1053 - sparse_categorical_accuracy: 0.9688\n",
            "285/469 [=================>............] - ETA: 36s - loss: 0.1051 - sparse_categorical_accuracy: 0.9688\n",
            "286/469 [=================>............] - ETA: 36s - loss: 0.1052 - sparse_categorical_accuracy: 0.9688\n",
            "287/469 [=================>............] - ETA: 35s - loss: 0.1051 - sparse_categorical_accuracy: 0.9688\n",
            "288/469 [=================>............] - ETA: 35s - loss: 0.1050 - sparse_categorical_accuracy: 0.9688\n",
            "289/469 [=================>............] - ETA: 35s - loss: 0.1050 - sparse_categorical_accuracy: 0.9688\n",
            "290/469 [=================>............] - ETA: 35s - loss: 0.1050 - sparse_categorical_accuracy: 0.9688\n",
            "291/469 [=================>............] - ETA: 35s - loss: 0.1048 - sparse_categorical_accuracy: 0.9688\n",
            "292/469 [=================>............] - ETA: 34s - loss: 0.1049 - sparse_categorical_accuracy: 0.9688\n",
            "293/469 [=================>............] - ETA: 34s - loss: 0.1050 - sparse_categorical_accuracy: 0.9687\n",
            "294/469 [=================>............] - ETA: 34s - loss: 0.1048 - sparse_categorical_accuracy: 0.9688\n",
            "295/469 [=================>............] - ETA: 34s - loss: 0.1047 - sparse_categorical_accuracy: 0.9688\n",
            "296/469 [=================>............] - ETA: 34s - loss: 0.1045 - sparse_categorical_accuracy: 0.9689\n",
            "297/469 [=================>............] - ETA: 33s - loss: 0.1043 - sparse_categorical_accuracy: 0.9689\n",
            "298/469 [==================>...........] - ETA: 33s - loss: 0.1044 - sparse_categorical_accuracy: 0.9689\n",
            "299/469 [==================>...........] - ETA: 33s - loss: 0.1043 - sparse_categorical_accuracy: 0.9689\n",
            "300/469 [==================>...........] - ETA: 33s - loss: 0.1043 - sparse_categorical_accuracy: 0.9689\n",
            "301/469 [==================>...........] - ETA: 33s - loss: 0.1041 - sparse_categorical_accuracy: 0.9689\n",
            "302/469 [==================>...........] - ETA: 32s - loss: 0.1040 - sparse_categorical_accuracy: 0.9689\n",
            "303/469 [==================>...........] - ETA: 32s - loss: 0.1038 - sparse_categorical_accuracy: 0.9689\n",
            "304/469 [==================>...........] - ETA: 32s - loss: 0.1040 - sparse_categorical_accuracy: 0.9689\n",
            "305/469 [==================>...........] - ETA: 32s - loss: 0.1040 - sparse_categorical_accuracy: 0.9689\n",
            "306/469 [==================>...........] - ETA: 32s - loss: 0.1039 - sparse_categorical_accuracy: 0.9689\n",
            "307/469 [==================>...........] - ETA: 31s - loss: 0.1038 - sparse_categorical_accuracy: 0.9690\n",
            "308/469 [==================>...........] - ETA: 31s - loss: 0.1036 - sparse_categorical_accuracy: 0.9690\n",
            "309/469 [==================>...........] - ETA: 31s - loss: 0.1035 - sparse_categorical_accuracy: 0.9691\n",
            "310/469 [==================>...........] - ETA: 31s - loss: 0.1033 - sparse_categorical_accuracy: 0.9691\n",
            "311/469 [==================>...........] - ETA: 31s - loss: 0.1035 - sparse_categorical_accuracy: 0.9691\n",
            "312/469 [==================>...........] - ETA: 31s - loss: 0.1035 - sparse_categorical_accuracy: 0.9691\n",
            "313/469 [===================>..........] - ETA: 30s - loss: 0.1034 - sparse_categorical_accuracy: 0.9691\n",
            "314/469 [===================>..........] - ETA: 30s - loss: 0.1033 - sparse_categorical_accuracy: 0.9691\n",
            "315/469 [===================>..........] - ETA: 30s - loss: 0.1033 - sparse_categorical_accuracy: 0.9691\n",
            "316/469 [===================>..........] - ETA: 30s - loss: 0.1032 - sparse_categorical_accuracy: 0.9691\n",
            "317/469 [===================>..........] - ETA: 30s - loss: 0.1035 - sparse_categorical_accuracy: 0.9691\n",
            "318/469 [===================>..........] - ETA: 30s - loss: 0.1032 - sparse_categorical_accuracy: 0.9692\n",
            "319/469 [===================>..........] - ETA: 29s - loss: 0.1030 - sparse_categorical_accuracy: 0.9693\n",
            "320/469 [===================>..........] - ETA: 29s - loss: 0.1031 - sparse_categorical_accuracy: 0.9692\n",
            "321/469 [===================>..........] - ETA: 29s - loss: 0.1029 - sparse_categorical_accuracy: 0.9693\n",
            "322/469 [===================>..........] - ETA: 29s - loss: 0.1031 - sparse_categorical_accuracy: 0.9693\n",
            "323/469 [===================>..........] - ETA: 29s - loss: 0.1030 - sparse_categorical_accuracy: 0.9693\n",
            "324/469 [===================>..........] - ETA: 28s - loss: 0.1028 - sparse_categorical_accuracy: 0.9694\n",
            "325/469 [===================>..........] - ETA: 28s - loss: 0.1029 - sparse_categorical_accuracy: 0.9693\n",
            "326/469 [===================>..........] - ETA: 28s - loss: 0.1030 - sparse_categorical_accuracy: 0.9693\n",
            "327/469 [===================>..........] - ETA: 28s - loss: 0.1029 - sparse_categorical_accuracy: 0.9693\n",
            "328/469 [===================>..........] - ETA: 28s - loss: 0.1028 - sparse_categorical_accuracy: 0.9693\n",
            "329/469 [====================>.........] - ETA: 27s - loss: 0.1027 - sparse_categorical_accuracy: 0.9693\n",
            "330/469 [====================>.........] - ETA: 27s - loss: 0.1029 - sparse_categorical_accuracy: 0.9692\n",
            "331/469 [====================>.........] - ETA: 27s - loss: 0.1027 - sparse_categorical_accuracy: 0.9693\n",
            "332/469 [====================>.........] - ETA: 27s - loss: 0.1028 - sparse_categorical_accuracy: 0.9693\n",
            "333/469 [====================>.........] - ETA: 27s - loss: 0.1028 - sparse_categorical_accuracy: 0.9693\n",
            "334/469 [====================>.........] - ETA: 26s - loss: 0.1026 - sparse_categorical_accuracy: 0.9694\n",
            "335/469 [====================>.........] - ETA: 26s - loss: 0.1028 - sparse_categorical_accuracy: 0.9694\n",
            "336/469 [====================>.........] - ETA: 26s - loss: 0.1027 - sparse_categorical_accuracy: 0.9694\n",
            "337/469 [====================>.........] - ETA: 26s - loss: 0.1026 - sparse_categorical_accuracy: 0.9694\n",
            "338/469 [====================>.........] - ETA: 26s - loss: 0.1027 - sparse_categorical_accuracy: 0.9694\n",
            "339/469 [====================>.........] - ETA: 25s - loss: 0.1029 - sparse_categorical_accuracy: 0.9693\n",
            "340/469 [====================>.........] - ETA: 25s - loss: 0.1028 - sparse_categorical_accuracy: 0.9694\n",
            "341/469 [====================>.........] - ETA: 25s - loss: 0.1026 - sparse_categorical_accuracy: 0.9694\n",
            "342/469 [====================>.........] - ETA: 25s - loss: 0.1026 - sparse_categorical_accuracy: 0.9694\n",
            "343/469 [====================>.........] - ETA: 25s - loss: 0.1023 - sparse_categorical_accuracy: 0.9695\n",
            "344/469 [=====================>........] - ETA: 24s - loss: 0.1022 - sparse_categorical_accuracy: 0.9695\n",
            "345/469 [=====================>........] - ETA: 24s - loss: 0.1022 - sparse_categorical_accuracy: 0.9695\n",
            "346/469 [=====================>........] - ETA: 24s - loss: 0.1023 - sparse_categorical_accuracy: 0.9695\n",
            "347/469 [=====================>........] - ETA: 24s - loss: 0.1022 - sparse_categorical_accuracy: 0.9696\n",
            "348/469 [=====================>........] - ETA: 24s - loss: 0.1027 - sparse_categorical_accuracy: 0.9696\n",
            "349/469 [=====================>........] - ETA: 23s - loss: 0.1027 - sparse_categorical_accuracy: 0.9696\n",
            "350/469 [=====================>........] - ETA: 23s - loss: 0.1026 - sparse_categorical_accuracy: 0.9696\n",
            "351/469 [=====================>........] - ETA: 23s - loss: 0.1025 - sparse_categorical_accuracy: 0.9696\n",
            "352/469 [=====================>........] - ETA: 23s - loss: 0.1024 - sparse_categorical_accuracy: 0.9696\n",
            "353/469 [=====================>........] - ETA: 23s - loss: 0.1024 - sparse_categorical_accuracy: 0.9696\n",
            "354/469 [=====================>........] - ETA: 22s - loss: 0.1023 - sparse_categorical_accuracy: 0.9696\n",
            "355/469 [=====================>........] - ETA: 22s - loss: 0.1022 - sparse_categorical_accuracy: 0.9696\n",
            "356/469 [=====================>........] - ETA: 22s - loss: 0.1021 - sparse_categorical_accuracy: 0.9696\n",
            "357/469 [=====================>........] - ETA: 22s - loss: 0.1021 - sparse_categorical_accuracy: 0.9696\n",
            "358/469 [=====================>........] - ETA: 22s - loss: 0.1020 - sparse_categorical_accuracy: 0.9696\n",
            "359/469 [=====================>........] - ETA: 21s - loss: 0.1023 - sparse_categorical_accuracy: 0.9695\n",
            "360/469 [======================>.......] - ETA: 21s - loss: 0.1022 - sparse_categorical_accuracy: 0.9695\n",
            "361/469 [======================>.......] - ETA: 21s - loss: 0.1024 - sparse_categorical_accuracy: 0.9695\n",
            "362/469 [======================>.......] - ETA: 21s - loss: 0.1022 - sparse_categorical_accuracy: 0.9696\n",
            "363/469 [======================>.......] - ETA: 21s - loss: 0.1023 - sparse_categorical_accuracy: 0.9696\n",
            "364/469 [======================>.......] - ETA: 20s - loss: 0.1022 - sparse_categorical_accuracy: 0.9695\n",
            "365/469 [======================>.......] - ETA: 20s - loss: 0.1022 - sparse_categorical_accuracy: 0.9695\n",
            "366/469 [======================>.......] - ETA: 20s - loss: 0.1023 - sparse_categorical_accuracy: 0.9695\n",
            "367/469 [======================>.......] - ETA: 20s - loss: 0.1023 - sparse_categorical_accuracy: 0.9695\n",
            "368/469 [======================>.......] - ETA: 19s - loss: 0.1022 - sparse_categorical_accuracy: 0.9696\n",
            "369/469 [======================>.......] - ETA: 19s - loss: 0.1023 - sparse_categorical_accuracy: 0.9695\n",
            "370/469 [======================>.......] - ETA: 19s - loss: 0.1022 - sparse_categorical_accuracy: 0.9696\n",
            "371/469 [======================>.......] - ETA: 19s - loss: 0.1021 - sparse_categorical_accuracy: 0.9696\n",
            "372/469 [======================>.......] - ETA: 19s - loss: 0.1019 - sparse_categorical_accuracy: 0.9696\n",
            "373/469 [======================>.......] - ETA: 18s - loss: 0.1019 - sparse_categorical_accuracy: 0.9696\n",
            "374/469 [======================>.......] - ETA: 18s - loss: 0.1020 - sparse_categorical_accuracy: 0.9696\n",
            "375/469 [======================>.......] - ETA: 18s - loss: 0.1021 - sparse_categorical_accuracy: 0.9696\n",
            "376/469 [=======================>......] - ETA: 18s - loss: 0.1020 - sparse_categorical_accuracy: 0.9696\n",
            "377/469 [=======================>......] - ETA: 18s - loss: 0.1019 - sparse_categorical_accuracy: 0.9696\n",
            "378/469 [=======================>......] - ETA: 18s - loss: 0.1018 - sparse_categorical_accuracy: 0.9696\n",
            "379/469 [=======================>......] - ETA: 17s - loss: 0.1018 - sparse_categorical_accuracy: 0.9696\n",
            "380/469 [=======================>......] - ETA: 17s - loss: 0.1017 - sparse_categorical_accuracy: 0.9696\n",
            "381/469 [=======================>......] - ETA: 17s - loss: 0.1015 - sparse_categorical_accuracy: 0.9697\n",
            "382/469 [=======================>......] - ETA: 17s - loss: 0.1015 - sparse_categorical_accuracy: 0.9697\n",
            "383/469 [=======================>......] - ETA: 17s - loss: 0.1017 - sparse_categorical_accuracy: 0.9696\n",
            "384/469 [=======================>......] - ETA: 17s - loss: 0.1015 - sparse_categorical_accuracy: 0.9696\n",
            "385/469 [=======================>......] - ETA: 16s - loss: 0.1015 - sparse_categorical_accuracy: 0.9697\n",
            "386/469 [=======================>......] - ETA: 16s - loss: 0.1014 - sparse_categorical_accuracy: 0.9697\n",
            "387/469 [=======================>......] - ETA: 16s - loss: 0.1013 - sparse_categorical_accuracy: 0.9697\n",
            "388/469 [=======================>......] - ETA: 16s - loss: 0.1015 - sparse_categorical_accuracy: 0.9696\n",
            "389/469 [=======================>......] - ETA: 16s - loss: 0.1014 - sparse_categorical_accuracy: 0.9697\n",
            "390/469 [=======================>......] - ETA: 15s - loss: 0.1014 - sparse_categorical_accuracy: 0.9697\n",
            "391/469 [========================>.....] - ETA: 15s - loss: 0.1012 - sparse_categorical_accuracy: 0.9697\n",
            "392/469 [========================>.....] - ETA: 15s - loss: 0.1012 - sparse_categorical_accuracy: 0.9697\n",
            "393/469 [========================>.....] - ETA: 15s - loss: 0.1012 - sparse_categorical_accuracy: 0.9697\n",
            "394/469 [========================>.....] - ETA: 15s - loss: 0.1011 - sparse_categorical_accuracy: 0.9698\n",
            "395/469 [========================>.....] - ETA: 14s - loss: 0.1011 - sparse_categorical_accuracy: 0.9698\n",
            "396/469 [========================>.....] - ETA: 14s - loss: 0.1012 - sparse_categorical_accuracy: 0.9698\n",
            "397/469 [========================>.....] - ETA: 14s - loss: 0.1014 - sparse_categorical_accuracy: 0.9697\n",
            "398/469 [========================>.....] - ETA: 14s - loss: 0.1014 - sparse_categorical_accuracy: 0.9697\n",
            "399/469 [========================>.....] - ETA: 14s - loss: 0.1014 - sparse_categorical_accuracy: 0.9697\n",
            "400/469 [========================>.....] - ETA: 13s - loss: 0.1013 - sparse_categorical_accuracy: 0.9697\n",
            "401/469 [========================>.....] - ETA: 13s - loss: 0.1012 - sparse_categorical_accuracy: 0.9697\n",
            "402/469 [========================>.....] - ETA: 13s - loss: 0.1012 - sparse_categorical_accuracy: 0.9697\n",
            "403/469 [========================>.....] - ETA: 13s - loss: 0.1011 - sparse_categorical_accuracy: 0.9697\n",
            "404/469 [========================>.....] - ETA: 13s - loss: 0.1010 - sparse_categorical_accuracy: 0.9697\n",
            "405/469 [========================>.....] - ETA: 12s - loss: 0.1011 - sparse_categorical_accuracy: 0.9697\n",
            "406/469 [========================>.....] - ETA: 12s - loss: 0.1009 - sparse_categorical_accuracy: 0.9697\n",
            "407/469 [=========================>....] - ETA: 12s - loss: 0.1010 - sparse_categorical_accuracy: 0.9697\n",
            "408/469 [=========================>....] - ETA: 12s - loss: 0.1009 - sparse_categorical_accuracy: 0.9697\n",
            "409/469 [=========================>....] - ETA: 12s - loss: 0.1009 - sparse_categorical_accuracy: 0.9697\n",
            "410/469 [=========================>....] - ETA: 11s - loss: 0.1007 - sparse_categorical_accuracy: 0.9698\n",
            "411/469 [=========================>....] - ETA: 11s - loss: 0.1006 - sparse_categorical_accuracy: 0.9698\n",
            "412/469 [=========================>....] - ETA: 11s - loss: 0.1008 - sparse_categorical_accuracy: 0.9697\n",
            "413/469 [=========================>....] - ETA: 11s - loss: 0.1006 - sparse_categorical_accuracy: 0.9698\n",
            "414/469 [=========================>....] - ETA: 11s - loss: 0.1006 - sparse_categorical_accuracy: 0.9698\n",
            "415/469 [=========================>....] - ETA: 10s - loss: 0.1005 - sparse_categorical_accuracy: 0.9698\n",
            "416/469 [=========================>....] - ETA: 10s - loss: 0.1004 - sparse_categorical_accuracy: 0.9698\n",
            "417/469 [=========================>....] - ETA: 10s - loss: 0.1004 - sparse_categorical_accuracy: 0.9698\n",
            "418/469 [=========================>....] - ETA: 10s - loss: 0.1004 - sparse_categorical_accuracy: 0.9698\n",
            "419/469 [=========================>....] - ETA: 9s - loss: 0.1004 - sparse_categorical_accuracy: 0.9698 \n",
            "420/469 [=========================>....] - ETA: 9s - loss: 0.1004 - sparse_categorical_accuracy: 0.9698\n",
            "421/469 [=========================>....] - ETA: 9s - loss: 0.1004 - sparse_categorical_accuracy: 0.9698\n",
            "422/469 [=========================>....] - ETA: 9s - loss: 0.1003 - sparse_categorical_accuracy: 0.9698\n",
            "423/469 [==========================>...] - ETA: 9s - loss: 0.1003 - sparse_categorical_accuracy: 0.9698\n",
            "424/469 [==========================>...] - ETA: 8s - loss: 0.1004 - sparse_categorical_accuracy: 0.9698\n",
            "425/469 [==========================>...] - ETA: 8s - loss: 0.1004 - sparse_categorical_accuracy: 0.9697\n",
            "426/469 [==========================>...] - ETA: 8s - loss: 0.1004 - sparse_categorical_accuracy: 0.9698\n",
            "427/469 [==========================>...] - ETA: 8s - loss: 0.1003 - sparse_categorical_accuracy: 0.9698\n",
            "428/469 [==========================>...] - ETA: 8s - loss: 0.1003 - sparse_categorical_accuracy: 0.9698\n",
            "429/469 [==========================>...] - ETA: 7s - loss: 0.1003 - sparse_categorical_accuracy: 0.9698\n",
            "430/469 [==========================>...] - ETA: 7s - loss: 0.1002 - sparse_categorical_accuracy: 0.9698\n",
            "431/469 [==========================>...] - ETA: 7s - loss: 0.1002 - sparse_categorical_accuracy: 0.9698\n",
            "432/469 [==========================>...] - ETA: 7s - loss: 0.1001 - sparse_categorical_accuracy: 0.9698\n",
            "433/469 [==========================>...] - ETA: 7s - loss: 0.1002 - sparse_categorical_accuracy: 0.9697\n",
            "434/469 [==========================>...] - ETA: 6s - loss: 0.1002 - sparse_categorical_accuracy: 0.9698\n",
            "435/469 [==========================>...] - ETA: 6s - loss: 0.1000 - sparse_categorical_accuracy: 0.9698\n",
            "436/469 [==========================>...] - ETA: 6s - loss: 0.0999 - sparse_categorical_accuracy: 0.9698\n",
            "437/469 [==========================>...] - ETA: 6s - loss: 0.0999 - sparse_categorical_accuracy: 0.9698\n",
            "438/469 [===========================>..] - ETA: 6s - loss: 0.0999 - sparse_categorical_accuracy: 0.9699\n",
            "439/469 [===========================>..] - ETA: 5s - loss: 0.0999 - sparse_categorical_accuracy: 0.9699\n",
            "440/469 [===========================>..] - ETA: 5s - loss: 0.1001 - sparse_categorical_accuracy: 0.9698\n",
            "441/469 [===========================>..] - ETA: 5s - loss: 0.1002 - sparse_categorical_accuracy: 0.9698\n",
            "442/469 [===========================>..] - ETA: 5s - loss: 0.1001 - sparse_categorical_accuracy: 0.9698\n",
            "443/469 [===========================>..] - ETA: 5s - loss: 0.1001 - sparse_categorical_accuracy: 0.9698\n",
            "444/469 [===========================>..] - ETA: 4s - loss: 0.1000 - sparse_categorical_accuracy: 0.9699\n",
            "445/469 [===========================>..] - ETA: 4s - loss: 0.1000 - sparse_categorical_accuracy: 0.9699\n",
            "446/469 [===========================>..] - ETA: 4s - loss: 0.1000 - sparse_categorical_accuracy: 0.9699\n",
            "447/469 [===========================>..] - ETA: 4s - loss: 0.1001 - sparse_categorical_accuracy: 0.9698\n",
            "448/469 [===========================>..] - ETA: 4s - loss: 0.1000 - sparse_categorical_accuracy: 0.9698\n",
            "449/469 [===========================>..] - ETA: 4s - loss: 0.1001 - sparse_categorical_accuracy: 0.9698\n",
            "450/469 [===========================>..] - ETA: 3s - loss: 0.1000 - sparse_categorical_accuracy: 0.9698\n",
            "451/469 [===========================>..] - ETA: 3s - loss: 0.1001 - sparse_categorical_accuracy: 0.9698\n",
            "452/469 [===========================>..] - ETA: 3s - loss: 0.1000 - sparse_categorical_accuracy: 0.9698\n",
            "453/469 [===========================>..] - ETA: 3s - loss: 0.0999 - sparse_categorical_accuracy: 0.9698\n",
            "454/469 [============================>.] - ETA: 3s - loss: 0.0998 - sparse_categorical_accuracy: 0.9698\n",
            "455/469 [============================>.] - ETA: 2s - loss: 0.0997 - sparse_categorical_accuracy: 0.9699\n",
            "456/469 [============================>.] - ETA: 2s - loss: 0.0997 - sparse_categorical_accuracy: 0.9698\n",
            "457/469 [============================>.] - ETA: 2s - loss: 0.0996 - sparse_categorical_accuracy: 0.9698\n",
            "458/469 [============================>.] - ETA: 2s - loss: 0.0995 - sparse_categorical_accuracy: 0.9698\n",
            "459/469 [============================>.] - ETA: 2s - loss: 0.0995 - sparse_categorical_accuracy: 0.9698\n",
            "460/469 [============================>.] - ETA: 1s - loss: 0.0994 - sparse_categorical_accuracy: 0.9699\n",
            "461/469 [============================>.] - ETA: 1s - loss: 0.0994 - sparse_categorical_accuracy: 0.9699\n",
            "462/469 [============================>.] - ETA: 1s - loss: 0.0993 - sparse_categorical_accuracy: 0.9699\n",
            "463/469 [============================>.] - ETA: 1s - loss: 0.0993 - sparse_categorical_accuracy: 0.9699\n",
            "464/469 [============================>.] - ETA: 1s - loss: 0.0994 - sparse_categorical_accuracy: 0.9699\n",
            "465/469 [============================>.] - ETA: 0s - loss: 0.0993 - sparse_categorical_accuracy: 0.9699\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.0993 - sparse_categorical_accuracy: 0.9699\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.0993 - sparse_categorical_accuracy: 0.9699\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0993 - sparse_categorical_accuracy: 0.9699\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0993 - sparse_categorical_accuracy: 0.9699\n",
            " 20%|██        | 1/5 [36:35<2:07:25, 1911.46s/trial, best loss: -0.9830999970436096]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/04/16 01:08:35 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 94s 201ms/step - loss: 0.0993 - sparse_categorical_accuracy: 0.9699\n",
            "\n",
            "Epoch 4/5\n",
            "\n",
            "  1/469 [..............................] - ETA: 1:36 - loss: 0.0410 - sparse_categorical_accuracy: 0.9922\n",
            "  2/469 [..............................] - ETA: 1:22 - loss: 0.1160 - sparse_categorical_accuracy: 0.9688\n",
            "  3/469 [..............................] - ETA: 1:26 - loss: 0.0957 - sparse_categorical_accuracy: 0.9766\n",
            "  4/469 [..............................] - ETA: 1:26 - loss: 0.1113 - sparse_categorical_accuracy: 0.9707\n",
            "  5/469 [..............................] - ETA: 1:25 - loss: 0.0976 - sparse_categorical_accuracy: 0.9750\n",
            "  6/469 [..............................] - ETA: 1:24 - loss: 0.1000 - sparse_categorical_accuracy: 0.9740\n",
            "  7/469 [..............................] - ETA: 1:23 - loss: 0.0988 - sparse_categorical_accuracy: 0.9721\n",
            "  8/469 [..............................] - ETA: 1:23 - loss: 0.0931 - sparse_categorical_accuracy: 0.9727\n",
            "  9/469 [..............................] - ETA: 1:22 - loss: 0.0948 - sparse_categorical_accuracy: 0.9714\n",
            " 10/469 [..............................] - ETA: 1:23 - loss: 0.0940 - sparse_categorical_accuracy: 0.9703\n",
            " 11/469 [..............................] - ETA: 1:22 - loss: 0.0905 - sparse_categorical_accuracy: 0.9716\n",
            " 12/469 [..............................] - ETA: 1:22 - loss: 0.1027 - sparse_categorical_accuracy: 0.9681\n",
            " 13/469 [..............................] - ETA: 1:22 - loss: 0.0992 - sparse_categorical_accuracy: 0.9694\n",
            " 14/469 [..............................] - ETA: 1:21 - loss: 0.0982 - sparse_categorical_accuracy: 0.9710\n",
            " 15/469 [..............................] - ETA: 1:21 - loss: 0.0956 - sparse_categorical_accuracy: 0.9714\n",
            " 16/469 [>.............................] - ETA: 1:21 - loss: 0.0938 - sparse_categorical_accuracy: 0.9712\n",
            " 17/469 [>.............................] - ETA: 1:21 - loss: 0.0906 - sparse_categorical_accuracy: 0.9720\n",
            " 18/469 [>.............................] - ETA: 1:21 - loss: 0.0879 - sparse_categorical_accuracy: 0.9727\n",
            " 19/469 [>.............................] - ETA: 1:20 - loss: 0.0861 - sparse_categorical_accuracy: 0.9729\n",
            " 20/469 [>.............................] - ETA: 1:20 - loss: 0.0839 - sparse_categorical_accuracy: 0.9734\n",
            " 21/469 [>.............................] - ETA: 1:20 - loss: 0.0809 - sparse_categorical_accuracy: 0.9747\n",
            " 22/469 [>.............................] - ETA: 1:20 - loss: 0.0809 - sparse_categorical_accuracy: 0.9755\n",
            " 23/469 [>.............................] - ETA: 1:20 - loss: 0.0794 - sparse_categorical_accuracy: 0.9759\n",
            " 24/469 [>.............................] - ETA: 1:20 - loss: 0.0808 - sparse_categorical_accuracy: 0.9756\n",
            " 25/469 [>.............................] - ETA: 1:19 - loss: 0.0811 - sparse_categorical_accuracy: 0.9747\n",
            " 26/469 [>.............................] - ETA: 1:19 - loss: 0.0789 - sparse_categorical_accuracy: 0.9754\n",
            " 27/469 [>.............................] - ETA: 1:19 - loss: 0.0781 - sparse_categorical_accuracy: 0.9757\n",
            " 28/469 [>.............................] - ETA: 1:19 - loss: 0.0796 - sparse_categorical_accuracy: 0.9749\n",
            " 29/469 [>.............................] - ETA: 1:19 - loss: 0.0802 - sparse_categorical_accuracy: 0.9749\n",
            " 30/469 [>.............................] - ETA: 1:19 - loss: 0.0792 - sparse_categorical_accuracy: 0.9750\n",
            " 31/469 [>.............................] - ETA: 1:18 - loss: 0.0789 - sparse_categorical_accuracy: 0.9753\n",
            " 32/469 [=>............................] - ETA: 1:18 - loss: 0.0780 - sparse_categorical_accuracy: 0.9756\n",
            " 33/469 [=>............................] - ETA: 1:18 - loss: 0.0770 - sparse_categorical_accuracy: 0.9759\n",
            " 34/469 [=>............................] - ETA: 1:18 - loss: 0.0763 - sparse_categorical_accuracy: 0.9761\n",
            " 35/469 [=>............................] - ETA: 1:18 - loss: 0.0756 - sparse_categorical_accuracy: 0.9761\n",
            " 36/469 [=>............................] - ETA: 1:18 - loss: 0.0768 - sparse_categorical_accuracy: 0.9753\n",
            " 37/469 [=>............................] - ETA: 1:17 - loss: 0.0758 - sparse_categorical_accuracy: 0.9757\n",
            " 38/469 [=>............................] - ETA: 1:17 - loss: 0.0756 - sparse_categorical_accuracy: 0.9759\n",
            " 39/469 [=>............................] - ETA: 1:17 - loss: 0.0755 - sparse_categorical_accuracy: 0.9760\n",
            " 40/469 [=>............................] - ETA: 1:17 - loss: 0.0755 - sparse_categorical_accuracy: 0.9760\n",
            " 41/469 [=>............................] - ETA: 1:17 - loss: 0.0754 - sparse_categorical_accuracy: 0.9764\n",
            " 42/469 [=>............................] - ETA: 1:18 - loss: 0.0752 - sparse_categorical_accuracy: 0.9764\n",
            " 43/469 [=>............................] - ETA: 1:19 - loss: 0.0755 - sparse_categorical_accuracy: 0.9766\n",
            " 44/469 [=>............................] - ETA: 1:20 - loss: 0.0776 - sparse_categorical_accuracy: 0.9760\n",
            " 45/469 [=>............................] - ETA: 1:20 - loss: 0.0773 - sparse_categorical_accuracy: 0.9760\n",
            " 46/469 [=>............................] - ETA: 1:21 - loss: 0.0764 - sparse_categorical_accuracy: 0.9762\n",
            " 47/469 [==>...........................] - ETA: 1:22 - loss: 0.0769 - sparse_categorical_accuracy: 0.9759\n",
            " 48/469 [==>...........................] - ETA: 1:22 - loss: 0.0762 - sparse_categorical_accuracy: 0.9759\n",
            " 49/469 [==>...........................] - ETA: 1:23 - loss: 0.0754 - sparse_categorical_accuracy: 0.9762\n",
            " 50/469 [==>...........................] - ETA: 1:24 - loss: 0.0759 - sparse_categorical_accuracy: 0.9759\n",
            " 51/469 [==>...........................] - ETA: 1:24 - loss: 0.0753 - sparse_categorical_accuracy: 0.9761\n",
            " 52/469 [==>...........................] - ETA: 1:25 - loss: 0.0765 - sparse_categorical_accuracy: 0.9760\n",
            " 53/469 [==>...........................] - ETA: 1:25 - loss: 0.0766 - sparse_categorical_accuracy: 0.9757\n",
            " 54/469 [==>...........................] - ETA: 1:25 - loss: 0.0766 - sparse_categorical_accuracy: 0.9757\n",
            " 55/469 [==>...........................] - ETA: 1:24 - loss: 0.0761 - sparse_categorical_accuracy: 0.9759\n",
            " 56/469 [==>...........................] - ETA: 1:24 - loss: 0.0768 - sparse_categorical_accuracy: 0.9756\n",
            " 57/469 [==>...........................] - ETA: 1:24 - loss: 0.0766 - sparse_categorical_accuracy: 0.9756\n",
            " 58/469 [==>...........................] - ETA: 1:23 - loss: 0.0772 - sparse_categorical_accuracy: 0.9751\n",
            " 59/469 [==>...........................] - ETA: 1:23 - loss: 0.0767 - sparse_categorical_accuracy: 0.9751\n",
            " 60/469 [==>...........................] - ETA: 1:23 - loss: 0.0770 - sparse_categorical_accuracy: 0.9750\n",
            " 61/469 [==>...........................] - ETA: 1:22 - loss: 0.0767 - sparse_categorical_accuracy: 0.9750\n",
            " 62/469 [==>...........................] - ETA: 1:22 - loss: 0.0776 - sparse_categorical_accuracy: 0.9748\n",
            " 63/469 [===>..........................] - ETA: 1:22 - loss: 0.0785 - sparse_categorical_accuracy: 0.9746\n",
            " 64/469 [===>..........................] - ETA: 1:21 - loss: 0.0788 - sparse_categorical_accuracy: 0.9742\n",
            " 65/469 [===>..........................] - ETA: 1:21 - loss: 0.0785 - sparse_categorical_accuracy: 0.9744\n",
            " 66/469 [===>..........................] - ETA: 1:21 - loss: 0.0776 - sparse_categorical_accuracy: 0.9748\n",
            " 67/469 [===>..........................] - ETA: 1:20 - loss: 0.0772 - sparse_categorical_accuracy: 0.9746\n",
            " 68/469 [===>..........................] - ETA: 1:20 - loss: 0.0771 - sparse_categorical_accuracy: 0.9745\n",
            " 69/469 [===>..........................] - ETA: 1:20 - loss: 0.0780 - sparse_categorical_accuracy: 0.9746\n",
            " 70/469 [===>..........................] - ETA: 1:19 - loss: 0.0776 - sparse_categorical_accuracy: 0.9748\n",
            " 71/469 [===>..........................] - ETA: 1:19 - loss: 0.0775 - sparse_categorical_accuracy: 0.9750\n",
            " 72/469 [===>..........................] - ETA: 1:19 - loss: 0.0778 - sparse_categorical_accuracy: 0.9748\n",
            " 73/469 [===>..........................] - ETA: 1:19 - loss: 0.0774 - sparse_categorical_accuracy: 0.9750\n",
            " 74/469 [===>..........................] - ETA: 1:18 - loss: 0.0777 - sparse_categorical_accuracy: 0.9751\n",
            " 75/469 [===>..........................] - ETA: 1:18 - loss: 0.0777 - sparse_categorical_accuracy: 0.9750\n",
            " 76/469 [===>..........................] - ETA: 1:18 - loss: 0.0775 - sparse_categorical_accuracy: 0.9751\n",
            " 77/469 [===>..........................] - ETA: 1:18 - loss: 0.0775 - sparse_categorical_accuracy: 0.9750\n",
            " 78/469 [===>..........................] - ETA: 1:17 - loss: 0.0774 - sparse_categorical_accuracy: 0.9750\n",
            " 79/469 [====>.........................] - ETA: 1:17 - loss: 0.0771 - sparse_categorical_accuracy: 0.9751\n",
            " 80/469 [====>.........................] - ETA: 1:17 - loss: 0.0770 - sparse_categorical_accuracy: 0.9751\n",
            " 81/469 [====>.........................] - ETA: 1:16 - loss: 0.0776 - sparse_categorical_accuracy: 0.9750\n",
            " 82/469 [====>.........................] - ETA: 1:16 - loss: 0.0781 - sparse_categorical_accuracy: 0.9748\n",
            " 83/469 [====>.........................] - ETA: 1:16 - loss: 0.0782 - sparse_categorical_accuracy: 0.9748\n",
            " 84/469 [====>.........................] - ETA: 1:16 - loss: 0.0782 - sparse_categorical_accuracy: 0.9748\n",
            " 85/469 [====>.........................] - ETA: 1:15 - loss: 0.0779 - sparse_categorical_accuracy: 0.9749\n",
            " 86/469 [====>.........................] - ETA: 1:15 - loss: 0.0776 - sparse_categorical_accuracy: 0.9750\n",
            " 87/469 [====>.........................] - ETA: 1:15 - loss: 0.0776 - sparse_categorical_accuracy: 0.9749\n",
            " 88/469 [====>.........................] - ETA: 1:15 - loss: 0.0773 - sparse_categorical_accuracy: 0.9751\n",
            " 89/469 [====>.........................] - ETA: 1:14 - loss: 0.0785 - sparse_categorical_accuracy: 0.9749\n",
            " 90/469 [====>.........................] - ETA: 1:14 - loss: 0.0782 - sparse_categorical_accuracy: 0.9750\n",
            " 91/469 [====>.........................] - ETA: 1:14 - loss: 0.0793 - sparse_categorical_accuracy: 0.9747\n",
            " 92/469 [====>.........................] - ETA: 1:13 - loss: 0.0801 - sparse_categorical_accuracy: 0.9744\n",
            " 93/469 [====>.........................] - ETA: 1:13 - loss: 0.0809 - sparse_categorical_accuracy: 0.9744\n",
            " 94/469 [=====>........................] - ETA: 1:13 - loss: 0.0806 - sparse_categorical_accuracy: 0.9745\n",
            " 95/469 [=====>........................] - ETA: 1:13 - loss: 0.0805 - sparse_categorical_accuracy: 0.9746\n",
            " 96/469 [=====>........................] - ETA: 1:13 - loss: 0.0805 - sparse_categorical_accuracy: 0.9747\n",
            " 97/469 [=====>........................] - ETA: 1:12 - loss: 0.0800 - sparse_categorical_accuracy: 0.9749\n",
            " 98/469 [=====>........................] - ETA: 1:12 - loss: 0.0805 - sparse_categorical_accuracy: 0.9746\n",
            " 99/469 [=====>........................] - ETA: 1:12 - loss: 0.0810 - sparse_categorical_accuracy: 0.9746\n",
            "100/469 [=====>........................] - ETA: 1:12 - loss: 0.0811 - sparse_categorical_accuracy: 0.9745\n",
            "101/469 [=====>........................] - ETA: 1:11 - loss: 0.0807 - sparse_categorical_accuracy: 0.9747\n",
            "102/469 [=====>........................] - ETA: 1:11 - loss: 0.0805 - sparse_categorical_accuracy: 0.9747\n",
            "103/469 [=====>........................] - ETA: 1:11 - loss: 0.0803 - sparse_categorical_accuracy: 0.9747\n",
            "104/469 [=====>........................] - ETA: 1:11 - loss: 0.0805 - sparse_categorical_accuracy: 0.9745\n",
            "105/469 [=====>........................] - ETA: 1:10 - loss: 0.0808 - sparse_categorical_accuracy: 0.9746\n",
            "106/469 [=====>........................] - ETA: 1:10 - loss: 0.0818 - sparse_categorical_accuracy: 0.9744\n",
            "107/469 [=====>........................] - ETA: 1:10 - loss: 0.0815 - sparse_categorical_accuracy: 0.9744\n",
            "108/469 [=====>........................] - ETA: 1:10 - loss: 0.0812 - sparse_categorical_accuracy: 0.9745\n",
            "109/469 [=====>........................] - ETA: 1:10 - loss: 0.0818 - sparse_categorical_accuracy: 0.9744\n",
            "110/469 [======>.......................] - ETA: 1:10 - loss: 0.0819 - sparse_categorical_accuracy: 0.9744\n",
            "111/469 [======>.......................] - ETA: 1:10 - loss: 0.0814 - sparse_categorical_accuracy: 0.9745\n",
            "112/469 [======>.......................] - ETA: 1:10 - loss: 0.0818 - sparse_categorical_accuracy: 0.9744\n",
            "113/469 [======>.......................] - ETA: 1:10 - loss: 0.0819 - sparse_categorical_accuracy: 0.9744\n",
            "114/469 [======>.......................] - ETA: 1:10 - loss: 0.0817 - sparse_categorical_accuracy: 0.9746\n",
            "115/469 [======>.......................] - ETA: 1:10 - loss: 0.0814 - sparse_categorical_accuracy: 0.9747\n",
            "116/469 [======>.......................] - ETA: 1:11 - loss: 0.0822 - sparse_categorical_accuracy: 0.9745\n",
            "117/469 [======>.......................] - ETA: 1:11 - loss: 0.0828 - sparse_categorical_accuracy: 0.9743\n",
            "118/469 [======>.......................] - ETA: 1:11 - loss: 0.0832 - sparse_categorical_accuracy: 0.9742\n",
            "119/469 [======>.......................] - ETA: 1:11 - loss: 0.0830 - sparse_categorical_accuracy: 0.9742\n",
            "120/469 [======>.......................] - ETA: 1:11 - loss: 0.0826 - sparse_categorical_accuracy: 0.9743\n",
            "121/469 [======>.......................] - ETA: 1:11 - loss: 0.0829 - sparse_categorical_accuracy: 0.9743\n",
            "122/469 [======>.......................] - ETA: 1:10 - loss: 0.0841 - sparse_categorical_accuracy: 0.9741\n",
            "123/469 [======>.......................] - ETA: 1:10 - loss: 0.0839 - sparse_categorical_accuracy: 0.9741\n",
            "124/469 [======>.......................] - ETA: 1:10 - loss: 0.0839 - sparse_categorical_accuracy: 0.9740\n",
            "125/469 [======>.......................] - ETA: 1:10 - loss: 0.0836 - sparse_categorical_accuracy: 0.9741\n",
            "126/469 [=======>......................] - ETA: 1:09 - loss: 0.0833 - sparse_categorical_accuracy: 0.9742\n",
            "127/469 [=======>......................] - ETA: 1:09 - loss: 0.0832 - sparse_categorical_accuracy: 0.9742\n",
            "128/469 [=======>......................] - ETA: 1:09 - loss: 0.0830 - sparse_categorical_accuracy: 0.9743\n",
            "129/469 [=======>......................] - ETA: 1:09 - loss: 0.0827 - sparse_categorical_accuracy: 0.9744\n",
            "130/469 [=======>......................] - ETA: 1:08 - loss: 0.0825 - sparse_categorical_accuracy: 0.9745\n",
            "131/469 [=======>......................] - ETA: 1:08 - loss: 0.0826 - sparse_categorical_accuracy: 0.9745\n",
            "132/469 [=======>......................] - ETA: 1:08 - loss: 0.0834 - sparse_categorical_accuracy: 0.9744\n",
            "133/469 [=======>......................] - ETA: 1:08 - loss: 0.0839 - sparse_categorical_accuracy: 0.9743\n",
            "134/469 [=======>......................] - ETA: 1:07 - loss: 0.0836 - sparse_categorical_accuracy: 0.9743\n",
            "135/469 [=======>......................] - ETA: 1:07 - loss: 0.0832 - sparse_categorical_accuracy: 0.9745\n",
            "136/469 [=======>......................] - ETA: 1:07 - loss: 0.0835 - sparse_categorical_accuracy: 0.9745\n",
            "137/469 [=======>......................] - ETA: 1:07 - loss: 0.0833 - sparse_categorical_accuracy: 0.9746\n",
            "138/469 [=======>......................] - ETA: 1:06 - loss: 0.0829 - sparse_categorical_accuracy: 0.9747\n",
            "139/469 [=======>......................] - ETA: 1:06 - loss: 0.0835 - sparse_categorical_accuracy: 0.9745\n",
            "140/469 [=======>......................] - ETA: 1:06 - loss: 0.0836 - sparse_categorical_accuracy: 0.9744\n",
            "141/469 [========>.....................] - ETA: 1:06 - loss: 0.0833 - sparse_categorical_accuracy: 0.9746\n",
            "142/469 [========>.....................] - ETA: 1:05 - loss: 0.0831 - sparse_categorical_accuracy: 0.9747\n",
            "143/469 [========>.....................] - ETA: 1:05 - loss: 0.0835 - sparse_categorical_accuracy: 0.9745\n",
            "144/469 [========>.....................] - ETA: 1:05 - loss: 0.0841 - sparse_categorical_accuracy: 0.9743\n",
            "145/469 [========>.....................] - ETA: 1:05 - loss: 0.0839 - sparse_categorical_accuracy: 0.9744\n",
            "146/469 [========>.....................] - ETA: 1:04 - loss: 0.0837 - sparse_categorical_accuracy: 0.9744\n",
            "147/469 [========>.....................] - ETA: 1:04 - loss: 0.0835 - sparse_categorical_accuracy: 0.9744\n",
            "148/469 [========>.....................] - ETA: 1:04 - loss: 0.0834 - sparse_categorical_accuracy: 0.9745\n",
            "149/469 [========>.....................] - ETA: 1:04 - loss: 0.0834 - sparse_categorical_accuracy: 0.9745\n",
            "150/469 [========>.....................] - ETA: 1:04 - loss: 0.0834 - sparse_categorical_accuracy: 0.9744\n",
            "151/469 [========>.....................] - ETA: 1:03 - loss: 0.0841 - sparse_categorical_accuracy: 0.9741\n",
            "152/469 [========>.....................] - ETA: 1:03 - loss: 0.0839 - sparse_categorical_accuracy: 0.9742\n",
            "153/469 [========>.....................] - ETA: 1:03 - loss: 0.0839 - sparse_categorical_accuracy: 0.9742\n",
            "154/469 [========>.....................] - ETA: 1:03 - loss: 0.0843 - sparse_categorical_accuracy: 0.9741\n",
            "155/469 [========>.....................] - ETA: 1:02 - loss: 0.0841 - sparse_categorical_accuracy: 0.9741\n",
            "156/469 [========>.....................] - ETA: 1:02 - loss: 0.0842 - sparse_categorical_accuracy: 0.9741\n",
            "157/469 [=========>....................] - ETA: 1:02 - loss: 0.0842 - sparse_categorical_accuracy: 0.9741\n",
            "158/469 [=========>....................] - ETA: 1:02 - loss: 0.0849 - sparse_categorical_accuracy: 0.9737\n",
            "159/469 [=========>....................] - ETA: 1:01 - loss: 0.0854 - sparse_categorical_accuracy: 0.9737\n",
            "160/469 [=========>....................] - ETA: 1:01 - loss: 0.0856 - sparse_categorical_accuracy: 0.9737\n",
            "161/469 [=========>....................] - ETA: 1:01 - loss: 0.0857 - sparse_categorical_accuracy: 0.9737\n",
            "162/469 [=========>....................] - ETA: 1:01 - loss: 0.0861 - sparse_categorical_accuracy: 0.9735\n",
            "163/469 [=========>....................] - ETA: 1:01 - loss: 0.0864 - sparse_categorical_accuracy: 0.9735\n",
            "164/469 [=========>....................] - ETA: 1:00 - loss: 0.0862 - sparse_categorical_accuracy: 0.9736\n",
            "165/469 [=========>....................] - ETA: 1:00 - loss: 0.0861 - sparse_categorical_accuracy: 0.9736\n",
            "166/469 [=========>....................] - ETA: 1:00 - loss: 0.0860 - sparse_categorical_accuracy: 0.9736\n",
            "167/469 [=========>....................] - ETA: 1:00 - loss: 0.0859 - sparse_categorical_accuracy: 0.9736\n",
            "168/469 [=========>....................] - ETA: 59s - loss: 0.0861 - sparse_categorical_accuracy: 0.9736 \n",
            "169/469 [=========>....................] - ETA: 59s - loss: 0.0858 - sparse_categorical_accuracy: 0.9737\n",
            "170/469 [=========>....................] - ETA: 59s - loss: 0.0855 - sparse_categorical_accuracy: 0.9738\n",
            "171/469 [=========>....................] - ETA: 59s - loss: 0.0857 - sparse_categorical_accuracy: 0.9737\n",
            "172/469 [==========>...................] - ETA: 59s - loss: 0.0860 - sparse_categorical_accuracy: 0.9737\n",
            "173/469 [==========>...................] - ETA: 58s - loss: 0.0857 - sparse_categorical_accuracy: 0.9739\n",
            "174/469 [==========>...................] - ETA: 58s - loss: 0.0855 - sparse_categorical_accuracy: 0.9739\n",
            "175/469 [==========>...................] - ETA: 58s - loss: 0.0855 - sparse_categorical_accuracy: 0.9739\n",
            "176/469 [==========>...................] - ETA: 58s - loss: 0.0862 - sparse_categorical_accuracy: 0.9738\n",
            "177/469 [==========>...................] - ETA: 58s - loss: 0.0862 - sparse_categorical_accuracy: 0.9738\n",
            "178/469 [==========>...................] - ETA: 58s - loss: 0.0865 - sparse_categorical_accuracy: 0.9736\n",
            "179/469 [==========>...................] - ETA: 58s - loss: 0.0866 - sparse_categorical_accuracy: 0.9737\n",
            "180/469 [==========>...................] - ETA: 58s - loss: 0.0863 - sparse_categorical_accuracy: 0.9738\n",
            "181/469 [==========>...................] - ETA: 58s - loss: 0.0863 - sparse_categorical_accuracy: 0.9738\n",
            "182/469 [==========>...................] - ETA: 58s - loss: 0.0862 - sparse_categorical_accuracy: 0.9738\n",
            "183/469 [==========>...................] - ETA: 58s - loss: 0.0862 - sparse_categorical_accuracy: 0.9738\n",
            "184/469 [==========>...................] - ETA: 58s - loss: 0.0862 - sparse_categorical_accuracy: 0.9739\n",
            "185/469 [==========>...................] - ETA: 58s - loss: 0.0864 - sparse_categorical_accuracy: 0.9739\n",
            "186/469 [==========>...................] - ETA: 58s - loss: 0.0864 - sparse_categorical_accuracy: 0.9739\n",
            "187/469 [==========>...................] - ETA: 57s - loss: 0.0865 - sparse_categorical_accuracy: 0.9738\n",
            "188/469 [===========>..................] - ETA: 57s - loss: 0.0862 - sparse_categorical_accuracy: 0.9739\n",
            "189/469 [===========>..................] - ETA: 57s - loss: 0.0861 - sparse_categorical_accuracy: 0.9739\n",
            "190/469 [===========>..................] - ETA: 57s - loss: 0.0861 - sparse_categorical_accuracy: 0.9739\n",
            "191/469 [===========>..................] - ETA: 56s - loss: 0.0860 - sparse_categorical_accuracy: 0.9739\n",
            "192/469 [===========>..................] - ETA: 56s - loss: 0.0863 - sparse_categorical_accuracy: 0.9738\n",
            "193/469 [===========>..................] - ETA: 56s - loss: 0.0863 - sparse_categorical_accuracy: 0.9739\n",
            "194/469 [===========>..................] - ETA: 56s - loss: 0.0860 - sparse_categorical_accuracy: 0.9740\n",
            "195/469 [===========>..................] - ETA: 55s - loss: 0.0860 - sparse_categorical_accuracy: 0.9740\n",
            "196/469 [===========>..................] - ETA: 55s - loss: 0.0861 - sparse_categorical_accuracy: 0.9739\n",
            "197/469 [===========>..................] - ETA: 55s - loss: 0.0861 - sparse_categorical_accuracy: 0.9739\n",
            "198/469 [===========>..................] - ETA: 55s - loss: 0.0861 - sparse_categorical_accuracy: 0.9740\n",
            "199/469 [===========>..................] - ETA: 55s - loss: 0.0863 - sparse_categorical_accuracy: 0.9739\n",
            "200/469 [===========>..................] - ETA: 54s - loss: 0.0861 - sparse_categorical_accuracy: 0.9739\n",
            "201/469 [===========>..................] - ETA: 54s - loss: 0.0858 - sparse_categorical_accuracy: 0.9740\n",
            "202/469 [===========>..................] - ETA: 54s - loss: 0.0857 - sparse_categorical_accuracy: 0.9740\n",
            "203/469 [===========>..................] - ETA: 54s - loss: 0.0856 - sparse_categorical_accuracy: 0.9741\n",
            "204/469 [============>.................] - ETA: 53s - loss: 0.0854 - sparse_categorical_accuracy: 0.9742\n",
            "205/469 [============>.................] - ETA: 53s - loss: 0.0853 - sparse_categorical_accuracy: 0.9742\n",
            "206/469 [============>.................] - ETA: 53s - loss: 0.0853 - sparse_categorical_accuracy: 0.9742\n",
            "207/469 [============>.................] - ETA: 53s - loss: 0.0852 - sparse_categorical_accuracy: 0.9743\n",
            "208/469 [============>.................] - ETA: 53s - loss: 0.0851 - sparse_categorical_accuracy: 0.9742\n",
            "209/469 [============>.................] - ETA: 52s - loss: 0.0854 - sparse_categorical_accuracy: 0.9742\n",
            "210/469 [============>.................] - ETA: 52s - loss: 0.0852 - sparse_categorical_accuracy: 0.9743\n",
            "211/469 [============>.................] - ETA: 52s - loss: 0.0849 - sparse_categorical_accuracy: 0.9744\n",
            "212/469 [============>.................] - ETA: 52s - loss: 0.0848 - sparse_categorical_accuracy: 0.9744\n",
            "213/469 [============>.................] - ETA: 51s - loss: 0.0846 - sparse_categorical_accuracy: 0.9744\n",
            "214/469 [============>.................] - ETA: 51s - loss: 0.0846 - sparse_categorical_accuracy: 0.9744\n",
            "215/469 [============>.................] - ETA: 51s - loss: 0.0844 - sparse_categorical_accuracy: 0.9745\n",
            "216/469 [============>.................] - ETA: 51s - loss: 0.0844 - sparse_categorical_accuracy: 0.9744\n",
            "217/469 [============>.................] - ETA: 51s - loss: 0.0843 - sparse_categorical_accuracy: 0.9744\n",
            "218/469 [============>.................] - ETA: 50s - loss: 0.0843 - sparse_categorical_accuracy: 0.9744\n",
            "219/469 [=============>................] - ETA: 50s - loss: 0.0844 - sparse_categorical_accuracy: 0.9744\n",
            "220/469 [=============>................] - ETA: 50s - loss: 0.0841 - sparse_categorical_accuracy: 0.9745\n",
            "221/469 [=============>................] - ETA: 50s - loss: 0.0843 - sparse_categorical_accuracy: 0.9745\n",
            "222/469 [=============>................] - ETA: 49s - loss: 0.0844 - sparse_categorical_accuracy: 0.9745\n",
            "223/469 [=============>................] - ETA: 49s - loss: 0.0850 - sparse_categorical_accuracy: 0.9745\n",
            "224/469 [=============>................] - ETA: 49s - loss: 0.0852 - sparse_categorical_accuracy: 0.9744\n",
            "225/469 [=============>................] - ETA: 49s - loss: 0.0850 - sparse_categorical_accuracy: 0.9744\n",
            "226/469 [=============>................] - ETA: 48s - loss: 0.0850 - sparse_categorical_accuracy: 0.9744\n",
            "227/469 [=============>................] - ETA: 48s - loss: 0.0851 - sparse_categorical_accuracy: 0.9744\n",
            "228/469 [=============>................] - ETA: 48s - loss: 0.0849 - sparse_categorical_accuracy: 0.9745\n",
            "229/469 [=============>................] - ETA: 48s - loss: 0.0850 - sparse_categorical_accuracy: 0.9744\n",
            "230/469 [=============>................] - ETA: 48s - loss: 0.0852 - sparse_categorical_accuracy: 0.9743\n",
            "231/469 [=============>................] - ETA: 47s - loss: 0.0852 - sparse_categorical_accuracy: 0.9743\n",
            "232/469 [=============>................] - ETA: 47s - loss: 0.0850 - sparse_categorical_accuracy: 0.9744\n",
            "233/469 [=============>................] - ETA: 47s - loss: 0.0848 - sparse_categorical_accuracy: 0.9744\n",
            "234/469 [=============>................] - ETA: 47s - loss: 0.0848 - sparse_categorical_accuracy: 0.9744\n",
            "235/469 [==============>...............] - ETA: 47s - loss: 0.0848 - sparse_categorical_accuracy: 0.9744\n",
            "236/469 [==============>...............] - ETA: 46s - loss: 0.0848 - sparse_categorical_accuracy: 0.9744\n",
            "237/469 [==============>...............] - ETA: 46s - loss: 0.0849 - sparse_categorical_accuracy: 0.9743\n",
            "238/469 [==============>...............] - ETA: 46s - loss: 0.0850 - sparse_categorical_accuracy: 0.9742\n",
            "239/469 [==============>...............] - ETA: 46s - loss: 0.0849 - sparse_categorical_accuracy: 0.9742\n",
            "240/469 [==============>...............] - ETA: 45s - loss: 0.0850 - sparse_categorical_accuracy: 0.9741\n",
            "241/469 [==============>...............] - ETA: 45s - loss: 0.0849 - sparse_categorical_accuracy: 0.9741\n",
            "242/469 [==============>...............] - ETA: 45s - loss: 0.0850 - sparse_categorical_accuracy: 0.9741\n",
            "243/469 [==============>...............] - ETA: 45s - loss: 0.0849 - sparse_categorical_accuracy: 0.9742\n",
            "244/469 [==============>...............] - ETA: 45s - loss: 0.0849 - sparse_categorical_accuracy: 0.9741\n",
            "245/469 [==============>...............] - ETA: 45s - loss: 0.0848 - sparse_categorical_accuracy: 0.9741\n",
            "246/469 [==============>...............] - ETA: 45s - loss: 0.0849 - sparse_categorical_accuracy: 0.9741\n",
            "247/469 [==============>...............] - ETA: 45s - loss: 0.0848 - sparse_categorical_accuracy: 0.9741\n",
            "248/469 [==============>...............] - ETA: 44s - loss: 0.0846 - sparse_categorical_accuracy: 0.9742\n",
            "249/469 [==============>...............] - ETA: 44s - loss: 0.0850 - sparse_categorical_accuracy: 0.9741\n",
            "250/469 [==============>...............] - ETA: 44s - loss: 0.0850 - sparse_categorical_accuracy: 0.9742\n",
            "251/469 [===============>..............] - ETA: 44s - loss: 0.0849 - sparse_categorical_accuracy: 0.9742\n",
            "252/469 [===============>..............] - ETA: 44s - loss: 0.0848 - sparse_categorical_accuracy: 0.9743\n",
            "253/469 [===============>..............] - ETA: 44s - loss: 0.0846 - sparse_categorical_accuracy: 0.9743\n",
            "254/469 [===============>..............] - ETA: 43s - loss: 0.0847 - sparse_categorical_accuracy: 0.9743\n",
            "255/469 [===============>..............] - ETA: 43s - loss: 0.0846 - sparse_categorical_accuracy: 0.9743\n",
            "256/469 [===============>..............] - ETA: 43s - loss: 0.0847 - sparse_categorical_accuracy: 0.9743\n",
            "257/469 [===============>..............] - ETA: 43s - loss: 0.0846 - sparse_categorical_accuracy: 0.9743\n",
            "258/469 [===============>..............] - ETA: 43s - loss: 0.0847 - sparse_categorical_accuracy: 0.9743\n",
            "259/469 [===============>..............] - ETA: 42s - loss: 0.0844 - sparse_categorical_accuracy: 0.9744\n",
            "260/469 [===============>..............] - ETA: 42s - loss: 0.0845 - sparse_categorical_accuracy: 0.9745\n",
            "261/469 [===============>..............] - ETA: 42s - loss: 0.0843 - sparse_categorical_accuracy: 0.9745\n",
            "262/469 [===============>..............] - ETA: 42s - loss: 0.0842 - sparse_categorical_accuracy: 0.9745\n",
            "263/469 [===============>..............] - ETA: 42s - loss: 0.0843 - sparse_categorical_accuracy: 0.9745\n",
            "264/469 [===============>..............] - ETA: 41s - loss: 0.0843 - sparse_categorical_accuracy: 0.9745\n",
            "265/469 [===============>..............] - ETA: 41s - loss: 0.0842 - sparse_categorical_accuracy: 0.9745\n",
            "266/469 [================>.............] - ETA: 41s - loss: 0.0839 - sparse_categorical_accuracy: 0.9746\n",
            "267/469 [================>.............] - ETA: 41s - loss: 0.0839 - sparse_categorical_accuracy: 0.9746\n",
            "268/469 [================>.............] - ETA: 40s - loss: 0.0838 - sparse_categorical_accuracy: 0.9747\n",
            "269/469 [================>.............] - ETA: 40s - loss: 0.0836 - sparse_categorical_accuracy: 0.9747\n",
            "270/469 [================>.............] - ETA: 40s - loss: 0.0837 - sparse_categorical_accuracy: 0.9747\n",
            "271/469 [================>.............] - ETA: 40s - loss: 0.0841 - sparse_categorical_accuracy: 0.9747\n",
            "272/469 [================>.............] - ETA: 40s - loss: 0.0840 - sparse_categorical_accuracy: 0.9748\n",
            "273/469 [================>.............] - ETA: 39s - loss: 0.0841 - sparse_categorical_accuracy: 0.9747\n",
            "274/469 [================>.............] - ETA: 39s - loss: 0.0840 - sparse_categorical_accuracy: 0.9747\n",
            "275/469 [================>.............] - ETA: 39s - loss: 0.0839 - sparse_categorical_accuracy: 0.9747\n",
            "276/469 [================>.............] - ETA: 39s - loss: 0.0839 - sparse_categorical_accuracy: 0.9748\n",
            "277/469 [================>.............] - ETA: 38s - loss: 0.0838 - sparse_categorical_accuracy: 0.9748\n",
            "278/469 [================>.............] - ETA: 38s - loss: 0.0840 - sparse_categorical_accuracy: 0.9747\n",
            "279/469 [================>.............] - ETA: 38s - loss: 0.0843 - sparse_categorical_accuracy: 0.9747\n",
            "280/469 [================>.............] - ETA: 38s - loss: 0.0842 - sparse_categorical_accuracy: 0.9747\n",
            "281/469 [================>.............] - ETA: 38s - loss: 0.0841 - sparse_categorical_accuracy: 0.9747\n",
            "282/469 [=================>............] - ETA: 37s - loss: 0.0842 - sparse_categorical_accuracy: 0.9747\n",
            "283/469 [=================>............] - ETA: 37s - loss: 0.0844 - sparse_categorical_accuracy: 0.9746\n",
            "284/469 [=================>............] - ETA: 37s - loss: 0.0842 - sparse_categorical_accuracy: 0.9747\n",
            "285/469 [=================>............] - ETA: 37s - loss: 0.0841 - sparse_categorical_accuracy: 0.9747\n",
            "286/469 [=================>............] - ETA: 37s - loss: 0.0840 - sparse_categorical_accuracy: 0.9748\n",
            "287/469 [=================>............] - ETA: 36s - loss: 0.0838 - sparse_categorical_accuracy: 0.9748\n",
            "288/469 [=================>............] - ETA: 36s - loss: 0.0837 - sparse_categorical_accuracy: 0.9748\n",
            "289/469 [=================>............] - ETA: 36s - loss: 0.0835 - sparse_categorical_accuracy: 0.9748\n",
            "290/469 [=================>............] - ETA: 36s - loss: 0.0837 - sparse_categorical_accuracy: 0.9748\n",
            "291/469 [=================>............] - ETA: 35s - loss: 0.0840 - sparse_categorical_accuracy: 0.9748\n",
            "292/469 [=================>............] - ETA: 35s - loss: 0.0839 - sparse_categorical_accuracy: 0.9748\n",
            "293/469 [=================>............] - ETA: 35s - loss: 0.0839 - sparse_categorical_accuracy: 0.9748\n",
            "294/469 [=================>............] - ETA: 35s - loss: 0.0842 - sparse_categorical_accuracy: 0.9748\n",
            "295/469 [=================>............] - ETA: 35s - loss: 0.0842 - sparse_categorical_accuracy: 0.9747\n",
            "296/469 [=================>............] - ETA: 34s - loss: 0.0841 - sparse_categorical_accuracy: 0.9747\n",
            "297/469 [=================>............] - ETA: 34s - loss: 0.0840 - sparse_categorical_accuracy: 0.9748\n",
            "298/469 [==================>...........] - ETA: 34s - loss: 0.0842 - sparse_categorical_accuracy: 0.9747\n",
            "299/469 [==================>...........] - ETA: 34s - loss: 0.0839 - sparse_categorical_accuracy: 0.9748\n",
            "300/469 [==================>...........] - ETA: 34s - loss: 0.0838 - sparse_categorical_accuracy: 0.9748\n",
            "301/469 [==================>...........] - ETA: 33s - loss: 0.0841 - sparse_categorical_accuracy: 0.9748\n",
            "302/469 [==================>...........] - ETA: 33s - loss: 0.0843 - sparse_categorical_accuracy: 0.9747\n",
            "303/469 [==================>...........] - ETA: 33s - loss: 0.0842 - sparse_categorical_accuracy: 0.9747\n",
            "304/469 [==================>...........] - ETA: 33s - loss: 0.0841 - sparse_categorical_accuracy: 0.9748\n",
            "305/469 [==================>...........] - ETA: 33s - loss: 0.0841 - sparse_categorical_accuracy: 0.9748\n",
            "306/469 [==================>...........] - ETA: 32s - loss: 0.0843 - sparse_categorical_accuracy: 0.9747\n",
            "307/469 [==================>...........] - ETA: 32s - loss: 0.0843 - sparse_categorical_accuracy: 0.9747\n",
            "308/469 [==================>...........] - ETA: 32s - loss: 0.0844 - sparse_categorical_accuracy: 0.9747\n",
            "309/469 [==================>...........] - ETA: 32s - loss: 0.0842 - sparse_categorical_accuracy: 0.9747\n",
            "310/469 [==================>...........] - ETA: 32s - loss: 0.0842 - sparse_categorical_accuracy: 0.9747\n",
            "311/469 [==================>...........] - ETA: 31s - loss: 0.0843 - sparse_categorical_accuracy: 0.9746\n",
            "312/469 [==================>...........] - ETA: 31s - loss: 0.0843 - sparse_categorical_accuracy: 0.9746\n",
            "313/469 [===================>..........] - ETA: 31s - loss: 0.0843 - sparse_categorical_accuracy: 0.9747\n",
            "314/469 [===================>..........] - ETA: 31s - loss: 0.0842 - sparse_categorical_accuracy: 0.9747\n",
            "315/469 [===================>..........] - ETA: 31s - loss: 0.0842 - sparse_categorical_accuracy: 0.9747\n",
            "316/469 [===================>..........] - ETA: 31s - loss: 0.0844 - sparse_categorical_accuracy: 0.9746\n",
            "317/469 [===================>..........] - ETA: 31s - loss: 0.0844 - sparse_categorical_accuracy: 0.9746\n",
            "318/469 [===================>..........] - ETA: 30s - loss: 0.0844 - sparse_categorical_accuracy: 0.9746\n",
            "319/469 [===================>..........] - ETA: 30s - loss: 0.0843 - sparse_categorical_accuracy: 0.9747\n",
            "320/469 [===================>..........] - ETA: 30s - loss: 0.0844 - sparse_categorical_accuracy: 0.9746\n",
            "321/469 [===================>..........] - ETA: 30s - loss: 0.0846 - sparse_categorical_accuracy: 0.9745\n",
            "322/469 [===================>..........] - ETA: 30s - loss: 0.0845 - sparse_categorical_accuracy: 0.9746\n",
            "323/469 [===================>..........] - ETA: 29s - loss: 0.0846 - sparse_categorical_accuracy: 0.9746\n",
            "324/469 [===================>..........] - ETA: 29s - loss: 0.0844 - sparse_categorical_accuracy: 0.9746\n",
            "325/469 [===================>..........] - ETA: 29s - loss: 0.0845 - sparse_categorical_accuracy: 0.9746\n",
            "326/469 [===================>..........] - ETA: 29s - loss: 0.0843 - sparse_categorical_accuracy: 0.9747\n",
            "327/469 [===================>..........] - ETA: 29s - loss: 0.0841 - sparse_categorical_accuracy: 0.9748\n",
            "328/469 [===================>..........] - ETA: 28s - loss: 0.0841 - sparse_categorical_accuracy: 0.9748\n",
            "329/469 [====================>.........] - ETA: 28s - loss: 0.0842 - sparse_categorical_accuracy: 0.9748\n",
            "330/469 [====================>.........] - ETA: 28s - loss: 0.0841 - sparse_categorical_accuracy: 0.9748\n",
            "331/469 [====================>.........] - ETA: 28s - loss: 0.0841 - sparse_categorical_accuracy: 0.9748\n",
            "332/469 [====================>.........] - ETA: 27s - loss: 0.0840 - sparse_categorical_accuracy: 0.9749\n",
            "333/469 [====================>.........] - ETA: 27s - loss: 0.0841 - sparse_categorical_accuracy: 0.9748\n",
            "334/469 [====================>.........] - ETA: 27s - loss: 0.0840 - sparse_categorical_accuracy: 0.9749\n",
            "335/469 [====================>.........] - ETA: 27s - loss: 0.0838 - sparse_categorical_accuracy: 0.9749\n",
            "336/469 [====================>.........] - ETA: 27s - loss: 0.0837 - sparse_categorical_accuracy: 0.9750\n",
            "337/469 [====================>.........] - ETA: 26s - loss: 0.0836 - sparse_categorical_accuracy: 0.9750\n",
            "338/469 [====================>.........] - ETA: 26s - loss: 0.0836 - sparse_categorical_accuracy: 0.9750\n",
            "339/469 [====================>.........] - ETA: 26s - loss: 0.0835 - sparse_categorical_accuracy: 0.9750\n",
            "340/469 [====================>.........] - ETA: 26s - loss: 0.0833 - sparse_categorical_accuracy: 0.9750\n",
            "341/469 [====================>.........] - ETA: 26s - loss: 0.0833 - sparse_categorical_accuracy: 0.9750\n",
            "342/469 [====================>.........] - ETA: 25s - loss: 0.0832 - sparse_categorical_accuracy: 0.9751\n",
            "343/469 [====================>.........] - ETA: 25s - loss: 0.0832 - sparse_categorical_accuracy: 0.9751\n",
            "344/469 [=====================>........] - ETA: 25s - loss: 0.0830 - sparse_categorical_accuracy: 0.9751\n",
            "345/469 [=====================>........] - ETA: 25s - loss: 0.0829 - sparse_categorical_accuracy: 0.9752\n",
            "346/469 [=====================>........] - ETA: 25s - loss: 0.0828 - sparse_categorical_accuracy: 0.9752\n",
            "347/469 [=====================>........] - ETA: 24s - loss: 0.0827 - sparse_categorical_accuracy: 0.9752\n",
            "348/469 [=====================>........] - ETA: 24s - loss: 0.0827 - sparse_categorical_accuracy: 0.9752\n",
            "349/469 [=====================>........] - ETA: 24s - loss: 0.0826 - sparse_categorical_accuracy: 0.9752\n",
            "350/469 [=====================>........] - ETA: 24s - loss: 0.0827 - sparse_categorical_accuracy: 0.9751\n",
            "351/469 [=====================>........] - ETA: 23s - loss: 0.0826 - sparse_categorical_accuracy: 0.9751\n",
            "352/469 [=====================>........] - ETA: 23s - loss: 0.0825 - sparse_categorical_accuracy: 0.9752\n",
            "353/469 [=====================>........] - ETA: 23s - loss: 0.0824 - sparse_categorical_accuracy: 0.9752\n",
            "354/469 [=====================>........] - ETA: 23s - loss: 0.0823 - sparse_categorical_accuracy: 0.9753\n",
            "355/469 [=====================>........] - ETA: 23s - loss: 0.0824 - sparse_categorical_accuracy: 0.9752\n",
            "356/469 [=====================>........] - ETA: 22s - loss: 0.0826 - sparse_categorical_accuracy: 0.9751\n",
            "357/469 [=====================>........] - ETA: 22s - loss: 0.0828 - sparse_categorical_accuracy: 0.9751\n",
            "358/469 [=====================>........] - ETA: 22s - loss: 0.0830 - sparse_categorical_accuracy: 0.9750\n",
            "359/469 [=====================>........] - ETA: 22s - loss: 0.0831 - sparse_categorical_accuracy: 0.9750\n",
            "360/469 [======================>.......] - ETA: 22s - loss: 0.0830 - sparse_categorical_accuracy: 0.9750\n",
            "361/469 [======================>.......] - ETA: 21s - loss: 0.0829 - sparse_categorical_accuracy: 0.9750\n",
            "362/469 [======================>.......] - ETA: 21s - loss: 0.0831 - sparse_categorical_accuracy: 0.9749\n",
            "363/469 [======================>.......] - ETA: 21s - loss: 0.0831 - sparse_categorical_accuracy: 0.9749\n",
            "364/469 [======================>.......] - ETA: 21s - loss: 0.0832 - sparse_categorical_accuracy: 0.9749\n",
            "365/469 [======================>.......] - ETA: 21s - loss: 0.0831 - sparse_categorical_accuracy: 0.9749\n",
            "366/469 [======================>.......] - ETA: 20s - loss: 0.0832 - sparse_categorical_accuracy: 0.9748\n",
            "367/469 [======================>.......] - ETA: 20s - loss: 0.0831 - sparse_categorical_accuracy: 0.9748\n",
            "368/469 [======================>.......] - ETA: 20s - loss: 0.0832 - sparse_categorical_accuracy: 0.9748\n",
            "369/469 [======================>.......] - ETA: 20s - loss: 0.0832 - sparse_categorical_accuracy: 0.9748\n",
            "370/469 [======================>.......] - ETA: 20s - loss: 0.0831 - sparse_categorical_accuracy: 0.9749\n",
            "371/469 [======================>.......] - ETA: 19s - loss: 0.0830 - sparse_categorical_accuracy: 0.9749\n",
            "372/469 [======================>.......] - ETA: 19s - loss: 0.0831 - sparse_categorical_accuracy: 0.9748\n",
            "373/469 [======================>.......] - ETA: 19s - loss: 0.0830 - sparse_categorical_accuracy: 0.9749\n",
            "374/469 [======================>.......] - ETA: 19s - loss: 0.0831 - sparse_categorical_accuracy: 0.9749\n",
            "375/469 [======================>.......] - ETA: 19s - loss: 0.0829 - sparse_categorical_accuracy: 0.9749\n",
            "376/469 [=======================>......] - ETA: 18s - loss: 0.0831 - sparse_categorical_accuracy: 0.9749\n",
            "377/469 [=======================>......] - ETA: 18s - loss: 0.0831 - sparse_categorical_accuracy: 0.9749\n",
            "378/469 [=======================>......] - ETA: 18s - loss: 0.0829 - sparse_categorical_accuracy: 0.9749\n",
            "379/469 [=======================>......] - ETA: 18s - loss: 0.0829 - sparse_categorical_accuracy: 0.9749\n",
            "380/469 [=======================>......] - ETA: 18s - loss: 0.0830 - sparse_categorical_accuracy: 0.9749\n",
            "381/469 [=======================>......] - ETA: 17s - loss: 0.0833 - sparse_categorical_accuracy: 0.9749\n",
            "382/469 [=======================>......] - ETA: 17s - loss: 0.0832 - sparse_categorical_accuracy: 0.9749\n",
            "383/469 [=======================>......] - ETA: 17s - loss: 0.0833 - sparse_categorical_accuracy: 0.9748\n",
            "384/469 [=======================>......] - ETA: 17s - loss: 0.0835 - sparse_categorical_accuracy: 0.9748\n",
            "385/469 [=======================>......] - ETA: 17s - loss: 0.0835 - sparse_categorical_accuracy: 0.9748\n",
            "386/469 [=======================>......] - ETA: 17s - loss: 0.0836 - sparse_categorical_accuracy: 0.9747\n",
            "387/469 [=======================>......] - ETA: 16s - loss: 0.0835 - sparse_categorical_accuracy: 0.9747\n",
            "388/469 [=======================>......] - ETA: 16s - loss: 0.0834 - sparse_categorical_accuracy: 0.9748\n",
            "389/469 [=======================>......] - ETA: 16s - loss: 0.0833 - sparse_categorical_accuracy: 0.9748\n",
            "390/469 [=======================>......] - ETA: 16s - loss: 0.0832 - sparse_categorical_accuracy: 0.9748\n",
            "391/469 [========================>.....] - ETA: 16s - loss: 0.0831 - sparse_categorical_accuracy: 0.9748\n",
            "392/469 [========================>.....] - ETA: 15s - loss: 0.0831 - sparse_categorical_accuracy: 0.9748\n",
            "393/469 [========================>.....] - ETA: 15s - loss: 0.0831 - sparse_categorical_accuracy: 0.9748\n",
            "394/469 [========================>.....] - ETA: 15s - loss: 0.0830 - sparse_categorical_accuracy: 0.9748\n",
            "395/469 [========================>.....] - ETA: 15s - loss: 0.0831 - sparse_categorical_accuracy: 0.9747\n",
            "396/469 [========================>.....] - ETA: 14s - loss: 0.0832 - sparse_categorical_accuracy: 0.9747\n",
            "397/469 [========================>.....] - ETA: 14s - loss: 0.0831 - sparse_categorical_accuracy: 0.9747\n",
            "398/469 [========================>.....] - ETA: 14s - loss: 0.0830 - sparse_categorical_accuracy: 0.9748\n",
            "399/469 [========================>.....] - ETA: 14s - loss: 0.0830 - sparse_categorical_accuracy: 0.9748\n",
            "400/469 [========================>.....] - ETA: 14s - loss: 0.0828 - sparse_categorical_accuracy: 0.9748\n",
            "401/469 [========================>.....] - ETA: 13s - loss: 0.0828 - sparse_categorical_accuracy: 0.9748\n",
            "402/469 [========================>.....] - ETA: 13s - loss: 0.0827 - sparse_categorical_accuracy: 0.9748\n",
            "403/469 [========================>.....] - ETA: 13s - loss: 0.0827 - sparse_categorical_accuracy: 0.9749\n",
            "404/469 [========================>.....] - ETA: 13s - loss: 0.0827 - sparse_categorical_accuracy: 0.9748\n",
            "405/469 [========================>.....] - ETA: 13s - loss: 0.0828 - sparse_categorical_accuracy: 0.9748\n",
            "406/469 [========================>.....] - ETA: 12s - loss: 0.0828 - sparse_categorical_accuracy: 0.9748\n",
            "407/469 [=========================>....] - ETA: 12s - loss: 0.0832 - sparse_categorical_accuracy: 0.9747\n",
            "408/469 [=========================>....] - ETA: 12s - loss: 0.0831 - sparse_categorical_accuracy: 0.9747\n",
            "409/469 [=========================>....] - ETA: 12s - loss: 0.0831 - sparse_categorical_accuracy: 0.9747\n",
            "410/469 [=========================>....] - ETA: 12s - loss: 0.0831 - sparse_categorical_accuracy: 0.9747\n",
            "411/469 [=========================>....] - ETA: 11s - loss: 0.0830 - sparse_categorical_accuracy: 0.9747\n",
            "412/469 [=========================>....] - ETA: 11s - loss: 0.0829 - sparse_categorical_accuracy: 0.9748\n",
            "413/469 [=========================>....] - ETA: 11s - loss: 0.0828 - sparse_categorical_accuracy: 0.9748\n",
            "414/469 [=========================>....] - ETA: 11s - loss: 0.0828 - sparse_categorical_accuracy: 0.9748\n",
            "415/469 [=========================>....] - ETA: 11s - loss: 0.0828 - sparse_categorical_accuracy: 0.9748\n",
            "416/469 [=========================>....] - ETA: 10s - loss: 0.0831 - sparse_categorical_accuracy: 0.9748\n",
            "417/469 [=========================>....] - ETA: 10s - loss: 0.0832 - sparse_categorical_accuracy: 0.9747\n",
            "418/469 [=========================>....] - ETA: 10s - loss: 0.0833 - sparse_categorical_accuracy: 0.9747\n",
            "419/469 [=========================>....] - ETA: 10s - loss: 0.0832 - sparse_categorical_accuracy: 0.9747\n",
            "420/469 [=========================>....] - ETA: 10s - loss: 0.0831 - sparse_categorical_accuracy: 0.9748\n",
            "421/469 [=========================>....] - ETA: 9s - loss: 0.0830 - sparse_categorical_accuracy: 0.9747 \n",
            "422/469 [=========================>....] - ETA: 9s - loss: 0.0829 - sparse_categorical_accuracy: 0.9748\n",
            "423/469 [==========================>...] - ETA: 9s - loss: 0.0829 - sparse_categorical_accuracy: 0.9748\n",
            "424/469 [==========================>...] - ETA: 9s - loss: 0.0828 - sparse_categorical_accuracy: 0.9748\n",
            "425/469 [==========================>...] - ETA: 8s - loss: 0.0828 - sparse_categorical_accuracy: 0.9748\n",
            "426/469 [==========================>...] - ETA: 8s - loss: 0.0827 - sparse_categorical_accuracy: 0.9748\n",
            "427/469 [==========================>...] - ETA: 8s - loss: 0.0826 - sparse_categorical_accuracy: 0.9748\n",
            "428/469 [==========================>...] - ETA: 8s - loss: 0.0827 - sparse_categorical_accuracy: 0.9748\n",
            "429/469 [==========================>...] - ETA: 8s - loss: 0.0826 - sparse_categorical_accuracy: 0.9748\n",
            "430/469 [==========================>...] - ETA: 7s - loss: 0.0826 - sparse_categorical_accuracy: 0.9748\n",
            "431/469 [==========================>...] - ETA: 7s - loss: 0.0826 - sparse_categorical_accuracy: 0.9748\n",
            "432/469 [==========================>...] - ETA: 7s - loss: 0.0827 - sparse_categorical_accuracy: 0.9748\n",
            "433/469 [==========================>...] - ETA: 7s - loss: 0.0826 - sparse_categorical_accuracy: 0.9748\n",
            "434/469 [==========================>...] - ETA: 7s - loss: 0.0827 - sparse_categorical_accuracy: 0.9748\n",
            "435/469 [==========================>...] - ETA: 6s - loss: 0.0827 - sparse_categorical_accuracy: 0.9748\n",
            "436/469 [==========================>...] - ETA: 6s - loss: 0.0826 - sparse_categorical_accuracy: 0.9748\n",
            "437/469 [==========================>...] - ETA: 6s - loss: 0.0827 - sparse_categorical_accuracy: 0.9748\n",
            "438/469 [===========================>..] - ETA: 6s - loss: 0.0827 - sparse_categorical_accuracy: 0.9748\n",
            "439/469 [===========================>..] - ETA: 6s - loss: 0.0825 - sparse_categorical_accuracy: 0.9749\n",
            "440/469 [===========================>..] - ETA: 5s - loss: 0.0825 - sparse_categorical_accuracy: 0.9748\n",
            "441/469 [===========================>..] - ETA: 5s - loss: 0.0826 - sparse_categorical_accuracy: 0.9748\n",
            "442/469 [===========================>..] - ETA: 5s - loss: 0.0825 - sparse_categorical_accuracy: 0.9748\n",
            "443/469 [===========================>..] - ETA: 5s - loss: 0.0824 - sparse_categorical_accuracy: 0.9749\n",
            "444/469 [===========================>..] - ETA: 5s - loss: 0.0824 - sparse_categorical_accuracy: 0.9749\n",
            "445/469 [===========================>..] - ETA: 4s - loss: 0.0825 - sparse_categorical_accuracy: 0.9748\n",
            "446/469 [===========================>..] - ETA: 4s - loss: 0.0826 - sparse_categorical_accuracy: 0.9748\n",
            "447/469 [===========================>..] - ETA: 4s - loss: 0.0826 - sparse_categorical_accuracy: 0.9747\n",
            "448/469 [===========================>..] - ETA: 4s - loss: 0.0826 - sparse_categorical_accuracy: 0.9747\n",
            "449/469 [===========================>..] - ETA: 4s - loss: 0.0826 - sparse_categorical_accuracy: 0.9747\n",
            "450/469 [===========================>..] - ETA: 3s - loss: 0.0825 - sparse_categorical_accuracy: 0.9748\n",
            "451/469 [===========================>..] - ETA: 3s - loss: 0.0825 - sparse_categorical_accuracy: 0.9747\n",
            "452/469 [===========================>..] - ETA: 3s - loss: 0.0824 - sparse_categorical_accuracy: 0.9747\n",
            "453/469 [===========================>..] - ETA: 3s - loss: 0.0823 - sparse_categorical_accuracy: 0.9748\n",
            "454/469 [============================>.] - ETA: 3s - loss: 0.0825 - sparse_categorical_accuracy: 0.9748\n",
            "455/469 [============================>.] - ETA: 2s - loss: 0.0826 - sparse_categorical_accuracy: 0.9748\n",
            "456/469 [============================>.] - ETA: 2s - loss: 0.0825 - sparse_categorical_accuracy: 0.9748\n",
            "457/469 [============================>.] - ETA: 2s - loss: 0.0825 - sparse_categorical_accuracy: 0.9748\n",
            "458/469 [============================>.] - ETA: 2s - loss: 0.0825 - sparse_categorical_accuracy: 0.9748\n",
            "459/469 [============================>.] - ETA: 2s - loss: 0.0824 - sparse_categorical_accuracy: 0.9749\n",
            "460/469 [============================>.] - ETA: 1s - loss: 0.0826 - sparse_categorical_accuracy: 0.9748\n",
            "461/469 [============================>.] - ETA: 1s - loss: 0.0825 - sparse_categorical_accuracy: 0.9749\n",
            "462/469 [============================>.] - ETA: 1s - loss: 0.0825 - sparse_categorical_accuracy: 0.9749\n",
            "463/469 [============================>.] - ETA: 1s - loss: 0.0824 - sparse_categorical_accuracy: 0.9749\n",
            "464/469 [============================>.] - ETA: 1s - loss: 0.0824 - sparse_categorical_accuracy: 0.9749\n",
            "465/469 [============================>.] - ETA: 0s - loss: 0.0824 - sparse_categorical_accuracy: 0.9748\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.0824 - sparse_categorical_accuracy: 0.9748\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.0823 - sparse_categorical_accuracy: 0.9749\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0823 - sparse_categorical_accuracy: 0.9749\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0823 - sparse_categorical_accuracy: 0.9749\n",
            " 20%|██        | 1/5 [38:11<2:07:25, 1911.46s/trial, best loss: -0.9830999970436096]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/04/16 01:10:12 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 97s 206ms/step - loss: 0.0823 - sparse_categorical_accuracy: 0.9749\n",
            "\n",
            "Epoch 5/5\n",
            "\n",
            "  1/469 [..............................] - ETA: 1:43 - loss: 0.0388 - sparse_categorical_accuracy: 0.9844\n",
            "  2/469 [..............................] - ETA: 1:22 - loss: 0.0917 - sparse_categorical_accuracy: 0.9766\n",
            "  3/469 [..............................] - ETA: 1:27 - loss: 0.0792 - sparse_categorical_accuracy: 0.9766\n",
            "  4/469 [..............................] - ETA: 1:27 - loss: 0.0806 - sparse_categorical_accuracy: 0.9766\n",
            "  5/469 [..............................] - ETA: 1:26 - loss: 0.0766 - sparse_categorical_accuracy: 0.9734\n",
            "  6/469 [..............................] - ETA: 1:26 - loss: 0.0736 - sparse_categorical_accuracy: 0.9766\n",
            "  7/469 [..............................] - ETA: 1:25 - loss: 0.0717 - sparse_categorical_accuracy: 0.9766\n",
            "  8/469 [..............................] - ETA: 1:25 - loss: 0.0705 - sparse_categorical_accuracy: 0.9775\n",
            "  9/469 [..............................] - ETA: 1:25 - loss: 0.0734 - sparse_categorical_accuracy: 0.9774\n",
            " 10/469 [..............................] - ETA: 1:25 - loss: 0.0692 - sparse_categorical_accuracy: 0.9797\n",
            " 11/469 [..............................] - ETA: 1:25 - loss: 0.0653 - sparse_categorical_accuracy: 0.9808\n",
            " 12/469 [..............................] - ETA: 1:24 - loss: 0.0669 - sparse_categorical_accuracy: 0.9805\n",
            " 13/469 [..............................] - ETA: 1:24 - loss: 0.0650 - sparse_categorical_accuracy: 0.9814\n",
            " 14/469 [..............................] - ETA: 1:24 - loss: 0.0630 - sparse_categorical_accuracy: 0.9821\n",
            " 15/469 [..............................] - ETA: 1:24 - loss: 0.0628 - sparse_categorical_accuracy: 0.9818\n",
            " 16/469 [>.............................] - ETA: 1:23 - loss: 0.0645 - sparse_categorical_accuracy: 0.9810\n",
            " 17/469 [>.............................] - ETA: 1:23 - loss: 0.0662 - sparse_categorical_accuracy: 0.9798\n",
            " 18/469 [>.............................] - ETA: 1:23 - loss: 0.0677 - sparse_categorical_accuracy: 0.9787\n",
            " 19/469 [>.............................] - ETA: 1:23 - loss: 0.0680 - sparse_categorical_accuracy: 0.9786\n",
            " 20/469 [>.............................] - ETA: 1:23 - loss: 0.0721 - sparse_categorical_accuracy: 0.9777\n",
            " 21/469 [>.............................] - ETA: 1:23 - loss: 0.0722 - sparse_categorical_accuracy: 0.9773\n",
            " 22/469 [>.............................] - ETA: 1:23 - loss: 0.0706 - sparse_categorical_accuracy: 0.9780\n",
            " 23/469 [>.............................] - ETA: 1:22 - loss: 0.0700 - sparse_categorical_accuracy: 0.9779\n",
            " 24/469 [>.............................] - ETA: 1:22 - loss: 0.0679 - sparse_categorical_accuracy: 0.9788\n",
            " 25/469 [>.............................] - ETA: 1:22 - loss: 0.0688 - sparse_categorical_accuracy: 0.9781\n",
            " 26/469 [>.............................] - ETA: 1:22 - loss: 0.0714 - sparse_categorical_accuracy: 0.9775\n",
            " 27/469 [>.............................] - ETA: 1:22 - loss: 0.0719 - sparse_categorical_accuracy: 0.9771\n",
            " 28/469 [>.............................] - ETA: 1:21 - loss: 0.0704 - sparse_categorical_accuracy: 0.9777\n",
            " 29/469 [>.............................] - ETA: 1:21 - loss: 0.0706 - sparse_categorical_accuracy: 0.9779\n",
            " 30/469 [>.............................] - ETA: 1:21 - loss: 0.0721 - sparse_categorical_accuracy: 0.9779\n",
            " 31/469 [>.............................] - ETA: 1:21 - loss: 0.0733 - sparse_categorical_accuracy: 0.9773\n",
            " 32/469 [=>............................] - ETA: 1:21 - loss: 0.0722 - sparse_categorical_accuracy: 0.9775\n",
            " 33/469 [=>............................] - ETA: 1:20 - loss: 0.0722 - sparse_categorical_accuracy: 0.9773\n",
            " 34/469 [=>............................] - ETA: 1:21 - loss: 0.0714 - sparse_categorical_accuracy: 0.9775\n",
            " 35/469 [=>............................] - ETA: 1:21 - loss: 0.0733 - sparse_categorical_accuracy: 0.9770\n",
            " 36/469 [=>............................] - ETA: 1:23 - loss: 0.0725 - sparse_categorical_accuracy: 0.9772\n",
            " 37/469 [=>............................] - ETA: 1:23 - loss: 0.0721 - sparse_categorical_accuracy: 0.9774\n",
            " 38/469 [=>............................] - ETA: 1:24 - loss: 0.0725 - sparse_categorical_accuracy: 0.9772\n",
            " 39/469 [=>............................] - ETA: 1:25 - loss: 0.0730 - sparse_categorical_accuracy: 0.9766\n",
            " 40/469 [=>............................] - ETA: 1:25 - loss: 0.0722 - sparse_categorical_accuracy: 0.9768\n",
            " 41/469 [=>............................] - ETA: 1:26 - loss: 0.0714 - sparse_categorical_accuracy: 0.9771\n",
            " 42/469 [=>............................] - ETA: 1:27 - loss: 0.0734 - sparse_categorical_accuracy: 0.9771\n",
            " 43/469 [=>............................] - ETA: 1:28 - loss: 0.0740 - sparse_categorical_accuracy: 0.9769\n",
            " 44/469 [=>............................] - ETA: 1:28 - loss: 0.0729 - sparse_categorical_accuracy: 0.9773\n",
            " 45/469 [=>............................] - ETA: 1:29 - loss: 0.0720 - sparse_categorical_accuracy: 0.9776\n",
            " 46/469 [=>............................] - ETA: 1:29 - loss: 0.0717 - sparse_categorical_accuracy: 0.9778\n",
            " 47/469 [==>...........................] - ETA: 1:30 - loss: 0.0713 - sparse_categorical_accuracy: 0.9781\n",
            " 48/469 [==>...........................] - ETA: 1:29 - loss: 0.0718 - sparse_categorical_accuracy: 0.9777\n",
            " 49/469 [==>...........................] - ETA: 1:29 - loss: 0.0715 - sparse_categorical_accuracy: 0.9778\n",
            " 50/469 [==>...........................] - ETA: 1:28 - loss: 0.0708 - sparse_categorical_accuracy: 0.9781\n",
            " 51/469 [==>...........................] - ETA: 1:28 - loss: 0.0728 - sparse_categorical_accuracy: 0.9776\n",
            " 52/469 [==>...........................] - ETA: 1:27 - loss: 0.0726 - sparse_categorical_accuracy: 0.9776\n",
            " 53/469 [==>...........................] - ETA: 1:27 - loss: 0.0739 - sparse_categorical_accuracy: 0.9772\n",
            " 54/469 [==>...........................] - ETA: 1:26 - loss: 0.0730 - sparse_categorical_accuracy: 0.9776\n",
            " 55/469 [==>...........................] - ETA: 1:26 - loss: 0.0727 - sparse_categorical_accuracy: 0.9778\n",
            " 56/469 [==>...........................] - ETA: 1:25 - loss: 0.0725 - sparse_categorical_accuracy: 0.9777\n",
            " 57/469 [==>...........................] - ETA: 1:25 - loss: 0.0722 - sparse_categorical_accuracy: 0.9774\n",
            " 58/469 [==>...........................] - ETA: 1:25 - loss: 0.0727 - sparse_categorical_accuracy: 0.9775\n",
            " 59/469 [==>...........................] - ETA: 1:24 - loss: 0.0735 - sparse_categorical_accuracy: 0.9771\n",
            " 60/469 [==>...........................] - ETA: 1:24 - loss: 0.0737 - sparse_categorical_accuracy: 0.9770\n",
            " 61/469 [==>...........................] - ETA: 1:23 - loss: 0.0742 - sparse_categorical_accuracy: 0.9769\n",
            " 62/469 [==>...........................] - ETA: 1:23 - loss: 0.0740 - sparse_categorical_accuracy: 0.9772\n",
            " 63/469 [===>..........................] - ETA: 1:23 - loss: 0.0733 - sparse_categorical_accuracy: 0.9773\n",
            " 64/469 [===>..........................] - ETA: 1:22 - loss: 0.0735 - sparse_categorical_accuracy: 0.9773\n",
            " 65/469 [===>..........................] - ETA: 1:22 - loss: 0.0732 - sparse_categorical_accuracy: 0.9774\n",
            " 66/469 [===>..........................] - ETA: 1:22 - loss: 0.0726 - sparse_categorical_accuracy: 0.9776\n",
            " 67/469 [===>..........................] - ETA: 1:21 - loss: 0.0728 - sparse_categorical_accuracy: 0.9775\n",
            " 68/469 [===>..........................] - ETA: 1:21 - loss: 0.0722 - sparse_categorical_accuracy: 0.9777\n",
            " 69/469 [===>..........................] - ETA: 1:21 - loss: 0.0723 - sparse_categorical_accuracy: 0.9776\n",
            " 70/469 [===>..........................] - ETA: 1:20 - loss: 0.0721 - sparse_categorical_accuracy: 0.9776\n",
            " 71/469 [===>..........................] - ETA: 1:20 - loss: 0.0717 - sparse_categorical_accuracy: 0.9777\n",
            " 72/469 [===>..........................] - ETA: 1:20 - loss: 0.0714 - sparse_categorical_accuracy: 0.9779\n",
            " 73/469 [===>..........................] - ETA: 1:19 - loss: 0.0712 - sparse_categorical_accuracy: 0.9778\n",
            " 74/469 [===>..........................] - ETA: 1:19 - loss: 0.0706 - sparse_categorical_accuracy: 0.9780\n",
            " 75/469 [===>..........................] - ETA: 1:19 - loss: 0.0700 - sparse_categorical_accuracy: 0.9781\n",
            " 76/469 [===>..........................] - ETA: 1:18 - loss: 0.0716 - sparse_categorical_accuracy: 0.9777\n",
            " 77/469 [===>..........................] - ETA: 1:18 - loss: 0.0715 - sparse_categorical_accuracy: 0.9777\n",
            " 78/469 [===>..........................] - ETA: 1:18 - loss: 0.0722 - sparse_categorical_accuracy: 0.9777\n",
            " 79/469 [====>.........................] - ETA: 1:18 - loss: 0.0723 - sparse_categorical_accuracy: 0.9775\n",
            " 80/469 [====>.........................] - ETA: 1:17 - loss: 0.0721 - sparse_categorical_accuracy: 0.9774\n",
            " 81/469 [====>.........................] - ETA: 1:17 - loss: 0.0720 - sparse_categorical_accuracy: 0.9774\n",
            " 82/469 [====>.........................] - ETA: 1:17 - loss: 0.0717 - sparse_categorical_accuracy: 0.9776\n",
            " 83/469 [====>.........................] - ETA: 1:17 - loss: 0.0732 - sparse_categorical_accuracy: 0.9778\n",
            " 84/469 [====>.........................] - ETA: 1:16 - loss: 0.0728 - sparse_categorical_accuracy: 0.9780\n",
            " 85/469 [====>.........................] - ETA: 1:16 - loss: 0.0726 - sparse_categorical_accuracy: 0.9779\n",
            " 86/469 [====>.........................] - ETA: 1:16 - loss: 0.0727 - sparse_categorical_accuracy: 0.9780\n",
            " 87/469 [====>.........................] - ETA: 1:16 - loss: 0.0724 - sparse_categorical_accuracy: 0.9781\n",
            " 88/469 [====>.........................] - ETA: 1:15 - loss: 0.0721 - sparse_categorical_accuracy: 0.9782\n",
            " 89/469 [====>.........................] - ETA: 1:15 - loss: 0.0718 - sparse_categorical_accuracy: 0.9782\n",
            " 90/469 [====>.........................] - ETA: 1:15 - loss: 0.0715 - sparse_categorical_accuracy: 0.9783\n",
            " 91/469 [====>.........................] - ETA: 1:15 - loss: 0.0712 - sparse_categorical_accuracy: 0.9785\n",
            " 92/469 [====>.........................] - ETA: 1:14 - loss: 0.0719 - sparse_categorical_accuracy: 0.9783\n",
            " 93/469 [====>.........................] - ETA: 1:14 - loss: 0.0726 - sparse_categorical_accuracy: 0.9782\n",
            " 94/469 [=====>........................] - ETA: 1:14 - loss: 0.0725 - sparse_categorical_accuracy: 0.9781\n",
            " 95/469 [=====>........................] - ETA: 1:14 - loss: 0.0726 - sparse_categorical_accuracy: 0.9781\n",
            " 96/469 [=====>........................] - ETA: 1:13 - loss: 0.0724 - sparse_categorical_accuracy: 0.9781\n",
            " 97/469 [=====>........................] - ETA: 1:13 - loss: 0.0724 - sparse_categorical_accuracy: 0.9779\n",
            " 98/469 [=====>........................] - ETA: 1:13 - loss: 0.0724 - sparse_categorical_accuracy: 0.9779\n",
            " 99/469 [=====>........................] - ETA: 1:13 - loss: 0.0724 - sparse_categorical_accuracy: 0.9779\n",
            "100/469 [=====>........................] - ETA: 1:12 - loss: 0.0728 - sparse_categorical_accuracy: 0.9777\n",
            "101/469 [=====>........................] - ETA: 1:12 - loss: 0.0730 - sparse_categorical_accuracy: 0.9776\n",
            "102/469 [=====>........................] - ETA: 1:12 - loss: 0.0731 - sparse_categorical_accuracy: 0.9776\n",
            "103/469 [=====>........................] - ETA: 1:12 - loss: 0.0733 - sparse_categorical_accuracy: 0.9775\n",
            "104/469 [=====>........................] - ETA: 1:12 - loss: 0.0736 - sparse_categorical_accuracy: 0.9776\n",
            "105/469 [=====>........................] - ETA: 1:12 - loss: 0.0736 - sparse_categorical_accuracy: 0.9775\n",
            "106/469 [=====>........................] - ETA: 1:13 - loss: 0.0737 - sparse_categorical_accuracy: 0.9775\n",
            "107/469 [=====>........................] - ETA: 1:13 - loss: 0.0735 - sparse_categorical_accuracy: 0.9776\n",
            "108/469 [=====>........................] - ETA: 1:13 - loss: 0.0730 - sparse_categorical_accuracy: 0.9778\n",
            "109/469 [=====>........................] - ETA: 1:13 - loss: 0.0728 - sparse_categorical_accuracy: 0.9778\n",
            "110/469 [======>.......................] - ETA: 1:13 - loss: 0.0728 - sparse_categorical_accuracy: 0.9779\n",
            "111/469 [======>.......................] - ETA: 1:13 - loss: 0.0725 - sparse_categorical_accuracy: 0.9780\n",
            "112/469 [======>.......................] - ETA: 1:13 - loss: 0.0730 - sparse_categorical_accuracy: 0.9780\n",
            "113/469 [======>.......................] - ETA: 1:13 - loss: 0.0735 - sparse_categorical_accuracy: 0.9778\n",
            "114/469 [======>.......................] - ETA: 1:13 - loss: 0.0734 - sparse_categorical_accuracy: 0.9778\n",
            "115/469 [======>.......................] - ETA: 1:13 - loss: 0.0734 - sparse_categorical_accuracy: 0.9779\n",
            "116/469 [======>.......................] - ETA: 1:13 - loss: 0.0730 - sparse_categorical_accuracy: 0.9780\n",
            "117/469 [======>.......................] - ETA: 1:12 - loss: 0.0733 - sparse_categorical_accuracy: 0.9779\n",
            "118/469 [======>.......................] - ETA: 1:12 - loss: 0.0732 - sparse_categorical_accuracy: 0.9780\n",
            "119/469 [======>.......................] - ETA: 1:12 - loss: 0.0732 - sparse_categorical_accuracy: 0.9779\n",
            "120/469 [======>.......................] - ETA: 1:12 - loss: 0.0734 - sparse_categorical_accuracy: 0.9779\n",
            "121/469 [======>.......................] - ETA: 1:11 - loss: 0.0735 - sparse_categorical_accuracy: 0.9779\n",
            "122/469 [======>.......................] - ETA: 1:11 - loss: 0.0736 - sparse_categorical_accuracy: 0.9779\n",
            "123/469 [======>.......................] - ETA: 1:11 - loss: 0.0734 - sparse_categorical_accuracy: 0.9780\n",
            "124/469 [======>.......................] - ETA: 1:11 - loss: 0.0731 - sparse_categorical_accuracy: 0.9781\n",
            "125/469 [======>.......................] - ETA: 1:10 - loss: 0.0732 - sparse_categorical_accuracy: 0.9781\n",
            "126/469 [=======>......................] - ETA: 1:10 - loss: 0.0734 - sparse_categorical_accuracy: 0.9779\n",
            "127/469 [=======>......................] - ETA: 1:10 - loss: 0.0738 - sparse_categorical_accuracy: 0.9776\n",
            "128/469 [=======>......................] - ETA: 1:10 - loss: 0.0741 - sparse_categorical_accuracy: 0.9776\n",
            "129/469 [=======>......................] - ETA: 1:09 - loss: 0.0740 - sparse_categorical_accuracy: 0.9777\n",
            "130/469 [=======>......................] - ETA: 1:09 - loss: 0.0741 - sparse_categorical_accuracy: 0.9775\n",
            "131/469 [=======>......................] - ETA: 1:09 - loss: 0.0741 - sparse_categorical_accuracy: 0.9775\n",
            "132/469 [=======>......................] - ETA: 1:09 - loss: 0.0738 - sparse_categorical_accuracy: 0.9776\n",
            "133/469 [=======>......................] - ETA: 1:08 - loss: 0.0743 - sparse_categorical_accuracy: 0.9774\n",
            "134/469 [=======>......................] - ETA: 1:08 - loss: 0.0740 - sparse_categorical_accuracy: 0.9775\n",
            "135/469 [=======>......................] - ETA: 1:08 - loss: 0.0739 - sparse_categorical_accuracy: 0.9775\n",
            "136/469 [=======>......................] - ETA: 1:08 - loss: 0.0742 - sparse_categorical_accuracy: 0.9774\n",
            "137/469 [=======>......................] - ETA: 1:07 - loss: 0.0744 - sparse_categorical_accuracy: 0.9774\n",
            "138/469 [=======>......................] - ETA: 1:07 - loss: 0.0745 - sparse_categorical_accuracy: 0.9774\n",
            "139/469 [=======>......................] - ETA: 1:07 - loss: 0.0742 - sparse_categorical_accuracy: 0.9775\n",
            "140/469 [=======>......................] - ETA: 1:07 - loss: 0.0743 - sparse_categorical_accuracy: 0.9774\n",
            "141/469 [========>.....................] - ETA: 1:06 - loss: 0.0743 - sparse_categorical_accuracy: 0.9774\n",
            "142/469 [========>.....................] - ETA: 1:06 - loss: 0.0740 - sparse_categorical_accuracy: 0.9776\n",
            "143/469 [========>.....................] - ETA: 1:06 - loss: 0.0743 - sparse_categorical_accuracy: 0.9774\n",
            "144/469 [========>.....................] - ETA: 1:06 - loss: 0.0747 - sparse_categorical_accuracy: 0.9773\n",
            "145/469 [========>.....................] - ETA: 1:06 - loss: 0.0747 - sparse_categorical_accuracy: 0.9774\n",
            "146/469 [========>.....................] - ETA: 1:05 - loss: 0.0747 - sparse_categorical_accuracy: 0.9774\n",
            "147/469 [========>.....................] - ETA: 1:05 - loss: 0.0746 - sparse_categorical_accuracy: 0.9773\n",
            "148/469 [========>.....................] - ETA: 1:05 - loss: 0.0748 - sparse_categorical_accuracy: 0.9772\n",
            "149/469 [========>.....................] - ETA: 1:05 - loss: 0.0746 - sparse_categorical_accuracy: 0.9773\n",
            "150/469 [========>.....................] - ETA: 1:04 - loss: 0.0746 - sparse_categorical_accuracy: 0.9773\n",
            "151/469 [========>.....................] - ETA: 1:04 - loss: 0.0748 - sparse_categorical_accuracy: 0.9771\n",
            "152/469 [========>.....................] - ETA: 1:04 - loss: 0.0758 - sparse_categorical_accuracy: 0.9768\n",
            "153/469 [========>.....................] - ETA: 1:04 - loss: 0.0757 - sparse_categorical_accuracy: 0.9767\n",
            "154/469 [========>.....................] - ETA: 1:03 - loss: 0.0762 - sparse_categorical_accuracy: 0.9766\n",
            "155/469 [========>.....................] - ETA: 1:03 - loss: 0.0762 - sparse_categorical_accuracy: 0.9765\n",
            "156/469 [========>.....................] - ETA: 1:03 - loss: 0.0764 - sparse_categorical_accuracy: 0.9764\n",
            "157/469 [=========>....................] - ETA: 1:03 - loss: 0.0761 - sparse_categorical_accuracy: 0.9765\n",
            "158/469 [=========>....................] - ETA: 1:03 - loss: 0.0760 - sparse_categorical_accuracy: 0.9765\n",
            "159/469 [=========>....................] - ETA: 1:02 - loss: 0.0760 - sparse_categorical_accuracy: 0.9765\n",
            "160/469 [=========>....................] - ETA: 1:02 - loss: 0.0760 - sparse_categorical_accuracy: 0.9764\n",
            "161/469 [=========>....................] - ETA: 1:02 - loss: 0.0761 - sparse_categorical_accuracy: 0.9764\n",
            "162/469 [=========>....................] - ETA: 1:02 - loss: 0.0760 - sparse_categorical_accuracy: 0.9764\n",
            "163/469 [=========>....................] - ETA: 1:01 - loss: 0.0767 - sparse_categorical_accuracy: 0.9763\n",
            "164/469 [=========>....................] - ETA: 1:01 - loss: 0.0765 - sparse_categorical_accuracy: 0.9763\n",
            "165/469 [=========>....................] - ETA: 1:01 - loss: 0.0765 - sparse_categorical_accuracy: 0.9763\n",
            "166/469 [=========>....................] - ETA: 1:01 - loss: 0.0765 - sparse_categorical_accuracy: 0.9764\n",
            "167/469 [=========>....................] - ETA: 1:00 - loss: 0.0763 - sparse_categorical_accuracy: 0.9764\n",
            "168/469 [=========>....................] - ETA: 1:00 - loss: 0.0761 - sparse_categorical_accuracy: 0.9765\n",
            "169/469 [=========>....................] - ETA: 1:00 - loss: 0.0766 - sparse_categorical_accuracy: 0.9765\n",
            "170/469 [=========>....................] - ETA: 1:00 - loss: 0.0770 - sparse_categorical_accuracy: 0.9764\n",
            "171/469 [=========>....................] - ETA: 1:00 - loss: 0.0771 - sparse_categorical_accuracy: 0.9765\n",
            "172/469 [==========>...................] - ETA: 1:00 - loss: 0.0770 - sparse_categorical_accuracy: 0.9765\n",
            "173/469 [==========>...................] - ETA: 1:00 - loss: 0.0773 - sparse_categorical_accuracy: 0.9764\n",
            "174/469 [==========>...................] - ETA: 1:00 - loss: 0.0770 - sparse_categorical_accuracy: 0.9766\n",
            "175/469 [==========>...................] - ETA: 1:00 - loss: 0.0772 - sparse_categorical_accuracy: 0.9766\n",
            "176/469 [==========>...................] - ETA: 1:00 - loss: 0.0774 - sparse_categorical_accuracy: 0.9766\n",
            "177/469 [==========>...................] - ETA: 1:00 - loss: 0.0773 - sparse_categorical_accuracy: 0.9766\n",
            "178/469 [==========>...................] - ETA: 1:00 - loss: 0.0770 - sparse_categorical_accuracy: 0.9767\n",
            "179/469 [==========>...................] - ETA: 1:00 - loss: 0.0771 - sparse_categorical_accuracy: 0.9766\n",
            "180/469 [==========>...................] - ETA: 1:00 - loss: 0.0770 - sparse_categorical_accuracy: 0.9766\n",
            "181/469 [==========>...................] - ETA: 59s - loss: 0.0770 - sparse_categorical_accuracy: 0.9766 \n",
            "182/469 [==========>...................] - ETA: 59s - loss: 0.0773 - sparse_categorical_accuracy: 0.9765\n",
            "183/469 [==========>...................] - ETA: 59s - loss: 0.0772 - sparse_categorical_accuracy: 0.9766\n",
            "184/469 [==========>...................] - ETA: 59s - loss: 0.0772 - sparse_categorical_accuracy: 0.9765\n",
            "185/469 [==========>...................] - ETA: 58s - loss: 0.0774 - sparse_categorical_accuracy: 0.9764\n",
            "186/469 [==========>...................] - ETA: 58s - loss: 0.0778 - sparse_categorical_accuracy: 0.9763\n",
            "187/469 [==========>...................] - ETA: 58s - loss: 0.0777 - sparse_categorical_accuracy: 0.9763\n",
            "188/469 [===========>..................] - ETA: 58s - loss: 0.0777 - sparse_categorical_accuracy: 0.9764\n",
            "189/469 [===========>..................] - ETA: 57s - loss: 0.0777 - sparse_categorical_accuracy: 0.9763\n",
            "190/469 [===========>..................] - ETA: 57s - loss: 0.0775 - sparse_categorical_accuracy: 0.9764\n",
            "191/469 [===========>..................] - ETA: 57s - loss: 0.0773 - sparse_categorical_accuracy: 0.9764\n",
            "192/469 [===========>..................] - ETA: 57s - loss: 0.0775 - sparse_categorical_accuracy: 0.9764\n",
            "193/469 [===========>..................] - ETA: 57s - loss: 0.0777 - sparse_categorical_accuracy: 0.9764\n",
            "194/469 [===========>..................] - ETA: 56s - loss: 0.0777 - sparse_categorical_accuracy: 0.9764\n",
            "195/469 [===========>..................] - ETA: 56s - loss: 0.0779 - sparse_categorical_accuracy: 0.9764\n",
            "196/469 [===========>..................] - ETA: 56s - loss: 0.0778 - sparse_categorical_accuracy: 0.9764\n",
            "197/469 [===========>..................] - ETA: 56s - loss: 0.0776 - sparse_categorical_accuracy: 0.9765\n",
            "198/469 [===========>..................] - ETA: 55s - loss: 0.0774 - sparse_categorical_accuracy: 0.9766\n",
            "199/469 [===========>..................] - ETA: 55s - loss: 0.0772 - sparse_categorical_accuracy: 0.9767\n",
            "200/469 [===========>..................] - ETA: 55s - loss: 0.0770 - sparse_categorical_accuracy: 0.9768\n",
            "201/469 [===========>..................] - ETA: 55s - loss: 0.0770 - sparse_categorical_accuracy: 0.9768\n",
            "202/469 [===========>..................] - ETA: 54s - loss: 0.0768 - sparse_categorical_accuracy: 0.9769\n",
            "203/469 [===========>..................] - ETA: 54s - loss: 0.0766 - sparse_categorical_accuracy: 0.9769\n",
            "204/469 [============>.................] - ETA: 54s - loss: 0.0768 - sparse_categorical_accuracy: 0.9768\n",
            "205/469 [============>.................] - ETA: 54s - loss: 0.0766 - sparse_categorical_accuracy: 0.9769\n",
            "206/469 [============>.................] - ETA: 53s - loss: 0.0764 - sparse_categorical_accuracy: 0.9769\n",
            "207/469 [============>.................] - ETA: 53s - loss: 0.0766 - sparse_categorical_accuracy: 0.9768\n",
            "208/469 [============>.................] - ETA: 53s - loss: 0.0766 - sparse_categorical_accuracy: 0.9768\n",
            "209/469 [============>.................] - ETA: 53s - loss: 0.0764 - sparse_categorical_accuracy: 0.9769\n",
            "210/469 [============>.................] - ETA: 53s - loss: 0.0764 - sparse_categorical_accuracy: 0.9769\n",
            "211/469 [============>.................] - ETA: 52s - loss: 0.0763 - sparse_categorical_accuracy: 0.9770\n",
            "212/469 [============>.................] - ETA: 52s - loss: 0.0764 - sparse_categorical_accuracy: 0.9769\n",
            "213/469 [============>.................] - ETA: 52s - loss: 0.0763 - sparse_categorical_accuracy: 0.9770\n",
            "214/469 [============>.................] - ETA: 52s - loss: 0.0767 - sparse_categorical_accuracy: 0.9768\n",
            "215/469 [============>.................] - ETA: 51s - loss: 0.0764 - sparse_categorical_accuracy: 0.9769\n",
            "216/469 [============>.................] - ETA: 51s - loss: 0.0763 - sparse_categorical_accuracy: 0.9770\n",
            "217/469 [============>.................] - ETA: 51s - loss: 0.0768 - sparse_categorical_accuracy: 0.9770\n",
            "218/469 [============>.................] - ETA: 51s - loss: 0.0767 - sparse_categorical_accuracy: 0.9770\n",
            "219/469 [=============>................] - ETA: 50s - loss: 0.0766 - sparse_categorical_accuracy: 0.9771\n",
            "220/469 [=============>................] - ETA: 50s - loss: 0.0766 - sparse_categorical_accuracy: 0.9771\n",
            "221/469 [=============>................] - ETA: 50s - loss: 0.0766 - sparse_categorical_accuracy: 0.9770\n",
            "222/469 [=============>................] - ETA: 50s - loss: 0.0766 - sparse_categorical_accuracy: 0.9770\n",
            "223/469 [=============>................] - ETA: 50s - loss: 0.0766 - sparse_categorical_accuracy: 0.9770\n",
            "224/469 [=============>................] - ETA: 49s - loss: 0.0768 - sparse_categorical_accuracy: 0.9769\n",
            "225/469 [=============>................] - ETA: 49s - loss: 0.0769 - sparse_categorical_accuracy: 0.9769\n",
            "226/469 [=============>................] - ETA: 49s - loss: 0.0772 - sparse_categorical_accuracy: 0.9768\n",
            "227/469 [=============>................] - ETA: 49s - loss: 0.0772 - sparse_categorical_accuracy: 0.9768\n",
            "228/469 [=============>................] - ETA: 48s - loss: 0.0770 - sparse_categorical_accuracy: 0.9768\n",
            "229/469 [=============>................] - ETA: 48s - loss: 0.0770 - sparse_categorical_accuracy: 0.9768\n",
            "230/469 [=============>................] - ETA: 48s - loss: 0.0773 - sparse_categorical_accuracy: 0.9767\n",
            "231/469 [=============>................] - ETA: 48s - loss: 0.0772 - sparse_categorical_accuracy: 0.9768\n",
            "232/469 [=============>................] - ETA: 48s - loss: 0.0772 - sparse_categorical_accuracy: 0.9768\n",
            "233/469 [=============>................] - ETA: 47s - loss: 0.0774 - sparse_categorical_accuracy: 0.9767\n",
            "234/469 [=============>................] - ETA: 47s - loss: 0.0772 - sparse_categorical_accuracy: 0.9768\n",
            "235/469 [==============>...............] - ETA: 47s - loss: 0.0771 - sparse_categorical_accuracy: 0.9768\n",
            "236/469 [==============>...............] - ETA: 47s - loss: 0.0769 - sparse_categorical_accuracy: 0.9769\n",
            "237/469 [==============>...............] - ETA: 47s - loss: 0.0770 - sparse_categorical_accuracy: 0.9769\n",
            "238/469 [==============>...............] - ETA: 46s - loss: 0.0768 - sparse_categorical_accuracy: 0.9769\n",
            "239/469 [==============>...............] - ETA: 46s - loss: 0.0766 - sparse_categorical_accuracy: 0.9770\n",
            "240/469 [==============>...............] - ETA: 46s - loss: 0.0766 - sparse_categorical_accuracy: 0.9771\n",
            "241/469 [==============>...............] - ETA: 46s - loss: 0.0763 - sparse_categorical_accuracy: 0.9771\n",
            "242/469 [==============>...............] - ETA: 46s - loss: 0.0761 - sparse_categorical_accuracy: 0.9772\n",
            "243/469 [==============>...............] - ETA: 46s - loss: 0.0760 - sparse_categorical_accuracy: 0.9773\n",
            "244/469 [==============>...............] - ETA: 46s - loss: 0.0760 - sparse_categorical_accuracy: 0.9773\n",
            "245/469 [==============>...............] - ETA: 46s - loss: 0.0758 - sparse_categorical_accuracy: 0.9773\n",
            "246/469 [==============>...............] - ETA: 45s - loss: 0.0761 - sparse_categorical_accuracy: 0.9772\n",
            "247/469 [==============>...............] - ETA: 45s - loss: 0.0761 - sparse_categorical_accuracy: 0.9772\n",
            "248/469 [==============>...............] - ETA: 45s - loss: 0.0759 - sparse_categorical_accuracy: 0.9773\n",
            "249/469 [==============>...............] - ETA: 45s - loss: 0.0758 - sparse_categorical_accuracy: 0.9773\n",
            "250/469 [==============>...............] - ETA: 45s - loss: 0.0758 - sparse_categorical_accuracy: 0.9773\n",
            "251/469 [===============>..............] - ETA: 44s - loss: 0.0761 - sparse_categorical_accuracy: 0.9772\n",
            "252/469 [===============>..............] - ETA: 44s - loss: 0.0759 - sparse_categorical_accuracy: 0.9773\n",
            "253/469 [===============>..............] - ETA: 44s - loss: 0.0759 - sparse_categorical_accuracy: 0.9773\n",
            "254/469 [===============>..............] - ETA: 44s - loss: 0.0758 - sparse_categorical_accuracy: 0.9774\n",
            "255/469 [===============>..............] - ETA: 44s - loss: 0.0756 - sparse_categorical_accuracy: 0.9775\n",
            "256/469 [===============>..............] - ETA: 43s - loss: 0.0755 - sparse_categorical_accuracy: 0.9775\n",
            "257/469 [===============>..............] - ETA: 43s - loss: 0.0755 - sparse_categorical_accuracy: 0.9774\n",
            "258/469 [===============>..............] - ETA: 43s - loss: 0.0754 - sparse_categorical_accuracy: 0.9774\n",
            "259/469 [===============>..............] - ETA: 43s - loss: 0.0755 - sparse_categorical_accuracy: 0.9774\n",
            "260/469 [===============>..............] - ETA: 42s - loss: 0.0754 - sparse_categorical_accuracy: 0.9775\n",
            "261/469 [===============>..............] - ETA: 42s - loss: 0.0753 - sparse_categorical_accuracy: 0.9775\n",
            "262/469 [===============>..............] - ETA: 42s - loss: 0.0754 - sparse_categorical_accuracy: 0.9774\n",
            "263/469 [===============>..............] - ETA: 42s - loss: 0.0755 - sparse_categorical_accuracy: 0.9774\n",
            "264/469 [===============>..............] - ETA: 42s - loss: 0.0754 - sparse_categorical_accuracy: 0.9774\n",
            "265/469 [===============>..............] - ETA: 41s - loss: 0.0757 - sparse_categorical_accuracy: 0.9774\n",
            "266/469 [================>.............] - ETA: 41s - loss: 0.0756 - sparse_categorical_accuracy: 0.9774\n",
            "267/469 [================>.............] - ETA: 41s - loss: 0.0758 - sparse_categorical_accuracy: 0.9774\n",
            "268/469 [================>.............] - ETA: 41s - loss: 0.0760 - sparse_categorical_accuracy: 0.9773\n",
            "269/469 [================>.............] - ETA: 40s - loss: 0.0762 - sparse_categorical_accuracy: 0.9772\n",
            "270/469 [================>.............] - ETA: 40s - loss: 0.0761 - sparse_categorical_accuracy: 0.9773\n",
            "271/469 [================>.............] - ETA: 40s - loss: 0.0760 - sparse_categorical_accuracy: 0.9773\n",
            "272/469 [================>.............] - ETA: 40s - loss: 0.0760 - sparse_categorical_accuracy: 0.9773\n",
            "273/469 [================>.............] - ETA: 40s - loss: 0.0761 - sparse_categorical_accuracy: 0.9773\n",
            "274/469 [================>.............] - ETA: 39s - loss: 0.0762 - sparse_categorical_accuracy: 0.9772\n",
            "275/469 [================>.............] - ETA: 39s - loss: 0.0763 - sparse_categorical_accuracy: 0.9772\n",
            "276/469 [================>.............] - ETA: 39s - loss: 0.0761 - sparse_categorical_accuracy: 0.9773\n",
            "277/469 [================>.............] - ETA: 39s - loss: 0.0761 - sparse_categorical_accuracy: 0.9773\n",
            "278/469 [================>.............] - ETA: 39s - loss: 0.0760 - sparse_categorical_accuracy: 0.9773\n",
            "279/469 [================>.............] - ETA: 38s - loss: 0.0759 - sparse_categorical_accuracy: 0.9774\n",
            "280/469 [================>.............] - ETA: 38s - loss: 0.0757 - sparse_categorical_accuracy: 0.9775\n",
            "281/469 [================>.............] - ETA: 38s - loss: 0.0757 - sparse_categorical_accuracy: 0.9774\n",
            "282/469 [=================>............] - ETA: 38s - loss: 0.0757 - sparse_categorical_accuracy: 0.9775\n",
            "283/469 [=================>............] - ETA: 37s - loss: 0.0757 - sparse_categorical_accuracy: 0.9775\n",
            "284/469 [=================>............] - ETA: 37s - loss: 0.0755 - sparse_categorical_accuracy: 0.9776\n",
            "285/469 [=================>............] - ETA: 37s - loss: 0.0758 - sparse_categorical_accuracy: 0.9775\n",
            "286/469 [=================>............] - ETA: 37s - loss: 0.0758 - sparse_categorical_accuracy: 0.9775\n",
            "287/469 [=================>............] - ETA: 37s - loss: 0.0756 - sparse_categorical_accuracy: 0.9775\n",
            "288/469 [=================>............] - ETA: 36s - loss: 0.0757 - sparse_categorical_accuracy: 0.9775\n",
            "289/469 [=================>............] - ETA: 36s - loss: 0.0757 - sparse_categorical_accuracy: 0.9774\n",
            "290/469 [=================>............] - ETA: 36s - loss: 0.0761 - sparse_categorical_accuracy: 0.9773\n",
            "291/469 [=================>............] - ETA: 36s - loss: 0.0760 - sparse_categorical_accuracy: 0.9773\n",
            "292/469 [=================>............] - ETA: 36s - loss: 0.0759 - sparse_categorical_accuracy: 0.9774\n",
            "293/469 [=================>............] - ETA: 35s - loss: 0.0758 - sparse_categorical_accuracy: 0.9774\n",
            "294/469 [=================>............] - ETA: 35s - loss: 0.0757 - sparse_categorical_accuracy: 0.9774\n",
            "295/469 [=================>............] - ETA: 35s - loss: 0.0756 - sparse_categorical_accuracy: 0.9775\n",
            "296/469 [=================>............] - ETA: 35s - loss: 0.0758 - sparse_categorical_accuracy: 0.9774\n",
            "297/469 [=================>............] - ETA: 34s - loss: 0.0758 - sparse_categorical_accuracy: 0.9774\n",
            "298/469 [==================>...........] - ETA: 34s - loss: 0.0759 - sparse_categorical_accuracy: 0.9773\n",
            "299/469 [==================>...........] - ETA: 34s - loss: 0.0759 - sparse_categorical_accuracy: 0.9773\n",
            "300/469 [==================>...........] - ETA: 34s - loss: 0.0758 - sparse_categorical_accuracy: 0.9774\n",
            "301/469 [==================>...........] - ETA: 34s - loss: 0.0759 - sparse_categorical_accuracy: 0.9773\n",
            "302/469 [==================>...........] - ETA: 33s - loss: 0.0759 - sparse_categorical_accuracy: 0.9774\n",
            "303/469 [==================>...........] - ETA: 33s - loss: 0.0759 - sparse_categorical_accuracy: 0.9773\n",
            "304/469 [==================>...........] - ETA: 33s - loss: 0.0758 - sparse_categorical_accuracy: 0.9773\n",
            "305/469 [==================>...........] - ETA: 33s - loss: 0.0758 - sparse_categorical_accuracy: 0.9773\n",
            "306/469 [==================>...........] - ETA: 33s - loss: 0.0758 - sparse_categorical_accuracy: 0.9773\n",
            "307/469 [==================>...........] - ETA: 33s - loss: 0.0758 - sparse_categorical_accuracy: 0.9774\n",
            "308/469 [==================>...........] - ETA: 32s - loss: 0.0758 - sparse_categorical_accuracy: 0.9773\n",
            "309/469 [==================>...........] - ETA: 32s - loss: 0.0760 - sparse_categorical_accuracy: 0.9773\n",
            "310/469 [==================>...........] - ETA: 32s - loss: 0.0760 - sparse_categorical_accuracy: 0.9773\n",
            "311/469 [==================>...........] - ETA: 32s - loss: 0.0759 - sparse_categorical_accuracy: 0.9773\n",
            "312/469 [==================>...........] - ETA: 32s - loss: 0.0761 - sparse_categorical_accuracy: 0.9773\n",
            "313/469 [===================>..........] - ETA: 32s - loss: 0.0764 - sparse_categorical_accuracy: 0.9772\n",
            "314/469 [===================>..........] - ETA: 32s - loss: 0.0763 - sparse_categorical_accuracy: 0.9772\n",
            "315/469 [===================>..........] - ETA: 31s - loss: 0.0762 - sparse_categorical_accuracy: 0.9772\n",
            "316/469 [===================>..........] - ETA: 31s - loss: 0.0762 - sparse_categorical_accuracy: 0.9773\n",
            "317/469 [===================>..........] - ETA: 31s - loss: 0.0762 - sparse_categorical_accuracy: 0.9773\n",
            "318/469 [===================>..........] - ETA: 31s - loss: 0.0764 - sparse_categorical_accuracy: 0.9772\n",
            "319/469 [===================>..........] - ETA: 31s - loss: 0.0763 - sparse_categorical_accuracy: 0.9772\n",
            "320/469 [===================>..........] - ETA: 30s - loss: 0.0764 - sparse_categorical_accuracy: 0.9772\n",
            "321/469 [===================>..........] - ETA: 30s - loss: 0.0763 - sparse_categorical_accuracy: 0.9773\n",
            "322/469 [===================>..........] - ETA: 30s - loss: 0.0761 - sparse_categorical_accuracy: 0.9773\n",
            "323/469 [===================>..........] - ETA: 30s - loss: 0.0760 - sparse_categorical_accuracy: 0.9774\n",
            "324/469 [===================>..........] - ETA: 29s - loss: 0.0761 - sparse_categorical_accuracy: 0.9774\n",
            "325/469 [===================>..........] - ETA: 29s - loss: 0.0763 - sparse_categorical_accuracy: 0.9773\n",
            "326/469 [===================>..........] - ETA: 29s - loss: 0.0762 - sparse_categorical_accuracy: 0.9773\n",
            "327/469 [===================>..........] - ETA: 29s - loss: 0.0761 - sparse_categorical_accuracy: 0.9774\n",
            "328/469 [===================>..........] - ETA: 29s - loss: 0.0761 - sparse_categorical_accuracy: 0.9774\n",
            "329/469 [====================>.........] - ETA: 28s - loss: 0.0761 - sparse_categorical_accuracy: 0.9774\n",
            "330/469 [====================>.........] - ETA: 28s - loss: 0.0761 - sparse_categorical_accuracy: 0.9774\n",
            "331/469 [====================>.........] - ETA: 28s - loss: 0.0762 - sparse_categorical_accuracy: 0.9774\n",
            "332/469 [====================>.........] - ETA: 28s - loss: 0.0760 - sparse_categorical_accuracy: 0.9774\n",
            "333/469 [====================>.........] - ETA: 28s - loss: 0.0762 - sparse_categorical_accuracy: 0.9774\n",
            "334/469 [====================>.........] - ETA: 27s - loss: 0.0760 - sparse_categorical_accuracy: 0.9774\n",
            "335/469 [====================>.........] - ETA: 27s - loss: 0.0763 - sparse_categorical_accuracy: 0.9774\n",
            "336/469 [====================>.........] - ETA: 27s - loss: 0.0763 - sparse_categorical_accuracy: 0.9774\n",
            "337/469 [====================>.........] - ETA: 27s - loss: 0.0763 - sparse_categorical_accuracy: 0.9774\n",
            "338/469 [====================>.........] - ETA: 26s - loss: 0.0763 - sparse_categorical_accuracy: 0.9773\n",
            "339/469 [====================>.........] - ETA: 26s - loss: 0.0763 - sparse_categorical_accuracy: 0.9773\n",
            "340/469 [====================>.........] - ETA: 26s - loss: 0.0767 - sparse_categorical_accuracy: 0.9772\n",
            "341/469 [====================>.........] - ETA: 26s - loss: 0.0766 - sparse_categorical_accuracy: 0.9772\n",
            "342/469 [====================>.........] - ETA: 26s - loss: 0.0765 - sparse_categorical_accuracy: 0.9772\n",
            "343/469 [====================>.........] - ETA: 25s - loss: 0.0765 - sparse_categorical_accuracy: 0.9772\n",
            "344/469 [=====================>........] - ETA: 25s - loss: 0.0764 - sparse_categorical_accuracy: 0.9772\n",
            "345/469 [=====================>........] - ETA: 25s - loss: 0.0763 - sparse_categorical_accuracy: 0.9773\n",
            "346/469 [=====================>........] - ETA: 25s - loss: 0.0763 - sparse_categorical_accuracy: 0.9773\n",
            "347/469 [=====================>........] - ETA: 25s - loss: 0.0763 - sparse_categorical_accuracy: 0.9773\n",
            "348/469 [=====================>........] - ETA: 24s - loss: 0.0764 - sparse_categorical_accuracy: 0.9772\n",
            "349/469 [=====================>........] - ETA: 24s - loss: 0.0764 - sparse_categorical_accuracy: 0.9772\n",
            "350/469 [=====================>........] - ETA: 24s - loss: 0.0764 - sparse_categorical_accuracy: 0.9772\n",
            "351/469 [=====================>........] - ETA: 24s - loss: 0.0763 - sparse_categorical_accuracy: 0.9772\n",
            "352/469 [=====================>........] - ETA: 23s - loss: 0.0763 - sparse_categorical_accuracy: 0.9772\n",
            "353/469 [=====================>........] - ETA: 23s - loss: 0.0761 - sparse_categorical_accuracy: 0.9773\n",
            "354/469 [=====================>........] - ETA: 23s - loss: 0.0761 - sparse_categorical_accuracy: 0.9773\n",
            "355/469 [=====================>........] - ETA: 23s - loss: 0.0759 - sparse_categorical_accuracy: 0.9774\n",
            "356/469 [=====================>........] - ETA: 23s - loss: 0.0758 - sparse_categorical_accuracy: 0.9774\n",
            "357/469 [=====================>........] - ETA: 22s - loss: 0.0757 - sparse_categorical_accuracy: 0.9774\n",
            "358/469 [=====================>........] - ETA: 22s - loss: 0.0756 - sparse_categorical_accuracy: 0.9775\n",
            "359/469 [=====================>........] - ETA: 22s - loss: 0.0758 - sparse_categorical_accuracy: 0.9774\n",
            "360/469 [======================>.......] - ETA: 22s - loss: 0.0758 - sparse_categorical_accuracy: 0.9774\n",
            "361/469 [======================>.......] - ETA: 22s - loss: 0.0758 - sparse_categorical_accuracy: 0.9773\n",
            "362/469 [======================>.......] - ETA: 21s - loss: 0.0758 - sparse_categorical_accuracy: 0.9773\n",
            "363/469 [======================>.......] - ETA: 21s - loss: 0.0758 - sparse_categorical_accuracy: 0.9773\n",
            "364/469 [======================>.......] - ETA: 21s - loss: 0.0757 - sparse_categorical_accuracy: 0.9773\n",
            "365/469 [======================>.......] - ETA: 21s - loss: 0.0757 - sparse_categorical_accuracy: 0.9774\n",
            "366/469 [======================>.......] - ETA: 21s - loss: 0.0757 - sparse_categorical_accuracy: 0.9774\n",
            "367/469 [======================>.......] - ETA: 20s - loss: 0.0757 - sparse_categorical_accuracy: 0.9774\n",
            "368/469 [======================>.......] - ETA: 20s - loss: 0.0757 - sparse_categorical_accuracy: 0.9774\n",
            "369/469 [======================>.......] - ETA: 20s - loss: 0.0757 - sparse_categorical_accuracy: 0.9773\n",
            "370/469 [======================>.......] - ETA: 20s - loss: 0.0756 - sparse_categorical_accuracy: 0.9774\n",
            "371/469 [======================>.......] - ETA: 20s - loss: 0.0756 - sparse_categorical_accuracy: 0.9774\n",
            "372/469 [======================>.......] - ETA: 19s - loss: 0.0756 - sparse_categorical_accuracy: 0.9774\n",
            "373/469 [======================>.......] - ETA: 19s - loss: 0.0757 - sparse_categorical_accuracy: 0.9774\n",
            "374/469 [======================>.......] - ETA: 19s - loss: 0.0755 - sparse_categorical_accuracy: 0.9774\n",
            "375/469 [======================>.......] - ETA: 19s - loss: 0.0754 - sparse_categorical_accuracy: 0.9775\n",
            "376/469 [=======================>......] - ETA: 19s - loss: 0.0754 - sparse_categorical_accuracy: 0.9774\n",
            "377/469 [=======================>......] - ETA: 18s - loss: 0.0753 - sparse_categorical_accuracy: 0.9774\n",
            "378/469 [=======================>......] - ETA: 18s - loss: 0.0753 - sparse_categorical_accuracy: 0.9774\n",
            "379/469 [=======================>......] - ETA: 18s - loss: 0.0755 - sparse_categorical_accuracy: 0.9774\n",
            "380/469 [=======================>......] - ETA: 18s - loss: 0.0756 - sparse_categorical_accuracy: 0.9773\n",
            "381/469 [=======================>......] - ETA: 18s - loss: 0.0755 - sparse_categorical_accuracy: 0.9774\n",
            "382/469 [=======================>......] - ETA: 18s - loss: 0.0756 - sparse_categorical_accuracy: 0.9774\n",
            "383/469 [=======================>......] - ETA: 17s - loss: 0.0757 - sparse_categorical_accuracy: 0.9774\n",
            "384/469 [=======================>......] - ETA: 17s - loss: 0.0756 - sparse_categorical_accuracy: 0.9774\n",
            "385/469 [=======================>......] - ETA: 17s - loss: 0.0756 - sparse_categorical_accuracy: 0.9774\n",
            "386/469 [=======================>......] - ETA: 17s - loss: 0.0754 - sparse_categorical_accuracy: 0.9775\n",
            "387/469 [=======================>......] - ETA: 16s - loss: 0.0755 - sparse_categorical_accuracy: 0.9775\n",
            "388/469 [=======================>......] - ETA: 16s - loss: 0.0755 - sparse_categorical_accuracy: 0.9775\n",
            "389/469 [=======================>......] - ETA: 16s - loss: 0.0754 - sparse_categorical_accuracy: 0.9775\n",
            "390/469 [=======================>......] - ETA: 16s - loss: 0.0754 - sparse_categorical_accuracy: 0.9775\n",
            "391/469 [========================>.....] - ETA: 16s - loss: 0.0753 - sparse_categorical_accuracy: 0.9775\n",
            "392/469 [========================>.....] - ETA: 15s - loss: 0.0753 - sparse_categorical_accuracy: 0.9775\n",
            "393/469 [========================>.....] - ETA: 15s - loss: 0.0752 - sparse_categorical_accuracy: 0.9776\n",
            "394/469 [========================>.....] - ETA: 15s - loss: 0.0751 - sparse_categorical_accuracy: 0.9776\n",
            "395/469 [========================>.....] - ETA: 15s - loss: 0.0751 - sparse_categorical_accuracy: 0.9775\n",
            "396/469 [========================>.....] - ETA: 15s - loss: 0.0750 - sparse_categorical_accuracy: 0.9776\n",
            "397/469 [========================>.....] - ETA: 14s - loss: 0.0750 - sparse_categorical_accuracy: 0.9776\n",
            "398/469 [========================>.....] - ETA: 14s - loss: 0.0750 - sparse_categorical_accuracy: 0.9776\n",
            "399/469 [========================>.....] - ETA: 14s - loss: 0.0749 - sparse_categorical_accuracy: 0.9777\n",
            "400/469 [========================>.....] - ETA: 14s - loss: 0.0748 - sparse_categorical_accuracy: 0.9777\n",
            "401/469 [========================>.....] - ETA: 14s - loss: 0.0747 - sparse_categorical_accuracy: 0.9777\n",
            "402/469 [========================>.....] - ETA: 13s - loss: 0.0748 - sparse_categorical_accuracy: 0.9777\n",
            "403/469 [========================>.....] - ETA: 13s - loss: 0.0748 - sparse_categorical_accuracy: 0.9777\n",
            "404/469 [========================>.....] - ETA: 13s - loss: 0.0750 - sparse_categorical_accuracy: 0.9777\n",
            "405/469 [========================>.....] - ETA: 13s - loss: 0.0749 - sparse_categorical_accuracy: 0.9777\n",
            "406/469 [========================>.....] - ETA: 13s - loss: 0.0751 - sparse_categorical_accuracy: 0.9777\n",
            "407/469 [=========================>....] - ETA: 12s - loss: 0.0751 - sparse_categorical_accuracy: 0.9777\n",
            "408/469 [=========================>....] - ETA: 12s - loss: 0.0751 - sparse_categorical_accuracy: 0.9777\n",
            "409/469 [=========================>....] - ETA: 12s - loss: 0.0751 - sparse_categorical_accuracy: 0.9777\n",
            "410/469 [=========================>....] - ETA: 12s - loss: 0.0751 - sparse_categorical_accuracy: 0.9777\n",
            "411/469 [=========================>....] - ETA: 11s - loss: 0.0751 - sparse_categorical_accuracy: 0.9777\n",
            "412/469 [=========================>....] - ETA: 11s - loss: 0.0753 - sparse_categorical_accuracy: 0.9777\n",
            "413/469 [=========================>....] - ETA: 11s - loss: 0.0752 - sparse_categorical_accuracy: 0.9777\n",
            "414/469 [=========================>....] - ETA: 11s - loss: 0.0753 - sparse_categorical_accuracy: 0.9777\n",
            "415/469 [=========================>....] - ETA: 11s - loss: 0.0752 - sparse_categorical_accuracy: 0.9777\n",
            "416/469 [=========================>....] - ETA: 10s - loss: 0.0753 - sparse_categorical_accuracy: 0.9777\n",
            "417/469 [=========================>....] - ETA: 10s - loss: 0.0752 - sparse_categorical_accuracy: 0.9777\n",
            "418/469 [=========================>....] - ETA: 10s - loss: 0.0752 - sparse_categorical_accuracy: 0.9777\n",
            "419/469 [=========================>....] - ETA: 10s - loss: 0.0752 - sparse_categorical_accuracy: 0.9776\n",
            "420/469 [=========================>....] - ETA: 10s - loss: 0.0754 - sparse_categorical_accuracy: 0.9775\n",
            "421/469 [=========================>....] - ETA: 9s - loss: 0.0754 - sparse_categorical_accuracy: 0.9775 \n",
            "422/469 [=========================>....] - ETA: 9s - loss: 0.0753 - sparse_categorical_accuracy: 0.9776\n",
            "423/469 [==========================>...] - ETA: 9s - loss: 0.0752 - sparse_categorical_accuracy: 0.9776\n",
            "424/469 [==========================>...] - ETA: 9s - loss: 0.0752 - sparse_categorical_accuracy: 0.9776\n",
            "425/469 [==========================>...] - ETA: 9s - loss: 0.0752 - sparse_categorical_accuracy: 0.9776\n",
            "426/469 [==========================>...] - ETA: 8s - loss: 0.0752 - sparse_categorical_accuracy: 0.9776\n",
            "427/469 [==========================>...] - ETA: 8s - loss: 0.0753 - sparse_categorical_accuracy: 0.9776\n",
            "428/469 [==========================>...] - ETA: 8s - loss: 0.0754 - sparse_categorical_accuracy: 0.9776\n",
            "429/469 [==========================>...] - ETA: 8s - loss: 0.0754 - sparse_categorical_accuracy: 0.9776\n",
            "430/469 [==========================>...] - ETA: 8s - loss: 0.0754 - sparse_categorical_accuracy: 0.9775\n",
            "431/469 [==========================>...] - ETA: 7s - loss: 0.0753 - sparse_categorical_accuracy: 0.9776\n",
            "432/469 [==========================>...] - ETA: 7s - loss: 0.0752 - sparse_categorical_accuracy: 0.9776\n",
            "433/469 [==========================>...] - ETA: 7s - loss: 0.0753 - sparse_categorical_accuracy: 0.9775\n",
            "434/469 [==========================>...] - ETA: 7s - loss: 0.0753 - sparse_categorical_accuracy: 0.9776\n",
            "435/469 [==========================>...] - ETA: 7s - loss: 0.0752 - sparse_categorical_accuracy: 0.9776\n",
            "436/469 [==========================>...] - ETA: 6s - loss: 0.0752 - sparse_categorical_accuracy: 0.9776\n",
            "437/469 [==========================>...] - ETA: 6s - loss: 0.0751 - sparse_categorical_accuracy: 0.9776\n",
            "438/469 [===========================>..] - ETA: 6s - loss: 0.0753 - sparse_categorical_accuracy: 0.9775\n",
            "439/469 [===========================>..] - ETA: 6s - loss: 0.0753 - sparse_categorical_accuracy: 0.9775\n",
            "440/469 [===========================>..] - ETA: 6s - loss: 0.0752 - sparse_categorical_accuracy: 0.9776\n",
            "441/469 [===========================>..] - ETA: 5s - loss: 0.0751 - sparse_categorical_accuracy: 0.9776\n",
            "442/469 [===========================>..] - ETA: 5s - loss: 0.0750 - sparse_categorical_accuracy: 0.9776\n",
            "443/469 [===========================>..] - ETA: 5s - loss: 0.0750 - sparse_categorical_accuracy: 0.9777\n",
            "444/469 [===========================>..] - ETA: 5s - loss: 0.0750 - sparse_categorical_accuracy: 0.9777\n",
            "445/469 [===========================>..] - ETA: 4s - loss: 0.0750 - sparse_categorical_accuracy: 0.9777\n",
            "446/469 [===========================>..] - ETA: 4s - loss: 0.0749 - sparse_categorical_accuracy: 0.9777\n",
            "447/469 [===========================>..] - ETA: 4s - loss: 0.0748 - sparse_categorical_accuracy: 0.9777\n",
            "448/469 [===========================>..] - ETA: 4s - loss: 0.0747 - sparse_categorical_accuracy: 0.9778\n",
            "449/469 [===========================>..] - ETA: 4s - loss: 0.0747 - sparse_categorical_accuracy: 0.9778\n",
            "450/469 [===========================>..] - ETA: 3s - loss: 0.0747 - sparse_categorical_accuracy: 0.9778\n",
            "451/469 [===========================>..] - ETA: 3s - loss: 0.0747 - sparse_categorical_accuracy: 0.9778\n",
            "452/469 [===========================>..] - ETA: 3s - loss: 0.0746 - sparse_categorical_accuracy: 0.9778\n",
            "453/469 [===========================>..] - ETA: 3s - loss: 0.0746 - sparse_categorical_accuracy: 0.9778\n",
            "454/469 [============================>.] - ETA: 3s - loss: 0.0746 - sparse_categorical_accuracy: 0.9777\n",
            "455/469 [============================>.] - ETA: 2s - loss: 0.0747 - sparse_categorical_accuracy: 0.9778\n",
            "456/469 [============================>.] - ETA: 2s - loss: 0.0747 - sparse_categorical_accuracy: 0.9777\n",
            "457/469 [============================>.] - ETA: 2s - loss: 0.0746 - sparse_categorical_accuracy: 0.9778\n",
            "458/469 [============================>.] - ETA: 2s - loss: 0.0746 - sparse_categorical_accuracy: 0.9778\n",
            "459/469 [============================>.] - ETA: 2s - loss: 0.0746 - sparse_categorical_accuracy: 0.9778\n",
            "460/469 [============================>.] - ETA: 1s - loss: 0.0745 - sparse_categorical_accuracy: 0.9778\n",
            "461/469 [============================>.] - ETA: 1s - loss: 0.0745 - sparse_categorical_accuracy: 0.9778\n",
            "462/469 [============================>.] - ETA: 1s - loss: 0.0744 - sparse_categorical_accuracy: 0.9778\n",
            "463/469 [============================>.] - ETA: 1s - loss: 0.0743 - sparse_categorical_accuracy: 0.9778\n",
            "464/469 [============================>.] - ETA: 1s - loss: 0.0745 - sparse_categorical_accuracy: 0.9778\n",
            "465/469 [============================>.] - ETA: 0s - loss: 0.0745 - sparse_categorical_accuracy: 0.9778\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.0745 - sparse_categorical_accuracy: 0.9778\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.0745 - sparse_categorical_accuracy: 0.9778\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0745 - sparse_categorical_accuracy: 0.9778\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0744 - sparse_categorical_accuracy: 0.9779\n",
            " 20%|██        | 1/5 [39:49<2:07:25, 1911.46s/trial, best loss: -0.9830999970436096]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/04/16 01:11:49 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 98s 208ms/step - loss: 0.0744 - sparse_categorical_accuracy: 0.9779\n",
            "\n",
            "1/1 [==============================] - ETA: 0s\n",
            "1/1 [==============================] - 0s 137ms/step\n",
            "\n",
            " 20%|██        | 1/5 [39:49<2:07:25, 1911.46s/trial, best loss: -0.9830999970436096]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\n",
            "  1/469 [..............................] - ETA: 7:17 - loss: 5.5776 - sparse_categorical_accuracy: 0.0000e+00\n",
            "  2/469 [..............................] - ETA: 3:16 - loss: 5.5718 - sparse_categorical_accuracy: 0.0000e+00\n",
            "  3/469 [..............................] - ETA: 3:07 - loss: 5.5647 - sparse_categorical_accuracy: 0.0000e+00\n",
            "  4/469 [..............................] - ETA: 3:03 - loss: 5.5514 - sparse_categorical_accuracy: 0.0000e+00\n",
            "  5/469 [..............................] - ETA: 3:00 - loss: 5.5379 - sparse_categorical_accuracy: 0.0016    \n",
            "  6/469 [..............................] - ETA: 2:58 - loss: 5.5227 - sparse_categorical_accuracy: 0.0039\n",
            "  7/469 [..............................] - ETA: 3:01 - loss: 5.5051 - sparse_categorical_accuracy: 0.0156\n",
            "  8/469 [..............................] - ETA: 3:08 - loss: 5.4843 - sparse_categorical_accuracy: 0.0322\n",
            "  9/469 [..............................] - ETA: 3:19 - loss: 5.4616 - sparse_categorical_accuracy: 0.0356\n",
            " 10/469 [..............................] - ETA: 3:31 - loss: 5.4361 - sparse_categorical_accuracy: 0.0453\n",
            " 11/469 [..............................] - ETA: 3:39 - loss: 5.4023 - sparse_categorical_accuracy: 0.0561\n",
            " 12/469 [..............................] - ETA: 3:43 - loss: 5.3604 - sparse_categorical_accuracy: 0.0632\n",
            " 13/469 [..............................] - ETA: 3:47 - loss: 5.3048 - sparse_categorical_accuracy: 0.0679\n",
            " 14/469 [..............................] - ETA: 3:43 - loss: 5.2310 - sparse_categorical_accuracy: 0.0709\n",
            " 15/469 [..............................] - ETA: 3:40 - loss: 5.1341 - sparse_categorical_accuracy: 0.0740\n",
            " 16/469 [>.............................] - ETA: 3:36 - loss: 5.0088 - sparse_categorical_accuracy: 0.0771\n",
            " 17/469 [>.............................] - ETA: 3:34 - loss: 4.8654 - sparse_categorical_accuracy: 0.0846\n",
            " 18/469 [>.............................] - ETA: 3:30 - loss: 4.7280 - sparse_categorical_accuracy: 0.0898\n",
            " 19/469 [>.............................] - ETA: 3:28 - loss: 4.5994 - sparse_categorical_accuracy: 0.0933\n",
            " 20/469 [>.............................] - ETA: 3:26 - loss: 4.4744 - sparse_categorical_accuracy: 0.1027\n",
            " 21/469 [>.............................] - ETA: 3:24 - loss: 4.3677 - sparse_categorical_accuracy: 0.1086\n",
            " 22/469 [>.............................] - ETA: 3:22 - loss: 4.2555 - sparse_categorical_accuracy: 0.1161\n",
            " 23/469 [>.............................] - ETA: 3:21 - loss: 4.1546 - sparse_categorical_accuracy: 0.1260\n",
            " 24/469 [>.............................] - ETA: 3:19 - loss: 4.0625 - sparse_categorical_accuracy: 0.1370\n",
            " 25/469 [>.............................] - ETA: 3:18 - loss: 3.9636 - sparse_categorical_accuracy: 0.1500\n",
            " 26/469 [>.............................] - ETA: 3:16 - loss: 3.8841 - sparse_categorical_accuracy: 0.1562\n",
            " 27/469 [>.............................] - ETA: 3:15 - loss: 3.8238 - sparse_categorical_accuracy: 0.1658\n",
            " 28/469 [>.............................] - ETA: 3:13 - loss: 3.7667 - sparse_categorical_accuracy: 0.1738\n",
            " 29/469 [>.............................] - ETA: 3:12 - loss: 3.6970 - sparse_categorical_accuracy: 0.1813\n",
            " 30/469 [>.............................] - ETA: 3:12 - loss: 3.6531 - sparse_categorical_accuracy: 0.1865\n",
            " 31/469 [>.............................] - ETA: 3:11 - loss: 3.6087 - sparse_categorical_accuracy: 0.1958\n",
            " 32/469 [=>............................] - ETA: 3:10 - loss: 3.5556 - sparse_categorical_accuracy: 0.2039\n",
            " 33/469 [=>............................] - ETA: 3:09 - loss: 3.4892 - sparse_categorical_accuracy: 0.2147\n",
            " 34/469 [=>............................] - ETA: 3:08 - loss: 3.4266 - sparse_categorical_accuracy: 0.2233\n",
            " 35/469 [=>............................] - ETA: 3:07 - loss: 3.3602 - sparse_categorical_accuracy: 0.2364\n",
            " 36/469 [=>............................] - ETA: 3:06 - loss: 3.2958 - sparse_categorical_accuracy: 0.2483\n",
            " 37/469 [=>............................] - ETA: 3:05 - loss: 3.2348 - sparse_categorical_accuracy: 0.2587\n",
            " 38/469 [=>............................] - ETA: 3:04 - loss: 3.1799 - sparse_categorical_accuracy: 0.2681\n",
            " 39/469 [=>............................] - ETA: 3:05 - loss: 3.1208 - sparse_categorical_accuracy: 0.2792\n",
            " 40/469 [=>............................] - ETA: 3:07 - loss: 3.0681 - sparse_categorical_accuracy: 0.2891\n",
            " 41/469 [=>............................] - ETA: 3:09 - loss: 3.0161 - sparse_categorical_accuracy: 0.2992\n",
            " 42/469 [=>............................] - ETA: 3:10 - loss: 2.9645 - sparse_categorical_accuracy: 0.3086\n",
            " 43/469 [=>............................] - ETA: 3:12 - loss: 2.9145 - sparse_categorical_accuracy: 0.3185\n",
            " 44/469 [=>............................] - ETA: 3:12 - loss: 2.8659 - sparse_categorical_accuracy: 0.3285\n",
            " 45/469 [=>............................] - ETA: 3:11 - loss: 2.8191 - sparse_categorical_accuracy: 0.3378\n",
            " 46/469 [=>............................] - ETA: 3:10 - loss: 2.7712 - sparse_categorical_accuracy: 0.3480\n",
            " 47/469 [==>...........................] - ETA: 3:09 - loss: 2.7293 - sparse_categorical_accuracy: 0.3570\n",
            " 48/469 [==>...........................] - ETA: 3:09 - loss: 2.6925 - sparse_categorical_accuracy: 0.3634\n",
            " 49/469 [==>...........................] - ETA: 3:08 - loss: 2.6527 - sparse_categorical_accuracy: 0.3718\n",
            " 50/469 [==>...........................] - ETA: 3:07 - loss: 2.6134 - sparse_categorical_accuracy: 0.3802\n",
            " 51/469 [==>...........................] - ETA: 3:06 - loss: 2.5783 - sparse_categorical_accuracy: 0.3866\n",
            " 52/469 [==>...........................] - ETA: 3:05 - loss: 2.5376 - sparse_categorical_accuracy: 0.3956\n",
            " 53/469 [==>...........................] - ETA: 3:04 - loss: 2.5032 - sparse_categorical_accuracy: 0.4024\n",
            " 54/469 [==>...........................] - ETA: 3:04 - loss: 2.4717 - sparse_categorical_accuracy: 0.4089\n",
            " 55/469 [==>...........................] - ETA: 3:03 - loss: 2.4393 - sparse_categorical_accuracy: 0.4149\n",
            " 56/469 [==>...........................] - ETA: 3:03 - loss: 2.4064 - sparse_categorical_accuracy: 0.4223\n",
            " 57/469 [==>...........................] - ETA: 3:02 - loss: 2.3758 - sparse_categorical_accuracy: 0.4287\n",
            " 58/469 [==>...........................] - ETA: 3:01 - loss: 2.3458 - sparse_categorical_accuracy: 0.4348\n",
            " 59/469 [==>...........................] - ETA: 3:00 - loss: 2.3159 - sparse_categorical_accuracy: 0.4412\n",
            " 60/469 [==>...........................] - ETA: 2:59 - loss: 2.2877 - sparse_categorical_accuracy: 0.4467\n",
            " 61/469 [==>...........................] - ETA: 2:59 - loss: 2.2632 - sparse_categorical_accuracy: 0.4518\n",
            " 62/469 [==>...........................] - ETA: 2:58 - loss: 2.2370 - sparse_categorical_accuracy: 0.4575\n",
            " 63/469 [===>..........................] - ETA: 2:57 - loss: 2.2140 - sparse_categorical_accuracy: 0.4619\n",
            " 64/469 [===>..........................] - ETA: 2:56 - loss: 2.1891 - sparse_categorical_accuracy: 0.4678\n",
            " 65/469 [===>..........................] - ETA: 2:56 - loss: 2.1645 - sparse_categorical_accuracy: 0.4728\n",
            " 66/469 [===>..........................] - ETA: 2:55 - loss: 2.1417 - sparse_categorical_accuracy: 0.4782\n",
            " 67/469 [===>..........................] - ETA: 2:54 - loss: 2.1218 - sparse_categorical_accuracy: 0.4824\n",
            " 68/469 [===>..........................] - ETA: 2:53 - loss: 2.1007 - sparse_categorical_accuracy: 0.4866\n",
            " 69/469 [===>..........................] - ETA: 2:53 - loss: 2.0791 - sparse_categorical_accuracy: 0.4914\n",
            " 70/469 [===>..........................] - ETA: 2:53 - loss: 2.0578 - sparse_categorical_accuracy: 0.4959\n",
            " 71/469 [===>..........................] - ETA: 2:54 - loss: 2.0368 - sparse_categorical_accuracy: 0.5006\n",
            " 72/469 [===>..........................] - ETA: 2:54 - loss: 2.0187 - sparse_categorical_accuracy: 0.5043\n",
            " 73/469 [===>..........................] - ETA: 2:55 - loss: 1.9981 - sparse_categorical_accuracy: 0.5091\n",
            " 74/469 [===>..........................] - ETA: 2:55 - loss: 1.9815 - sparse_categorical_accuracy: 0.5124\n",
            " 75/469 [===>..........................] - ETA: 2:55 - loss: 1.9623 - sparse_categorical_accuracy: 0.5170\n",
            " 76/469 [===>..........................] - ETA: 2:54 - loss: 1.9438 - sparse_categorical_accuracy: 0.5216\n",
            " 77/469 [===>..........................] - ETA: 2:54 - loss: 1.9277 - sparse_categorical_accuracy: 0.5250\n",
            " 78/469 [===>..........................] - ETA: 2:53 - loss: 1.9091 - sparse_categorical_accuracy: 0.5291\n",
            " 79/469 [====>.........................] - ETA: 2:52 - loss: 1.8919 - sparse_categorical_accuracy: 0.5328\n",
            " 80/469 [====>.........................] - ETA: 2:51 - loss: 1.8751 - sparse_categorical_accuracy: 0.5366\n",
            " 81/469 [====>.........................] - ETA: 2:50 - loss: 1.8580 - sparse_categorical_accuracy: 0.5401\n",
            " 82/469 [====>.........................] - ETA: 2:50 - loss: 1.8417 - sparse_categorical_accuracy: 0.5436\n",
            " 83/469 [====>.........................] - ETA: 2:49 - loss: 1.8279 - sparse_categorical_accuracy: 0.5461\n",
            " 84/469 [====>.........................] - ETA: 2:48 - loss: 1.8118 - sparse_categorical_accuracy: 0.5496\n",
            " 85/469 [====>.........................] - ETA: 2:48 - loss: 1.7975 - sparse_categorical_accuracy: 0.5528\n",
            " 86/469 [====>.........................] - ETA: 2:47 - loss: 1.7805 - sparse_categorical_accuracy: 0.5571\n",
            " 87/469 [====>.........................] - ETA: 2:46 - loss: 1.7666 - sparse_categorical_accuracy: 0.5603\n",
            " 88/469 [====>.........................] - ETA: 2:46 - loss: 1.7547 - sparse_categorical_accuracy: 0.5627\n",
            " 89/469 [====>.........................] - ETA: 2:45 - loss: 1.7415 - sparse_categorical_accuracy: 0.5658\n",
            " 90/469 [====>.........................] - ETA: 2:44 - loss: 1.7268 - sparse_categorical_accuracy: 0.5690\n",
            " 91/469 [====>.........................] - ETA: 2:44 - loss: 1.7146 - sparse_categorical_accuracy: 0.5718\n",
            " 92/469 [====>.........................] - ETA: 2:43 - loss: 1.7013 - sparse_categorical_accuracy: 0.5747\n",
            " 93/469 [====>.........................] - ETA: 2:42 - loss: 1.6894 - sparse_categorical_accuracy: 0.5772\n",
            " 94/469 [=====>........................] - ETA: 2:42 - loss: 1.6768 - sparse_categorical_accuracy: 0.5798\n",
            " 95/469 [=====>........................] - ETA: 2:41 - loss: 1.6645 - sparse_categorical_accuracy: 0.5822\n",
            " 96/469 [=====>........................] - ETA: 2:40 - loss: 1.6524 - sparse_categorical_accuracy: 0.5850\n",
            " 97/469 [=====>........................] - ETA: 2:40 - loss: 1.6409 - sparse_categorical_accuracy: 0.5875\n",
            " 98/469 [=====>........................] - ETA: 2:39 - loss: 1.6305 - sparse_categorical_accuracy: 0.5898\n",
            " 99/469 [=====>........................] - ETA: 2:38 - loss: 1.6181 - sparse_categorical_accuracy: 0.5926\n",
            "100/469 [=====>........................] - ETA: 2:38 - loss: 1.6062 - sparse_categorical_accuracy: 0.5951\n",
            "101/469 [=====>........................] - ETA: 2:37 - loss: 1.5977 - sparse_categorical_accuracy: 0.5967\n",
            "102/469 [=====>........................] - ETA: 2:37 - loss: 1.5861 - sparse_categorical_accuracy: 0.5993\n",
            "103/469 [=====>........................] - ETA: 2:37 - loss: 1.5745 - sparse_categorical_accuracy: 0.6021\n",
            "104/469 [=====>........................] - ETA: 2:38 - loss: 1.5629 - sparse_categorical_accuracy: 0.6049\n",
            "105/469 [=====>........................] - ETA: 2:38 - loss: 1.5525 - sparse_categorical_accuracy: 0.6071\n",
            "106/469 [=====>........................] - ETA: 2:38 - loss: 1.5423 - sparse_categorical_accuracy: 0.6093\n",
            "107/469 [=====>........................] - ETA: 2:38 - loss: 1.5319 - sparse_categorical_accuracy: 0.6118\n",
            "108/469 [=====>........................] - ETA: 2:37 - loss: 1.5215 - sparse_categorical_accuracy: 0.6143\n",
            "109/469 [=====>........................] - ETA: 2:37 - loss: 1.5136 - sparse_categorical_accuracy: 0.6161\n",
            "110/469 [======>.......................] - ETA: 2:36 - loss: 1.5037 - sparse_categorical_accuracy: 0.6185\n",
            "111/469 [======>.......................] - ETA: 2:36 - loss: 1.4945 - sparse_categorical_accuracy: 0.6208\n",
            "112/469 [======>.......................] - ETA: 2:35 - loss: 1.4853 - sparse_categorical_accuracy: 0.6230\n",
            "113/469 [======>.......................] - ETA: 2:35 - loss: 1.4762 - sparse_categorical_accuracy: 0.6253\n",
            "114/469 [======>.......................] - ETA: 2:34 - loss: 1.4674 - sparse_categorical_accuracy: 0.6276\n",
            "115/469 [======>.......................] - ETA: 2:33 - loss: 1.4585 - sparse_categorical_accuracy: 0.6292\n",
            "116/469 [======>.......................] - ETA: 2:33 - loss: 1.4501 - sparse_categorical_accuracy: 0.6312\n",
            "117/469 [======>.......................] - ETA: 2:32 - loss: 1.4407 - sparse_categorical_accuracy: 0.6335\n",
            "118/469 [======>.......................] - ETA: 2:32 - loss: 1.4332 - sparse_categorical_accuracy: 0.6350\n",
            "119/469 [======>.......................] - ETA: 2:31 - loss: 1.4240 - sparse_categorical_accuracy: 0.6370\n",
            "120/469 [======>.......................] - ETA: 2:31 - loss: 1.4168 - sparse_categorical_accuracy: 0.6386\n",
            "121/469 [======>.......................] - ETA: 2:30 - loss: 1.4097 - sparse_categorical_accuracy: 0.6401\n",
            "122/469 [======>.......................] - ETA: 2:29 - loss: 1.4014 - sparse_categorical_accuracy: 0.6421\n",
            "123/469 [======>.......................] - ETA: 2:29 - loss: 1.3947 - sparse_categorical_accuracy: 0.6437\n",
            "124/469 [======>.......................] - ETA: 2:28 - loss: 1.3868 - sparse_categorical_accuracy: 0.6455\n",
            "125/469 [======>.......................] - ETA: 2:28 - loss: 1.3778 - sparse_categorical_accuracy: 0.6476\n",
            "126/469 [=======>......................] - ETA: 2:27 - loss: 1.3710 - sparse_categorical_accuracy: 0.6494\n",
            "127/469 [=======>......................] - ETA: 2:27 - loss: 1.3632 - sparse_categorical_accuracy: 0.6513\n",
            "128/469 [=======>......................] - ETA: 2:26 - loss: 1.3552 - sparse_categorical_accuracy: 0.6530\n",
            "129/469 [=======>......................] - ETA: 2:26 - loss: 1.3477 - sparse_categorical_accuracy: 0.6550\n",
            "130/469 [=======>......................] - ETA: 2:25 - loss: 1.3403 - sparse_categorical_accuracy: 0.6567\n",
            "131/469 [=======>......................] - ETA: 2:24 - loss: 1.3328 - sparse_categorical_accuracy: 0.6584\n",
            "132/469 [=======>......................] - ETA: 2:24 - loss: 1.3250 - sparse_categorical_accuracy: 0.6604\n",
            "133/469 [=======>......................] - ETA: 2:23 - loss: 1.3172 - sparse_categorical_accuracy: 0.6624\n",
            "134/469 [=======>......................] - ETA: 2:23 - loss: 1.3110 - sparse_categorical_accuracy: 0.6638\n",
            "135/469 [=======>......................] - ETA: 2:23 - loss: 1.3037 - sparse_categorical_accuracy: 0.6655\n",
            "136/469 [=======>......................] - ETA: 2:23 - loss: 1.2968 - sparse_categorical_accuracy: 0.6672\n",
            "137/469 [=======>......................] - ETA: 2:23 - loss: 1.2903 - sparse_categorical_accuracy: 0.6689\n",
            "138/469 [=======>......................] - ETA: 2:23 - loss: 1.2834 - sparse_categorical_accuracy: 0.6705\n",
            "139/469 [=======>......................] - ETA: 2:23 - loss: 1.2770 - sparse_categorical_accuracy: 0.6720\n",
            "140/469 [=======>......................] - ETA: 2:22 - loss: 1.2710 - sparse_categorical_accuracy: 0.6736\n",
            "141/469 [========>.....................] - ETA: 2:22 - loss: 1.2644 - sparse_categorical_accuracy: 0.6749\n",
            "142/469 [========>.....................] - ETA: 2:21 - loss: 1.2579 - sparse_categorical_accuracy: 0.6765\n",
            "143/469 [========>.....................] - ETA: 2:20 - loss: 1.2519 - sparse_categorical_accuracy: 0.6781\n",
            "144/469 [========>.....................] - ETA: 2:20 - loss: 1.2465 - sparse_categorical_accuracy: 0.6794\n",
            "145/469 [========>.....................] - ETA: 2:19 - loss: 1.2402 - sparse_categorical_accuracy: 0.6809\n",
            "146/469 [========>.....................] - ETA: 2:19 - loss: 1.2353 - sparse_categorical_accuracy: 0.6821\n",
            "147/469 [========>.....................] - ETA: 2:18 - loss: 1.2296 - sparse_categorical_accuracy: 0.6833\n",
            "148/469 [========>.....................] - ETA: 2:18 - loss: 1.2235 - sparse_categorical_accuracy: 0.6850\n",
            "149/469 [========>.....................] - ETA: 2:17 - loss: 1.2179 - sparse_categorical_accuracy: 0.6863\n",
            "150/469 [========>.....................] - ETA: 2:17 - loss: 1.2120 - sparse_categorical_accuracy: 0.6877\n",
            "151/469 [========>.....................] - ETA: 2:16 - loss: 1.2060 - sparse_categorical_accuracy: 0.6891\n",
            "152/469 [========>.....................] - ETA: 2:16 - loss: 1.2008 - sparse_categorical_accuracy: 0.6902\n",
            "153/469 [========>.....................] - ETA: 2:15 - loss: 1.1956 - sparse_categorical_accuracy: 0.6914\n",
            "154/469 [========>.....................] - ETA: 2:15 - loss: 1.1909 - sparse_categorical_accuracy: 0.6924\n",
            "155/469 [========>.....................] - ETA: 2:14 - loss: 1.1864 - sparse_categorical_accuracy: 0.6933\n",
            "156/469 [========>.....................] - ETA: 2:14 - loss: 1.1810 - sparse_categorical_accuracy: 0.6946\n",
            "157/469 [=========>....................] - ETA: 2:13 - loss: 1.1755 - sparse_categorical_accuracy: 0.6958\n",
            "158/469 [=========>....................] - ETA: 2:12 - loss: 1.1700 - sparse_categorical_accuracy: 0.6971\n",
            "159/469 [=========>....................] - ETA: 2:12 - loss: 1.1649 - sparse_categorical_accuracy: 0.6981\n",
            "160/469 [=========>....................] - ETA: 2:11 - loss: 1.1599 - sparse_categorical_accuracy: 0.6993\n",
            "161/469 [=========>....................] - ETA: 2:11 - loss: 1.1556 - sparse_categorical_accuracy: 0.7003\n",
            "162/469 [=========>....................] - ETA: 2:10 - loss: 1.1500 - sparse_categorical_accuracy: 0.7016\n",
            "163/469 [=========>....................] - ETA: 2:10 - loss: 1.1456 - sparse_categorical_accuracy: 0.7025\n",
            "164/469 [=========>....................] - ETA: 2:09 - loss: 1.1405 - sparse_categorical_accuracy: 0.7036\n",
            "165/469 [=========>....................] - ETA: 2:09 - loss: 1.1367 - sparse_categorical_accuracy: 0.7047\n",
            "166/469 [=========>....................] - ETA: 2:09 - loss: 1.1318 - sparse_categorical_accuracy: 0.7059\n",
            "167/469 [=========>....................] - ETA: 2:08 - loss: 1.1269 - sparse_categorical_accuracy: 0.7070\n",
            "168/469 [=========>....................] - ETA: 2:08 - loss: 1.1226 - sparse_categorical_accuracy: 0.7081\n",
            "169/469 [=========>....................] - ETA: 2:08 - loss: 1.1182 - sparse_categorical_accuracy: 0.7092\n",
            "170/469 [=========>....................] - ETA: 2:08 - loss: 1.1139 - sparse_categorical_accuracy: 0.7101\n",
            "171/469 [=========>....................] - ETA: 2:08 - loss: 1.1096 - sparse_categorical_accuracy: 0.7110\n",
            "172/469 [==========>...................] - ETA: 2:07 - loss: 1.1050 - sparse_categorical_accuracy: 0.7122\n",
            "173/469 [==========>...................] - ETA: 2:07 - loss: 1.1003 - sparse_categorical_accuracy: 0.7133\n",
            "174/469 [==========>...................] - ETA: 2:06 - loss: 1.0956 - sparse_categorical_accuracy: 0.7145\n",
            "175/469 [==========>...................] - ETA: 2:06 - loss: 1.0918 - sparse_categorical_accuracy: 0.7156\n",
            "176/469 [==========>...................] - ETA: 2:05 - loss: 1.0878 - sparse_categorical_accuracy: 0.7165\n",
            "177/469 [==========>...................] - ETA: 2:05 - loss: 1.0836 - sparse_categorical_accuracy: 0.7176\n",
            "178/469 [==========>...................] - ETA: 2:04 - loss: 1.0796 - sparse_categorical_accuracy: 0.7185\n",
            "179/469 [==========>...................] - ETA: 2:03 - loss: 1.0754 - sparse_categorical_accuracy: 0.7195\n",
            "180/469 [==========>...................] - ETA: 2:03 - loss: 1.0715 - sparse_categorical_accuracy: 0.7204\n",
            "181/469 [==========>...................] - ETA: 2:02 - loss: 1.0677 - sparse_categorical_accuracy: 0.7210\n",
            "182/469 [==========>...................] - ETA: 2:02 - loss: 1.0630 - sparse_categorical_accuracy: 0.7221\n",
            "183/469 [==========>...................] - ETA: 2:01 - loss: 1.0587 - sparse_categorical_accuracy: 0.7234\n",
            "184/469 [==========>...................] - ETA: 2:01 - loss: 1.0547 - sparse_categorical_accuracy: 0.7244\n",
            "185/469 [==========>...................] - ETA: 2:00 - loss: 1.0508 - sparse_categorical_accuracy: 0.7253\n",
            "186/469 [==========>...................] - ETA: 2:00 - loss: 1.0478 - sparse_categorical_accuracy: 0.7260\n",
            "187/469 [==========>...................] - ETA: 1:59 - loss: 1.0443 - sparse_categorical_accuracy: 0.7268\n",
            "188/469 [===========>..................] - ETA: 1:59 - loss: 1.0409 - sparse_categorical_accuracy: 0.7276\n",
            "189/469 [===========>..................] - ETA: 1:58 - loss: 1.0366 - sparse_categorical_accuracy: 0.7288\n",
            "190/469 [===========>..................] - ETA: 1:58 - loss: 1.0330 - sparse_categorical_accuracy: 0.7295\n",
            "191/469 [===========>..................] - ETA: 1:57 - loss: 1.0293 - sparse_categorical_accuracy: 0.7303\n",
            "192/469 [===========>..................] - ETA: 1:57 - loss: 1.0258 - sparse_categorical_accuracy: 0.7313\n",
            "193/469 [===========>..................] - ETA: 1:56 - loss: 1.0226 - sparse_categorical_accuracy: 0.7321\n",
            "194/469 [===========>..................] - ETA: 1:56 - loss: 1.0190 - sparse_categorical_accuracy: 0.7331\n",
            "195/469 [===========>..................] - ETA: 1:55 - loss: 1.0162 - sparse_categorical_accuracy: 0.7339\n",
            "196/469 [===========>..................] - ETA: 1:55 - loss: 1.0124 - sparse_categorical_accuracy: 0.7348\n",
            "197/469 [===========>..................] - ETA: 1:54 - loss: 1.0083 - sparse_categorical_accuracy: 0.7358\n",
            "198/469 [===========>..................] - ETA: 1:54 - loss: 1.0047 - sparse_categorical_accuracy: 0.7368\n",
            "199/469 [===========>..................] - ETA: 1:53 - loss: 1.0011 - sparse_categorical_accuracy: 0.7376\n",
            "200/469 [===========>..................] - ETA: 1:53 - loss: 0.9976 - sparse_categorical_accuracy: 0.7385\n",
            "201/469 [===========>..................] - ETA: 1:53 - loss: 0.9938 - sparse_categorical_accuracy: 0.7395\n",
            "202/469 [===========>..................] - ETA: 1:53 - loss: 0.9903 - sparse_categorical_accuracy: 0.7403\n",
            "203/469 [===========>..................] - ETA: 1:53 - loss: 0.9865 - sparse_categorical_accuracy: 0.7413\n",
            "204/469 [============>.................] - ETA: 1:52 - loss: 0.9833 - sparse_categorical_accuracy: 0.7421\n",
            "205/469 [============>.................] - ETA: 1:52 - loss: 0.9796 - sparse_categorical_accuracy: 0.7430\n",
            "206/469 [============>.................] - ETA: 1:51 - loss: 0.9764 - sparse_categorical_accuracy: 0.7437\n",
            "207/469 [============>.................] - ETA: 1:51 - loss: 0.9736 - sparse_categorical_accuracy: 0.7445\n",
            "208/469 [============>.................] - ETA: 1:50 - loss: 0.9703 - sparse_categorical_accuracy: 0.7454\n",
            "209/469 [============>.................] - ETA: 1:50 - loss: 0.9674 - sparse_categorical_accuracy: 0.7460\n",
            "210/469 [============>.................] - ETA: 1:49 - loss: 0.9642 - sparse_categorical_accuracy: 0.7469\n",
            "211/469 [============>.................] - ETA: 1:49 - loss: 0.9610 - sparse_categorical_accuracy: 0.7476\n",
            "212/469 [============>.................] - ETA: 1:48 - loss: 0.9573 - sparse_categorical_accuracy: 0.7486\n",
            "213/469 [============>.................] - ETA: 1:48 - loss: 0.9541 - sparse_categorical_accuracy: 0.7494\n",
            "214/469 [============>.................] - ETA: 1:47 - loss: 0.9511 - sparse_categorical_accuracy: 0.7501\n",
            "215/469 [============>.................] - ETA: 1:47 - loss: 0.9480 - sparse_categorical_accuracy: 0.7509\n",
            "216/469 [============>.................] - ETA: 1:46 - loss: 0.9450 - sparse_categorical_accuracy: 0.7517\n",
            "217/469 [============>.................] - ETA: 1:46 - loss: 0.9420 - sparse_categorical_accuracy: 0.7525\n",
            "218/469 [============>.................] - ETA: 1:45 - loss: 0.9387 - sparse_categorical_accuracy: 0.7533\n",
            "219/469 [=============>................] - ETA: 1:45 - loss: 0.9354 - sparse_categorical_accuracy: 0.7541\n",
            "220/469 [=============>................] - ETA: 1:44 - loss: 0.9325 - sparse_categorical_accuracy: 0.7548\n",
            "221/469 [=============>................] - ETA: 1:44 - loss: 0.9290 - sparse_categorical_accuracy: 0.7557\n",
            "222/469 [=============>................] - ETA: 1:43 - loss: 0.9260 - sparse_categorical_accuracy: 0.7564\n",
            "223/469 [=============>................] - ETA: 1:43 - loss: 0.9236 - sparse_categorical_accuracy: 0.7571\n",
            "224/469 [=============>................] - ETA: 1:43 - loss: 0.9204 - sparse_categorical_accuracy: 0.7579\n",
            "225/469 [=============>................] - ETA: 1:42 - loss: 0.9172 - sparse_categorical_accuracy: 0.7587\n",
            "226/469 [=============>................] - ETA: 1:42 - loss: 0.9142 - sparse_categorical_accuracy: 0.7594\n",
            "227/469 [=============>................] - ETA: 1:41 - loss: 0.9114 - sparse_categorical_accuracy: 0.7601\n",
            "228/469 [=============>................] - ETA: 1:41 - loss: 0.9085 - sparse_categorical_accuracy: 0.7608\n",
            "229/469 [=============>................] - ETA: 1:40 - loss: 0.9060 - sparse_categorical_accuracy: 0.7615\n",
            "230/469 [=============>................] - ETA: 1:40 - loss: 0.9030 - sparse_categorical_accuracy: 0.7622\n",
            "231/469 [=============>................] - ETA: 1:39 - loss: 0.8999 - sparse_categorical_accuracy: 0.7630\n",
            "232/469 [=============>................] - ETA: 1:39 - loss: 0.8970 - sparse_categorical_accuracy: 0.7638\n",
            "233/469 [=============>................] - ETA: 1:39 - loss: 0.8944 - sparse_categorical_accuracy: 0.7643\n",
            "234/469 [=============>................] - ETA: 1:39 - loss: 0.8919 - sparse_categorical_accuracy: 0.7649\n",
            "235/469 [==============>...............] - ETA: 1:38 - loss: 0.8892 - sparse_categorical_accuracy: 0.7655\n",
            "236/469 [==============>...............] - ETA: 1:38 - loss: 0.8866 - sparse_categorical_accuracy: 0.7663\n",
            "237/469 [==============>...............] - ETA: 1:38 - loss: 0.8842 - sparse_categorical_accuracy: 0.7668\n",
            "238/469 [==============>...............] - ETA: 1:37 - loss: 0.8813 - sparse_categorical_accuracy: 0.7676\n",
            "239/469 [==============>...............] - ETA: 1:37 - loss: 0.8783 - sparse_categorical_accuracy: 0.7683\n",
            "240/469 [==============>...............] - ETA: 1:36 - loss: 0.8757 - sparse_categorical_accuracy: 0.7689\n",
            "241/469 [==============>...............] - ETA: 1:36 - loss: 0.8727 - sparse_categorical_accuracy: 0.7696\n",
            "242/469 [==============>...............] - ETA: 1:35 - loss: 0.8697 - sparse_categorical_accuracy: 0.7705\n",
            "243/469 [==============>...............] - ETA: 1:35 - loss: 0.8673 - sparse_categorical_accuracy: 0.7711\n",
            "244/469 [==============>...............] - ETA: 1:34 - loss: 0.8647 - sparse_categorical_accuracy: 0.7716\n",
            "245/469 [==============>...............] - ETA: 1:34 - loss: 0.8623 - sparse_categorical_accuracy: 0.7723\n",
            "246/469 [==============>...............] - ETA: 1:33 - loss: 0.8595 - sparse_categorical_accuracy: 0.7730\n",
            "247/469 [==============>...............] - ETA: 1:33 - loss: 0.8575 - sparse_categorical_accuracy: 0.7735\n",
            "248/469 [==============>...............] - ETA: 1:32 - loss: 0.8547 - sparse_categorical_accuracy: 0.7743\n",
            "249/469 [==============>...............] - ETA: 1:32 - loss: 0.8519 - sparse_categorical_accuracy: 0.7750\n",
            "250/469 [==============>...............] - ETA: 1:32 - loss: 0.8496 - sparse_categorical_accuracy: 0.7757\n",
            "251/469 [===============>..............] - ETA: 1:31 - loss: 0.8471 - sparse_categorical_accuracy: 0.7764\n",
            "252/469 [===============>..............] - ETA: 1:31 - loss: 0.8447 - sparse_categorical_accuracy: 0.7768\n",
            "253/469 [===============>..............] - ETA: 1:30 - loss: 0.8428 - sparse_categorical_accuracy: 0.7771\n",
            "254/469 [===============>..............] - ETA: 1:30 - loss: 0.8402 - sparse_categorical_accuracy: 0.7777\n",
            "255/469 [===============>..............] - ETA: 1:29 - loss: 0.8378 - sparse_categorical_accuracy: 0.7782\n",
            "256/469 [===============>..............] - ETA: 1:29 - loss: 0.8359 - sparse_categorical_accuracy: 0.7787\n",
            "257/469 [===============>..............] - ETA: 1:28 - loss: 0.8332 - sparse_categorical_accuracy: 0.7794\n",
            "258/469 [===============>..............] - ETA: 1:28 - loss: 0.8306 - sparse_categorical_accuracy: 0.7801\n",
            "259/469 [===============>..............] - ETA: 1:27 - loss: 0.8282 - sparse_categorical_accuracy: 0.7807\n",
            "260/469 [===============>..............] - ETA: 1:27 - loss: 0.8261 - sparse_categorical_accuracy: 0.7812\n",
            "261/469 [===============>..............] - ETA: 1:27 - loss: 0.8241 - sparse_categorical_accuracy: 0.7816\n",
            "262/469 [===============>..............] - ETA: 1:26 - loss: 0.8219 - sparse_categorical_accuracy: 0.7822\n",
            "263/469 [===============>..............] - ETA: 1:26 - loss: 0.8196 - sparse_categorical_accuracy: 0.7829\n",
            "264/469 [===============>..............] - ETA: 1:25 - loss: 0.8174 - sparse_categorical_accuracy: 0.7834\n",
            "265/469 [===============>..............] - ETA: 1:25 - loss: 0.8149 - sparse_categorical_accuracy: 0.7841\n",
            "266/469 [================>.............] - ETA: 1:25 - loss: 0.8122 - sparse_categorical_accuracy: 0.7848\n",
            "267/469 [================>.............] - ETA: 1:24 - loss: 0.8101 - sparse_categorical_accuracy: 0.7854\n",
            "268/469 [================>.............] - ETA: 1:24 - loss: 0.8079 - sparse_categorical_accuracy: 0.7859\n",
            "269/469 [================>.............] - ETA: 1:24 - loss: 0.8055 - sparse_categorical_accuracy: 0.7865\n",
            "270/469 [================>.............] - ETA: 1:23 - loss: 0.8031 - sparse_categorical_accuracy: 0.7870\n",
            "271/469 [================>.............] - ETA: 1:23 - loss: 0.8009 - sparse_categorical_accuracy: 0.7876\n",
            "272/469 [================>.............] - ETA: 1:23 - loss: 0.7987 - sparse_categorical_accuracy: 0.7881\n",
            "273/469 [================>.............] - ETA: 1:22 - loss: 0.7965 - sparse_categorical_accuracy: 0.7886\n",
            "274/469 [================>.............] - ETA: 1:22 - loss: 0.7942 - sparse_categorical_accuracy: 0.7891\n",
            "275/469 [================>.............] - ETA: 1:21 - loss: 0.7921 - sparse_categorical_accuracy: 0.7897\n",
            "276/469 [================>.............] - ETA: 1:21 - loss: 0.7902 - sparse_categorical_accuracy: 0.7903\n",
            "277/469 [================>.............] - ETA: 1:20 - loss: 0.7881 - sparse_categorical_accuracy: 0.7908\n",
            "278/469 [================>.............] - ETA: 1:20 - loss: 0.7861 - sparse_categorical_accuracy: 0.7913\n",
            "279/469 [================>.............] - ETA: 1:19 - loss: 0.7838 - sparse_categorical_accuracy: 0.7920\n",
            "280/469 [================>.............] - ETA: 1:19 - loss: 0.7818 - sparse_categorical_accuracy: 0.7926\n",
            "281/469 [================>.............] - ETA: 1:19 - loss: 0.7802 - sparse_categorical_accuracy: 0.7930\n",
            "282/469 [=================>............] - ETA: 1:18 - loss: 0.7785 - sparse_categorical_accuracy: 0.7935\n",
            "283/469 [=================>............] - ETA: 1:18 - loss: 0.7763 - sparse_categorical_accuracy: 0.7941\n",
            "284/469 [=================>............] - ETA: 1:17 - loss: 0.7744 - sparse_categorical_accuracy: 0.7946\n",
            "285/469 [=================>............] - ETA: 1:17 - loss: 0.7723 - sparse_categorical_accuracy: 0.7951\n",
            "286/469 [=================>............] - ETA: 1:16 - loss: 0.7704 - sparse_categorical_accuracy: 0.7955\n",
            "287/469 [=================>............] - ETA: 1:16 - loss: 0.7686 - sparse_categorical_accuracy: 0.7960\n",
            "288/469 [=================>............] - ETA: 1:15 - loss: 0.7665 - sparse_categorical_accuracy: 0.7966\n",
            "289/469 [=================>............] - ETA: 1:15 - loss: 0.7643 - sparse_categorical_accuracy: 0.7972\n",
            "290/469 [=================>............] - ETA: 1:15 - loss: 0.7626 - sparse_categorical_accuracy: 0.7976\n",
            "291/469 [=================>............] - ETA: 1:14 - loss: 0.7608 - sparse_categorical_accuracy: 0.7981\n",
            "292/469 [=================>............] - ETA: 1:14 - loss: 0.7589 - sparse_categorical_accuracy: 0.7986\n",
            "293/469 [=================>............] - ETA: 1:13 - loss: 0.7569 - sparse_categorical_accuracy: 0.7991\n",
            "294/469 [=================>............] - ETA: 1:13 - loss: 0.7551 - sparse_categorical_accuracy: 0.7995\n",
            "295/469 [=================>............] - ETA: 1:12 - loss: 0.7529 - sparse_categorical_accuracy: 0.8001\n",
            "296/469 [=================>............] - ETA: 1:12 - loss: 0.7511 - sparse_categorical_accuracy: 0.8005\n",
            "297/469 [=================>............] - ETA: 1:12 - loss: 0.7494 - sparse_categorical_accuracy: 0.8010\n",
            "298/469 [==================>...........] - ETA: 1:11 - loss: 0.7478 - sparse_categorical_accuracy: 0.8013\n",
            "299/469 [==================>...........] - ETA: 1:11 - loss: 0.7459 - sparse_categorical_accuracy: 0.8017\n",
            "300/469 [==================>...........] - ETA: 1:11 - loss: 0.7444 - sparse_categorical_accuracy: 0.8021\n",
            "301/469 [==================>...........] - ETA: 1:10 - loss: 0.7424 - sparse_categorical_accuracy: 0.8026\n",
            "302/469 [==================>...........] - ETA: 1:10 - loss: 0.7406 - sparse_categorical_accuracy: 0.8031\n",
            "303/469 [==================>...........] - ETA: 1:10 - loss: 0.7389 - sparse_categorical_accuracy: 0.8034\n",
            "304/469 [==================>...........] - ETA: 1:09 - loss: 0.7373 - sparse_categorical_accuracy: 0.8037\n",
            "305/469 [==================>...........] - ETA: 1:09 - loss: 0.7355 - sparse_categorical_accuracy: 0.8042\n",
            "306/469 [==================>...........] - ETA: 1:08 - loss: 0.7340 - sparse_categorical_accuracy: 0.8046\n",
            "307/469 [==================>...........] - ETA: 1:08 - loss: 0.7322 - sparse_categorical_accuracy: 0.8050\n",
            "308/469 [==================>...........] - ETA: 1:07 - loss: 0.7303 - sparse_categorical_accuracy: 0.8055\n",
            "309/469 [==================>...........] - ETA: 1:07 - loss: 0.7288 - sparse_categorical_accuracy: 0.8059\n",
            "310/469 [==================>...........] - ETA: 1:06 - loss: 0.7270 - sparse_categorical_accuracy: 0.8064\n",
            "311/469 [==================>...........] - ETA: 1:06 - loss: 0.7255 - sparse_categorical_accuracy: 0.8068\n",
            "312/469 [==================>...........] - ETA: 1:06 - loss: 0.7242 - sparse_categorical_accuracy: 0.8072\n",
            "313/469 [===================>..........] - ETA: 1:05 - loss: 0.7226 - sparse_categorical_accuracy: 0.8075\n",
            "314/469 [===================>..........] - ETA: 1:05 - loss: 0.7212 - sparse_categorical_accuracy: 0.8078\n",
            "315/469 [===================>..........] - ETA: 1:04 - loss: 0.7199 - sparse_categorical_accuracy: 0.8081\n",
            "316/469 [===================>..........] - ETA: 1:04 - loss: 0.7183 - sparse_categorical_accuracy: 0.8085\n",
            "317/469 [===================>..........] - ETA: 1:03 - loss: 0.7170 - sparse_categorical_accuracy: 0.8089\n",
            "318/469 [===================>..........] - ETA: 1:03 - loss: 0.7156 - sparse_categorical_accuracy: 0.8092\n",
            "319/469 [===================>..........] - ETA: 1:03 - loss: 0.7138 - sparse_categorical_accuracy: 0.8097\n",
            "320/469 [===================>..........] - ETA: 1:02 - loss: 0.7123 - sparse_categorical_accuracy: 0.8101\n",
            "321/469 [===================>..........] - ETA: 1:02 - loss: 0.7104 - sparse_categorical_accuracy: 0.8107\n",
            "322/469 [===================>..........] - ETA: 1:01 - loss: 0.7088 - sparse_categorical_accuracy: 0.8111\n",
            "323/469 [===================>..........] - ETA: 1:01 - loss: 0.7073 - sparse_categorical_accuracy: 0.8114\n",
            "324/469 [===================>..........] - ETA: 1:00 - loss: 0.7056 - sparse_categorical_accuracy: 0.8118\n",
            "325/469 [===================>..........] - ETA: 1:00 - loss: 0.7046 - sparse_categorical_accuracy: 0.8121\n",
            "326/469 [===================>..........] - ETA: 1:00 - loss: 0.7028 - sparse_categorical_accuracy: 0.8126\n",
            "327/469 [===================>..........] - ETA: 59s - loss: 0.7011 - sparse_categorical_accuracy: 0.8130 \n",
            "328/469 [===================>..........] - ETA: 59s - loss: 0.6997 - sparse_categorical_accuracy: 0.8134\n",
            "329/469 [====================>.........] - ETA: 58s - loss: 0.6982 - sparse_categorical_accuracy: 0.8138\n",
            "330/469 [====================>.........] - ETA: 58s - loss: 0.6966 - sparse_categorical_accuracy: 0.8142\n",
            "331/469 [====================>.........] - ETA: 58s - loss: 0.6951 - sparse_categorical_accuracy: 0.8146\n",
            "332/469 [====================>.........] - ETA: 57s - loss: 0.6936 - sparse_categorical_accuracy: 0.8150\n",
            "333/469 [====================>.........] - ETA: 57s - loss: 0.6921 - sparse_categorical_accuracy: 0.8154\n",
            "334/469 [====================>.........] - ETA: 57s - loss: 0.6903 - sparse_categorical_accuracy: 0.8159\n",
            "335/469 [====================>.........] - ETA: 56s - loss: 0.6891 - sparse_categorical_accuracy: 0.8162\n",
            "336/469 [====================>.........] - ETA: 56s - loss: 0.6875 - sparse_categorical_accuracy: 0.8167\n",
            "337/469 [====================>.........] - ETA: 55s - loss: 0.6861 - sparse_categorical_accuracy: 0.8170\n",
            "338/469 [====================>.........] - ETA: 55s - loss: 0.6847 - sparse_categorical_accuracy: 0.8173\n",
            "339/469 [====================>.........] - ETA: 54s - loss: 0.6832 - sparse_categorical_accuracy: 0.8177\n",
            "340/469 [====================>.........] - ETA: 54s - loss: 0.6817 - sparse_categorical_accuracy: 0.8181\n",
            "341/469 [====================>.........] - ETA: 54s - loss: 0.6803 - sparse_categorical_accuracy: 0.8185\n",
            "342/469 [====================>.........] - ETA: 53s - loss: 0.6787 - sparse_categorical_accuracy: 0.8189\n",
            "343/469 [====================>.........] - ETA: 53s - loss: 0.6774 - sparse_categorical_accuracy: 0.8192\n",
            "344/469 [=====================>........] - ETA: 52s - loss: 0.6758 - sparse_categorical_accuracy: 0.8197\n",
            "345/469 [=====================>........] - ETA: 52s - loss: 0.6744 - sparse_categorical_accuracy: 0.8200\n",
            "346/469 [=====================>........] - ETA: 51s - loss: 0.6728 - sparse_categorical_accuracy: 0.8204\n",
            "347/469 [=====================>........] - ETA: 51s - loss: 0.6714 - sparse_categorical_accuracy: 0.8208\n",
            "348/469 [=====================>........] - ETA: 51s - loss: 0.6701 - sparse_categorical_accuracy: 0.8211\n",
            "349/469 [=====================>........] - ETA: 50s - loss: 0.6685 - sparse_categorical_accuracy: 0.8215\n",
            "350/469 [=====================>........] - ETA: 50s - loss: 0.6672 - sparse_categorical_accuracy: 0.8218\n",
            "351/469 [=====================>........] - ETA: 49s - loss: 0.6658 - sparse_categorical_accuracy: 0.8222\n",
            "352/469 [=====================>........] - ETA: 49s - loss: 0.6649 - sparse_categorical_accuracy: 0.8224\n",
            "353/469 [=====================>........] - ETA: 48s - loss: 0.6639 - sparse_categorical_accuracy: 0.8227\n",
            "354/469 [=====================>........] - ETA: 48s - loss: 0.6626 - sparse_categorical_accuracy: 0.8230\n",
            "355/469 [=====================>........] - ETA: 48s - loss: 0.6613 - sparse_categorical_accuracy: 0.8233\n",
            "356/469 [=====================>........] - ETA: 47s - loss: 0.6601 - sparse_categorical_accuracy: 0.8236\n",
            "357/469 [=====================>........] - ETA: 47s - loss: 0.6586 - sparse_categorical_accuracy: 0.8241\n",
            "358/469 [=====================>........] - ETA: 46s - loss: 0.6575 - sparse_categorical_accuracy: 0.8244\n",
            "359/469 [=====================>........] - ETA: 46s - loss: 0.6564 - sparse_categorical_accuracy: 0.8247\n",
            "360/469 [======================>.......] - ETA: 45s - loss: 0.6555 - sparse_categorical_accuracy: 0.8250\n",
            "361/469 [======================>.......] - ETA: 45s - loss: 0.6541 - sparse_categorical_accuracy: 0.8254\n",
            "362/469 [======================>.......] - ETA: 45s - loss: 0.6527 - sparse_categorical_accuracy: 0.8258\n",
            "363/469 [======================>.......] - ETA: 44s - loss: 0.6513 - sparse_categorical_accuracy: 0.8261\n",
            "364/469 [======================>.......] - ETA: 44s - loss: 0.6499 - sparse_categorical_accuracy: 0.8264\n",
            "365/469 [======================>.......] - ETA: 44s - loss: 0.6486 - sparse_categorical_accuracy: 0.8267\n",
            "366/469 [======================>.......] - ETA: 43s - loss: 0.6475 - sparse_categorical_accuracy: 0.8270\n",
            "367/469 [======================>.......] - ETA: 43s - loss: 0.6462 - sparse_categorical_accuracy: 0.8273\n",
            "368/469 [======================>.......] - ETA: 42s - loss: 0.6448 - sparse_categorical_accuracy: 0.8276\n",
            "369/469 [======================>.......] - ETA: 42s - loss: 0.6436 - sparse_categorical_accuracy: 0.8280\n",
            "370/469 [======================>.......] - ETA: 41s - loss: 0.6425 - sparse_categorical_accuracy: 0.8283\n",
            "371/469 [======================>.......] - ETA: 41s - loss: 0.6414 - sparse_categorical_accuracy: 0.8285\n",
            "372/469 [======================>.......] - ETA: 40s - loss: 0.6400 - sparse_categorical_accuracy: 0.8288\n",
            "373/469 [======================>.......] - ETA: 40s - loss: 0.6387 - sparse_categorical_accuracy: 0.8292\n",
            "374/469 [======================>.......] - ETA: 40s - loss: 0.6374 - sparse_categorical_accuracy: 0.8295\n",
            "375/469 [======================>.......] - ETA: 39s - loss: 0.6363 - sparse_categorical_accuracy: 0.8298\n",
            "376/469 [=======================>......] - ETA: 39s - loss: 0.6352 - sparse_categorical_accuracy: 0.8301\n",
            "377/469 [=======================>......] - ETA: 38s - loss: 0.6340 - sparse_categorical_accuracy: 0.8304\n",
            "378/469 [=======================>......] - ETA: 38s - loss: 0.6328 - sparse_categorical_accuracy: 0.8307\n",
            "379/469 [=======================>......] - ETA: 37s - loss: 0.6317 - sparse_categorical_accuracy: 0.8309\n",
            "380/469 [=======================>......] - ETA: 37s - loss: 0.6305 - sparse_categorical_accuracy: 0.8313\n",
            "381/469 [=======================>......] - ETA: 37s - loss: 0.6298 - sparse_categorical_accuracy: 0.8315\n",
            "382/469 [=======================>......] - ETA: 36s - loss: 0.6287 - sparse_categorical_accuracy: 0.8317\n",
            "383/469 [=======================>......] - ETA: 36s - loss: 0.6275 - sparse_categorical_accuracy: 0.8321\n",
            "384/469 [=======================>......] - ETA: 35s - loss: 0.6262 - sparse_categorical_accuracy: 0.8324\n",
            "385/469 [=======================>......] - ETA: 35s - loss: 0.6251 - sparse_categorical_accuracy: 0.8327\n",
            "386/469 [=======================>......] - ETA: 34s - loss: 0.6239 - sparse_categorical_accuracy: 0.8330\n",
            "387/469 [=======================>......] - ETA: 34s - loss: 0.6227 - sparse_categorical_accuracy: 0.8334\n",
            "388/469 [=======================>......] - ETA: 34s - loss: 0.6217 - sparse_categorical_accuracy: 0.8336\n",
            "389/469 [=======================>......] - ETA: 33s - loss: 0.6208 - sparse_categorical_accuracy: 0.8338\n",
            "390/469 [=======================>......] - ETA: 33s - loss: 0.6195 - sparse_categorical_accuracy: 0.8341\n",
            "391/469 [========================>.....] - ETA: 32s - loss: 0.6182 - sparse_categorical_accuracy: 0.8345\n",
            "392/469 [========================>.....] - ETA: 32s - loss: 0.6168 - sparse_categorical_accuracy: 0.8349\n",
            "393/469 [========================>.....] - ETA: 32s - loss: 0.6156 - sparse_categorical_accuracy: 0.8352\n",
            "394/469 [========================>.....] - ETA: 31s - loss: 0.6147 - sparse_categorical_accuracy: 0.8354\n",
            "395/469 [========================>.....] - ETA: 31s - loss: 0.6139 - sparse_categorical_accuracy: 0.8357\n",
            "396/469 [========================>.....] - ETA: 30s - loss: 0.6128 - sparse_categorical_accuracy: 0.8360\n",
            "397/469 [========================>.....] - ETA: 30s - loss: 0.6117 - sparse_categorical_accuracy: 0.8362\n",
            "398/469 [========================>.....] - ETA: 30s - loss: 0.6105 - sparse_categorical_accuracy: 0.8365\n",
            "399/469 [========================>.....] - ETA: 29s - loss: 0.6095 - sparse_categorical_accuracy: 0.8368\n",
            "400/469 [========================>.....] - ETA: 29s - loss: 0.6084 - sparse_categorical_accuracy: 0.8370\n",
            "401/469 [========================>.....] - ETA: 28s - loss: 0.6074 - sparse_categorical_accuracy: 0.8373\n",
            "402/469 [========================>.....] - ETA: 28s - loss: 0.6062 - sparse_categorical_accuracy: 0.8376\n",
            "403/469 [========================>.....] - ETA: 27s - loss: 0.6054 - sparse_categorical_accuracy: 0.8378\n",
            "404/469 [========================>.....] - ETA: 27s - loss: 0.6043 - sparse_categorical_accuracy: 0.8381\n",
            "405/469 [========================>.....] - ETA: 27s - loss: 0.6032 - sparse_categorical_accuracy: 0.8383\n",
            "406/469 [========================>.....] - ETA: 26s - loss: 0.6021 - sparse_categorical_accuracy: 0.8386\n",
            "407/469 [=========================>....] - ETA: 26s - loss: 0.6010 - sparse_categorical_accuracy: 0.8389\n",
            "408/469 [=========================>....] - ETA: 25s - loss: 0.6000 - sparse_categorical_accuracy: 0.8392\n",
            "409/469 [=========================>....] - ETA: 25s - loss: 0.5989 - sparse_categorical_accuracy: 0.8395\n",
            "410/469 [=========================>....] - ETA: 24s - loss: 0.5977 - sparse_categorical_accuracy: 0.8397\n",
            "411/469 [=========================>....] - ETA: 24s - loss: 0.5966 - sparse_categorical_accuracy: 0.8400\n",
            "412/469 [=========================>....] - ETA: 24s - loss: 0.5959 - sparse_categorical_accuracy: 0.8402\n",
            "413/469 [=========================>....] - ETA: 23s - loss: 0.5949 - sparse_categorical_accuracy: 0.8405\n",
            "414/469 [=========================>....] - ETA: 23s - loss: 0.5938 - sparse_categorical_accuracy: 0.8407\n",
            "415/469 [=========================>....] - ETA: 22s - loss: 0.5928 - sparse_categorical_accuracy: 0.8409\n",
            "416/469 [=========================>....] - ETA: 22s - loss: 0.5918 - sparse_categorical_accuracy: 0.8412\n",
            "417/469 [=========================>....] - ETA: 21s - loss: 0.5908 - sparse_categorical_accuracy: 0.8415\n",
            "418/469 [=========================>....] - ETA: 21s - loss: 0.5897 - sparse_categorical_accuracy: 0.8418\n",
            "419/469 [=========================>....] - ETA: 21s - loss: 0.5888 - sparse_categorical_accuracy: 0.8420\n",
            "420/469 [=========================>....] - ETA: 20s - loss: 0.5876 - sparse_categorical_accuracy: 0.8424\n",
            "421/469 [=========================>....] - ETA: 20s - loss: 0.5865 - sparse_categorical_accuracy: 0.8427\n",
            "422/469 [=========================>....] - ETA: 19s - loss: 0.5855 - sparse_categorical_accuracy: 0.8429\n",
            "423/469 [==========================>...] - ETA: 19s - loss: 0.5845 - sparse_categorical_accuracy: 0.8432\n",
            "424/469 [==========================>...] - ETA: 19s - loss: 0.5835 - sparse_categorical_accuracy: 0.8434\n",
            "425/469 [==========================>...] - ETA: 18s - loss: 0.5826 - sparse_categorical_accuracy: 0.8437\n",
            "426/469 [==========================>...] - ETA: 18s - loss: 0.5817 - sparse_categorical_accuracy: 0.8439\n",
            "427/469 [==========================>...] - ETA: 17s - loss: 0.5807 - sparse_categorical_accuracy: 0.8441\n",
            "428/469 [==========================>...] - ETA: 17s - loss: 0.5796 - sparse_categorical_accuracy: 0.8444\n",
            "429/469 [==========================>...] - ETA: 16s - loss: 0.5784 - sparse_categorical_accuracy: 0.8447\n",
            "430/469 [==========================>...] - ETA: 16s - loss: 0.5772 - sparse_categorical_accuracy: 0.8450\n",
            "431/469 [==========================>...] - ETA: 16s - loss: 0.5764 - sparse_categorical_accuracy: 0.8452\n",
            "432/469 [==========================>...] - ETA: 15s - loss: 0.5752 - sparse_categorical_accuracy: 0.8456\n",
            "433/469 [==========================>...] - ETA: 15s - loss: 0.5741 - sparse_categorical_accuracy: 0.8458\n",
            "434/469 [==========================>...] - ETA: 14s - loss: 0.5730 - sparse_categorical_accuracy: 0.8461\n",
            "435/469 [==========================>...] - ETA: 14s - loss: 0.5721 - sparse_categorical_accuracy: 0.8463\n",
            "436/469 [==========================>...] - ETA: 13s - loss: 0.5713 - sparse_categorical_accuracy: 0.8465\n",
            "437/469 [==========================>...] - ETA: 13s - loss: 0.5704 - sparse_categorical_accuracy: 0.8468\n",
            "438/469 [===========================>..] - ETA: 13s - loss: 0.5694 - sparse_categorical_accuracy: 0.8470\n",
            "439/469 [===========================>..] - ETA: 12s - loss: 0.5683 - sparse_categorical_accuracy: 0.8473\n",
            "440/469 [===========================>..] - ETA: 12s - loss: 0.5673 - sparse_categorical_accuracy: 0.8475\n",
            "441/469 [===========================>..] - ETA: 11s - loss: 0.5662 - sparse_categorical_accuracy: 0.8478\n",
            "442/469 [===========================>..] - ETA: 11s - loss: 0.5656 - sparse_categorical_accuracy: 0.8479\n",
            "443/469 [===========================>..] - ETA: 10s - loss: 0.5648 - sparse_categorical_accuracy: 0.8481\n",
            "444/469 [===========================>..] - ETA: 10s - loss: 0.5640 - sparse_categorical_accuracy: 0.8483\n",
            "445/469 [===========================>..] - ETA: 10s - loss: 0.5631 - sparse_categorical_accuracy: 0.8486\n",
            "446/469 [===========================>..] - ETA: 9s - loss: 0.5624 - sparse_categorical_accuracy: 0.8487 \n",
            "447/469 [===========================>..] - ETA: 9s - loss: 0.5616 - sparse_categorical_accuracy: 0.8489\n",
            "448/469 [===========================>..] - ETA: 8s - loss: 0.5608 - sparse_categorical_accuracy: 0.8491\n",
            "449/469 [===========================>..] - ETA: 8s - loss: 0.5599 - sparse_categorical_accuracy: 0.8493\n",
            "450/469 [===========================>..] - ETA: 8s - loss: 0.5589 - sparse_categorical_accuracy: 0.8496\n",
            "451/469 [===========================>..] - ETA: 7s - loss: 0.5579 - sparse_categorical_accuracy: 0.8498\n",
            "452/469 [===========================>..] - ETA: 7s - loss: 0.5570 - sparse_categorical_accuracy: 0.8501\n",
            "453/469 [===========================>..] - ETA: 6s - loss: 0.5562 - sparse_categorical_accuracy: 0.8503\n",
            "454/469 [============================>.] - ETA: 6s - loss: 0.5553 - sparse_categorical_accuracy: 0.8505\n",
            "455/469 [============================>.] - ETA: 5s - loss: 0.5546 - sparse_categorical_accuracy: 0.8507\n",
            "456/469 [============================>.] - ETA: 5s - loss: 0.5537 - sparse_categorical_accuracy: 0.8510\n",
            "457/469 [============================>.] - ETA: 5s - loss: 0.5526 - sparse_categorical_accuracy: 0.8513\n",
            "458/469 [============================>.] - ETA: 4s - loss: 0.5519 - sparse_categorical_accuracy: 0.8515\n",
            "459/469 [============================>.] - ETA: 4s - loss: 0.5510 - sparse_categorical_accuracy: 0.8517\n",
            "460/469 [============================>.] - ETA: 3s - loss: 0.5501 - sparse_categorical_accuracy: 0.8520\n",
            "461/469 [============================>.] - ETA: 3s - loss: 0.5492 - sparse_categorical_accuracy: 0.8522\n",
            "462/469 [============================>.] - ETA: 2s - loss: 0.5483 - sparse_categorical_accuracy: 0.8524\n",
            "463/469 [============================>.] - ETA: 2s - loss: 0.5474 - sparse_categorical_accuracy: 0.8526\n",
            "464/469 [============================>.] - ETA: 2s - loss: 0.5466 - sparse_categorical_accuracy: 0.8529\n",
            "465/469 [============================>.] - ETA: 1s - loss: 0.5457 - sparse_categorical_accuracy: 0.8531\n",
            "466/469 [============================>.] - ETA: 1s - loss: 0.5447 - sparse_categorical_accuracy: 0.8534\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.5438 - sparse_categorical_accuracy: 0.8536\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.5428 - sparse_categorical_accuracy: 0.8538\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.5421 - sparse_categorical_accuracy: 0.8541\n",
            " 40%|████      | 2/5 [43:23<53:49, 1076.55s/trial, best loss: -0.9830999970436096]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/04/16 01:15:24 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 199s 424ms/step - loss: 0.5421 - sparse_categorical_accuracy: 0.8541\n",
            "\n",
            "Epoch 2/5\n",
            "\n",
            "  1/469 [..............................] - ETA: 3:08 - loss: 0.2658 - sparse_categorical_accuracy: 0.9141\n",
            "  2/469 [..............................] - ETA: 3:03 - loss: 0.1889 - sparse_categorical_accuracy: 0.9297\n",
            "  3/469 [..............................] - ETA: 2:55 - loss: 0.1687 - sparse_categorical_accuracy: 0.9453\n",
            "  4/469 [..............................] - ETA: 2:55 - loss: 0.1645 - sparse_categorical_accuracy: 0.9434\n",
            "  5/469 [..............................] - ETA: 2:52 - loss: 0.1598 - sparse_categorical_accuracy: 0.9453\n",
            "  6/469 [..............................] - ETA: 2:55 - loss: 0.1491 - sparse_categorical_accuracy: 0.9492\n",
            "  7/469 [..............................] - ETA: 2:57 - loss: 0.1380 - sparse_categorical_accuracy: 0.9554\n",
            "  8/469 [..............................] - ETA: 2:58 - loss: 0.1437 - sparse_categorical_accuracy: 0.9541\n",
            "  9/469 [..............................] - ETA: 2:57 - loss: 0.1461 - sparse_categorical_accuracy: 0.9549\n",
            " 10/469 [..............................] - ETA: 2:57 - loss: 0.1431 - sparse_categorical_accuracy: 0.9555\n",
            " 11/469 [..............................] - ETA: 2:56 - loss: 0.1462 - sparse_categorical_accuracy: 0.9553\n",
            " 12/469 [..............................] - ETA: 2:55 - loss: 0.1435 - sparse_categorical_accuracy: 0.9564\n",
            " 13/469 [..............................] - ETA: 2:56 - loss: 0.1428 - sparse_categorical_accuracy: 0.9573\n",
            " 14/469 [..............................] - ETA: 2:55 - loss: 0.1373 - sparse_categorical_accuracy: 0.9587\n",
            " 15/469 [..............................] - ETA: 2:56 - loss: 0.1422 - sparse_categorical_accuracy: 0.9568\n",
            " 16/469 [>.............................] - ETA: 3:01 - loss: 0.1391 - sparse_categorical_accuracy: 0.9580\n",
            " 17/469 [>.............................] - ETA: 3:06 - loss: 0.1395 - sparse_categorical_accuracy: 0.9573\n",
            " 18/469 [>.............................] - ETA: 3:12 - loss: 0.1382 - sparse_categorical_accuracy: 0.9570\n",
            " 19/469 [>.............................] - ETA: 3:16 - loss: 0.1358 - sparse_categorical_accuracy: 0.9568\n",
            " 20/469 [>.............................] - ETA: 3:19 - loss: 0.1341 - sparse_categorical_accuracy: 0.9574\n",
            " 21/469 [>.............................] - ETA: 3:20 - loss: 0.1314 - sparse_categorical_accuracy: 0.9587\n",
            " 22/469 [>.............................] - ETA: 3:18 - loss: 0.1311 - sparse_categorical_accuracy: 0.9592\n",
            " 23/469 [>.............................] - ETA: 3:17 - loss: 0.1283 - sparse_categorical_accuracy: 0.9599\n",
            " 24/469 [>.............................] - ETA: 3:14 - loss: 0.1315 - sparse_categorical_accuracy: 0.9590\n",
            " 25/469 [>.............................] - ETA: 3:13 - loss: 0.1352 - sparse_categorical_accuracy: 0.9572\n",
            " 26/469 [>.............................] - ETA: 3:11 - loss: 0.1354 - sparse_categorical_accuracy: 0.9567\n",
            " 27/469 [>.............................] - ETA: 3:10 - loss: 0.1395 - sparse_categorical_accuracy: 0.9552\n",
            " 28/469 [>.............................] - ETA: 3:09 - loss: 0.1382 - sparse_categorical_accuracy: 0.9551\n",
            " 29/469 [>.............................] - ETA: 3:08 - loss: 0.1409 - sparse_categorical_accuracy: 0.9542\n",
            " 30/469 [>.............................] - ETA: 3:06 - loss: 0.1400 - sparse_categorical_accuracy: 0.9549\n",
            " 31/469 [>.............................] - ETA: 3:05 - loss: 0.1398 - sparse_categorical_accuracy: 0.9546\n",
            " 32/469 [=>............................] - ETA: 3:05 - loss: 0.1423 - sparse_categorical_accuracy: 0.9536\n",
            " 33/469 [=>............................] - ETA: 3:04 - loss: 0.1429 - sparse_categorical_accuracy: 0.9538\n",
            " 34/469 [=>............................] - ETA: 3:03 - loss: 0.1433 - sparse_categorical_accuracy: 0.9540\n",
            " 35/469 [=>............................] - ETA: 3:02 - loss: 0.1421 - sparse_categorical_accuracy: 0.9545\n",
            " 36/469 [=>............................] - ETA: 3:01 - loss: 0.1397 - sparse_categorical_accuracy: 0.9553\n",
            " 37/469 [=>............................] - ETA: 3:01 - loss: 0.1413 - sparse_categorical_accuracy: 0.9552\n",
            " 38/469 [=>............................] - ETA: 3:00 - loss: 0.1407 - sparse_categorical_accuracy: 0.9556\n",
            " 39/469 [=>............................] - ETA: 2:59 - loss: 0.1412 - sparse_categorical_accuracy: 0.9553\n",
            " 40/469 [=>............................] - ETA: 2:58 - loss: 0.1437 - sparse_categorical_accuracy: 0.9543\n",
            " 41/469 [=>............................] - ETA: 2:58 - loss: 0.1438 - sparse_categorical_accuracy: 0.9539\n",
            " 42/469 [=>............................] - ETA: 2:57 - loss: 0.1458 - sparse_categorical_accuracy: 0.9533\n",
            " 43/469 [=>............................] - ETA: 2:56 - loss: 0.1444 - sparse_categorical_accuracy: 0.9539\n",
            " 44/469 [=>............................] - ETA: 2:56 - loss: 0.1452 - sparse_categorical_accuracy: 0.9537\n",
            " 45/469 [=>............................] - ETA: 2:55 - loss: 0.1441 - sparse_categorical_accuracy: 0.9540\n",
            " 46/469 [=>............................] - ETA: 2:54 - loss: 0.1425 - sparse_categorical_accuracy: 0.9547\n",
            " 47/469 [==>...........................] - ETA: 2:54 - loss: 0.1417 - sparse_categorical_accuracy: 0.9548\n",
            " 48/469 [==>...........................] - ETA: 2:55 - loss: 0.1420 - sparse_categorical_accuracy: 0.9544\n",
            " 49/469 [==>...........................] - ETA: 2:56 - loss: 0.1422 - sparse_categorical_accuracy: 0.9542\n",
            " 50/469 [==>...........................] - ETA: 2:58 - loss: 0.1420 - sparse_categorical_accuracy: 0.9542\n",
            " 51/469 [==>...........................] - ETA: 2:59 - loss: 0.1416 - sparse_categorical_accuracy: 0.9545\n",
            " 52/469 [==>...........................] - ETA: 2:59 - loss: 0.1404 - sparse_categorical_accuracy: 0.9548\n",
            " 53/469 [==>...........................] - ETA: 3:00 - loss: 0.1402 - sparse_categorical_accuracy: 0.9549\n",
            " 54/469 [==>...........................] - ETA: 2:59 - loss: 0.1398 - sparse_categorical_accuracy: 0.9550\n",
            " 55/469 [==>...........................] - ETA: 2:58 - loss: 0.1392 - sparse_categorical_accuracy: 0.9551\n",
            " 56/469 [==>...........................] - ETA: 2:58 - loss: 0.1395 - sparse_categorical_accuracy: 0.9549\n",
            " 57/469 [==>...........................] - ETA: 2:57 - loss: 0.1413 - sparse_categorical_accuracy: 0.9544\n",
            " 58/469 [==>...........................] - ETA: 2:56 - loss: 0.1405 - sparse_categorical_accuracy: 0.9546\n",
            " 59/469 [==>...........................] - ETA: 2:56 - loss: 0.1403 - sparse_categorical_accuracy: 0.9547\n",
            " 60/469 [==>...........................] - ETA: 2:56 - loss: 0.1399 - sparse_categorical_accuracy: 0.9548\n",
            " 61/469 [==>...........................] - ETA: 2:55 - loss: 0.1401 - sparse_categorical_accuracy: 0.9545\n",
            " 62/469 [==>...........................] - ETA: 2:55 - loss: 0.1401 - sparse_categorical_accuracy: 0.9545\n",
            " 63/469 [===>..........................] - ETA: 2:54 - loss: 0.1399 - sparse_categorical_accuracy: 0.9545\n",
            " 64/469 [===>..........................] - ETA: 2:54 - loss: 0.1390 - sparse_categorical_accuracy: 0.9550\n",
            " 65/469 [===>..........................] - ETA: 2:53 - loss: 0.1388 - sparse_categorical_accuracy: 0.9548\n",
            " 66/469 [===>..........................] - ETA: 2:53 - loss: 0.1388 - sparse_categorical_accuracy: 0.9551\n",
            " 67/469 [===>..........................] - ETA: 2:52 - loss: 0.1387 - sparse_categorical_accuracy: 0.9552\n",
            " 68/469 [===>..........................] - ETA: 2:51 - loss: 0.1380 - sparse_categorical_accuracy: 0.9557\n",
            " 69/469 [===>..........................] - ETA: 2:51 - loss: 0.1416 - sparse_categorical_accuracy: 0.9545\n",
            " 70/469 [===>..........................] - ETA: 2:50 - loss: 0.1416 - sparse_categorical_accuracy: 0.9547\n",
            " 71/469 [===>..........................] - ETA: 2:49 - loss: 0.1416 - sparse_categorical_accuracy: 0.9549\n",
            " 72/469 [===>..........................] - ETA: 2:49 - loss: 0.1417 - sparse_categorical_accuracy: 0.9548\n",
            " 73/469 [===>..........................] - ETA: 2:48 - loss: 0.1419 - sparse_categorical_accuracy: 0.9549\n",
            " 74/469 [===>..........................] - ETA: 2:47 - loss: 0.1430 - sparse_categorical_accuracy: 0.9548\n",
            " 75/469 [===>..........................] - ETA: 2:47 - loss: 0.1439 - sparse_categorical_accuracy: 0.9545\n",
            " 76/469 [===>..........................] - ETA: 2:46 - loss: 0.1440 - sparse_categorical_accuracy: 0.9545\n",
            " 77/469 [===>..........................] - ETA: 2:46 - loss: 0.1437 - sparse_categorical_accuracy: 0.9545\n",
            " 78/469 [===>..........................] - ETA: 2:45 - loss: 0.1432 - sparse_categorical_accuracy: 0.9547\n",
            " 79/469 [====>.........................] - ETA: 2:45 - loss: 0.1447 - sparse_categorical_accuracy: 0.9545\n",
            " 80/469 [====>.........................] - ETA: 2:46 - loss: 0.1444 - sparse_categorical_accuracy: 0.9547\n",
            " 81/469 [====>.........................] - ETA: 2:46 - loss: 0.1445 - sparse_categorical_accuracy: 0.9548\n",
            " 82/469 [====>.........................] - ETA: 2:47 - loss: 0.1442 - sparse_categorical_accuracy: 0.9549\n",
            " 83/469 [====>.........................] - ETA: 2:47 - loss: 0.1436 - sparse_categorical_accuracy: 0.9551\n",
            " 84/469 [====>.........................] - ETA: 2:47 - loss: 0.1443 - sparse_categorical_accuracy: 0.9548\n",
            " 85/469 [====>.........................] - ETA: 2:47 - loss: 0.1448 - sparse_categorical_accuracy: 0.9547\n",
            " 86/469 [====>.........................] - ETA: 2:46 - loss: 0.1444 - sparse_categorical_accuracy: 0.9548\n",
            " 87/469 [====>.........................] - ETA: 2:45 - loss: 0.1451 - sparse_categorical_accuracy: 0.9545\n",
            " 88/469 [====>.........................] - ETA: 2:45 - loss: 0.1442 - sparse_categorical_accuracy: 0.9548\n",
            " 89/469 [====>.........................] - ETA: 2:44 - loss: 0.1462 - sparse_categorical_accuracy: 0.9544\n",
            " 90/469 [====>.........................] - ETA: 2:44 - loss: 0.1462 - sparse_categorical_accuracy: 0.9543\n",
            " 91/469 [====>.........................] - ETA: 2:43 - loss: 0.1460 - sparse_categorical_accuracy: 0.9542\n",
            " 92/469 [====>.........................] - ETA: 2:43 - loss: 0.1455 - sparse_categorical_accuracy: 0.9543\n",
            " 93/469 [====>.........................] - ETA: 2:42 - loss: 0.1468 - sparse_categorical_accuracy: 0.9539\n",
            " 94/469 [=====>........................] - ETA: 2:41 - loss: 0.1467 - sparse_categorical_accuracy: 0.9538\n",
            " 95/469 [=====>........................] - ETA: 2:41 - loss: 0.1462 - sparse_categorical_accuracy: 0.9540\n",
            " 96/469 [=====>........................] - ETA: 2:40 - loss: 0.1455 - sparse_categorical_accuracy: 0.9543\n",
            " 97/469 [=====>........................] - ETA: 2:40 - loss: 0.1453 - sparse_categorical_accuracy: 0.9543\n",
            " 98/469 [=====>........................] - ETA: 2:39 - loss: 0.1449 - sparse_categorical_accuracy: 0.9545\n",
            " 99/469 [=====>........................] - ETA: 2:39 - loss: 0.1448 - sparse_categorical_accuracy: 0.9547\n",
            "100/469 [=====>........................] - ETA: 2:38 - loss: 0.1443 - sparse_categorical_accuracy: 0.9547\n",
            "101/469 [=====>........................] - ETA: 2:38 - loss: 0.1444 - sparse_categorical_accuracy: 0.9547\n",
            "102/469 [=====>........................] - ETA: 2:37 - loss: 0.1442 - sparse_categorical_accuracy: 0.9549\n",
            "103/469 [=====>........................] - ETA: 2:37 - loss: 0.1437 - sparse_categorical_accuracy: 0.9551\n",
            "104/469 [=====>........................] - ETA: 2:36 - loss: 0.1436 - sparse_categorical_accuracy: 0.9552\n",
            "105/469 [=====>........................] - ETA: 2:36 - loss: 0.1434 - sparse_categorical_accuracy: 0.9551\n",
            "106/469 [=====>........................] - ETA: 2:35 - loss: 0.1431 - sparse_categorical_accuracy: 0.9553\n",
            "107/469 [=====>........................] - ETA: 2:34 - loss: 0.1438 - sparse_categorical_accuracy: 0.9552\n",
            "108/469 [=====>........................] - ETA: 2:34 - loss: 0.1438 - sparse_categorical_accuracy: 0.9553\n",
            "109/469 [=====>........................] - ETA: 2:33 - loss: 0.1434 - sparse_categorical_accuracy: 0.9553\n",
            "110/469 [======>.......................] - ETA: 2:34 - loss: 0.1437 - sparse_categorical_accuracy: 0.9553\n",
            "111/469 [======>.......................] - ETA: 2:34 - loss: 0.1439 - sparse_categorical_accuracy: 0.9550\n",
            "112/469 [======>.......................] - ETA: 2:34 - loss: 0.1451 - sparse_categorical_accuracy: 0.9547\n",
            "113/469 [======>.......................] - ETA: 2:35 - loss: 0.1449 - sparse_categorical_accuracy: 0.9549\n",
            "114/469 [======>.......................] - ETA: 2:34 - loss: 0.1446 - sparse_categorical_accuracy: 0.9549\n",
            "115/469 [======>.......................] - ETA: 2:34 - loss: 0.1449 - sparse_categorical_accuracy: 0.9548\n",
            "116/469 [======>.......................] - ETA: 2:33 - loss: 0.1447 - sparse_categorical_accuracy: 0.9548\n",
            "117/469 [======>.......................] - ETA: 2:33 - loss: 0.1447 - sparse_categorical_accuracy: 0.9548\n",
            "118/469 [======>.......................] - ETA: 2:32 - loss: 0.1452 - sparse_categorical_accuracy: 0.9548\n",
            "119/469 [======>.......................] - ETA: 2:32 - loss: 0.1457 - sparse_categorical_accuracy: 0.9548\n",
            "120/469 [======>.......................] - ETA: 2:31 - loss: 0.1452 - sparse_categorical_accuracy: 0.9548\n",
            "121/469 [======>.......................] - ETA: 2:31 - loss: 0.1452 - sparse_categorical_accuracy: 0.9549\n",
            "122/469 [======>.......................] - ETA: 2:30 - loss: 0.1458 - sparse_categorical_accuracy: 0.9547\n",
            "123/469 [======>.......................] - ETA: 2:30 - loss: 0.1455 - sparse_categorical_accuracy: 0.9547\n",
            "124/469 [======>.......................] - ETA: 2:29 - loss: 0.1459 - sparse_categorical_accuracy: 0.9548\n",
            "125/469 [======>.......................] - ETA: 2:29 - loss: 0.1456 - sparse_categorical_accuracy: 0.9549\n",
            "126/469 [=======>......................] - ETA: 2:28 - loss: 0.1456 - sparse_categorical_accuracy: 0.9547\n",
            "127/469 [=======>......................] - ETA: 2:27 - loss: 0.1452 - sparse_categorical_accuracy: 0.9548\n",
            "128/469 [=======>......................] - ETA: 2:27 - loss: 0.1454 - sparse_categorical_accuracy: 0.9547\n",
            "129/469 [=======>......................] - ETA: 2:26 - loss: 0.1455 - sparse_categorical_accuracy: 0.9546\n",
            "130/469 [=======>......................] - ETA: 2:26 - loss: 0.1453 - sparse_categorical_accuracy: 0.9547\n",
            "131/469 [=======>......................] - ETA: 2:25 - loss: 0.1451 - sparse_categorical_accuracy: 0.9547\n",
            "132/469 [=======>......................] - ETA: 2:25 - loss: 0.1448 - sparse_categorical_accuracy: 0.9548\n",
            "133/469 [=======>......................] - ETA: 2:24 - loss: 0.1458 - sparse_categorical_accuracy: 0.9547\n",
            "134/469 [=======>......................] - ETA: 2:24 - loss: 0.1457 - sparse_categorical_accuracy: 0.9547\n",
            "135/469 [=======>......................] - ETA: 2:23 - loss: 0.1456 - sparse_categorical_accuracy: 0.9546\n",
            "136/469 [=======>......................] - ETA: 2:23 - loss: 0.1457 - sparse_categorical_accuracy: 0.9546\n",
            "137/469 [=======>......................] - ETA: 2:22 - loss: 0.1456 - sparse_categorical_accuracy: 0.9547\n",
            "138/469 [=======>......................] - ETA: 2:21 - loss: 0.1461 - sparse_categorical_accuracy: 0.9546\n",
            "139/469 [=======>......................] - ETA: 2:21 - loss: 0.1458 - sparse_categorical_accuracy: 0.9547\n",
            "140/469 [=======>......................] - ETA: 2:20 - loss: 0.1455 - sparse_categorical_accuracy: 0.9547\n",
            "141/469 [========>.....................] - ETA: 2:20 - loss: 0.1463 - sparse_categorical_accuracy: 0.9546\n",
            "142/469 [========>.....................] - ETA: 2:20 - loss: 0.1460 - sparse_categorical_accuracy: 0.9547\n",
            "143/469 [========>.....................] - ETA: 2:20 - loss: 0.1459 - sparse_categorical_accuracy: 0.9547\n",
            "144/469 [========>.....................] - ETA: 2:20 - loss: 0.1453 - sparse_categorical_accuracy: 0.9549\n",
            "145/469 [========>.....................] - ETA: 2:20 - loss: 0.1449 - sparse_categorical_accuracy: 0.9551\n",
            "146/469 [========>.....................] - ETA: 2:20 - loss: 0.1447 - sparse_categorical_accuracy: 0.9551\n",
            "147/469 [========>.....................] - ETA: 2:19 - loss: 0.1447 - sparse_categorical_accuracy: 0.9551\n",
            "148/469 [========>.....................] - ETA: 2:19 - loss: 0.1444 - sparse_categorical_accuracy: 0.9552\n",
            "149/469 [========>.....................] - ETA: 2:19 - loss: 0.1448 - sparse_categorical_accuracy: 0.9552\n",
            "150/469 [========>.....................] - ETA: 2:18 - loss: 0.1444 - sparse_categorical_accuracy: 0.9554\n",
            "151/469 [========>.....................] - ETA: 2:18 - loss: 0.1445 - sparse_categorical_accuracy: 0.9555\n",
            "152/469 [========>.....................] - ETA: 2:17 - loss: 0.1442 - sparse_categorical_accuracy: 0.9554\n",
            "153/469 [========>.....................] - ETA: 2:17 - loss: 0.1439 - sparse_categorical_accuracy: 0.9555\n",
            "154/469 [========>.....................] - ETA: 2:16 - loss: 0.1446 - sparse_categorical_accuracy: 0.9553\n",
            "155/469 [========>.....................] - ETA: 2:16 - loss: 0.1445 - sparse_categorical_accuracy: 0.9553\n",
            "156/469 [========>.....................] - ETA: 2:15 - loss: 0.1449 - sparse_categorical_accuracy: 0.9553\n",
            "157/469 [=========>....................] - ETA: 2:15 - loss: 0.1444 - sparse_categorical_accuracy: 0.9554\n",
            "158/469 [=========>....................] - ETA: 2:14 - loss: 0.1444 - sparse_categorical_accuracy: 0.9554\n",
            "159/469 [=========>....................] - ETA: 2:14 - loss: 0.1440 - sparse_categorical_accuracy: 0.9557\n",
            "160/469 [=========>....................] - ETA: 2:13 - loss: 0.1438 - sparse_categorical_accuracy: 0.9557\n",
            "161/469 [=========>....................] - ETA: 2:13 - loss: 0.1435 - sparse_categorical_accuracy: 0.9557\n",
            "162/469 [=========>....................] - ETA: 2:12 - loss: 0.1434 - sparse_categorical_accuracy: 0.9556\n",
            "163/469 [=========>....................] - ETA: 2:12 - loss: 0.1437 - sparse_categorical_accuracy: 0.9555\n",
            "164/469 [=========>....................] - ETA: 2:11 - loss: 0.1436 - sparse_categorical_accuracy: 0.9556\n",
            "165/469 [=========>....................] - ETA: 2:11 - loss: 0.1434 - sparse_categorical_accuracy: 0.9556\n",
            "166/469 [=========>....................] - ETA: 2:10 - loss: 0.1431 - sparse_categorical_accuracy: 0.9558\n",
            "167/469 [=========>....................] - ETA: 2:10 - loss: 0.1431 - sparse_categorical_accuracy: 0.9558\n",
            "168/469 [=========>....................] - ETA: 2:09 - loss: 0.1427 - sparse_categorical_accuracy: 0.9560\n",
            "169/469 [=========>....................] - ETA: 2:09 - loss: 0.1423 - sparse_categorical_accuracy: 0.9561\n",
            "170/469 [=========>....................] - ETA: 2:08 - loss: 0.1420 - sparse_categorical_accuracy: 0.9563\n",
            "171/469 [=========>....................] - ETA: 2:08 - loss: 0.1419 - sparse_categorical_accuracy: 0.9563\n",
            "172/469 [==========>...................] - ETA: 2:08 - loss: 0.1418 - sparse_categorical_accuracy: 0.9563\n",
            "173/469 [==========>...................] - ETA: 2:08 - loss: 0.1412 - sparse_categorical_accuracy: 0.9566\n",
            "174/469 [==========>...................] - ETA: 2:07 - loss: 0.1410 - sparse_categorical_accuracy: 0.9566\n",
            "175/469 [==========>...................] - ETA: 2:07 - loss: 0.1406 - sparse_categorical_accuracy: 0.9566\n",
            "176/469 [==========>...................] - ETA: 2:07 - loss: 0.1406 - sparse_categorical_accuracy: 0.9566\n",
            "177/469 [==========>...................] - ETA: 2:07 - loss: 0.1402 - sparse_categorical_accuracy: 0.9567\n",
            "178/469 [==========>...................] - ETA: 2:06 - loss: 0.1399 - sparse_categorical_accuracy: 0.9568\n",
            "179/469 [==========>...................] - ETA: 2:06 - loss: 0.1396 - sparse_categorical_accuracy: 0.9569\n",
            "180/469 [==========>...................] - ETA: 2:05 - loss: 0.1395 - sparse_categorical_accuracy: 0.9569\n",
            "181/469 [==========>...................] - ETA: 2:05 - loss: 0.1396 - sparse_categorical_accuracy: 0.9568\n",
            "182/469 [==========>...................] - ETA: 2:04 - loss: 0.1397 - sparse_categorical_accuracy: 0.9569\n",
            "183/469 [==========>...................] - ETA: 2:04 - loss: 0.1397 - sparse_categorical_accuracy: 0.9568\n",
            "184/469 [==========>...................] - ETA: 2:03 - loss: 0.1399 - sparse_categorical_accuracy: 0.9567\n",
            "185/469 [==========>...................] - ETA: 2:03 - loss: 0.1394 - sparse_categorical_accuracy: 0.9568\n",
            "186/469 [==========>...................] - ETA: 2:02 - loss: 0.1392 - sparse_categorical_accuracy: 0.9568\n",
            "187/469 [==========>...................] - ETA: 2:02 - loss: 0.1393 - sparse_categorical_accuracy: 0.9568\n",
            "188/469 [===========>..................] - ETA: 2:01 - loss: 0.1393 - sparse_categorical_accuracy: 0.9568\n",
            "189/469 [===========>..................] - ETA: 2:01 - loss: 0.1391 - sparse_categorical_accuracy: 0.9568\n",
            "190/469 [===========>..................] - ETA: 2:00 - loss: 0.1389 - sparse_categorical_accuracy: 0.9569\n",
            "191/469 [===========>..................] - ETA: 2:00 - loss: 0.1388 - sparse_categorical_accuracy: 0.9569\n",
            "192/469 [===========>..................] - ETA: 1:59 - loss: 0.1392 - sparse_categorical_accuracy: 0.9569\n",
            "193/469 [===========>..................] - ETA: 1:59 - loss: 0.1387 - sparse_categorical_accuracy: 0.9571\n",
            "194/469 [===========>..................] - ETA: 1:58 - loss: 0.1389 - sparse_categorical_accuracy: 0.9571\n",
            "195/469 [===========>..................] - ETA: 1:58 - loss: 0.1388 - sparse_categorical_accuracy: 0.9571\n",
            "196/469 [===========>..................] - ETA: 1:57 - loss: 0.1387 - sparse_categorical_accuracy: 0.9572\n",
            "197/469 [===========>..................] - ETA: 1:57 - loss: 0.1387 - sparse_categorical_accuracy: 0.9572\n",
            "198/469 [===========>..................] - ETA: 1:56 - loss: 0.1387 - sparse_categorical_accuracy: 0.9570\n",
            "199/469 [===========>..................] - ETA: 1:56 - loss: 0.1388 - sparse_categorical_accuracy: 0.9570\n",
            "200/469 [===========>..................] - ETA: 1:55 - loss: 0.1385 - sparse_categorical_accuracy: 0.9571\n",
            "201/469 [===========>..................] - ETA: 1:55 - loss: 0.1384 - sparse_categorical_accuracy: 0.9571\n",
            "202/469 [===========>..................] - ETA: 1:54 - loss: 0.1382 - sparse_categorical_accuracy: 0.9571\n",
            "203/469 [===========>..................] - ETA: 1:54 - loss: 0.1383 - sparse_categorical_accuracy: 0.9572\n",
            "204/469 [============>.................] - ETA: 1:54 - loss: 0.1380 - sparse_categorical_accuracy: 0.9572\n",
            "205/469 [============>.................] - ETA: 1:54 - loss: 0.1380 - sparse_categorical_accuracy: 0.9572\n",
            "206/469 [============>.................] - ETA: 1:53 - loss: 0.1378 - sparse_categorical_accuracy: 0.9573\n",
            "207/469 [============>.................] - ETA: 1:53 - loss: 0.1377 - sparse_categorical_accuracy: 0.9574\n",
            "208/469 [============>.................] - ETA: 1:53 - loss: 0.1377 - sparse_categorical_accuracy: 0.9573\n",
            "209/469 [============>.................] - ETA: 1:52 - loss: 0.1373 - sparse_categorical_accuracy: 0.9574\n",
            "210/469 [============>.................] - ETA: 1:52 - loss: 0.1373 - sparse_categorical_accuracy: 0.9574\n",
            "211/469 [============>.................] - ETA: 1:51 - loss: 0.1373 - sparse_categorical_accuracy: 0.9574\n",
            "212/469 [============>.................] - ETA: 1:51 - loss: 0.1368 - sparse_categorical_accuracy: 0.9576\n",
            "213/469 [============>.................] - ETA: 1:50 - loss: 0.1369 - sparse_categorical_accuracy: 0.9576\n",
            "214/469 [============>.................] - ETA: 1:50 - loss: 0.1370 - sparse_categorical_accuracy: 0.9576\n",
            "215/469 [============>.................] - ETA: 1:49 - loss: 0.1368 - sparse_categorical_accuracy: 0.9576\n",
            "216/469 [============>.................] - ETA: 1:49 - loss: 0.1369 - sparse_categorical_accuracy: 0.9576\n",
            "217/469 [============>.................] - ETA: 1:48 - loss: 0.1367 - sparse_categorical_accuracy: 0.9577\n",
            "218/469 [============>.................] - ETA: 1:48 - loss: 0.1370 - sparse_categorical_accuracy: 0.9577\n",
            "219/469 [=============>................] - ETA: 1:48 - loss: 0.1369 - sparse_categorical_accuracy: 0.9577\n",
            "220/469 [=============>................] - ETA: 1:47 - loss: 0.1368 - sparse_categorical_accuracy: 0.9578\n",
            "221/469 [=============>................] - ETA: 1:47 - loss: 0.1371 - sparse_categorical_accuracy: 0.9577\n",
            "222/469 [=============>................] - ETA: 1:46 - loss: 0.1368 - sparse_categorical_accuracy: 0.9578\n",
            "223/469 [=============>................] - ETA: 1:46 - loss: 0.1364 - sparse_categorical_accuracy: 0.9580\n",
            "224/469 [=============>................] - ETA: 1:45 - loss: 0.1366 - sparse_categorical_accuracy: 0.9579\n",
            "225/469 [=============>................] - ETA: 1:45 - loss: 0.1364 - sparse_categorical_accuracy: 0.9580\n",
            "226/469 [=============>................] - ETA: 1:44 - loss: 0.1361 - sparse_categorical_accuracy: 0.9581\n",
            "227/469 [=============>................] - ETA: 1:44 - loss: 0.1361 - sparse_categorical_accuracy: 0.9581\n",
            "228/469 [=============>................] - ETA: 1:43 - loss: 0.1358 - sparse_categorical_accuracy: 0.9582\n",
            "229/469 [=============>................] - ETA: 1:43 - loss: 0.1356 - sparse_categorical_accuracy: 0.9582\n",
            "230/469 [=============>................] - ETA: 1:42 - loss: 0.1356 - sparse_categorical_accuracy: 0.9583\n",
            "231/469 [=============>................] - ETA: 1:42 - loss: 0.1358 - sparse_categorical_accuracy: 0.9582\n",
            "232/469 [=============>................] - ETA: 1:41 - loss: 0.1358 - sparse_categorical_accuracy: 0.9582\n",
            "233/469 [=============>................] - ETA: 1:41 - loss: 0.1355 - sparse_categorical_accuracy: 0.9583\n",
            "234/469 [=============>................] - ETA: 1:41 - loss: 0.1353 - sparse_categorical_accuracy: 0.9584\n",
            "235/469 [==============>...............] - ETA: 1:40 - loss: 0.1352 - sparse_categorical_accuracy: 0.9584\n",
            "236/469 [==============>...............] - ETA: 1:40 - loss: 0.1350 - sparse_categorical_accuracy: 0.9584\n",
            "237/469 [==============>...............] - ETA: 1:40 - loss: 0.1351 - sparse_categorical_accuracy: 0.9583\n",
            "238/469 [==============>...............] - ETA: 1:40 - loss: 0.1350 - sparse_categorical_accuracy: 0.9583\n",
            "239/469 [==============>...............] - ETA: 1:39 - loss: 0.1352 - sparse_categorical_accuracy: 0.9583\n",
            "240/469 [==============>...............] - ETA: 1:39 - loss: 0.1349 - sparse_categorical_accuracy: 0.9584\n",
            "241/469 [==============>...............] - ETA: 1:38 - loss: 0.1349 - sparse_categorical_accuracy: 0.9585\n",
            "242/469 [==============>...............] - ETA: 1:38 - loss: 0.1348 - sparse_categorical_accuracy: 0.9585\n",
            "243/469 [==============>...............] - ETA: 1:37 - loss: 0.1346 - sparse_categorical_accuracy: 0.9585\n",
            "244/469 [==============>...............] - ETA: 1:37 - loss: 0.1346 - sparse_categorical_accuracy: 0.9585\n",
            "245/469 [==============>...............] - ETA: 1:36 - loss: 0.1345 - sparse_categorical_accuracy: 0.9585\n",
            "246/469 [==============>...............] - ETA: 1:36 - loss: 0.1346 - sparse_categorical_accuracy: 0.9585\n",
            "247/469 [==============>...............] - ETA: 1:36 - loss: 0.1343 - sparse_categorical_accuracy: 0.9585\n",
            "248/469 [==============>...............] - ETA: 1:35 - loss: 0.1343 - sparse_categorical_accuracy: 0.9585\n",
            "249/469 [==============>...............] - ETA: 1:35 - loss: 0.1341 - sparse_categorical_accuracy: 0.9586\n",
            "250/469 [==============>...............] - ETA: 1:34 - loss: 0.1340 - sparse_categorical_accuracy: 0.9586\n",
            "251/469 [===============>..............] - ETA: 1:34 - loss: 0.1337 - sparse_categorical_accuracy: 0.9586\n",
            "252/469 [===============>..............] - ETA: 1:33 - loss: 0.1337 - sparse_categorical_accuracy: 0.9586\n",
            "253/469 [===============>..............] - ETA: 1:33 - loss: 0.1335 - sparse_categorical_accuracy: 0.9587\n",
            "254/469 [===============>..............] - ETA: 1:32 - loss: 0.1336 - sparse_categorical_accuracy: 0.9587\n",
            "255/469 [===============>..............] - ETA: 1:32 - loss: 0.1334 - sparse_categorical_accuracy: 0.9588\n",
            "256/469 [===============>..............] - ETA: 1:31 - loss: 0.1335 - sparse_categorical_accuracy: 0.9588\n",
            "257/469 [===============>..............] - ETA: 1:31 - loss: 0.1335 - sparse_categorical_accuracy: 0.9588\n",
            "258/469 [===============>..............] - ETA: 1:30 - loss: 0.1335 - sparse_categorical_accuracy: 0.9586\n",
            "259/469 [===============>..............] - ETA: 1:30 - loss: 0.1337 - sparse_categorical_accuracy: 0.9586\n",
            "260/469 [===============>..............] - ETA: 1:29 - loss: 0.1337 - sparse_categorical_accuracy: 0.9586\n",
            "261/469 [===============>..............] - ETA: 1:29 - loss: 0.1336 - sparse_categorical_accuracy: 0.9585\n",
            "262/469 [===============>..............] - ETA: 1:28 - loss: 0.1334 - sparse_categorical_accuracy: 0.9586\n",
            "263/469 [===============>..............] - ETA: 1:28 - loss: 0.1332 - sparse_categorical_accuracy: 0.9587\n",
            "264/469 [===============>..............] - ETA: 1:27 - loss: 0.1332 - sparse_categorical_accuracy: 0.9586\n",
            "265/469 [===============>..............] - ETA: 1:27 - loss: 0.1330 - sparse_categorical_accuracy: 0.9586\n",
            "266/469 [================>.............] - ETA: 1:27 - loss: 0.1331 - sparse_categorical_accuracy: 0.9586\n",
            "267/469 [================>.............] - ETA: 1:26 - loss: 0.1331 - sparse_categorical_accuracy: 0.9587\n",
            "268/469 [================>.............] - ETA: 1:26 - loss: 0.1331 - sparse_categorical_accuracy: 0.9587\n",
            "269/469 [================>.............] - ETA: 1:26 - loss: 0.1330 - sparse_categorical_accuracy: 0.9587\n",
            "270/469 [================>.............] - ETA: 1:25 - loss: 0.1330 - sparse_categorical_accuracy: 0.9587\n",
            "271/469 [================>.............] - ETA: 1:25 - loss: 0.1327 - sparse_categorical_accuracy: 0.9588\n",
            "272/469 [================>.............] - ETA: 1:25 - loss: 0.1326 - sparse_categorical_accuracy: 0.9589\n",
            "273/469 [================>.............] - ETA: 1:24 - loss: 0.1324 - sparse_categorical_accuracy: 0.9589\n",
            "274/469 [================>.............] - ETA: 1:24 - loss: 0.1325 - sparse_categorical_accuracy: 0.9589\n",
            "275/469 [================>.............] - ETA: 1:23 - loss: 0.1327 - sparse_categorical_accuracy: 0.9589\n",
            "276/469 [================>.............] - ETA: 1:23 - loss: 0.1327 - sparse_categorical_accuracy: 0.9589\n",
            "277/469 [================>.............] - ETA: 1:22 - loss: 0.1324 - sparse_categorical_accuracy: 0.9590\n",
            "278/469 [================>.............] - ETA: 1:22 - loss: 0.1322 - sparse_categorical_accuracy: 0.9590\n",
            "279/469 [================>.............] - ETA: 1:21 - loss: 0.1320 - sparse_categorical_accuracy: 0.9591\n",
            "280/469 [================>.............] - ETA: 1:21 - loss: 0.1319 - sparse_categorical_accuracy: 0.9592\n",
            "281/469 [================>.............] - ETA: 1:20 - loss: 0.1317 - sparse_categorical_accuracy: 0.9592\n",
            "282/469 [=================>............] - ETA: 1:20 - loss: 0.1315 - sparse_categorical_accuracy: 0.9593\n",
            "283/469 [=================>............] - ETA: 1:19 - loss: 0.1313 - sparse_categorical_accuracy: 0.9594\n",
            "284/469 [=================>............] - ETA: 1:19 - loss: 0.1315 - sparse_categorical_accuracy: 0.9593\n",
            "285/469 [=================>............] - ETA: 1:19 - loss: 0.1314 - sparse_categorical_accuracy: 0.9593\n",
            "286/469 [=================>............] - ETA: 1:18 - loss: 0.1313 - sparse_categorical_accuracy: 0.9594\n",
            "287/469 [=================>............] - ETA: 1:18 - loss: 0.1312 - sparse_categorical_accuracy: 0.9594\n",
            "288/469 [=================>............] - ETA: 1:17 - loss: 0.1310 - sparse_categorical_accuracy: 0.9594\n",
            "289/469 [=================>............] - ETA: 1:17 - loss: 0.1308 - sparse_categorical_accuracy: 0.9595\n",
            "290/469 [=================>............] - ETA: 1:16 - loss: 0.1307 - sparse_categorical_accuracy: 0.9595\n",
            "291/469 [=================>............] - ETA: 1:16 - loss: 0.1306 - sparse_categorical_accuracy: 0.9596\n",
            "292/469 [=================>............] - ETA: 1:15 - loss: 0.1303 - sparse_categorical_accuracy: 0.9597\n",
            "293/469 [=================>............] - ETA: 1:15 - loss: 0.1305 - sparse_categorical_accuracy: 0.9596\n",
            "294/469 [=================>............] - ETA: 1:15 - loss: 0.1306 - sparse_categorical_accuracy: 0.9597\n",
            "295/469 [=================>............] - ETA: 1:14 - loss: 0.1304 - sparse_categorical_accuracy: 0.9597\n",
            "296/469 [=================>............] - ETA: 1:14 - loss: 0.1303 - sparse_categorical_accuracy: 0.9598\n",
            "297/469 [=================>............] - ETA: 1:13 - loss: 0.1303 - sparse_categorical_accuracy: 0.9597\n",
            "298/469 [==================>...........] - ETA: 1:13 - loss: 0.1302 - sparse_categorical_accuracy: 0.9597\n",
            "299/469 [==================>...........] - ETA: 1:12 - loss: 0.1301 - sparse_categorical_accuracy: 0.9598\n",
            "300/469 [==================>...........] - ETA: 1:12 - loss: 0.1298 - sparse_categorical_accuracy: 0.9598\n",
            "301/469 [==================>...........] - ETA: 1:12 - loss: 0.1297 - sparse_categorical_accuracy: 0.9599\n",
            "302/469 [==================>...........] - ETA: 1:11 - loss: 0.1296 - sparse_categorical_accuracy: 0.9600\n",
            "303/469 [==================>...........] - ETA: 1:11 - loss: 0.1294 - sparse_categorical_accuracy: 0.9600\n",
            "304/469 [==================>...........] - ETA: 1:11 - loss: 0.1300 - sparse_categorical_accuracy: 0.9600\n",
            "305/469 [==================>...........] - ETA: 1:10 - loss: 0.1305 - sparse_categorical_accuracy: 0.9599\n",
            "306/469 [==================>...........] - ETA: 1:10 - loss: 0.1306 - sparse_categorical_accuracy: 0.9599\n",
            "307/469 [==================>...........] - ETA: 1:09 - loss: 0.1304 - sparse_categorical_accuracy: 0.9599\n",
            "308/469 [==================>...........] - ETA: 1:09 - loss: 0.1302 - sparse_categorical_accuracy: 0.9600\n",
            "309/469 [==================>...........] - ETA: 1:08 - loss: 0.1302 - sparse_categorical_accuracy: 0.9599\n",
            "310/469 [==================>...........] - ETA: 1:08 - loss: 0.1301 - sparse_categorical_accuracy: 0.9600\n",
            "311/469 [==================>...........] - ETA: 1:08 - loss: 0.1300 - sparse_categorical_accuracy: 0.9600\n",
            "312/469 [==================>...........] - ETA: 1:07 - loss: 0.1298 - sparse_categorical_accuracy: 0.9600\n",
            "313/469 [===================>..........] - ETA: 1:07 - loss: 0.1299 - sparse_categorical_accuracy: 0.9600\n",
            "314/469 [===================>..........] - ETA: 1:06 - loss: 0.1300 - sparse_categorical_accuracy: 0.9600\n",
            "315/469 [===================>..........] - ETA: 1:06 - loss: 0.1300 - sparse_categorical_accuracy: 0.9601\n",
            "316/469 [===================>..........] - ETA: 1:05 - loss: 0.1301 - sparse_categorical_accuracy: 0.9601\n",
            "317/469 [===================>..........] - ETA: 1:05 - loss: 0.1300 - sparse_categorical_accuracy: 0.9601\n",
            "318/469 [===================>..........] - ETA: 1:04 - loss: 0.1298 - sparse_categorical_accuracy: 0.9602\n",
            "319/469 [===================>..........] - ETA: 1:04 - loss: 0.1298 - sparse_categorical_accuracy: 0.9602\n",
            "320/469 [===================>..........] - ETA: 1:04 - loss: 0.1297 - sparse_categorical_accuracy: 0.9602\n",
            "321/469 [===================>..........] - ETA: 1:03 - loss: 0.1297 - sparse_categorical_accuracy: 0.9602\n",
            "322/469 [===================>..........] - ETA: 1:03 - loss: 0.1297 - sparse_categorical_accuracy: 0.9602\n",
            "323/469 [===================>..........] - ETA: 1:02 - loss: 0.1296 - sparse_categorical_accuracy: 0.9602\n",
            "324/469 [===================>..........] - ETA: 1:02 - loss: 0.1299 - sparse_categorical_accuracy: 0.9601\n",
            "325/469 [===================>..........] - ETA: 1:01 - loss: 0.1297 - sparse_categorical_accuracy: 0.9602\n",
            "326/469 [===================>..........] - ETA: 1:01 - loss: 0.1297 - sparse_categorical_accuracy: 0.9602\n",
            "327/469 [===================>..........] - ETA: 1:00 - loss: 0.1299 - sparse_categorical_accuracy: 0.9601\n",
            "328/469 [===================>..........] - ETA: 1:00 - loss: 0.1300 - sparse_categorical_accuracy: 0.9601\n",
            "329/469 [====================>.........] - ETA: 1:00 - loss: 0.1299 - sparse_categorical_accuracy: 0.9601\n",
            "330/469 [====================>.........] - ETA: 59s - loss: 0.1298 - sparse_categorical_accuracy: 0.9601 \n",
            "331/469 [====================>.........] - ETA: 59s - loss: 0.1299 - sparse_categorical_accuracy: 0.9601\n",
            "332/469 [====================>.........] - ETA: 58s - loss: 0.1301 - sparse_categorical_accuracy: 0.9601\n",
            "333/469 [====================>.........] - ETA: 58s - loss: 0.1301 - sparse_categorical_accuracy: 0.9601\n",
            "334/469 [====================>.........] - ETA: 58s - loss: 0.1300 - sparse_categorical_accuracy: 0.9601\n",
            "335/469 [====================>.........] - ETA: 57s - loss: 0.1301 - sparse_categorical_accuracy: 0.9601\n",
            "336/469 [====================>.........] - ETA: 57s - loss: 0.1300 - sparse_categorical_accuracy: 0.9601\n",
            "337/469 [====================>.........] - ETA: 56s - loss: 0.1299 - sparse_categorical_accuracy: 0.9601\n",
            "338/469 [====================>.........] - ETA: 56s - loss: 0.1298 - sparse_categorical_accuracy: 0.9602\n",
            "339/469 [====================>.........] - ETA: 55s - loss: 0.1298 - sparse_categorical_accuracy: 0.9601\n",
            "340/469 [====================>.........] - ETA: 55s - loss: 0.1298 - sparse_categorical_accuracy: 0.9601\n",
            "341/469 [====================>.........] - ETA: 55s - loss: 0.1297 - sparse_categorical_accuracy: 0.9602\n",
            "342/469 [====================>.........] - ETA: 54s - loss: 0.1297 - sparse_categorical_accuracy: 0.9602\n",
            "343/469 [====================>.........] - ETA: 54s - loss: 0.1296 - sparse_categorical_accuracy: 0.9602\n",
            "344/469 [=====================>........] - ETA: 53s - loss: 0.1299 - sparse_categorical_accuracy: 0.9601\n",
            "345/469 [=====================>........] - ETA: 53s - loss: 0.1299 - sparse_categorical_accuracy: 0.9601\n",
            "346/469 [=====================>........] - ETA: 52s - loss: 0.1297 - sparse_categorical_accuracy: 0.9602\n",
            "347/469 [=====================>........] - ETA: 52s - loss: 0.1300 - sparse_categorical_accuracy: 0.9601\n",
            "348/469 [=====================>........] - ETA: 52s - loss: 0.1303 - sparse_categorical_accuracy: 0.9600\n",
            "349/469 [=====================>........] - ETA: 51s - loss: 0.1303 - sparse_categorical_accuracy: 0.9601\n",
            "350/469 [=====================>........] - ETA: 51s - loss: 0.1303 - sparse_categorical_accuracy: 0.9601\n",
            "351/469 [=====================>........] - ETA: 50s - loss: 0.1303 - sparse_categorical_accuracy: 0.9601\n",
            "352/469 [=====================>........] - ETA: 50s - loss: 0.1305 - sparse_categorical_accuracy: 0.9600\n",
            "353/469 [=====================>........] - ETA: 49s - loss: 0.1305 - sparse_categorical_accuracy: 0.9601\n",
            "354/469 [=====================>........] - ETA: 49s - loss: 0.1303 - sparse_categorical_accuracy: 0.9601\n",
            "355/469 [=====================>........] - ETA: 48s - loss: 0.1307 - sparse_categorical_accuracy: 0.9600\n",
            "356/469 [=====================>........] - ETA: 48s - loss: 0.1304 - sparse_categorical_accuracy: 0.9601\n",
            "357/469 [=====================>........] - ETA: 48s - loss: 0.1303 - sparse_categorical_accuracy: 0.9601\n",
            "358/469 [=====================>........] - ETA: 47s - loss: 0.1303 - sparse_categorical_accuracy: 0.9602\n",
            "359/469 [=====================>........] - ETA: 47s - loss: 0.1304 - sparse_categorical_accuracy: 0.9601\n",
            "360/469 [======================>.......] - ETA: 46s - loss: 0.1303 - sparse_categorical_accuracy: 0.9602\n",
            "361/469 [======================>.......] - ETA: 46s - loss: 0.1302 - sparse_categorical_accuracy: 0.9602\n",
            "362/469 [======================>.......] - ETA: 46s - loss: 0.1301 - sparse_categorical_accuracy: 0.9603\n",
            "363/469 [======================>.......] - ETA: 45s - loss: 0.1303 - sparse_categorical_accuracy: 0.9602\n",
            "364/469 [======================>.......] - ETA: 45s - loss: 0.1303 - sparse_categorical_accuracy: 0.9601\n",
            "365/469 [======================>.......] - ETA: 44s - loss: 0.1303 - sparse_categorical_accuracy: 0.9601\n",
            "366/469 [======================>.......] - ETA: 44s - loss: 0.1303 - sparse_categorical_accuracy: 0.9601\n",
            "367/469 [======================>.......] - ETA: 44s - loss: 0.1302 - sparse_categorical_accuracy: 0.9601\n",
            "368/469 [======================>.......] - ETA: 43s - loss: 0.1301 - sparse_categorical_accuracy: 0.9602\n",
            "369/469 [======================>.......] - ETA: 43s - loss: 0.1300 - sparse_categorical_accuracy: 0.9602\n",
            "370/469 [======================>.......] - ETA: 42s - loss: 0.1299 - sparse_categorical_accuracy: 0.9603\n",
            "371/469 [======================>.......] - ETA: 42s - loss: 0.1297 - sparse_categorical_accuracy: 0.9603\n",
            "372/469 [======================>.......] - ETA: 41s - loss: 0.1295 - sparse_categorical_accuracy: 0.9604\n",
            "373/469 [======================>.......] - ETA: 41s - loss: 0.1297 - sparse_categorical_accuracy: 0.9603\n",
            "374/469 [======================>.......] - ETA: 40s - loss: 0.1296 - sparse_categorical_accuracy: 0.9603\n",
            "375/469 [======================>.......] - ETA: 40s - loss: 0.1295 - sparse_categorical_accuracy: 0.9604\n",
            "376/469 [=======================>......] - ETA: 40s - loss: 0.1293 - sparse_categorical_accuracy: 0.9604\n",
            "377/469 [=======================>......] - ETA: 39s - loss: 0.1295 - sparse_categorical_accuracy: 0.9604\n",
            "378/469 [=======================>......] - ETA: 39s - loss: 0.1297 - sparse_categorical_accuracy: 0.9604\n",
            "379/469 [=======================>......] - ETA: 38s - loss: 0.1297 - sparse_categorical_accuracy: 0.9604\n",
            "380/469 [=======================>......] - ETA: 38s - loss: 0.1297 - sparse_categorical_accuracy: 0.9603\n",
            "381/469 [=======================>......] - ETA: 37s - loss: 0.1295 - sparse_categorical_accuracy: 0.9604\n",
            "382/469 [=======================>......] - ETA: 37s - loss: 0.1294 - sparse_categorical_accuracy: 0.9605\n",
            "383/469 [=======================>......] - ETA: 36s - loss: 0.1295 - sparse_categorical_accuracy: 0.9604\n",
            "384/469 [=======================>......] - ETA: 36s - loss: 0.1293 - sparse_categorical_accuracy: 0.9605\n",
            "385/469 [=======================>......] - ETA: 36s - loss: 0.1292 - sparse_categorical_accuracy: 0.9605\n",
            "386/469 [=======================>......] - ETA: 35s - loss: 0.1291 - sparse_categorical_accuracy: 0.9605\n",
            "387/469 [=======================>......] - ETA: 35s - loss: 0.1291 - sparse_categorical_accuracy: 0.9605\n",
            "388/469 [=======================>......] - ETA: 34s - loss: 0.1289 - sparse_categorical_accuracy: 0.9606\n",
            "389/469 [=======================>......] - ETA: 34s - loss: 0.1290 - sparse_categorical_accuracy: 0.9606\n",
            "390/469 [=======================>......] - ETA: 33s - loss: 0.1290 - sparse_categorical_accuracy: 0.9606\n",
            "391/469 [========================>.....] - ETA: 33s - loss: 0.1289 - sparse_categorical_accuracy: 0.9606\n",
            "392/469 [========================>.....] - ETA: 33s - loss: 0.1287 - sparse_categorical_accuracy: 0.9606\n",
            "393/469 [========================>.....] - ETA: 32s - loss: 0.1287 - sparse_categorical_accuracy: 0.9607\n",
            "394/469 [========================>.....] - ETA: 32s - loss: 0.1285 - sparse_categorical_accuracy: 0.9607\n",
            "395/469 [========================>.....] - ETA: 31s - loss: 0.1285 - sparse_categorical_accuracy: 0.9608\n",
            "396/469 [========================>.....] - ETA: 31s - loss: 0.1284 - sparse_categorical_accuracy: 0.9607\n",
            "397/469 [========================>.....] - ETA: 31s - loss: 0.1284 - sparse_categorical_accuracy: 0.9607\n",
            "398/469 [========================>.....] - ETA: 30s - loss: 0.1285 - sparse_categorical_accuracy: 0.9607\n",
            "399/469 [========================>.....] - ETA: 30s - loss: 0.1283 - sparse_categorical_accuracy: 0.9608\n",
            "400/469 [========================>.....] - ETA: 29s - loss: 0.1282 - sparse_categorical_accuracy: 0.9608\n",
            "401/469 [========================>.....] - ETA: 29s - loss: 0.1282 - sparse_categorical_accuracy: 0.9608\n",
            "402/469 [========================>.....] - ETA: 28s - loss: 0.1281 - sparse_categorical_accuracy: 0.9608\n",
            "403/469 [========================>.....] - ETA: 28s - loss: 0.1281 - sparse_categorical_accuracy: 0.9608\n",
            "404/469 [========================>.....] - ETA: 28s - loss: 0.1281 - sparse_categorical_accuracy: 0.9608\n",
            "405/469 [========================>.....] - ETA: 27s - loss: 0.1281 - sparse_categorical_accuracy: 0.9609\n",
            "406/469 [========================>.....] - ETA: 27s - loss: 0.1282 - sparse_categorical_accuracy: 0.9609\n",
            "407/469 [=========================>....] - ETA: 26s - loss: 0.1284 - sparse_categorical_accuracy: 0.9608\n",
            "408/469 [=========================>....] - ETA: 26s - loss: 0.1282 - sparse_categorical_accuracy: 0.9609\n",
            "409/469 [=========================>....] - ETA: 25s - loss: 0.1281 - sparse_categorical_accuracy: 0.9610\n",
            "410/469 [=========================>....] - ETA: 25s - loss: 0.1279 - sparse_categorical_accuracy: 0.9611\n",
            "411/469 [=========================>....] - ETA: 24s - loss: 0.1278 - sparse_categorical_accuracy: 0.9611\n",
            "412/469 [=========================>....] - ETA: 24s - loss: 0.1278 - sparse_categorical_accuracy: 0.9611\n",
            "413/469 [=========================>....] - ETA: 24s - loss: 0.1277 - sparse_categorical_accuracy: 0.9611\n",
            "414/469 [=========================>....] - ETA: 23s - loss: 0.1276 - sparse_categorical_accuracy: 0.9611\n",
            "415/469 [=========================>....] - ETA: 23s - loss: 0.1280 - sparse_categorical_accuracy: 0.9610\n",
            "416/469 [=========================>....] - ETA: 22s - loss: 0.1279 - sparse_categorical_accuracy: 0.9610\n",
            "417/469 [=========================>....] - ETA: 22s - loss: 0.1278 - sparse_categorical_accuracy: 0.9610\n",
            "418/469 [=========================>....] - ETA: 21s - loss: 0.1278 - sparse_categorical_accuracy: 0.9610\n",
            "419/469 [=========================>....] - ETA: 21s - loss: 0.1278 - sparse_categorical_accuracy: 0.9610\n",
            "420/469 [=========================>....] - ETA: 21s - loss: 0.1277 - sparse_categorical_accuracy: 0.9611\n",
            "421/469 [=========================>....] - ETA: 20s - loss: 0.1277 - sparse_categorical_accuracy: 0.9610\n",
            "422/469 [=========================>....] - ETA: 20s - loss: 0.1278 - sparse_categorical_accuracy: 0.9610\n",
            "423/469 [==========================>...] - ETA: 19s - loss: 0.1275 - sparse_categorical_accuracy: 0.9611\n",
            "424/469 [==========================>...] - ETA: 19s - loss: 0.1275 - sparse_categorical_accuracy: 0.9611\n",
            "425/469 [==========================>...] - ETA: 18s - loss: 0.1275 - sparse_categorical_accuracy: 0.9611\n",
            "426/469 [==========================>...] - ETA: 18s - loss: 0.1278 - sparse_categorical_accuracy: 0.9611\n",
            "427/469 [==========================>...] - ETA: 18s - loss: 0.1276 - sparse_categorical_accuracy: 0.9612\n",
            "428/469 [==========================>...] - ETA: 17s - loss: 0.1275 - sparse_categorical_accuracy: 0.9612\n",
            "429/469 [==========================>...] - ETA: 17s - loss: 0.1276 - sparse_categorical_accuracy: 0.9612\n",
            "430/469 [==========================>...] - ETA: 16s - loss: 0.1275 - sparse_categorical_accuracy: 0.9612\n",
            "431/469 [==========================>...] - ETA: 16s - loss: 0.1275 - sparse_categorical_accuracy: 0.9612\n",
            "432/469 [==========================>...] - ETA: 15s - loss: 0.1276 - sparse_categorical_accuracy: 0.9612\n",
            "433/469 [==========================>...] - ETA: 15s - loss: 0.1276 - sparse_categorical_accuracy: 0.9612\n",
            "434/469 [==========================>...] - ETA: 15s - loss: 0.1274 - sparse_categorical_accuracy: 0.9612\n",
            "435/469 [==========================>...] - ETA: 14s - loss: 0.1273 - sparse_categorical_accuracy: 0.9612\n",
            "436/469 [==========================>...] - ETA: 14s - loss: 0.1273 - sparse_categorical_accuracy: 0.9612\n",
            "437/469 [==========================>...] - ETA: 13s - loss: 0.1273 - sparse_categorical_accuracy: 0.9613\n",
            "438/469 [===========================>..] - ETA: 13s - loss: 0.1273 - sparse_categorical_accuracy: 0.9613\n",
            "439/469 [===========================>..] - ETA: 12s - loss: 0.1272 - sparse_categorical_accuracy: 0.9613\n",
            "440/469 [===========================>..] - ETA: 12s - loss: 0.1272 - sparse_categorical_accuracy: 0.9613\n",
            "441/469 [===========================>..] - ETA: 12s - loss: 0.1271 - sparse_categorical_accuracy: 0.9613\n",
            "442/469 [===========================>..] - ETA: 11s - loss: 0.1273 - sparse_categorical_accuracy: 0.9612\n",
            "443/469 [===========================>..] - ETA: 11s - loss: 0.1272 - sparse_categorical_accuracy: 0.9612\n",
            "444/469 [===========================>..] - ETA: 10s - loss: 0.1271 - sparse_categorical_accuracy: 0.9612\n",
            "445/469 [===========================>..] - ETA: 10s - loss: 0.1269 - sparse_categorical_accuracy: 0.9613\n",
            "446/469 [===========================>..] - ETA: 9s - loss: 0.1270 - sparse_categorical_accuracy: 0.9613 \n",
            "447/469 [===========================>..] - ETA: 9s - loss: 0.1272 - sparse_categorical_accuracy: 0.9613\n",
            "448/469 [===========================>..] - ETA: 9s - loss: 0.1271 - sparse_categorical_accuracy: 0.9613\n",
            "449/469 [===========================>..] - ETA: 8s - loss: 0.1270 - sparse_categorical_accuracy: 0.9613\n",
            "450/469 [===========================>..] - ETA: 8s - loss: 0.1269 - sparse_categorical_accuracy: 0.9614\n",
            "451/469 [===========================>..] - ETA: 7s - loss: 0.1268 - sparse_categorical_accuracy: 0.9614\n",
            "452/469 [===========================>..] - ETA: 7s - loss: 0.1269 - sparse_categorical_accuracy: 0.9613\n",
            "453/469 [===========================>..] - ETA: 6s - loss: 0.1268 - sparse_categorical_accuracy: 0.9614\n",
            "454/469 [============================>.] - ETA: 6s - loss: 0.1266 - sparse_categorical_accuracy: 0.9614\n",
            "455/469 [============================>.] - ETA: 5s - loss: 0.1265 - sparse_categorical_accuracy: 0.9614\n",
            "456/469 [============================>.] - ETA: 5s - loss: 0.1265 - sparse_categorical_accuracy: 0.9614\n",
            "457/469 [============================>.] - ETA: 5s - loss: 0.1265 - sparse_categorical_accuracy: 0.9615\n",
            "458/469 [============================>.] - ETA: 4s - loss: 0.1263 - sparse_categorical_accuracy: 0.9615\n",
            "459/469 [============================>.] - ETA: 4s - loss: 0.1262 - sparse_categorical_accuracy: 0.9615\n",
            "460/469 [============================>.] - ETA: 3s - loss: 0.1264 - sparse_categorical_accuracy: 0.9615\n",
            "461/469 [============================>.] - ETA: 3s - loss: 0.1262 - sparse_categorical_accuracy: 0.9615\n",
            "462/469 [============================>.] - ETA: 3s - loss: 0.1262 - sparse_categorical_accuracy: 0.9615\n",
            "463/469 [============================>.] - ETA: 2s - loss: 0.1262 - sparse_categorical_accuracy: 0.9615\n",
            "464/469 [============================>.] - ETA: 2s - loss: 0.1263 - sparse_categorical_accuracy: 0.9615\n",
            "465/469 [============================>.] - ETA: 1s - loss: 0.1262 - sparse_categorical_accuracy: 0.9615\n",
            "466/469 [============================>.] - ETA: 1s - loss: 0.1261 - sparse_categorical_accuracy: 0.9615\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.1262 - sparse_categorical_accuracy: 0.9615\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.1262 - sparse_categorical_accuracy: 0.9615\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1262 - sparse_categorical_accuracy: 0.9615\n",
            " 40%|████      | 2/5 [46:44<53:49, 1076.55s/trial, best loss: -0.9830999970436096]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/04/16 01:18:45 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 201s 430ms/step - loss: 0.1262 - sparse_categorical_accuracy: 0.9615\n",
            "\n",
            "Epoch 3/5\n",
            "\n",
            "  1/469 [..............................] - ETA: 3:29 - loss: 0.0808 - sparse_categorical_accuracy: 0.9688\n",
            "  2/469 [..............................] - ETA: 2:59 - loss: 0.1622 - sparse_categorical_accuracy: 0.9414\n",
            "  3/469 [..............................] - ETA: 2:59 - loss: 0.1585 - sparse_categorical_accuracy: 0.9479\n",
            "  4/469 [..............................] - ETA: 3:02 - loss: 0.1555 - sparse_categorical_accuracy: 0.9531\n",
            "  5/469 [..............................] - ETA: 2:59 - loss: 0.1479 - sparse_categorical_accuracy: 0.9578\n",
            "  6/469 [..............................] - ETA: 2:57 - loss: 0.1371 - sparse_categorical_accuracy: 0.9596\n",
            "  7/469 [..............................] - ETA: 2:56 - loss: 0.1358 - sparse_categorical_accuracy: 0.9609\n",
            "  8/469 [..............................] - ETA: 2:55 - loss: 0.1343 - sparse_categorical_accuracy: 0.9619\n",
            "  9/469 [..............................] - ETA: 2:53 - loss: 0.1303 - sparse_categorical_accuracy: 0.9627\n",
            " 10/469 [..............................] - ETA: 2:53 - loss: 0.1240 - sparse_categorical_accuracy: 0.9648\n",
            " 11/469 [..............................] - ETA: 2:52 - loss: 0.1257 - sparse_categorical_accuracy: 0.9659\n",
            " 12/469 [..............................] - ETA: 2:51 - loss: 0.1206 - sparse_categorical_accuracy: 0.9661\n",
            " 13/469 [..............................] - ETA: 2:51 - loss: 0.1190 - sparse_categorical_accuracy: 0.9657\n",
            " 14/469 [..............................] - ETA: 2:50 - loss: 0.1209 - sparse_categorical_accuracy: 0.9660\n",
            " 15/469 [..............................] - ETA: 2:50 - loss: 0.1167 - sparse_categorical_accuracy: 0.9672\n",
            " 16/469 [>.............................] - ETA: 2:49 - loss: 0.1118 - sparse_categorical_accuracy: 0.9692\n",
            " 17/469 [>.............................] - ETA: 2:49 - loss: 0.1100 - sparse_categorical_accuracy: 0.9697\n",
            " 18/469 [>.............................] - ETA: 2:48 - loss: 0.1116 - sparse_categorical_accuracy: 0.9692\n",
            " 19/469 [>.............................] - ETA: 2:48 - loss: 0.1083 - sparse_categorical_accuracy: 0.9704\n",
            " 20/469 [>.............................] - ETA: 2:51 - loss: 0.1097 - sparse_categorical_accuracy: 0.9699\n",
            " 21/469 [>.............................] - ETA: 2:55 - loss: 0.1074 - sparse_categorical_accuracy: 0.9702\n",
            " 22/469 [>.............................] - ETA: 3:00 - loss: 0.1062 - sparse_categorical_accuracy: 0.9709\n",
            " 23/469 [>.............................] - ETA: 3:03 - loss: 0.1043 - sparse_categorical_accuracy: 0.9718\n",
            " 24/469 [>.............................] - ETA: 3:07 - loss: 0.1019 - sparse_categorical_accuracy: 0.9723\n",
            " 25/469 [>.............................] - ETA: 3:09 - loss: 0.1012 - sparse_categorical_accuracy: 0.9725\n",
            " 26/469 [>.............................] - ETA: 3:08 - loss: 0.1024 - sparse_categorical_accuracy: 0.9718\n",
            " 27/469 [>.............................] - ETA: 3:07 - loss: 0.1051 - sparse_categorical_accuracy: 0.9711\n",
            " 28/469 [>.............................] - ETA: 3:05 - loss: 0.1037 - sparse_categorical_accuracy: 0.9710\n",
            " 29/469 [>.............................] - ETA: 3:04 - loss: 0.1072 - sparse_categorical_accuracy: 0.9701\n",
            " 30/469 [>.............................] - ETA: 3:04 - loss: 0.1095 - sparse_categorical_accuracy: 0.9695\n",
            " 31/469 [>.............................] - ETA: 3:02 - loss: 0.1099 - sparse_categorical_accuracy: 0.9685\n",
            " 32/469 [=>............................] - ETA: 3:02 - loss: 0.1098 - sparse_categorical_accuracy: 0.9685\n",
            " 33/469 [=>............................] - ETA: 3:01 - loss: 0.1096 - sparse_categorical_accuracy: 0.9685\n",
            " 34/469 [=>............................] - ETA: 3:00 - loss: 0.1088 - sparse_categorical_accuracy: 0.9685\n",
            " 35/469 [=>............................] - ETA: 2:59 - loss: 0.1077 - sparse_categorical_accuracy: 0.9690\n",
            " 36/469 [=>............................] - ETA: 2:59 - loss: 0.1069 - sparse_categorical_accuracy: 0.9692\n",
            " 37/469 [=>............................] - ETA: 2:58 - loss: 0.1060 - sparse_categorical_accuracy: 0.9690\n",
            " 38/469 [=>............................] - ETA: 2:57 - loss: 0.1067 - sparse_categorical_accuracy: 0.9692\n",
            " 39/469 [=>............................] - ETA: 2:56 - loss: 0.1059 - sparse_categorical_accuracy: 0.9692\n",
            " 40/469 [=>............................] - ETA: 2:56 - loss: 0.1050 - sparse_categorical_accuracy: 0.9695\n",
            " 41/469 [=>............................] - ETA: 2:55 - loss: 0.1042 - sparse_categorical_accuracy: 0.9697\n",
            " 42/469 [=>............................] - ETA: 2:54 - loss: 0.1030 - sparse_categorical_accuracy: 0.9702\n",
            " 43/469 [=>............................] - ETA: 2:54 - loss: 0.1025 - sparse_categorical_accuracy: 0.9702\n",
            " 44/469 [=>............................] - ETA: 2:53 - loss: 0.1032 - sparse_categorical_accuracy: 0.9700\n",
            " 45/469 [=>............................] - ETA: 2:52 - loss: 0.1029 - sparse_categorical_accuracy: 0.9698\n",
            " 46/469 [=>............................] - ETA: 2:52 - loss: 0.1021 - sparse_categorical_accuracy: 0.9699\n",
            " 47/469 [==>...........................] - ETA: 2:51 - loss: 0.1026 - sparse_categorical_accuracy: 0.9697\n",
            " 48/469 [==>...........................] - ETA: 2:50 - loss: 0.1039 - sparse_categorical_accuracy: 0.9692\n",
            " 49/469 [==>...........................] - ETA: 2:50 - loss: 0.1039 - sparse_categorical_accuracy: 0.9691\n",
            " 50/469 [==>...........................] - ETA: 2:49 - loss: 0.1044 - sparse_categorical_accuracy: 0.9691\n",
            " 51/469 [==>...........................] - ETA: 2:49 - loss: 0.1051 - sparse_categorical_accuracy: 0.9694\n",
            " 52/469 [==>...........................] - ETA: 2:51 - loss: 0.1042 - sparse_categorical_accuracy: 0.9695\n",
            " 53/469 [==>...........................] - ETA: 2:52 - loss: 0.1046 - sparse_categorical_accuracy: 0.9695\n",
            " 54/469 [==>...........................] - ETA: 2:53 - loss: 0.1051 - sparse_categorical_accuracy: 0.9689\n",
            " 55/469 [==>...........................] - ETA: 2:54 - loss: 0.1048 - sparse_categorical_accuracy: 0.9688\n",
            " 56/469 [==>...........................] - ETA: 2:54 - loss: 0.1049 - sparse_categorical_accuracy: 0.9686\n",
            " 57/469 [==>...........................] - ETA: 2:55 - loss: 0.1050 - sparse_categorical_accuracy: 0.9683\n",
            " 58/469 [==>...........................] - ETA: 2:54 - loss: 0.1041 - sparse_categorical_accuracy: 0.9686\n",
            " 59/469 [==>...........................] - ETA: 2:53 - loss: 0.1030 - sparse_categorical_accuracy: 0.9689\n",
            " 60/469 [==>...........................] - ETA: 2:52 - loss: 0.1032 - sparse_categorical_accuracy: 0.9689\n",
            " 61/469 [==>...........................] - ETA: 2:51 - loss: 0.1024 - sparse_categorical_accuracy: 0.9690\n",
            " 62/469 [==>...........................] - ETA: 2:51 - loss: 0.1021 - sparse_categorical_accuracy: 0.9690\n",
            " 63/469 [===>..........................] - ETA: 2:50 - loss: 0.1023 - sparse_categorical_accuracy: 0.9689\n",
            " 64/469 [===>..........................] - ETA: 2:49 - loss: 0.1022 - sparse_categorical_accuracy: 0.9690\n",
            " 65/469 [===>..........................] - ETA: 2:49 - loss: 0.1017 - sparse_categorical_accuracy: 0.9690\n",
            " 66/469 [===>..........................] - ETA: 2:48 - loss: 0.1014 - sparse_categorical_accuracy: 0.9691\n",
            " 67/469 [===>..........................] - ETA: 2:47 - loss: 0.1005 - sparse_categorical_accuracy: 0.9694\n",
            " 68/469 [===>..........................] - ETA: 2:47 - loss: 0.0998 - sparse_categorical_accuracy: 0.9697\n",
            " 69/469 [===>..........................] - ETA: 2:46 - loss: 0.1000 - sparse_categorical_accuracy: 0.9698\n",
            " 70/469 [===>..........................] - ETA: 2:45 - loss: 0.1009 - sparse_categorical_accuracy: 0.9693\n",
            " 71/469 [===>..........................] - ETA: 2:45 - loss: 0.1005 - sparse_categorical_accuracy: 0.9692\n",
            " 72/469 [===>..........................] - ETA: 2:44 - loss: 0.0997 - sparse_categorical_accuracy: 0.9694\n",
            " 73/469 [===>..........................] - ETA: 2:43 - loss: 0.0996 - sparse_categorical_accuracy: 0.9695\n",
            " 74/469 [===>..........................] - ETA: 2:43 - loss: 0.0998 - sparse_categorical_accuracy: 0.9694\n",
            " 75/469 [===>..........................] - ETA: 2:42 - loss: 0.1011 - sparse_categorical_accuracy: 0.9689\n",
            " 76/469 [===>..........................] - ETA: 2:41 - loss: 0.1014 - sparse_categorical_accuracy: 0.9684\n",
            " 77/469 [===>..........................] - ETA: 2:41 - loss: 0.1023 - sparse_categorical_accuracy: 0.9684\n",
            " 78/469 [===>..........................] - ETA: 2:41 - loss: 0.1038 - sparse_categorical_accuracy: 0.9681\n",
            " 79/469 [====>.........................] - ETA: 2:40 - loss: 0.1032 - sparse_categorical_accuracy: 0.9683\n",
            " 80/469 [====>.........................] - ETA: 2:39 - loss: 0.1035 - sparse_categorical_accuracy: 0.9681\n",
            " 81/469 [====>.........................] - ETA: 2:39 - loss: 0.1033 - sparse_categorical_accuracy: 0.9683\n",
            " 82/469 [====>.........................] - ETA: 2:38 - loss: 0.1029 - sparse_categorical_accuracy: 0.9685\n",
            " 83/469 [====>.........................] - ETA: 2:38 - loss: 0.1027 - sparse_categorical_accuracy: 0.9686\n",
            " 84/469 [====>.........................] - ETA: 2:38 - loss: 0.1040 - sparse_categorical_accuracy: 0.9681\n",
            " 85/469 [====>.........................] - ETA: 2:38 - loss: 0.1041 - sparse_categorical_accuracy: 0.9681\n",
            " 86/469 [====>.........................] - ETA: 2:38 - loss: 0.1038 - sparse_categorical_accuracy: 0.9681\n",
            " 87/469 [====>.........................] - ETA: 2:39 - loss: 0.1035 - sparse_categorical_accuracy: 0.9683\n",
            " 88/469 [====>.........................] - ETA: 2:39 - loss: 0.1029 - sparse_categorical_accuracy: 0.9686\n",
            " 89/469 [====>.........................] - ETA: 2:39 - loss: 0.1024 - sparse_categorical_accuracy: 0.9688\n",
            " 90/469 [====>.........................] - ETA: 2:39 - loss: 0.1024 - sparse_categorical_accuracy: 0.9688\n",
            " 91/469 [====>.........................] - ETA: 2:38 - loss: 0.1017 - sparse_categorical_accuracy: 0.9690\n",
            " 92/469 [====>.........................] - ETA: 2:37 - loss: 0.1015 - sparse_categorical_accuracy: 0.9692\n",
            " 93/469 [====>.........................] - ETA: 2:37 - loss: 0.1013 - sparse_categorical_accuracy: 0.9693\n",
            " 94/469 [=====>........................] - ETA: 2:36 - loss: 0.1010 - sparse_categorical_accuracy: 0.9692\n",
            " 95/469 [=====>........................] - ETA: 2:36 - loss: 0.1003 - sparse_categorical_accuracy: 0.9694\n",
            " 96/469 [=====>........................] - ETA: 2:35 - loss: 0.0998 - sparse_categorical_accuracy: 0.9695\n",
            " 97/469 [=====>........................] - ETA: 2:34 - loss: 0.0996 - sparse_categorical_accuracy: 0.9696\n",
            " 98/469 [=====>........................] - ETA: 2:34 - loss: 0.0997 - sparse_categorical_accuracy: 0.9697\n",
            " 99/469 [=====>........................] - ETA: 2:33 - loss: 0.0996 - sparse_categorical_accuracy: 0.9697\n",
            "100/469 [=====>........................] - ETA: 2:33 - loss: 0.0996 - sparse_categorical_accuracy: 0.9695\n",
            "101/469 [=====>........................] - ETA: 2:32 - loss: 0.0997 - sparse_categorical_accuracy: 0.9694\n",
            "102/469 [=====>........................] - ETA: 2:31 - loss: 0.0992 - sparse_categorical_accuracy: 0.9697\n",
            "103/469 [=====>........................] - ETA: 2:31 - loss: 0.0991 - sparse_categorical_accuracy: 0.9697\n",
            "104/469 [=====>........................] - ETA: 2:30 - loss: 0.0989 - sparse_categorical_accuracy: 0.9697\n",
            "105/469 [=====>........................] - ETA: 2:30 - loss: 0.0992 - sparse_categorical_accuracy: 0.9696\n",
            "106/469 [=====>........................] - ETA: 2:29 - loss: 0.0992 - sparse_categorical_accuracy: 0.9697\n",
            "107/469 [=====>........................] - ETA: 2:29 - loss: 0.0989 - sparse_categorical_accuracy: 0.9698\n",
            "108/469 [=====>........................] - ETA: 2:28 - loss: 0.0986 - sparse_categorical_accuracy: 0.9698\n",
            "109/469 [=====>........................] - ETA: 2:28 - loss: 0.0985 - sparse_categorical_accuracy: 0.9698\n",
            "110/469 [======>.......................] - ETA: 2:27 - loss: 0.0989 - sparse_categorical_accuracy: 0.9697\n",
            "111/469 [======>.......................] - ETA: 2:27 - loss: 0.0986 - sparse_categorical_accuracy: 0.9699\n",
            "112/469 [======>.......................] - ETA: 2:26 - loss: 0.0982 - sparse_categorical_accuracy: 0.9699\n",
            "113/469 [======>.......................] - ETA: 2:26 - loss: 0.0980 - sparse_categorical_accuracy: 0.9701\n",
            "114/469 [======>.......................] - ETA: 2:25 - loss: 0.0977 - sparse_categorical_accuracy: 0.9701\n",
            "115/469 [======>.......................] - ETA: 2:25 - loss: 0.0976 - sparse_categorical_accuracy: 0.9702\n",
            "116/469 [======>.......................] - ETA: 2:24 - loss: 0.0973 - sparse_categorical_accuracy: 0.9702\n",
            "117/469 [======>.......................] - ETA: 2:24 - loss: 0.0977 - sparse_categorical_accuracy: 0.9700\n",
            "118/469 [======>.......................] - ETA: 2:24 - loss: 0.0982 - sparse_categorical_accuracy: 0.9699\n",
            "119/469 [======>.......................] - ETA: 2:24 - loss: 0.0993 - sparse_categorical_accuracy: 0.9699\n",
            "120/469 [======>.......................] - ETA: 2:24 - loss: 0.0989 - sparse_categorical_accuracy: 0.9700\n",
            "121/469 [======>.......................] - ETA: 2:24 - loss: 0.0987 - sparse_categorical_accuracy: 0.9700\n",
            "122/469 [======>.......................] - ETA: 2:24 - loss: 0.0990 - sparse_categorical_accuracy: 0.9698\n",
            "123/469 [======>.......................] - ETA: 2:24 - loss: 0.0993 - sparse_categorical_accuracy: 0.9696\n",
            "124/469 [======>.......................] - ETA: 2:23 - loss: 0.0995 - sparse_categorical_accuracy: 0.9696\n",
            "125/469 [======>.......................] - ETA: 2:23 - loss: 0.0996 - sparse_categorical_accuracy: 0.9695\n",
            "126/469 [=======>......................] - ETA: 2:22 - loss: 0.0999 - sparse_categorical_accuracy: 0.9693\n",
            "127/469 [=======>......................] - ETA: 2:22 - loss: 0.1002 - sparse_categorical_accuracy: 0.9693\n",
            "128/469 [=======>......................] - ETA: 2:21 - loss: 0.1003 - sparse_categorical_accuracy: 0.9692\n",
            "129/469 [=======>......................] - ETA: 2:21 - loss: 0.1006 - sparse_categorical_accuracy: 0.9689\n",
            "130/469 [=======>......................] - ETA: 2:20 - loss: 0.1001 - sparse_categorical_accuracy: 0.9691\n",
            "131/469 [=======>......................] - ETA: 2:19 - loss: 0.1002 - sparse_categorical_accuracy: 0.9691\n",
            "132/469 [=======>......................] - ETA: 2:19 - loss: 0.0998 - sparse_categorical_accuracy: 0.9693\n",
            "133/469 [=======>......................] - ETA: 2:18 - loss: 0.1003 - sparse_categorical_accuracy: 0.9691\n",
            "134/469 [=======>......................] - ETA: 2:18 - loss: 0.0999 - sparse_categorical_accuracy: 0.9692\n",
            "135/469 [=======>......................] - ETA: 2:17 - loss: 0.0998 - sparse_categorical_accuracy: 0.9693\n",
            "136/469 [=======>......................] - ETA: 2:17 - loss: 0.0996 - sparse_categorical_accuracy: 0.9694\n",
            "137/469 [=======>......................] - ETA: 2:16 - loss: 0.0997 - sparse_categorical_accuracy: 0.9694\n",
            "138/469 [=======>......................] - ETA: 2:16 - loss: 0.1000 - sparse_categorical_accuracy: 0.9693\n",
            "139/469 [=======>......................] - ETA: 2:15 - loss: 0.0999 - sparse_categorical_accuracy: 0.9694\n",
            "140/469 [=======>......................] - ETA: 2:15 - loss: 0.1001 - sparse_categorical_accuracy: 0.9693\n",
            "141/469 [========>.....................] - ETA: 2:15 - loss: 0.1004 - sparse_categorical_accuracy: 0.9692\n",
            "142/469 [========>.....................] - ETA: 2:14 - loss: 0.1008 - sparse_categorical_accuracy: 0.9691\n",
            "143/469 [========>.....................] - ETA: 2:14 - loss: 0.1009 - sparse_categorical_accuracy: 0.9690\n",
            "144/469 [========>.....................] - ETA: 2:13 - loss: 0.1009 - sparse_categorical_accuracy: 0.9690\n",
            "145/469 [========>.....................] - ETA: 2:13 - loss: 0.1008 - sparse_categorical_accuracy: 0.9691\n",
            "146/469 [========>.....................] - ETA: 2:12 - loss: 0.1007 - sparse_categorical_accuracy: 0.9691\n",
            "147/469 [========>.....................] - ETA: 2:12 - loss: 0.1006 - sparse_categorical_accuracy: 0.9691\n",
            "148/469 [========>.....................] - ETA: 2:11 - loss: 0.1009 - sparse_categorical_accuracy: 0.9691\n",
            "149/469 [========>.....................] - ETA: 2:11 - loss: 0.1007 - sparse_categorical_accuracy: 0.9692\n",
            "150/469 [========>.....................] - ETA: 2:11 - loss: 0.1008 - sparse_categorical_accuracy: 0.9691\n",
            "151/469 [========>.....................] - ETA: 2:11 - loss: 0.1006 - sparse_categorical_accuracy: 0.9691\n",
            "152/469 [========>.....................] - ETA: 2:11 - loss: 0.1013 - sparse_categorical_accuracy: 0.9690\n",
            "153/469 [========>.....................] - ETA: 2:11 - loss: 0.1009 - sparse_categorical_accuracy: 0.9690\n",
            "154/469 [========>.....................] - ETA: 2:11 - loss: 0.1007 - sparse_categorical_accuracy: 0.9691\n",
            "155/469 [========>.....................] - ETA: 2:10 - loss: 0.1007 - sparse_categorical_accuracy: 0.9692\n",
            "156/469 [========>.....................] - ETA: 2:10 - loss: 0.1009 - sparse_categorical_accuracy: 0.9691\n",
            "157/469 [=========>....................] - ETA: 2:09 - loss: 0.1005 - sparse_categorical_accuracy: 0.9692\n",
            "158/469 [=========>....................] - ETA: 2:09 - loss: 0.1007 - sparse_categorical_accuracy: 0.9692\n",
            "159/469 [=========>....................] - ETA: 2:08 - loss: 0.1009 - sparse_categorical_accuracy: 0.9691\n",
            "160/469 [=========>....................] - ETA: 2:08 - loss: 0.1008 - sparse_categorical_accuracy: 0.9692\n",
            "161/469 [=========>....................] - ETA: 2:07 - loss: 0.1006 - sparse_categorical_accuracy: 0.9692\n",
            "162/469 [=========>....................] - ETA: 2:07 - loss: 0.1008 - sparse_categorical_accuracy: 0.9690\n",
            "163/469 [=========>....................] - ETA: 2:06 - loss: 0.1013 - sparse_categorical_accuracy: 0.9688\n",
            "164/469 [=========>....................] - ETA: 2:06 - loss: 0.1013 - sparse_categorical_accuracy: 0.9688\n",
            "165/469 [=========>....................] - ETA: 2:05 - loss: 0.1014 - sparse_categorical_accuracy: 0.9689\n",
            "166/469 [=========>....................] - ETA: 2:05 - loss: 0.1016 - sparse_categorical_accuracy: 0.9688\n",
            "167/469 [=========>....................] - ETA: 2:04 - loss: 0.1021 - sparse_categorical_accuracy: 0.9688\n",
            "168/469 [=========>....................] - ETA: 2:03 - loss: 0.1020 - sparse_categorical_accuracy: 0.9688\n",
            "169/469 [=========>....................] - ETA: 2:03 - loss: 0.1016 - sparse_categorical_accuracy: 0.9690\n",
            "170/469 [=========>....................] - ETA: 2:03 - loss: 0.1014 - sparse_categorical_accuracy: 0.9691\n",
            "171/469 [=========>....................] - ETA: 2:02 - loss: 0.1013 - sparse_categorical_accuracy: 0.9691\n",
            "172/469 [==========>...................] - ETA: 2:02 - loss: 0.1010 - sparse_categorical_accuracy: 0.9692\n",
            "173/469 [==========>...................] - ETA: 2:01 - loss: 0.1012 - sparse_categorical_accuracy: 0.9691\n",
            "174/469 [==========>...................] - ETA: 2:01 - loss: 0.1014 - sparse_categorical_accuracy: 0.9690\n",
            "175/469 [==========>...................] - ETA: 2:00 - loss: 0.1011 - sparse_categorical_accuracy: 0.9690\n",
            "176/469 [==========>...................] - ETA: 2:00 - loss: 0.1013 - sparse_categorical_accuracy: 0.9690\n",
            "177/469 [==========>...................] - ETA: 1:59 - loss: 0.1009 - sparse_categorical_accuracy: 0.9691\n",
            "178/469 [==========>...................] - ETA: 1:59 - loss: 0.1008 - sparse_categorical_accuracy: 0.9692\n",
            "179/469 [==========>...................] - ETA: 1:58 - loss: 0.1007 - sparse_categorical_accuracy: 0.9692\n",
            "180/469 [==========>...................] - ETA: 1:58 - loss: 0.1006 - sparse_categorical_accuracy: 0.9693\n",
            "181/469 [==========>...................] - ETA: 1:57 - loss: 0.1003 - sparse_categorical_accuracy: 0.9694\n",
            "182/469 [==========>...................] - ETA: 1:57 - loss: 0.1006 - sparse_categorical_accuracy: 0.9693\n",
            "183/469 [==========>...................] - ETA: 1:57 - loss: 0.1005 - sparse_categorical_accuracy: 0.9694\n",
            "184/469 [==========>...................] - ETA: 1:57 - loss: 0.1005 - sparse_categorical_accuracy: 0.9693\n",
            "185/469 [==========>...................] - ETA: 1:57 - loss: 0.1004 - sparse_categorical_accuracy: 0.9693\n",
            "186/469 [==========>...................] - ETA: 1:56 - loss: 0.1005 - sparse_categorical_accuracy: 0.9691\n",
            "187/469 [==========>...................] - ETA: 1:56 - loss: 0.1003 - sparse_categorical_accuracy: 0.9692\n",
            "188/469 [===========>..................] - ETA: 1:56 - loss: 0.1001 - sparse_categorical_accuracy: 0.9692\n",
            "189/469 [===========>..................] - ETA: 1:56 - loss: 0.1002 - sparse_categorical_accuracy: 0.9692\n",
            "190/469 [===========>..................] - ETA: 1:55 - loss: 0.1001 - sparse_categorical_accuracy: 0.9692\n",
            "191/469 [===========>..................] - ETA: 1:55 - loss: 0.1002 - sparse_categorical_accuracy: 0.9690\n",
            "192/469 [===========>..................] - ETA: 1:54 - loss: 0.1000 - sparse_categorical_accuracy: 0.9690\n",
            "193/469 [===========>..................] - ETA: 1:54 - loss: 0.1004 - sparse_categorical_accuracy: 0.9688\n",
            "194/469 [===========>..................] - ETA: 1:53 - loss: 0.1002 - sparse_categorical_accuracy: 0.9689\n",
            "195/469 [===========>..................] - ETA: 1:53 - loss: 0.1001 - sparse_categorical_accuracy: 0.9690\n",
            "196/469 [===========>..................] - ETA: 1:52 - loss: 0.1001 - sparse_categorical_accuracy: 0.9689\n",
            "197/469 [===========>..................] - ETA: 1:52 - loss: 0.1002 - sparse_categorical_accuracy: 0.9688\n",
            "198/469 [===========>..................] - ETA: 1:51 - loss: 0.1006 - sparse_categorical_accuracy: 0.9688\n",
            "199/469 [===========>..................] - ETA: 1:51 - loss: 0.1004 - sparse_categorical_accuracy: 0.9688\n",
            "200/469 [===========>..................] - ETA: 1:50 - loss: 0.1001 - sparse_categorical_accuracy: 0.9689\n",
            "201/469 [===========>..................] - ETA: 1:50 - loss: 0.1001 - sparse_categorical_accuracy: 0.9688\n",
            "202/469 [===========>..................] - ETA: 1:49 - loss: 0.1002 - sparse_categorical_accuracy: 0.9688\n",
            "203/469 [===========>..................] - ETA: 1:49 - loss: 0.1000 - sparse_categorical_accuracy: 0.9688\n",
            "204/469 [============>.................] - ETA: 1:49 - loss: 0.0999 - sparse_categorical_accuracy: 0.9689\n",
            "205/469 [============>.................] - ETA: 1:48 - loss: 0.0998 - sparse_categorical_accuracy: 0.9689\n",
            "206/469 [============>.................] - ETA: 1:48 - loss: 0.0999 - sparse_categorical_accuracy: 0.9688\n",
            "207/469 [============>.................] - ETA: 1:47 - loss: 0.1001 - sparse_categorical_accuracy: 0.9687\n",
            "208/469 [============>.................] - ETA: 1:47 - loss: 0.0999 - sparse_categorical_accuracy: 0.9688\n",
            "209/469 [============>.................] - ETA: 1:46 - loss: 0.0997 - sparse_categorical_accuracy: 0.9689\n",
            "210/469 [============>.................] - ETA: 1:46 - loss: 0.0994 - sparse_categorical_accuracy: 0.9690\n",
            "211/469 [============>.................] - ETA: 1:45 - loss: 0.0997 - sparse_categorical_accuracy: 0.9690\n",
            "212/469 [============>.................] - ETA: 1:45 - loss: 0.0997 - sparse_categorical_accuracy: 0.9690\n",
            "213/469 [============>.................] - ETA: 1:44 - loss: 0.1001 - sparse_categorical_accuracy: 0.9689\n",
            "214/469 [============>.................] - ETA: 1:44 - loss: 0.0999 - sparse_categorical_accuracy: 0.9690\n",
            "215/469 [============>.................] - ETA: 1:44 - loss: 0.1002 - sparse_categorical_accuracy: 0.9690\n",
            "216/469 [============>.................] - ETA: 1:44 - loss: 0.1003 - sparse_categorical_accuracy: 0.9690\n",
            "217/469 [============>.................] - ETA: 1:43 - loss: 0.1009 - sparse_categorical_accuracy: 0.9689\n",
            "218/469 [============>.................] - ETA: 1:43 - loss: 0.1008 - sparse_categorical_accuracy: 0.9689\n",
            "219/469 [=============>................] - ETA: 1:43 - loss: 0.1013 - sparse_categorical_accuracy: 0.9688\n",
            "220/469 [=============>................] - ETA: 1:43 - loss: 0.1013 - sparse_categorical_accuracy: 0.9688\n",
            "221/469 [=============>................] - ETA: 1:42 - loss: 0.1014 - sparse_categorical_accuracy: 0.9688\n",
            "222/469 [=============>................] - ETA: 1:42 - loss: 0.1018 - sparse_categorical_accuracy: 0.9687\n",
            "223/469 [=============>................] - ETA: 1:41 - loss: 0.1016 - sparse_categorical_accuracy: 0.9688\n",
            "224/469 [=============>................] - ETA: 1:41 - loss: 0.1014 - sparse_categorical_accuracy: 0.9688\n",
            "225/469 [=============>................] - ETA: 1:40 - loss: 0.1013 - sparse_categorical_accuracy: 0.9689\n",
            "226/469 [=============>................] - ETA: 1:40 - loss: 0.1011 - sparse_categorical_accuracy: 0.9689\n",
            "227/469 [=============>................] - ETA: 1:39 - loss: 0.1013 - sparse_categorical_accuracy: 0.9689\n",
            "228/469 [=============>................] - ETA: 1:39 - loss: 0.1012 - sparse_categorical_accuracy: 0.9689\n",
            "229/469 [=============>................] - ETA: 1:38 - loss: 0.1010 - sparse_categorical_accuracy: 0.9689\n",
            "230/469 [=============>................] - ETA: 1:38 - loss: 0.1009 - sparse_categorical_accuracy: 0.9689\n",
            "231/469 [=============>................] - ETA: 1:37 - loss: 0.1007 - sparse_categorical_accuracy: 0.9690\n",
            "232/469 [=============>................] - ETA: 1:37 - loss: 0.1010 - sparse_categorical_accuracy: 0.9690\n",
            "233/469 [=============>................] - ETA: 1:37 - loss: 0.1010 - sparse_categorical_accuracy: 0.9690\n",
            "234/469 [=============>................] - ETA: 1:36 - loss: 0.1010 - sparse_categorical_accuracy: 0.9690\n",
            "235/469 [==============>...............] - ETA: 1:36 - loss: 0.1009 - sparse_categorical_accuracy: 0.9691\n",
            "236/469 [==============>...............] - ETA: 1:35 - loss: 0.1006 - sparse_categorical_accuracy: 0.9692\n",
            "237/469 [==============>...............] - ETA: 1:35 - loss: 0.1009 - sparse_categorical_accuracy: 0.9691\n",
            "238/469 [==============>...............] - ETA: 1:34 - loss: 0.1007 - sparse_categorical_accuracy: 0.9692\n",
            "239/469 [==============>...............] - ETA: 1:34 - loss: 0.1008 - sparse_categorical_accuracy: 0.9691\n",
            "240/469 [==============>...............] - ETA: 1:33 - loss: 0.1009 - sparse_categorical_accuracy: 0.9691\n",
            "241/469 [==============>...............] - ETA: 1:33 - loss: 0.1011 - sparse_categorical_accuracy: 0.9690\n",
            "242/469 [==============>...............] - ETA: 1:33 - loss: 0.1012 - sparse_categorical_accuracy: 0.9690\n",
            "243/469 [==============>...............] - ETA: 1:32 - loss: 0.1014 - sparse_categorical_accuracy: 0.9689\n",
            "244/469 [==============>...............] - ETA: 1:32 - loss: 0.1012 - sparse_categorical_accuracy: 0.9690\n",
            "245/469 [==============>...............] - ETA: 1:31 - loss: 0.1013 - sparse_categorical_accuracy: 0.9690\n",
            "246/469 [==============>...............] - ETA: 1:31 - loss: 0.1011 - sparse_categorical_accuracy: 0.9691\n",
            "247/469 [==============>...............] - ETA: 1:30 - loss: 0.1011 - sparse_categorical_accuracy: 0.9690\n",
            "248/469 [==============>...............] - ETA: 1:30 - loss: 0.1012 - sparse_categorical_accuracy: 0.9689\n",
            "249/469 [==============>...............] - ETA: 1:30 - loss: 0.1011 - sparse_categorical_accuracy: 0.9689\n",
            "250/469 [==============>...............] - ETA: 1:30 - loss: 0.1009 - sparse_categorical_accuracy: 0.9690\n",
            "251/469 [===============>..............] - ETA: 1:29 - loss: 0.1009 - sparse_categorical_accuracy: 0.9690\n",
            "252/469 [===============>..............] - ETA: 1:29 - loss: 0.1008 - sparse_categorical_accuracy: 0.9690\n",
            "253/469 [===============>..............] - ETA: 1:29 - loss: 0.1010 - sparse_categorical_accuracy: 0.9690\n",
            "254/469 [===============>..............] - ETA: 1:28 - loss: 0.1011 - sparse_categorical_accuracy: 0.9690\n",
            "255/469 [===============>..............] - ETA: 1:28 - loss: 0.1009 - sparse_categorical_accuracy: 0.9691\n",
            "256/469 [===============>..............] - ETA: 1:27 - loss: 0.1009 - sparse_categorical_accuracy: 0.9691\n",
            "257/469 [===============>..............] - ETA: 1:27 - loss: 0.1010 - sparse_categorical_accuracy: 0.9690\n",
            "258/469 [===============>..............] - ETA: 1:26 - loss: 0.1008 - sparse_categorical_accuracy: 0.9690\n",
            "259/469 [===============>..............] - ETA: 1:26 - loss: 0.1008 - sparse_categorical_accuracy: 0.9690\n",
            "260/469 [===============>..............] - ETA: 1:26 - loss: 0.1009 - sparse_categorical_accuracy: 0.9690\n",
            "261/469 [===============>..............] - ETA: 1:25 - loss: 0.1008 - sparse_categorical_accuracy: 0.9690\n",
            "262/469 [===============>..............] - ETA: 1:25 - loss: 0.1008 - sparse_categorical_accuracy: 0.9689\n",
            "263/469 [===============>..............] - ETA: 1:24 - loss: 0.1007 - sparse_categorical_accuracy: 0.9689\n",
            "264/469 [===============>..............] - ETA: 1:24 - loss: 0.1006 - sparse_categorical_accuracy: 0.9689\n",
            "265/469 [===============>..............] - ETA: 1:23 - loss: 0.1006 - sparse_categorical_accuracy: 0.9688\n",
            "266/469 [================>.............] - ETA: 1:23 - loss: 0.1007 - sparse_categorical_accuracy: 0.9688\n",
            "267/469 [================>.............] - ETA: 1:22 - loss: 0.1009 - sparse_categorical_accuracy: 0.9687\n",
            "268/469 [================>.............] - ETA: 1:22 - loss: 0.1010 - sparse_categorical_accuracy: 0.9686\n",
            "269/469 [================>.............] - ETA: 1:22 - loss: 0.1008 - sparse_categorical_accuracy: 0.9686\n",
            "270/469 [================>.............] - ETA: 1:21 - loss: 0.1007 - sparse_categorical_accuracy: 0.9687\n",
            "271/469 [================>.............] - ETA: 1:21 - loss: 0.1008 - sparse_categorical_accuracy: 0.9686\n",
            "272/469 [================>.............] - ETA: 1:20 - loss: 0.1006 - sparse_categorical_accuracy: 0.9687\n",
            "273/469 [================>.............] - ETA: 1:20 - loss: 0.1004 - sparse_categorical_accuracy: 0.9688\n",
            "274/469 [================>.............] - ETA: 1:19 - loss: 0.1004 - sparse_categorical_accuracy: 0.9688\n",
            "275/469 [================>.............] - ETA: 1:19 - loss: 0.1007 - sparse_categorical_accuracy: 0.9687\n",
            "276/469 [================>.............] - ETA: 1:19 - loss: 0.1008 - sparse_categorical_accuracy: 0.9686\n",
            "277/469 [================>.............] - ETA: 1:18 - loss: 0.1010 - sparse_categorical_accuracy: 0.9686\n",
            "278/469 [================>.............] - ETA: 1:18 - loss: 0.1010 - sparse_categorical_accuracy: 0.9686\n",
            "279/469 [================>.............] - ETA: 1:17 - loss: 0.1008 - sparse_categorical_accuracy: 0.9686\n",
            "280/469 [================>.............] - ETA: 1:17 - loss: 0.1008 - sparse_categorical_accuracy: 0.9687\n",
            "281/469 [================>.............] - ETA: 1:17 - loss: 0.1009 - sparse_categorical_accuracy: 0.9687\n",
            "282/469 [=================>............] - ETA: 1:16 - loss: 0.1011 - sparse_categorical_accuracy: 0.9687\n",
            "283/469 [=================>............] - ETA: 1:16 - loss: 0.1010 - sparse_categorical_accuracy: 0.9687\n",
            "284/469 [=================>............] - ETA: 1:16 - loss: 0.1009 - sparse_categorical_accuracy: 0.9687\n",
            "285/469 [=================>............] - ETA: 1:15 - loss: 0.1008 - sparse_categorical_accuracy: 0.9687\n",
            "286/469 [=================>............] - ETA: 1:15 - loss: 0.1008 - sparse_categorical_accuracy: 0.9687\n",
            "287/469 [=================>............] - ETA: 1:15 - loss: 0.1008 - sparse_categorical_accuracy: 0.9687\n",
            "288/469 [=================>............] - ETA: 1:14 - loss: 0.1007 - sparse_categorical_accuracy: 0.9687\n",
            "289/469 [=================>............] - ETA: 1:14 - loss: 0.1008 - sparse_categorical_accuracy: 0.9688\n",
            "290/469 [=================>............] - ETA: 1:13 - loss: 0.1007 - sparse_categorical_accuracy: 0.9687\n",
            "291/469 [=================>............] - ETA: 1:13 - loss: 0.1005 - sparse_categorical_accuracy: 0.9688\n",
            "292/469 [=================>............] - ETA: 1:13 - loss: 0.1007 - sparse_categorical_accuracy: 0.9686\n",
            "293/469 [=================>............] - ETA: 1:12 - loss: 0.1007 - sparse_categorical_accuracy: 0.9687\n",
            "294/469 [=================>............] - ETA: 1:12 - loss: 0.1006 - sparse_categorical_accuracy: 0.9687\n",
            "295/469 [=================>............] - ETA: 1:11 - loss: 0.1004 - sparse_categorical_accuracy: 0.9688\n",
            "296/469 [=================>............] - ETA: 1:11 - loss: 0.1002 - sparse_categorical_accuracy: 0.9689\n",
            "297/469 [=================>............] - ETA: 1:10 - loss: 0.1001 - sparse_categorical_accuracy: 0.9689\n",
            "298/469 [==================>...........] - ETA: 1:10 - loss: 0.1001 - sparse_categorical_accuracy: 0.9689\n",
            "299/469 [==================>...........] - ETA: 1:09 - loss: 0.1002 - sparse_categorical_accuracy: 0.9688\n",
            "300/469 [==================>...........] - ETA: 1:09 - loss: 0.1003 - sparse_categorical_accuracy: 0.9688\n",
            "301/469 [==================>...........] - ETA: 1:09 - loss: 0.1002 - sparse_categorical_accuracy: 0.9689\n",
            "302/469 [==================>...........] - ETA: 1:08 - loss: 0.1000 - sparse_categorical_accuracy: 0.9689\n",
            "303/469 [==================>...........] - ETA: 1:08 - loss: 0.1000 - sparse_categorical_accuracy: 0.9689\n",
            "304/469 [==================>...........] - ETA: 1:07 - loss: 0.1000 - sparse_categorical_accuracy: 0.9689\n",
            "305/469 [==================>...........] - ETA: 1:07 - loss: 0.1001 - sparse_categorical_accuracy: 0.9689\n",
            "306/469 [==================>...........] - ETA: 1:06 - loss: 0.0999 - sparse_categorical_accuracy: 0.9689\n",
            "307/469 [==================>...........] - ETA: 1:06 - loss: 0.0997 - sparse_categorical_accuracy: 0.9690\n",
            "308/469 [==================>...........] - ETA: 1:06 - loss: 0.0996 - sparse_categorical_accuracy: 0.9691\n",
            "309/469 [==================>...........] - ETA: 1:05 - loss: 0.0995 - sparse_categorical_accuracy: 0.9691\n",
            "310/469 [==================>...........] - ETA: 1:05 - loss: 0.0994 - sparse_categorical_accuracy: 0.9692\n",
            "311/469 [==================>...........] - ETA: 1:04 - loss: 0.0995 - sparse_categorical_accuracy: 0.9691\n",
            "312/469 [==================>...........] - ETA: 1:04 - loss: 0.0994 - sparse_categorical_accuracy: 0.9691\n",
            "313/469 [===================>..........] - ETA: 1:04 - loss: 0.0994 - sparse_categorical_accuracy: 0.9691\n",
            "314/469 [===================>..........] - ETA: 1:03 - loss: 0.0993 - sparse_categorical_accuracy: 0.9691\n",
            "315/469 [===================>..........] - ETA: 1:03 - loss: 0.0993 - sparse_categorical_accuracy: 0.9692\n",
            "316/469 [===================>..........] - ETA: 1:03 - loss: 0.0992 - sparse_categorical_accuracy: 0.9692\n",
            "317/469 [===================>..........] - ETA: 1:02 - loss: 0.0992 - sparse_categorical_accuracy: 0.9693\n",
            "318/469 [===================>..........] - ETA: 1:02 - loss: 0.0990 - sparse_categorical_accuracy: 0.9693\n",
            "319/469 [===================>..........] - ETA: 1:01 - loss: 0.0988 - sparse_categorical_accuracy: 0.9694\n",
            "320/469 [===================>..........] - ETA: 1:01 - loss: 0.0988 - sparse_categorical_accuracy: 0.9694\n",
            "321/469 [===================>..........] - ETA: 1:01 - loss: 0.0987 - sparse_categorical_accuracy: 0.9694\n",
            "322/469 [===================>..........] - ETA: 1:00 - loss: 0.0989 - sparse_categorical_accuracy: 0.9694\n",
            "323/469 [===================>..........] - ETA: 1:00 - loss: 0.0988 - sparse_categorical_accuracy: 0.9694\n",
            "324/469 [===================>..........] - ETA: 59s - loss: 0.0987 - sparse_categorical_accuracy: 0.9694 \n",
            "325/469 [===================>..........] - ETA: 59s - loss: 0.0987 - sparse_categorical_accuracy: 0.9695\n",
            "326/469 [===================>..........] - ETA: 58s - loss: 0.0987 - sparse_categorical_accuracy: 0.9694\n",
            "327/469 [===================>..........] - ETA: 58s - loss: 0.0986 - sparse_categorical_accuracy: 0.9694\n",
            "328/469 [===================>..........] - ETA: 58s - loss: 0.0986 - sparse_categorical_accuracy: 0.9694\n",
            "329/469 [====================>.........] - ETA: 57s - loss: 0.0986 - sparse_categorical_accuracy: 0.9694\n",
            "330/469 [====================>.........] - ETA: 57s - loss: 0.0988 - sparse_categorical_accuracy: 0.9694\n",
            "331/469 [====================>.........] - ETA: 56s - loss: 0.0987 - sparse_categorical_accuracy: 0.9694\n",
            "332/469 [====================>.........] - ETA: 56s - loss: 0.0986 - sparse_categorical_accuracy: 0.9694\n",
            "333/469 [====================>.........] - ETA: 56s - loss: 0.0987 - sparse_categorical_accuracy: 0.9695\n",
            "334/469 [====================>.........] - ETA: 55s - loss: 0.0987 - sparse_categorical_accuracy: 0.9695\n",
            "335/469 [====================>.........] - ETA: 55s - loss: 0.0990 - sparse_categorical_accuracy: 0.9694\n",
            "336/469 [====================>.........] - ETA: 54s - loss: 0.0988 - sparse_categorical_accuracy: 0.9695\n",
            "337/469 [====================>.........] - ETA: 54s - loss: 0.0986 - sparse_categorical_accuracy: 0.9696\n",
            "338/469 [====================>.........] - ETA: 53s - loss: 0.0989 - sparse_categorical_accuracy: 0.9696\n",
            "339/469 [====================>.........] - ETA: 53s - loss: 0.0989 - sparse_categorical_accuracy: 0.9695\n",
            "340/469 [====================>.........] - ETA: 53s - loss: 0.0989 - sparse_categorical_accuracy: 0.9695\n",
            "341/469 [====================>.........] - ETA: 52s - loss: 0.0988 - sparse_categorical_accuracy: 0.9696\n",
            "342/469 [====================>.........] - ETA: 52s - loss: 0.0988 - sparse_categorical_accuracy: 0.9695\n",
            "343/469 [====================>.........] - ETA: 51s - loss: 0.0986 - sparse_categorical_accuracy: 0.9696\n",
            "344/469 [=====================>........] - ETA: 51s - loss: 0.0985 - sparse_categorical_accuracy: 0.9697\n",
            "345/469 [=====================>........] - ETA: 51s - loss: 0.0983 - sparse_categorical_accuracy: 0.9697\n",
            "346/469 [=====================>........] - ETA: 50s - loss: 0.0985 - sparse_categorical_accuracy: 0.9697\n",
            "347/469 [=====================>........] - ETA: 50s - loss: 0.0983 - sparse_categorical_accuracy: 0.9697\n",
            "348/469 [=====================>........] - ETA: 50s - loss: 0.0988 - sparse_categorical_accuracy: 0.9698\n",
            "349/469 [=====================>........] - ETA: 49s - loss: 0.0988 - sparse_categorical_accuracy: 0.9697\n",
            "350/469 [=====================>........] - ETA: 49s - loss: 0.0988 - sparse_categorical_accuracy: 0.9697\n",
            "351/469 [=====================>........] - ETA: 48s - loss: 0.0987 - sparse_categorical_accuracy: 0.9697\n",
            "352/469 [=====================>........] - ETA: 48s - loss: 0.0986 - sparse_categorical_accuracy: 0.9697\n",
            "353/469 [=====================>........] - ETA: 48s - loss: 0.0987 - sparse_categorical_accuracy: 0.9697\n",
            "354/469 [=====================>........] - ETA: 47s - loss: 0.0986 - sparse_categorical_accuracy: 0.9697\n",
            "355/469 [=====================>........] - ETA: 47s - loss: 0.0985 - sparse_categorical_accuracy: 0.9698\n",
            "356/469 [=====================>........] - ETA: 46s - loss: 0.0985 - sparse_categorical_accuracy: 0.9698\n",
            "357/469 [=====================>........] - ETA: 46s - loss: 0.0984 - sparse_categorical_accuracy: 0.9698\n",
            "358/469 [=====================>........] - ETA: 46s - loss: 0.0984 - sparse_categorical_accuracy: 0.9698\n",
            "359/469 [=====================>........] - ETA: 45s - loss: 0.0985 - sparse_categorical_accuracy: 0.9697\n",
            "360/469 [======================>.......] - ETA: 45s - loss: 0.0983 - sparse_categorical_accuracy: 0.9698\n",
            "361/469 [======================>.......] - ETA: 44s - loss: 0.0986 - sparse_categorical_accuracy: 0.9698\n",
            "362/469 [======================>.......] - ETA: 44s - loss: 0.0984 - sparse_categorical_accuracy: 0.9698\n",
            "363/469 [======================>.......] - ETA: 43s - loss: 0.0986 - sparse_categorical_accuracy: 0.9698\n",
            "364/469 [======================>.......] - ETA: 43s - loss: 0.0985 - sparse_categorical_accuracy: 0.9698\n",
            "365/469 [======================>.......] - ETA: 43s - loss: 0.0986 - sparse_categorical_accuracy: 0.9698\n",
            "366/469 [======================>.......] - ETA: 42s - loss: 0.0986 - sparse_categorical_accuracy: 0.9698\n",
            "367/469 [======================>.......] - ETA: 42s - loss: 0.0986 - sparse_categorical_accuracy: 0.9698\n",
            "368/469 [======================>.......] - ETA: 41s - loss: 0.0984 - sparse_categorical_accuracy: 0.9699\n",
            "369/469 [======================>.......] - ETA: 41s - loss: 0.0984 - sparse_categorical_accuracy: 0.9699\n",
            "370/469 [======================>.......] - ETA: 41s - loss: 0.0983 - sparse_categorical_accuracy: 0.9699\n",
            "371/469 [======================>.......] - ETA: 40s - loss: 0.0982 - sparse_categorical_accuracy: 0.9699\n",
            "372/469 [======================>.......] - ETA: 40s - loss: 0.0980 - sparse_categorical_accuracy: 0.9699\n",
            "373/469 [======================>.......] - ETA: 39s - loss: 0.0980 - sparse_categorical_accuracy: 0.9700\n",
            "374/469 [======================>.......] - ETA: 39s - loss: 0.0981 - sparse_categorical_accuracy: 0.9699\n",
            "375/469 [======================>.......] - ETA: 38s - loss: 0.0981 - sparse_categorical_accuracy: 0.9700\n",
            "376/469 [=======================>......] - ETA: 38s - loss: 0.0981 - sparse_categorical_accuracy: 0.9700\n",
            "377/469 [=======================>......] - ETA: 38s - loss: 0.0981 - sparse_categorical_accuracy: 0.9700\n",
            "378/469 [=======================>......] - ETA: 37s - loss: 0.0980 - sparse_categorical_accuracy: 0.9700\n",
            "379/469 [=======================>......] - ETA: 37s - loss: 0.0979 - sparse_categorical_accuracy: 0.9700\n",
            "380/469 [=======================>......] - ETA: 37s - loss: 0.0977 - sparse_categorical_accuracy: 0.9701\n",
            "381/469 [=======================>......] - ETA: 36s - loss: 0.0975 - sparse_categorical_accuracy: 0.9701\n",
            "382/469 [=======================>......] - ETA: 36s - loss: 0.0975 - sparse_categorical_accuracy: 0.9701\n",
            "383/469 [=======================>......] - ETA: 35s - loss: 0.0976 - sparse_categorical_accuracy: 0.9701\n",
            "384/469 [=======================>......] - ETA: 35s - loss: 0.0974 - sparse_categorical_accuracy: 0.9702\n",
            "385/469 [=======================>......] - ETA: 34s - loss: 0.0974 - sparse_categorical_accuracy: 0.9702\n",
            "386/469 [=======================>......] - ETA: 34s - loss: 0.0972 - sparse_categorical_accuracy: 0.9702\n",
            "387/469 [=======================>......] - ETA: 34s - loss: 0.0971 - sparse_categorical_accuracy: 0.9703\n",
            "388/469 [=======================>......] - ETA: 33s - loss: 0.0973 - sparse_categorical_accuracy: 0.9702\n",
            "389/469 [=======================>......] - ETA: 33s - loss: 0.0972 - sparse_categorical_accuracy: 0.9703\n",
            "390/469 [=======================>......] - ETA: 32s - loss: 0.0972 - sparse_categorical_accuracy: 0.9703\n",
            "391/469 [========================>.....] - ETA: 32s - loss: 0.0970 - sparse_categorical_accuracy: 0.9704\n",
            "392/469 [========================>.....] - ETA: 32s - loss: 0.0970 - sparse_categorical_accuracy: 0.9703\n",
            "393/469 [========================>.....] - ETA: 31s - loss: 0.0971 - sparse_categorical_accuracy: 0.9703\n",
            "394/469 [========================>.....] - ETA: 31s - loss: 0.0970 - sparse_categorical_accuracy: 0.9704\n",
            "395/469 [========================>.....] - ETA: 30s - loss: 0.0970 - sparse_categorical_accuracy: 0.9704\n",
            "396/469 [========================>.....] - ETA: 30s - loss: 0.0971 - sparse_categorical_accuracy: 0.9704\n",
            "397/469 [========================>.....] - ETA: 29s - loss: 0.0973 - sparse_categorical_accuracy: 0.9704\n",
            "398/469 [========================>.....] - ETA: 29s - loss: 0.0973 - sparse_categorical_accuracy: 0.9703\n",
            "399/469 [========================>.....] - ETA: 29s - loss: 0.0973 - sparse_categorical_accuracy: 0.9703\n",
            "400/469 [========================>.....] - ETA: 28s - loss: 0.0971 - sparse_categorical_accuracy: 0.9704\n",
            "401/469 [========================>.....] - ETA: 28s - loss: 0.0969 - sparse_categorical_accuracy: 0.9704\n",
            "402/469 [========================>.....] - ETA: 27s - loss: 0.0969 - sparse_categorical_accuracy: 0.9704\n",
            "403/469 [========================>.....] - ETA: 27s - loss: 0.0969 - sparse_categorical_accuracy: 0.9705\n",
            "404/469 [========================>.....] - ETA: 27s - loss: 0.0968 - sparse_categorical_accuracy: 0.9705\n",
            "405/469 [========================>.....] - ETA: 26s - loss: 0.0968 - sparse_categorical_accuracy: 0.9705\n",
            "406/469 [========================>.....] - ETA: 26s - loss: 0.0967 - sparse_categorical_accuracy: 0.9705\n",
            "407/469 [=========================>....] - ETA: 25s - loss: 0.0969 - sparse_categorical_accuracy: 0.9705\n",
            "408/469 [=========================>....] - ETA: 25s - loss: 0.0968 - sparse_categorical_accuracy: 0.9705\n",
            "409/469 [=========================>....] - ETA: 25s - loss: 0.0969 - sparse_categorical_accuracy: 0.9705\n",
            "410/469 [=========================>....] - ETA: 24s - loss: 0.0967 - sparse_categorical_accuracy: 0.9705\n",
            "411/469 [=========================>....] - ETA: 24s - loss: 0.0966 - sparse_categorical_accuracy: 0.9706\n",
            "412/469 [=========================>....] - ETA: 23s - loss: 0.0967 - sparse_categorical_accuracy: 0.9705\n",
            "413/469 [=========================>....] - ETA: 23s - loss: 0.0966 - sparse_categorical_accuracy: 0.9705\n",
            "414/469 [=========================>....] - ETA: 23s - loss: 0.0966 - sparse_categorical_accuracy: 0.9706\n",
            "415/469 [=========================>....] - ETA: 22s - loss: 0.0966 - sparse_categorical_accuracy: 0.9706\n",
            "416/469 [=========================>....] - ETA: 22s - loss: 0.0965 - sparse_categorical_accuracy: 0.9706\n",
            "417/469 [=========================>....] - ETA: 21s - loss: 0.0965 - sparse_categorical_accuracy: 0.9706\n",
            "418/469 [=========================>....] - ETA: 21s - loss: 0.0964 - sparse_categorical_accuracy: 0.9706\n",
            "419/469 [=========================>....] - ETA: 20s - loss: 0.0963 - sparse_categorical_accuracy: 0.9707\n",
            "420/469 [=========================>....] - ETA: 20s - loss: 0.0963 - sparse_categorical_accuracy: 0.9707\n",
            "421/469 [=========================>....] - ETA: 20s - loss: 0.0963 - sparse_categorical_accuracy: 0.9707\n",
            "422/469 [=========================>....] - ETA: 19s - loss: 0.0962 - sparse_categorical_accuracy: 0.9707\n",
            "423/469 [==========================>...] - ETA: 19s - loss: 0.0961 - sparse_categorical_accuracy: 0.9708\n",
            "424/469 [==========================>...] - ETA: 18s - loss: 0.0963 - sparse_categorical_accuracy: 0.9707\n",
            "425/469 [==========================>...] - ETA: 18s - loss: 0.0963 - sparse_categorical_accuracy: 0.9707\n",
            "426/469 [==========================>...] - ETA: 17s - loss: 0.0964 - sparse_categorical_accuracy: 0.9707\n",
            "427/469 [==========================>...] - ETA: 17s - loss: 0.0964 - sparse_categorical_accuracy: 0.9707\n",
            "428/469 [==========================>...] - ETA: 17s - loss: 0.0964 - sparse_categorical_accuracy: 0.9706\n",
            "429/469 [==========================>...] - ETA: 16s - loss: 0.0963 - sparse_categorical_accuracy: 0.9707\n",
            "430/469 [==========================>...] - ETA: 16s - loss: 0.0964 - sparse_categorical_accuracy: 0.9706\n",
            "431/469 [==========================>...] - ETA: 15s - loss: 0.0964 - sparse_categorical_accuracy: 0.9707\n",
            "432/469 [==========================>...] - ETA: 15s - loss: 0.0964 - sparse_categorical_accuracy: 0.9706\n",
            "433/469 [==========================>...] - ETA: 15s - loss: 0.0965 - sparse_categorical_accuracy: 0.9706\n",
            "434/469 [==========================>...] - ETA: 14s - loss: 0.0965 - sparse_categorical_accuracy: 0.9706\n",
            "435/469 [==========================>...] - ETA: 14s - loss: 0.0963 - sparse_categorical_accuracy: 0.9706\n",
            "436/469 [==========================>...] - ETA: 13s - loss: 0.0964 - sparse_categorical_accuracy: 0.9705\n",
            "437/469 [==========================>...] - ETA: 13s - loss: 0.0964 - sparse_categorical_accuracy: 0.9706\n",
            "438/469 [===========================>..] - ETA: 12s - loss: 0.0964 - sparse_categorical_accuracy: 0.9706\n",
            "439/469 [===========================>..] - ETA: 12s - loss: 0.0964 - sparse_categorical_accuracy: 0.9706\n",
            "440/469 [===========================>..] - ETA: 12s - loss: 0.0965 - sparse_categorical_accuracy: 0.9705\n",
            "441/469 [===========================>..] - ETA: 11s - loss: 0.0966 - sparse_categorical_accuracy: 0.9705\n",
            "442/469 [===========================>..] - ETA: 11s - loss: 0.0966 - sparse_categorical_accuracy: 0.9705\n",
            "443/469 [===========================>..] - ETA: 10s - loss: 0.0965 - sparse_categorical_accuracy: 0.9705\n",
            "444/469 [===========================>..] - ETA: 10s - loss: 0.0966 - sparse_categorical_accuracy: 0.9705\n",
            "445/469 [===========================>..] - ETA: 10s - loss: 0.0965 - sparse_categorical_accuracy: 0.9705\n",
            "446/469 [===========================>..] - ETA: 9s - loss: 0.0965 - sparse_categorical_accuracy: 0.9705 \n",
            "447/469 [===========================>..] - ETA: 9s - loss: 0.0965 - sparse_categorical_accuracy: 0.9705\n",
            "448/469 [===========================>..] - ETA: 8s - loss: 0.0964 - sparse_categorical_accuracy: 0.9705\n",
            "449/469 [===========================>..] - ETA: 8s - loss: 0.0965 - sparse_categorical_accuracy: 0.9704\n",
            "450/469 [===========================>..] - ETA: 7s - loss: 0.0964 - sparse_categorical_accuracy: 0.9705\n",
            "451/469 [===========================>..] - ETA: 7s - loss: 0.0963 - sparse_categorical_accuracy: 0.9705\n",
            "452/469 [===========================>..] - ETA: 7s - loss: 0.0962 - sparse_categorical_accuracy: 0.9705\n",
            "453/469 [===========================>..] - ETA: 6s - loss: 0.0963 - sparse_categorical_accuracy: 0.9705\n",
            "454/469 [============================>.] - ETA: 6s - loss: 0.0962 - sparse_categorical_accuracy: 0.9706\n",
            "455/469 [============================>.] - ETA: 5s - loss: 0.0961 - sparse_categorical_accuracy: 0.9706\n",
            "456/469 [============================>.] - ETA: 5s - loss: 0.0960 - sparse_categorical_accuracy: 0.9706\n",
            "457/469 [============================>.] - ETA: 5s - loss: 0.0960 - sparse_categorical_accuracy: 0.9706\n",
            "458/469 [============================>.] - ETA: 4s - loss: 0.0959 - sparse_categorical_accuracy: 0.9707\n",
            "459/469 [============================>.] - ETA: 4s - loss: 0.0958 - sparse_categorical_accuracy: 0.9707\n",
            "460/469 [============================>.] - ETA: 3s - loss: 0.0958 - sparse_categorical_accuracy: 0.9707\n",
            "461/469 [============================>.] - ETA: 3s - loss: 0.0958 - sparse_categorical_accuracy: 0.9707\n",
            "462/469 [============================>.] - ETA: 2s - loss: 0.0957 - sparse_categorical_accuracy: 0.9707\n",
            "463/469 [============================>.] - ETA: 2s - loss: 0.0956 - sparse_categorical_accuracy: 0.9708\n",
            "464/469 [============================>.] - ETA: 2s - loss: 0.0957 - sparse_categorical_accuracy: 0.9708\n",
            "465/469 [============================>.] - ETA: 1s - loss: 0.0956 - sparse_categorical_accuracy: 0.9709\n",
            "466/469 [============================>.] - ETA: 1s - loss: 0.0956 - sparse_categorical_accuracy: 0.9708\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.0956 - sparse_categorical_accuracy: 0.9708\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0956 - sparse_categorical_accuracy: 0.9708\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0955 - sparse_categorical_accuracy: 0.9708\n",
            " 40%|████      | 2/5 [50:00<53:49, 1076.55s/trial, best loss: -0.9830999970436096]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/04/16 01:22:00 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 195s 416ms/step - loss: 0.0955 - sparse_categorical_accuracy: 0.9708\n",
            "\n",
            "Epoch 4/5\n",
            "\n",
            "  1/469 [..............................] - ETA: 4:12 - loss: 0.0594 - sparse_categorical_accuracy: 0.9844\n",
            "  2/469 [..............................] - ETA: 4:47 - loss: 0.1171 - sparse_categorical_accuracy: 0.9727\n",
            "  3/469 [..............................] - ETA: 4:31 - loss: 0.0953 - sparse_categorical_accuracy: 0.9740\n",
            "  4/469 [..............................] - ETA: 4:38 - loss: 0.1025 - sparse_categorical_accuracy: 0.9688\n",
            "  5/469 [..............................] - ETA: 4:37 - loss: 0.0887 - sparse_categorical_accuracy: 0.9734\n",
            "  6/469 [..............................] - ETA: 4:37 - loss: 0.0900 - sparse_categorical_accuracy: 0.9740\n",
            "  7/469 [..............................] - ETA: 4:21 - loss: 0.0876 - sparse_categorical_accuracy: 0.9754\n",
            "  8/469 [..............................] - ETA: 4:11 - loss: 0.0850 - sparse_categorical_accuracy: 0.9756\n",
            "  9/469 [..............................] - ETA: 4:01 - loss: 0.0872 - sparse_categorical_accuracy: 0.9748\n",
            " 10/469 [..............................] - ETA: 3:53 - loss: 0.0871 - sparse_categorical_accuracy: 0.9742\n",
            " 11/469 [..............................] - ETA: 3:48 - loss: 0.0842 - sparse_categorical_accuracy: 0.9744\n",
            " 12/469 [..............................] - ETA: 3:42 - loss: 0.0961 - sparse_categorical_accuracy: 0.9694\n",
            " 13/469 [..............................] - ETA: 3:39 - loss: 0.0939 - sparse_categorical_accuracy: 0.9700\n",
            " 14/469 [..............................] - ETA: 3:35 - loss: 0.0940 - sparse_categorical_accuracy: 0.9704\n",
            " 15/469 [..............................] - ETA: 3:31 - loss: 0.0937 - sparse_categorical_accuracy: 0.9703\n",
            " 16/469 [>.............................] - ETA: 3:29 - loss: 0.0918 - sparse_categorical_accuracy: 0.9712\n",
            " 17/469 [>.............................] - ETA: 3:26 - loss: 0.0886 - sparse_categorical_accuracy: 0.9724\n",
            " 18/469 [>.............................] - ETA: 3:24 - loss: 0.0849 - sparse_categorical_accuracy: 0.9740\n",
            " 19/469 [>.............................] - ETA: 3:21 - loss: 0.0839 - sparse_categorical_accuracy: 0.9745\n",
            " 20/469 [>.............................] - ETA: 3:19 - loss: 0.0819 - sparse_categorical_accuracy: 0.9754\n",
            " 21/469 [>.............................] - ETA: 3:18 - loss: 0.0803 - sparse_categorical_accuracy: 0.9762\n",
            " 22/469 [>.............................] - ETA: 3:16 - loss: 0.0811 - sparse_categorical_accuracy: 0.9759\n",
            " 23/469 [>.............................] - ETA: 3:15 - loss: 0.0789 - sparse_categorical_accuracy: 0.9766\n",
            " 24/469 [>.............................] - ETA: 3:13 - loss: 0.0800 - sparse_categorical_accuracy: 0.9759\n",
            " 25/469 [>.............................] - ETA: 3:12 - loss: 0.0793 - sparse_categorical_accuracy: 0.9759\n",
            " 26/469 [>.............................] - ETA: 3:10 - loss: 0.0770 - sparse_categorical_accuracy: 0.9766\n",
            " 27/469 [>.............................] - ETA: 3:09 - loss: 0.0767 - sparse_categorical_accuracy: 0.9766\n",
            " 28/469 [>.............................] - ETA: 3:08 - loss: 0.0784 - sparse_categorical_accuracy: 0.9766\n",
            " 29/469 [>.............................] - ETA: 3:07 - loss: 0.0779 - sparse_categorical_accuracy: 0.9763\n",
            " 30/469 [>.............................] - ETA: 3:06 - loss: 0.0784 - sparse_categorical_accuracy: 0.9760\n",
            " 31/469 [>.............................] - ETA: 3:05 - loss: 0.0777 - sparse_categorical_accuracy: 0.9763\n",
            " 32/469 [=>............................] - ETA: 3:05 - loss: 0.0761 - sparse_categorical_accuracy: 0.9768\n",
            " 33/469 [=>............................] - ETA: 3:07 - loss: 0.0745 - sparse_categorical_accuracy: 0.9775\n",
            " 34/469 [=>............................] - ETA: 3:09 - loss: 0.0739 - sparse_categorical_accuracy: 0.9775\n",
            " 35/469 [=>............................] - ETA: 3:11 - loss: 0.0731 - sparse_categorical_accuracy: 0.9779\n",
            " 36/469 [=>............................] - ETA: 3:12 - loss: 0.0741 - sparse_categorical_accuracy: 0.9776\n",
            " 37/469 [=>............................] - ETA: 3:13 - loss: 0.0738 - sparse_categorical_accuracy: 0.9776\n",
            " 38/469 [=>............................] - ETA: 3:13 - loss: 0.0729 - sparse_categorical_accuracy: 0.9782\n",
            " 39/469 [=>............................] - ETA: 3:12 - loss: 0.0724 - sparse_categorical_accuracy: 0.9784\n",
            " 40/469 [=>............................] - ETA: 3:11 - loss: 0.0727 - sparse_categorical_accuracy: 0.9781\n",
            " 41/469 [=>............................] - ETA: 3:10 - loss: 0.0737 - sparse_categorical_accuracy: 0.9781\n",
            " 42/469 [=>............................] - ETA: 3:09 - loss: 0.0730 - sparse_categorical_accuracy: 0.9784\n",
            " 43/469 [=>............................] - ETA: 3:08 - loss: 0.0731 - sparse_categorical_accuracy: 0.9786\n",
            " 44/469 [=>............................] - ETA: 3:07 - loss: 0.0756 - sparse_categorical_accuracy: 0.9782\n",
            " 45/469 [=>............................] - ETA: 3:06 - loss: 0.0753 - sparse_categorical_accuracy: 0.9783\n",
            " 46/469 [=>............................] - ETA: 3:05 - loss: 0.0749 - sparse_categorical_accuracy: 0.9781\n",
            " 47/469 [==>...........................] - ETA: 3:04 - loss: 0.0762 - sparse_categorical_accuracy: 0.9777\n",
            " 48/469 [==>...........................] - ETA: 3:03 - loss: 0.0759 - sparse_categorical_accuracy: 0.9779\n",
            " 49/469 [==>...........................] - ETA: 3:02 - loss: 0.0753 - sparse_categorical_accuracy: 0.9780\n",
            " 50/469 [==>...........................] - ETA: 3:01 - loss: 0.0759 - sparse_categorical_accuracy: 0.9777\n",
            " 51/469 [==>...........................] - ETA: 3:00 - loss: 0.0759 - sparse_categorical_accuracy: 0.9778\n",
            " 52/469 [==>...........................] - ETA: 2:59 - loss: 0.0768 - sparse_categorical_accuracy: 0.9776\n",
            " 53/469 [==>...........................] - ETA: 2:59 - loss: 0.0765 - sparse_categorical_accuracy: 0.9774\n",
            " 54/469 [==>...........................] - ETA: 2:58 - loss: 0.0763 - sparse_categorical_accuracy: 0.9774\n",
            " 55/469 [==>...........................] - ETA: 2:57 - loss: 0.0770 - sparse_categorical_accuracy: 0.9771\n",
            " 56/469 [==>...........................] - ETA: 2:57 - loss: 0.0772 - sparse_categorical_accuracy: 0.9770\n",
            " 57/469 [==>...........................] - ETA: 2:56 - loss: 0.0770 - sparse_categorical_accuracy: 0.9771\n",
            " 58/469 [==>...........................] - ETA: 2:55 - loss: 0.0771 - sparse_categorical_accuracy: 0.9768\n",
            " 59/469 [==>...........................] - ETA: 2:54 - loss: 0.0770 - sparse_categorical_accuracy: 0.9770\n",
            " 60/469 [==>...........................] - ETA: 2:54 - loss: 0.0772 - sparse_categorical_accuracy: 0.9768\n",
            " 61/469 [==>...........................] - ETA: 2:53 - loss: 0.0776 - sparse_categorical_accuracy: 0.9766\n",
            " 62/469 [==>...........................] - ETA: 2:52 - loss: 0.0785 - sparse_categorical_accuracy: 0.9763\n",
            " 63/469 [===>..........................] - ETA: 2:51 - loss: 0.0791 - sparse_categorical_accuracy: 0.9759\n",
            " 64/469 [===>..........................] - ETA: 2:51 - loss: 0.0794 - sparse_categorical_accuracy: 0.9758\n",
            " 65/469 [===>..........................] - ETA: 2:52 - loss: 0.0790 - sparse_categorical_accuracy: 0.9761\n",
            " 66/469 [===>..........................] - ETA: 2:53 - loss: 0.0781 - sparse_categorical_accuracy: 0.9764\n",
            " 67/469 [===>..........................] - ETA: 2:53 - loss: 0.0776 - sparse_categorical_accuracy: 0.9764\n",
            " 68/469 [===>..........................] - ETA: 2:54 - loss: 0.0776 - sparse_categorical_accuracy: 0.9766\n",
            " 69/469 [===>..........................] - ETA: 2:54 - loss: 0.0782 - sparse_categorical_accuracy: 0.9766\n",
            " 70/469 [===>..........................] - ETA: 2:54 - loss: 0.0784 - sparse_categorical_accuracy: 0.9765\n",
            " 71/469 [===>..........................] - ETA: 2:53 - loss: 0.0780 - sparse_categorical_accuracy: 0.9766\n",
            " 72/469 [===>..........................] - ETA: 2:52 - loss: 0.0782 - sparse_categorical_accuracy: 0.9766\n",
            " 73/469 [===>..........................] - ETA: 2:52 - loss: 0.0777 - sparse_categorical_accuracy: 0.9766\n",
            " 74/469 [===>..........................] - ETA: 2:51 - loss: 0.0777 - sparse_categorical_accuracy: 0.9766\n",
            " 75/469 [===>..........................] - ETA: 2:50 - loss: 0.0775 - sparse_categorical_accuracy: 0.9767\n",
            " 76/469 [===>..........................] - ETA: 2:49 - loss: 0.0774 - sparse_categorical_accuracy: 0.9767\n",
            " 77/469 [===>..........................] - ETA: 2:49 - loss: 0.0777 - sparse_categorical_accuracy: 0.9764\n",
            " 78/469 [===>..........................] - ETA: 2:48 - loss: 0.0773 - sparse_categorical_accuracy: 0.9765\n",
            " 79/469 [====>.........................] - ETA: 2:47 - loss: 0.0768 - sparse_categorical_accuracy: 0.9765\n",
            " 80/469 [====>.........................] - ETA: 2:47 - loss: 0.0770 - sparse_categorical_accuracy: 0.9762\n",
            " 81/469 [====>.........................] - ETA: 2:46 - loss: 0.0777 - sparse_categorical_accuracy: 0.9761\n",
            " 82/469 [====>.........................] - ETA: 2:45 - loss: 0.0778 - sparse_categorical_accuracy: 0.9760\n",
            " 83/469 [====>.........................] - ETA: 2:45 - loss: 0.0778 - sparse_categorical_accuracy: 0.9761\n",
            " 84/469 [====>.........................] - ETA: 2:44 - loss: 0.0777 - sparse_categorical_accuracy: 0.9763\n",
            " 85/469 [====>.........................] - ETA: 2:43 - loss: 0.0772 - sparse_categorical_accuracy: 0.9765\n",
            " 86/469 [====>.........................] - ETA: 2:43 - loss: 0.0770 - sparse_categorical_accuracy: 0.9765\n",
            " 87/469 [====>.........................] - ETA: 2:42 - loss: 0.0771 - sparse_categorical_accuracy: 0.9764\n",
            " 88/469 [====>.........................] - ETA: 2:41 - loss: 0.0769 - sparse_categorical_accuracy: 0.9764\n",
            " 89/469 [====>.........................] - ETA: 2:41 - loss: 0.0779 - sparse_categorical_accuracy: 0.9760\n",
            " 90/469 [====>.........................] - ETA: 2:40 - loss: 0.0774 - sparse_categorical_accuracy: 0.9762\n",
            " 91/469 [====>.........................] - ETA: 2:39 - loss: 0.0777 - sparse_categorical_accuracy: 0.9761\n",
            " 92/469 [====>.........................] - ETA: 2:39 - loss: 0.0781 - sparse_categorical_accuracy: 0.9761\n",
            " 93/469 [====>.........................] - ETA: 2:38 - loss: 0.0784 - sparse_categorical_accuracy: 0.9761\n",
            " 94/469 [=====>........................] - ETA: 2:38 - loss: 0.0783 - sparse_categorical_accuracy: 0.9760\n",
            " 95/469 [=====>........................] - ETA: 2:37 - loss: 0.0783 - sparse_categorical_accuracy: 0.9760\n",
            " 96/469 [=====>........................] - ETA: 2:36 - loss: 0.0782 - sparse_categorical_accuracy: 0.9761\n",
            " 97/469 [=====>........................] - ETA: 2:37 - loss: 0.0776 - sparse_categorical_accuracy: 0.9763\n",
            " 98/469 [=====>........................] - ETA: 2:37 - loss: 0.0778 - sparse_categorical_accuracy: 0.9762\n",
            " 99/469 [=====>........................] - ETA: 2:37 - loss: 0.0787 - sparse_categorical_accuracy: 0.9760\n",
            "100/469 [=====>........................] - ETA: 2:37 - loss: 0.0790 - sparse_categorical_accuracy: 0.9758\n",
            "101/469 [=====>........................] - ETA: 2:37 - loss: 0.0788 - sparse_categorical_accuracy: 0.9758\n",
            "102/469 [=====>........................] - ETA: 2:38 - loss: 0.0788 - sparse_categorical_accuracy: 0.9758\n",
            "103/469 [=====>........................] - ETA: 2:37 - loss: 0.0784 - sparse_categorical_accuracy: 0.9759\n",
            "104/469 [=====>........................] - ETA: 2:36 - loss: 0.0786 - sparse_categorical_accuracy: 0.9758\n",
            "105/469 [=====>........................] - ETA: 2:36 - loss: 0.0791 - sparse_categorical_accuracy: 0.9757\n",
            "106/469 [=====>........................] - ETA: 2:35 - loss: 0.0802 - sparse_categorical_accuracy: 0.9756\n",
            "107/469 [=====>........................] - ETA: 2:35 - loss: 0.0798 - sparse_categorical_accuracy: 0.9757\n",
            "108/469 [=====>........................] - ETA: 2:34 - loss: 0.0795 - sparse_categorical_accuracy: 0.9758\n",
            "109/469 [=====>........................] - ETA: 2:33 - loss: 0.0797 - sparse_categorical_accuracy: 0.9756\n",
            "110/469 [======>.......................] - ETA: 2:33 - loss: 0.0796 - sparse_categorical_accuracy: 0.9756\n",
            "111/469 [======>.......................] - ETA: 2:32 - loss: 0.0792 - sparse_categorical_accuracy: 0.9756\n",
            "112/469 [======>.......................] - ETA: 2:32 - loss: 0.0799 - sparse_categorical_accuracy: 0.9756\n",
            "113/469 [======>.......................] - ETA: 2:31 - loss: 0.0798 - sparse_categorical_accuracy: 0.9757\n",
            "114/469 [======>.......................] - ETA: 2:30 - loss: 0.0799 - sparse_categorical_accuracy: 0.9755\n",
            "115/469 [======>.......................] - ETA: 2:30 - loss: 0.0798 - sparse_categorical_accuracy: 0.9755\n",
            "116/469 [======>.......................] - ETA: 2:29 - loss: 0.0804 - sparse_categorical_accuracy: 0.9754\n",
            "117/469 [======>.......................] - ETA: 2:29 - loss: 0.0811 - sparse_categorical_accuracy: 0.9750\n",
            "118/469 [======>.......................] - ETA: 2:28 - loss: 0.0816 - sparse_categorical_accuracy: 0.9747\n",
            "119/469 [======>.......................] - ETA: 2:28 - loss: 0.0815 - sparse_categorical_accuracy: 0.9748\n",
            "120/469 [======>.......................] - ETA: 2:27 - loss: 0.0811 - sparse_categorical_accuracy: 0.9749\n",
            "121/469 [======>.......................] - ETA: 2:26 - loss: 0.0813 - sparse_categorical_accuracy: 0.9750\n",
            "122/469 [======>.......................] - ETA: 2:26 - loss: 0.0825 - sparse_categorical_accuracy: 0.9748\n",
            "123/469 [======>.......................] - ETA: 2:25 - loss: 0.0825 - sparse_categorical_accuracy: 0.9748\n",
            "124/469 [======>.......................] - ETA: 2:25 - loss: 0.0825 - sparse_categorical_accuracy: 0.9748\n",
            "125/469 [======>.......................] - ETA: 2:24 - loss: 0.0822 - sparse_categorical_accuracy: 0.9749\n",
            "126/469 [=======>......................] - ETA: 2:24 - loss: 0.0817 - sparse_categorical_accuracy: 0.9751\n",
            "127/469 [=======>......................] - ETA: 2:23 - loss: 0.0815 - sparse_categorical_accuracy: 0.9750\n",
            "128/469 [=======>......................] - ETA: 2:23 - loss: 0.0813 - sparse_categorical_accuracy: 0.9751\n",
            "129/469 [=======>......................] - ETA: 2:23 - loss: 0.0810 - sparse_categorical_accuracy: 0.9752\n",
            "130/469 [=======>......................] - ETA: 2:23 - loss: 0.0808 - sparse_categorical_accuracy: 0.9753\n",
            "131/469 [=======>......................] - ETA: 2:23 - loss: 0.0811 - sparse_categorical_accuracy: 0.9753\n",
            "132/469 [=======>......................] - ETA: 2:23 - loss: 0.0816 - sparse_categorical_accuracy: 0.9753\n",
            "133/469 [=======>......................] - ETA: 2:23 - loss: 0.0817 - sparse_categorical_accuracy: 0.9752\n",
            "134/469 [=======>......................] - ETA: 2:23 - loss: 0.0815 - sparse_categorical_accuracy: 0.9752\n",
            "135/469 [=======>......................] - ETA: 2:22 - loss: 0.0813 - sparse_categorical_accuracy: 0.9752\n",
            "136/469 [=======>......................] - ETA: 2:22 - loss: 0.0819 - sparse_categorical_accuracy: 0.9752\n",
            "137/469 [=======>......................] - ETA: 2:21 - loss: 0.0822 - sparse_categorical_accuracy: 0.9751\n",
            "138/469 [=======>......................] - ETA: 2:21 - loss: 0.0820 - sparse_categorical_accuracy: 0.9751\n",
            "139/469 [=======>......................] - ETA: 2:20 - loss: 0.0826 - sparse_categorical_accuracy: 0.9750\n",
            "140/469 [=======>......................] - ETA: 2:20 - loss: 0.0826 - sparse_categorical_accuracy: 0.9751\n",
            "141/469 [========>.....................] - ETA: 2:19 - loss: 0.0823 - sparse_categorical_accuracy: 0.9752\n",
            "142/469 [========>.....................] - ETA: 2:19 - loss: 0.0821 - sparse_categorical_accuracy: 0.9752\n",
            "143/469 [========>.....................] - ETA: 2:18 - loss: 0.0824 - sparse_categorical_accuracy: 0.9751\n",
            "144/469 [========>.....................] - ETA: 2:18 - loss: 0.0829 - sparse_categorical_accuracy: 0.9749\n",
            "145/469 [========>.....................] - ETA: 2:17 - loss: 0.0827 - sparse_categorical_accuracy: 0.9750\n",
            "146/469 [========>.....................] - ETA: 2:17 - loss: 0.0825 - sparse_categorical_accuracy: 0.9751\n",
            "147/469 [========>.....................] - ETA: 2:16 - loss: 0.0822 - sparse_categorical_accuracy: 0.9751\n",
            "148/469 [========>.....................] - ETA: 2:16 - loss: 0.0820 - sparse_categorical_accuracy: 0.9751\n",
            "149/469 [========>.....................] - ETA: 2:15 - loss: 0.0819 - sparse_categorical_accuracy: 0.9751\n",
            "150/469 [========>.....................] - ETA: 2:14 - loss: 0.0817 - sparse_categorical_accuracy: 0.9752\n",
            "151/469 [========>.....................] - ETA: 2:14 - loss: 0.0821 - sparse_categorical_accuracy: 0.9751\n",
            "152/469 [========>.....................] - ETA: 2:13 - loss: 0.0820 - sparse_categorical_accuracy: 0.9751\n",
            "153/469 [========>.....................] - ETA: 2:13 - loss: 0.0821 - sparse_categorical_accuracy: 0.9751\n",
            "154/469 [========>.....................] - ETA: 2:12 - loss: 0.0827 - sparse_categorical_accuracy: 0.9749\n",
            "155/469 [========>.....................] - ETA: 2:12 - loss: 0.0826 - sparse_categorical_accuracy: 0.9749\n",
            "156/469 [========>.....................] - ETA: 2:11 - loss: 0.0826 - sparse_categorical_accuracy: 0.9750\n",
            "157/469 [=========>....................] - ETA: 2:11 - loss: 0.0826 - sparse_categorical_accuracy: 0.9749\n",
            "158/469 [=========>....................] - ETA: 2:10 - loss: 0.0834 - sparse_categorical_accuracy: 0.9747\n",
            "159/469 [=========>....................] - ETA: 2:10 - loss: 0.0839 - sparse_categorical_accuracy: 0.9747\n",
            "160/469 [=========>....................] - ETA: 2:09 - loss: 0.0841 - sparse_categorical_accuracy: 0.9747\n",
            "161/469 [=========>....................] - ETA: 2:09 - loss: 0.0842 - sparse_categorical_accuracy: 0.9747\n",
            "162/469 [=========>....................] - ETA: 2:09 - loss: 0.0847 - sparse_categorical_accuracy: 0.9745\n",
            "163/469 [=========>....................] - ETA: 2:09 - loss: 0.0850 - sparse_categorical_accuracy: 0.9745\n",
            "164/469 [=========>....................] - ETA: 2:09 - loss: 0.0849 - sparse_categorical_accuracy: 0.9745\n",
            "165/469 [=========>....................] - ETA: 2:09 - loss: 0.0848 - sparse_categorical_accuracy: 0.9745\n",
            "166/469 [=========>....................] - ETA: 2:09 - loss: 0.0845 - sparse_categorical_accuracy: 0.9746\n",
            "167/469 [=========>....................] - ETA: 2:08 - loss: 0.0842 - sparse_categorical_accuracy: 0.9747\n",
            "168/469 [=========>....................] - ETA: 2:07 - loss: 0.0842 - sparse_categorical_accuracy: 0.9747\n",
            "169/469 [=========>....................] - ETA: 2:07 - loss: 0.0839 - sparse_categorical_accuracy: 0.9748\n",
            "170/469 [=========>....................] - ETA: 2:06 - loss: 0.0836 - sparse_categorical_accuracy: 0.9750\n",
            "171/469 [=========>....................] - ETA: 2:06 - loss: 0.0835 - sparse_categorical_accuracy: 0.9749\n",
            "172/469 [==========>...................] - ETA: 2:05 - loss: 0.0838 - sparse_categorical_accuracy: 0.9748\n",
            "173/469 [==========>...................] - ETA: 2:05 - loss: 0.0836 - sparse_categorical_accuracy: 0.9749\n",
            "174/469 [==========>...................] - ETA: 2:04 - loss: 0.0835 - sparse_categorical_accuracy: 0.9749\n",
            "175/469 [==========>...................] - ETA: 2:04 - loss: 0.0836 - sparse_categorical_accuracy: 0.9748\n",
            "176/469 [==========>...................] - ETA: 2:03 - loss: 0.0841 - sparse_categorical_accuracy: 0.9747\n",
            "177/469 [==========>...................] - ETA: 2:03 - loss: 0.0841 - sparse_categorical_accuracy: 0.9747\n",
            "178/469 [==========>...................] - ETA: 2:02 - loss: 0.0842 - sparse_categorical_accuracy: 0.9746\n",
            "179/469 [==========>...................] - ETA: 2:02 - loss: 0.0842 - sparse_categorical_accuracy: 0.9746\n",
            "180/469 [==========>...................] - ETA: 2:01 - loss: 0.0840 - sparse_categorical_accuracy: 0.9747\n",
            "181/469 [==========>...................] - ETA: 2:01 - loss: 0.0839 - sparse_categorical_accuracy: 0.9747\n",
            "182/469 [==========>...................] - ETA: 2:00 - loss: 0.0838 - sparse_categorical_accuracy: 0.9748\n",
            "183/469 [==========>...................] - ETA: 2:00 - loss: 0.0839 - sparse_categorical_accuracy: 0.9748\n",
            "184/469 [==========>...................] - ETA: 2:00 - loss: 0.0840 - sparse_categorical_accuracy: 0.9749\n",
            "185/469 [==========>...................] - ETA: 1:59 - loss: 0.0841 - sparse_categorical_accuracy: 0.9748\n",
            "186/469 [==========>...................] - ETA: 1:59 - loss: 0.0840 - sparse_categorical_accuracy: 0.9749\n",
            "187/469 [==========>...................] - ETA: 1:58 - loss: 0.0843 - sparse_categorical_accuracy: 0.9748\n",
            "188/469 [===========>..................] - ETA: 1:58 - loss: 0.0839 - sparse_categorical_accuracy: 0.9750\n",
            "189/469 [===========>..................] - ETA: 1:57 - loss: 0.0838 - sparse_categorical_accuracy: 0.9750\n",
            "190/469 [===========>..................] - ETA: 1:57 - loss: 0.0838 - sparse_categorical_accuracy: 0.9748\n",
            "191/469 [===========>..................] - ETA: 1:56 - loss: 0.0838 - sparse_categorical_accuracy: 0.9748\n",
            "192/469 [===========>..................] - ETA: 1:56 - loss: 0.0841 - sparse_categorical_accuracy: 0.9748\n",
            "193/469 [===========>..................] - ETA: 1:55 - loss: 0.0841 - sparse_categorical_accuracy: 0.9748\n",
            "194/469 [===========>..................] - ETA: 1:55 - loss: 0.0842 - sparse_categorical_accuracy: 0.9748\n",
            "195/469 [===========>..................] - ETA: 1:55 - loss: 0.0841 - sparse_categorical_accuracy: 0.9748\n",
            "196/469 [===========>..................] - ETA: 1:55 - loss: 0.0845 - sparse_categorical_accuracy: 0.9747\n",
            "197/469 [===========>..................] - ETA: 1:55 - loss: 0.0844 - sparse_categorical_accuracy: 0.9747\n",
            "198/469 [===========>..................] - ETA: 1:55 - loss: 0.0843 - sparse_categorical_accuracy: 0.9748\n",
            "199/469 [===========>..................] - ETA: 1:54 - loss: 0.0844 - sparse_categorical_accuracy: 0.9748\n",
            "200/469 [===========>..................] - ETA: 1:54 - loss: 0.0842 - sparse_categorical_accuracy: 0.9748\n",
            "201/469 [===========>..................] - ETA: 1:53 - loss: 0.0839 - sparse_categorical_accuracy: 0.9749\n",
            "202/469 [===========>..................] - ETA: 1:53 - loss: 0.0837 - sparse_categorical_accuracy: 0.9749\n",
            "203/469 [===========>..................] - ETA: 1:52 - loss: 0.0837 - sparse_categorical_accuracy: 0.9749\n",
            "204/469 [============>.................] - ETA: 1:52 - loss: 0.0838 - sparse_categorical_accuracy: 0.9749\n",
            "205/469 [============>.................] - ETA: 1:51 - loss: 0.0837 - sparse_categorical_accuracy: 0.9749\n",
            "206/469 [============>.................] - ETA: 1:51 - loss: 0.0837 - sparse_categorical_accuracy: 0.9749\n",
            "207/469 [============>.................] - ETA: 1:50 - loss: 0.0834 - sparse_categorical_accuracy: 0.9750\n",
            "208/469 [============>.................] - ETA: 1:50 - loss: 0.0834 - sparse_categorical_accuracy: 0.9749\n",
            "209/469 [============>.................] - ETA: 1:49 - loss: 0.0836 - sparse_categorical_accuracy: 0.9750\n",
            "210/469 [============>.................] - ETA: 1:49 - loss: 0.0835 - sparse_categorical_accuracy: 0.9749\n",
            "211/469 [============>.................] - ETA: 1:48 - loss: 0.0833 - sparse_categorical_accuracy: 0.9750\n",
            "212/469 [============>.................] - ETA: 1:48 - loss: 0.0832 - sparse_categorical_accuracy: 0.9750\n",
            "213/469 [============>.................] - ETA: 1:47 - loss: 0.0830 - sparse_categorical_accuracy: 0.9751\n",
            "214/469 [============>.................] - ETA: 1:47 - loss: 0.0829 - sparse_categorical_accuracy: 0.9751\n",
            "215/469 [============>.................] - ETA: 1:47 - loss: 0.0827 - sparse_categorical_accuracy: 0.9752\n",
            "216/469 [============>.................] - ETA: 1:46 - loss: 0.0827 - sparse_categorical_accuracy: 0.9752\n",
            "217/469 [============>.................] - ETA: 1:46 - loss: 0.0825 - sparse_categorical_accuracy: 0.9752\n",
            "218/469 [============>.................] - ETA: 1:45 - loss: 0.0825 - sparse_categorical_accuracy: 0.9752\n",
            "219/469 [=============>................] - ETA: 1:45 - loss: 0.0829 - sparse_categorical_accuracy: 0.9751\n",
            "220/469 [=============>................] - ETA: 1:44 - loss: 0.0826 - sparse_categorical_accuracy: 0.9752\n",
            "221/469 [=============>................] - ETA: 1:44 - loss: 0.0828 - sparse_categorical_accuracy: 0.9753\n",
            "222/469 [=============>................] - ETA: 1:43 - loss: 0.0828 - sparse_categorical_accuracy: 0.9752\n",
            "223/469 [=============>................] - ETA: 1:43 - loss: 0.0832 - sparse_categorical_accuracy: 0.9753\n",
            "224/469 [=============>................] - ETA: 1:42 - loss: 0.0833 - sparse_categorical_accuracy: 0.9752\n",
            "225/469 [=============>................] - ETA: 1:42 - loss: 0.0831 - sparse_categorical_accuracy: 0.9753\n",
            "226/469 [=============>................] - ETA: 1:42 - loss: 0.0834 - sparse_categorical_accuracy: 0.9753\n",
            "227/469 [=============>................] - ETA: 1:42 - loss: 0.0835 - sparse_categorical_accuracy: 0.9752\n",
            "228/469 [=============>................] - ETA: 1:41 - loss: 0.0834 - sparse_categorical_accuracy: 0.9752\n",
            "229/469 [=============>................] - ETA: 1:41 - loss: 0.0835 - sparse_categorical_accuracy: 0.9752\n",
            "230/469 [=============>................] - ETA: 1:41 - loss: 0.0837 - sparse_categorical_accuracy: 0.9751\n",
            "231/469 [=============>................] - ETA: 1:40 - loss: 0.0837 - sparse_categorical_accuracy: 0.9752\n",
            "232/469 [=============>................] - ETA: 1:40 - loss: 0.0836 - sparse_categorical_accuracy: 0.9752\n",
            "233/469 [=============>................] - ETA: 1:39 - loss: 0.0834 - sparse_categorical_accuracy: 0.9753\n",
            "234/469 [=============>................] - ETA: 1:39 - loss: 0.0835 - sparse_categorical_accuracy: 0.9753\n",
            "235/469 [==============>...............] - ETA: 1:39 - loss: 0.0834 - sparse_categorical_accuracy: 0.9753\n",
            "236/469 [==============>...............] - ETA: 1:38 - loss: 0.0834 - sparse_categorical_accuracy: 0.9753\n",
            "237/469 [==============>...............] - ETA: 1:38 - loss: 0.0833 - sparse_categorical_accuracy: 0.9753\n",
            "238/469 [==============>...............] - ETA: 1:37 - loss: 0.0834 - sparse_categorical_accuracy: 0.9752\n",
            "239/469 [==============>...............] - ETA: 1:37 - loss: 0.0832 - sparse_categorical_accuracy: 0.9752\n",
            "240/469 [==============>...............] - ETA: 1:36 - loss: 0.0832 - sparse_categorical_accuracy: 0.9752\n",
            "241/469 [==============>...............] - ETA: 1:36 - loss: 0.0831 - sparse_categorical_accuracy: 0.9752\n",
            "242/469 [==============>...............] - ETA: 1:35 - loss: 0.0831 - sparse_categorical_accuracy: 0.9752\n",
            "243/469 [==============>...............] - ETA: 1:35 - loss: 0.0829 - sparse_categorical_accuracy: 0.9752\n",
            "244/469 [==============>...............] - ETA: 1:34 - loss: 0.0829 - sparse_categorical_accuracy: 0.9753\n",
            "245/469 [==============>...............] - ETA: 1:34 - loss: 0.0828 - sparse_categorical_accuracy: 0.9753\n",
            "246/469 [==============>...............] - ETA: 1:33 - loss: 0.0829 - sparse_categorical_accuracy: 0.9753\n",
            "247/469 [==============>...............] - ETA: 1:33 - loss: 0.0828 - sparse_categorical_accuracy: 0.9754\n",
            "248/469 [==============>...............] - ETA: 1:33 - loss: 0.0826 - sparse_categorical_accuracy: 0.9755\n",
            "249/469 [==============>...............] - ETA: 1:32 - loss: 0.0830 - sparse_categorical_accuracy: 0.9754\n",
            "250/469 [==============>...............] - ETA: 1:32 - loss: 0.0831 - sparse_categorical_accuracy: 0.9754\n",
            "251/469 [===============>..............] - ETA: 1:31 - loss: 0.0830 - sparse_categorical_accuracy: 0.9754\n",
            "252/469 [===============>..............] - ETA: 1:31 - loss: 0.0828 - sparse_categorical_accuracy: 0.9755\n",
            "253/469 [===============>..............] - ETA: 1:30 - loss: 0.0827 - sparse_categorical_accuracy: 0.9755\n",
            "254/469 [===============>..............] - ETA: 1:30 - loss: 0.0828 - sparse_categorical_accuracy: 0.9755\n",
            "255/469 [===============>..............] - ETA: 1:29 - loss: 0.0827 - sparse_categorical_accuracy: 0.9755\n",
            "256/469 [===============>..............] - ETA: 1:29 - loss: 0.0827 - sparse_categorical_accuracy: 0.9755\n",
            "257/469 [===============>..............] - ETA: 1:29 - loss: 0.0827 - sparse_categorical_accuracy: 0.9755\n",
            "258/469 [===============>..............] - ETA: 1:28 - loss: 0.0827 - sparse_categorical_accuracy: 0.9755\n",
            "259/469 [===============>..............] - ETA: 1:28 - loss: 0.0825 - sparse_categorical_accuracy: 0.9756\n",
            "260/469 [===============>..............] - ETA: 1:28 - loss: 0.0825 - sparse_categorical_accuracy: 0.9755\n",
            "261/469 [===============>..............] - ETA: 1:27 - loss: 0.0823 - sparse_categorical_accuracy: 0.9756\n",
            "262/469 [===============>..............] - ETA: 1:27 - loss: 0.0823 - sparse_categorical_accuracy: 0.9756\n",
            "263/469 [===============>..............] - ETA: 1:27 - loss: 0.0824 - sparse_categorical_accuracy: 0.9756\n",
            "264/469 [===============>..............] - ETA: 1:26 - loss: 0.0824 - sparse_categorical_accuracy: 0.9755\n",
            "265/469 [===============>..............] - ETA: 1:26 - loss: 0.0823 - sparse_categorical_accuracy: 0.9756\n",
            "266/469 [================>.............] - ETA: 1:25 - loss: 0.0821 - sparse_categorical_accuracy: 0.9756\n",
            "267/469 [================>.............] - ETA: 1:25 - loss: 0.0820 - sparse_categorical_accuracy: 0.9756\n",
            "268/469 [================>.............] - ETA: 1:24 - loss: 0.0818 - sparse_categorical_accuracy: 0.9757\n",
            "269/469 [================>.............] - ETA: 1:24 - loss: 0.0818 - sparse_categorical_accuracy: 0.9757\n",
            "270/469 [================>.............] - ETA: 1:23 - loss: 0.0818 - sparse_categorical_accuracy: 0.9757\n",
            "271/469 [================>.............] - ETA: 1:23 - loss: 0.0821 - sparse_categorical_accuracy: 0.9757\n",
            "272/469 [================>.............] - ETA: 1:23 - loss: 0.0822 - sparse_categorical_accuracy: 0.9756\n",
            "273/469 [================>.............] - ETA: 1:22 - loss: 0.0822 - sparse_categorical_accuracy: 0.9756\n",
            "274/469 [================>.............] - ETA: 1:22 - loss: 0.0820 - sparse_categorical_accuracy: 0.9757\n",
            "275/469 [================>.............] - ETA: 1:21 - loss: 0.0819 - sparse_categorical_accuracy: 0.9758\n",
            "276/469 [================>.............] - ETA: 1:21 - loss: 0.0818 - sparse_categorical_accuracy: 0.9758\n",
            "277/469 [================>.............] - ETA: 1:20 - loss: 0.0817 - sparse_categorical_accuracy: 0.9757\n",
            "278/469 [================>.............] - ETA: 1:20 - loss: 0.0819 - sparse_categorical_accuracy: 0.9757\n",
            "279/469 [================>.............] - ETA: 1:19 - loss: 0.0822 - sparse_categorical_accuracy: 0.9757\n",
            "280/469 [================>.............] - ETA: 1:19 - loss: 0.0821 - sparse_categorical_accuracy: 0.9757\n",
            "281/469 [================>.............] - ETA: 1:19 - loss: 0.0819 - sparse_categorical_accuracy: 0.9757\n",
            "282/469 [=================>............] - ETA: 1:18 - loss: 0.0820 - sparse_categorical_accuracy: 0.9757\n",
            "283/469 [=================>............] - ETA: 1:18 - loss: 0.0821 - sparse_categorical_accuracy: 0.9757\n",
            "284/469 [=================>............] - ETA: 1:17 - loss: 0.0819 - sparse_categorical_accuracy: 0.9758\n",
            "285/469 [=================>............] - ETA: 1:17 - loss: 0.0818 - sparse_categorical_accuracy: 0.9758\n",
            "286/469 [=================>............] - ETA: 1:16 - loss: 0.0817 - sparse_categorical_accuracy: 0.9758\n",
            "287/469 [=================>............] - ETA: 1:16 - loss: 0.0816 - sparse_categorical_accuracy: 0.9758\n",
            "288/469 [=================>............] - ETA: 1:15 - loss: 0.0814 - sparse_categorical_accuracy: 0.9759\n",
            "289/469 [=================>............] - ETA: 1:15 - loss: 0.0813 - sparse_categorical_accuracy: 0.9759\n",
            "290/469 [=================>............] - ETA: 1:15 - loss: 0.0814 - sparse_categorical_accuracy: 0.9759\n",
            "291/469 [=================>............] - ETA: 1:14 - loss: 0.0817 - sparse_categorical_accuracy: 0.9758\n",
            "292/469 [=================>............] - ETA: 1:14 - loss: 0.0817 - sparse_categorical_accuracy: 0.9758\n",
            "293/469 [=================>............] - ETA: 1:14 - loss: 0.0817 - sparse_categorical_accuracy: 0.9758\n",
            "294/469 [=================>............] - ETA: 1:13 - loss: 0.0821 - sparse_categorical_accuracy: 0.9757\n",
            "295/469 [=================>............] - ETA: 1:13 - loss: 0.0820 - sparse_categorical_accuracy: 0.9757\n",
            "296/469 [=================>............] - ETA: 1:13 - loss: 0.0821 - sparse_categorical_accuracy: 0.9756\n",
            "297/469 [=================>............] - ETA: 1:12 - loss: 0.0820 - sparse_categorical_accuracy: 0.9757\n",
            "298/469 [==================>...........] - ETA: 1:12 - loss: 0.0821 - sparse_categorical_accuracy: 0.9756\n",
            "299/469 [==================>...........] - ETA: 1:11 - loss: 0.0819 - sparse_categorical_accuracy: 0.9757\n",
            "300/469 [==================>...........] - ETA: 1:11 - loss: 0.0819 - sparse_categorical_accuracy: 0.9757\n",
            "301/469 [==================>...........] - ETA: 1:10 - loss: 0.0821 - sparse_categorical_accuracy: 0.9756\n",
            "302/469 [==================>...........] - ETA: 1:10 - loss: 0.0822 - sparse_categorical_accuracy: 0.9757\n",
            "303/469 [==================>...........] - ETA: 1:09 - loss: 0.0821 - sparse_categorical_accuracy: 0.9757\n",
            "304/469 [==================>...........] - ETA: 1:09 - loss: 0.0821 - sparse_categorical_accuracy: 0.9756\n",
            "305/469 [==================>...........] - ETA: 1:09 - loss: 0.0821 - sparse_categorical_accuracy: 0.9756\n",
            "306/469 [==================>...........] - ETA: 1:08 - loss: 0.0821 - sparse_categorical_accuracy: 0.9756\n",
            "307/469 [==================>...........] - ETA: 1:08 - loss: 0.0822 - sparse_categorical_accuracy: 0.9755\n",
            "308/469 [==================>...........] - ETA: 1:07 - loss: 0.0822 - sparse_categorical_accuracy: 0.9755\n",
            "309/469 [==================>...........] - ETA: 1:07 - loss: 0.0820 - sparse_categorical_accuracy: 0.9756\n",
            "310/469 [==================>...........] - ETA: 1:06 - loss: 0.0821 - sparse_categorical_accuracy: 0.9755\n",
            "311/469 [==================>...........] - ETA: 1:06 - loss: 0.0823 - sparse_categorical_accuracy: 0.9754\n",
            "312/469 [==================>...........] - ETA: 1:05 - loss: 0.0824 - sparse_categorical_accuracy: 0.9754\n",
            "313/469 [===================>..........] - ETA: 1:05 - loss: 0.0823 - sparse_categorical_accuracy: 0.9754\n",
            "314/469 [===================>..........] - ETA: 1:05 - loss: 0.0822 - sparse_categorical_accuracy: 0.9754\n",
            "315/469 [===================>..........] - ETA: 1:04 - loss: 0.0823 - sparse_categorical_accuracy: 0.9754\n",
            "316/469 [===================>..........] - ETA: 1:04 - loss: 0.0825 - sparse_categorical_accuracy: 0.9754\n",
            "317/469 [===================>..........] - ETA: 1:03 - loss: 0.0824 - sparse_categorical_accuracy: 0.9754\n",
            "318/469 [===================>..........] - ETA: 1:03 - loss: 0.0823 - sparse_categorical_accuracy: 0.9754\n",
            "319/469 [===================>..........] - ETA: 1:02 - loss: 0.0823 - sparse_categorical_accuracy: 0.9754\n",
            "320/469 [===================>..........] - ETA: 1:02 - loss: 0.0823 - sparse_categorical_accuracy: 0.9754\n",
            "321/469 [===================>..........] - ETA: 1:02 - loss: 0.0823 - sparse_categorical_accuracy: 0.9755\n",
            "322/469 [===================>..........] - ETA: 1:01 - loss: 0.0823 - sparse_categorical_accuracy: 0.9754\n",
            "323/469 [===================>..........] - ETA: 1:01 - loss: 0.0824 - sparse_categorical_accuracy: 0.9754\n",
            "324/469 [===================>..........] - ETA: 1:01 - loss: 0.0823 - sparse_categorical_accuracy: 0.9755\n",
            "325/469 [===================>..........] - ETA: 1:00 - loss: 0.0823 - sparse_categorical_accuracy: 0.9755\n",
            "326/469 [===================>..........] - ETA: 1:00 - loss: 0.0822 - sparse_categorical_accuracy: 0.9755\n",
            "327/469 [===================>..........] - ETA: 59s - loss: 0.0820 - sparse_categorical_accuracy: 0.9756 \n",
            "328/469 [===================>..........] - ETA: 59s - loss: 0.0821 - sparse_categorical_accuracy: 0.9756\n",
            "329/469 [====================>.........] - ETA: 59s - loss: 0.0822 - sparse_categorical_accuracy: 0.9756\n",
            "330/469 [====================>.........] - ETA: 58s - loss: 0.0820 - sparse_categorical_accuracy: 0.9756\n",
            "331/469 [====================>.........] - ETA: 58s - loss: 0.0820 - sparse_categorical_accuracy: 0.9756\n",
            "332/469 [====================>.........] - ETA: 57s - loss: 0.0820 - sparse_categorical_accuracy: 0.9756\n",
            "333/469 [====================>.........] - ETA: 57s - loss: 0.0820 - sparse_categorical_accuracy: 0.9756\n",
            "334/469 [====================>.........] - ETA: 56s - loss: 0.0819 - sparse_categorical_accuracy: 0.9756\n",
            "335/469 [====================>.........] - ETA: 56s - loss: 0.0818 - sparse_categorical_accuracy: 0.9756\n",
            "336/469 [====================>.........] - ETA: 56s - loss: 0.0816 - sparse_categorical_accuracy: 0.9757\n",
            "337/469 [====================>.........] - ETA: 55s - loss: 0.0816 - sparse_categorical_accuracy: 0.9757\n",
            "338/469 [====================>.........] - ETA: 55s - loss: 0.0816 - sparse_categorical_accuracy: 0.9757\n",
            "339/469 [====================>.........] - ETA: 54s - loss: 0.0815 - sparse_categorical_accuracy: 0.9757\n",
            "340/469 [====================>.........] - ETA: 54s - loss: 0.0813 - sparse_categorical_accuracy: 0.9758\n",
            "341/469 [====================>.........] - ETA: 53s - loss: 0.0813 - sparse_categorical_accuracy: 0.9758\n",
            "342/469 [====================>.........] - ETA: 53s - loss: 0.0813 - sparse_categorical_accuracy: 0.9757\n",
            "343/469 [====================>.........] - ETA: 52s - loss: 0.0814 - sparse_categorical_accuracy: 0.9757\n",
            "344/469 [=====================>........] - ETA: 52s - loss: 0.0812 - sparse_categorical_accuracy: 0.9757\n",
            "345/469 [=====================>........] - ETA: 52s - loss: 0.0812 - sparse_categorical_accuracy: 0.9757\n",
            "346/469 [=====================>........] - ETA: 51s - loss: 0.0812 - sparse_categorical_accuracy: 0.9757\n",
            "347/469 [=====================>........] - ETA: 51s - loss: 0.0811 - sparse_categorical_accuracy: 0.9758\n",
            "348/469 [=====================>........] - ETA: 50s - loss: 0.0811 - sparse_categorical_accuracy: 0.9758\n",
            "349/469 [=====================>........] - ETA: 50s - loss: 0.0811 - sparse_categorical_accuracy: 0.9758\n",
            "350/469 [=====================>........] - ETA: 49s - loss: 0.0811 - sparse_categorical_accuracy: 0.9758\n",
            "351/469 [=====================>........] - ETA: 49s - loss: 0.0810 - sparse_categorical_accuracy: 0.9758\n",
            "352/469 [=====================>........] - ETA: 49s - loss: 0.0809 - sparse_categorical_accuracy: 0.9758\n",
            "353/469 [=====================>........] - ETA: 48s - loss: 0.0808 - sparse_categorical_accuracy: 0.9758\n",
            "354/469 [=====================>........] - ETA: 48s - loss: 0.0807 - sparse_categorical_accuracy: 0.9758\n",
            "355/469 [=====================>........] - ETA: 47s - loss: 0.0808 - sparse_categorical_accuracy: 0.9758\n",
            "356/469 [=====================>........] - ETA: 47s - loss: 0.0810 - sparse_categorical_accuracy: 0.9757\n",
            "357/469 [=====================>........] - ETA: 47s - loss: 0.0813 - sparse_categorical_accuracy: 0.9756\n",
            "358/469 [=====================>........] - ETA: 46s - loss: 0.0813 - sparse_categorical_accuracy: 0.9756\n",
            "359/469 [=====================>........] - ETA: 46s - loss: 0.0814 - sparse_categorical_accuracy: 0.9755\n",
            "360/469 [======================>.......] - ETA: 46s - loss: 0.0813 - sparse_categorical_accuracy: 0.9755\n",
            "361/469 [======================>.......] - ETA: 45s - loss: 0.0813 - sparse_categorical_accuracy: 0.9756\n",
            "362/469 [======================>.......] - ETA: 45s - loss: 0.0814 - sparse_categorical_accuracy: 0.9755\n",
            "363/469 [======================>.......] - ETA: 44s - loss: 0.0814 - sparse_categorical_accuracy: 0.9754\n",
            "364/469 [======================>.......] - ETA: 44s - loss: 0.0814 - sparse_categorical_accuracy: 0.9755\n",
            "365/469 [======================>.......] - ETA: 43s - loss: 0.0813 - sparse_categorical_accuracy: 0.9755\n",
            "366/469 [======================>.......] - ETA: 43s - loss: 0.0815 - sparse_categorical_accuracy: 0.9754\n",
            "367/469 [======================>.......] - ETA: 42s - loss: 0.0814 - sparse_categorical_accuracy: 0.9754\n",
            "368/469 [======================>.......] - ETA: 42s - loss: 0.0815 - sparse_categorical_accuracy: 0.9754\n",
            "369/469 [======================>.......] - ETA: 42s - loss: 0.0814 - sparse_categorical_accuracy: 0.9754\n",
            "370/469 [======================>.......] - ETA: 41s - loss: 0.0813 - sparse_categorical_accuracy: 0.9754\n",
            "371/469 [======================>.......] - ETA: 41s - loss: 0.0812 - sparse_categorical_accuracy: 0.9754\n",
            "372/469 [======================>.......] - ETA: 40s - loss: 0.0812 - sparse_categorical_accuracy: 0.9754\n",
            "373/469 [======================>.......] - ETA: 40s - loss: 0.0810 - sparse_categorical_accuracy: 0.9754\n",
            "374/469 [======================>.......] - ETA: 39s - loss: 0.0811 - sparse_categorical_accuracy: 0.9754\n",
            "375/469 [======================>.......] - ETA: 39s - loss: 0.0810 - sparse_categorical_accuracy: 0.9754\n",
            "376/469 [=======================>......] - ETA: 39s - loss: 0.0812 - sparse_categorical_accuracy: 0.9754\n",
            "377/469 [=======================>......] - ETA: 38s - loss: 0.0812 - sparse_categorical_accuracy: 0.9754\n",
            "378/469 [=======================>......] - ETA: 38s - loss: 0.0811 - sparse_categorical_accuracy: 0.9754\n",
            "379/469 [=======================>......] - ETA: 37s - loss: 0.0811 - sparse_categorical_accuracy: 0.9755\n",
            "380/469 [=======================>......] - ETA: 37s - loss: 0.0811 - sparse_categorical_accuracy: 0.9755\n",
            "381/469 [=======================>......] - ETA: 36s - loss: 0.0813 - sparse_categorical_accuracy: 0.9754\n",
            "382/469 [=======================>......] - ETA: 36s - loss: 0.0813 - sparse_categorical_accuracy: 0.9755\n",
            "383/469 [=======================>......] - ETA: 36s - loss: 0.0813 - sparse_categorical_accuracy: 0.9754\n",
            "384/469 [=======================>......] - ETA: 35s - loss: 0.0816 - sparse_categorical_accuracy: 0.9753\n",
            "385/469 [=======================>......] - ETA: 35s - loss: 0.0817 - sparse_categorical_accuracy: 0.9753\n",
            "386/469 [=======================>......] - ETA: 34s - loss: 0.0816 - sparse_categorical_accuracy: 0.9753\n",
            "387/469 [=======================>......] - ETA: 34s - loss: 0.0816 - sparse_categorical_accuracy: 0.9754\n",
            "388/469 [=======================>......] - ETA: 34s - loss: 0.0814 - sparse_categorical_accuracy: 0.9754\n",
            "389/469 [=======================>......] - ETA: 33s - loss: 0.0813 - sparse_categorical_accuracy: 0.9755\n",
            "390/469 [=======================>......] - ETA: 33s - loss: 0.0812 - sparse_categorical_accuracy: 0.9755\n",
            "391/469 [========================>.....] - ETA: 32s - loss: 0.0811 - sparse_categorical_accuracy: 0.9755\n",
            "392/469 [========================>.....] - ETA: 32s - loss: 0.0811 - sparse_categorical_accuracy: 0.9755\n",
            "393/469 [========================>.....] - ETA: 32s - loss: 0.0812 - sparse_categorical_accuracy: 0.9754\n",
            "394/469 [========================>.....] - ETA: 31s - loss: 0.0812 - sparse_categorical_accuracy: 0.9754\n",
            "395/469 [========================>.....] - ETA: 31s - loss: 0.0813 - sparse_categorical_accuracy: 0.9754\n",
            "396/469 [========================>.....] - ETA: 30s - loss: 0.0814 - sparse_categorical_accuracy: 0.9753\n",
            "397/469 [========================>.....] - ETA: 30s - loss: 0.0814 - sparse_categorical_accuracy: 0.9753\n",
            "398/469 [========================>.....] - ETA: 29s - loss: 0.0812 - sparse_categorical_accuracy: 0.9753\n",
            "399/469 [========================>.....] - ETA: 29s - loss: 0.0812 - sparse_categorical_accuracy: 0.9754\n",
            "400/469 [========================>.....] - ETA: 29s - loss: 0.0810 - sparse_categorical_accuracy: 0.9754\n",
            "401/469 [========================>.....] - ETA: 28s - loss: 0.0810 - sparse_categorical_accuracy: 0.9754\n",
            "402/469 [========================>.....] - ETA: 28s - loss: 0.0809 - sparse_categorical_accuracy: 0.9754\n",
            "403/469 [========================>.....] - ETA: 27s - loss: 0.0809 - sparse_categorical_accuracy: 0.9754\n",
            "404/469 [========================>.....] - ETA: 27s - loss: 0.0809 - sparse_categorical_accuracy: 0.9754\n",
            "405/469 [========================>.....] - ETA: 26s - loss: 0.0810 - sparse_categorical_accuracy: 0.9754\n",
            "406/469 [========================>.....] - ETA: 26s - loss: 0.0809 - sparse_categorical_accuracy: 0.9754\n",
            "407/469 [=========================>....] - ETA: 26s - loss: 0.0812 - sparse_categorical_accuracy: 0.9753\n",
            "408/469 [=========================>....] - ETA: 25s - loss: 0.0811 - sparse_categorical_accuracy: 0.9754\n",
            "409/469 [=========================>....] - ETA: 25s - loss: 0.0811 - sparse_categorical_accuracy: 0.9754\n",
            "410/469 [=========================>....] - ETA: 24s - loss: 0.0811 - sparse_categorical_accuracy: 0.9754\n",
            "411/469 [=========================>....] - ETA: 24s - loss: 0.0811 - sparse_categorical_accuracy: 0.9754\n",
            "412/469 [=========================>....] - ETA: 23s - loss: 0.0811 - sparse_categorical_accuracy: 0.9754\n",
            "413/469 [=========================>....] - ETA: 23s - loss: 0.0810 - sparse_categorical_accuracy: 0.9754\n",
            "414/469 [=========================>....] - ETA: 23s - loss: 0.0810 - sparse_categorical_accuracy: 0.9754\n",
            "415/469 [=========================>....] - ETA: 22s - loss: 0.0811 - sparse_categorical_accuracy: 0.9754\n",
            "416/469 [=========================>....] - ETA: 22s - loss: 0.0814 - sparse_categorical_accuracy: 0.9753\n",
            "417/469 [=========================>....] - ETA: 21s - loss: 0.0815 - sparse_categorical_accuracy: 0.9753\n",
            "418/469 [=========================>....] - ETA: 21s - loss: 0.0815 - sparse_categorical_accuracy: 0.9753\n",
            "419/469 [=========================>....] - ETA: 20s - loss: 0.0815 - sparse_categorical_accuracy: 0.9753\n",
            "420/469 [=========================>....] - ETA: 20s - loss: 0.0814 - sparse_categorical_accuracy: 0.9753\n",
            "421/469 [=========================>....] - ETA: 20s - loss: 0.0813 - sparse_categorical_accuracy: 0.9754\n",
            "422/469 [=========================>....] - ETA: 19s - loss: 0.0812 - sparse_categorical_accuracy: 0.9754\n",
            "423/469 [==========================>...] - ETA: 19s - loss: 0.0812 - sparse_categorical_accuracy: 0.9754\n",
            "424/469 [==========================>...] - ETA: 18s - loss: 0.0810 - sparse_categorical_accuracy: 0.9754\n",
            "425/469 [==========================>...] - ETA: 18s - loss: 0.0811 - sparse_categorical_accuracy: 0.9754\n",
            "426/469 [==========================>...] - ETA: 18s - loss: 0.0811 - sparse_categorical_accuracy: 0.9754\n",
            "427/469 [==========================>...] - ETA: 17s - loss: 0.0810 - sparse_categorical_accuracy: 0.9754\n",
            "428/469 [==========================>...] - ETA: 17s - loss: 0.0810 - sparse_categorical_accuracy: 0.9754\n",
            "429/469 [==========================>...] - ETA: 16s - loss: 0.0809 - sparse_categorical_accuracy: 0.9755\n",
            "430/469 [==========================>...] - ETA: 16s - loss: 0.0809 - sparse_categorical_accuracy: 0.9755\n",
            "431/469 [==========================>...] - ETA: 15s - loss: 0.0809 - sparse_categorical_accuracy: 0.9755\n",
            "432/469 [==========================>...] - ETA: 15s - loss: 0.0810 - sparse_categorical_accuracy: 0.9754\n",
            "433/469 [==========================>...] - ETA: 15s - loss: 0.0809 - sparse_categorical_accuracy: 0.9755\n",
            "434/469 [==========================>...] - ETA: 14s - loss: 0.0810 - sparse_categorical_accuracy: 0.9754\n",
            "435/469 [==========================>...] - ETA: 14s - loss: 0.0810 - sparse_categorical_accuracy: 0.9755\n",
            "436/469 [==========================>...] - ETA: 13s - loss: 0.0810 - sparse_categorical_accuracy: 0.9755\n",
            "437/469 [==========================>...] - ETA: 13s - loss: 0.0810 - sparse_categorical_accuracy: 0.9755\n",
            "438/469 [===========================>..] - ETA: 13s - loss: 0.0810 - sparse_categorical_accuracy: 0.9754\n",
            "439/469 [===========================>..] - ETA: 12s - loss: 0.0809 - sparse_categorical_accuracy: 0.9754\n",
            "440/469 [===========================>..] - ETA: 12s - loss: 0.0809 - sparse_categorical_accuracy: 0.9754\n",
            "441/469 [===========================>..] - ETA: 11s - loss: 0.0810 - sparse_categorical_accuracy: 0.9754\n",
            "442/469 [===========================>..] - ETA: 11s - loss: 0.0808 - sparse_categorical_accuracy: 0.9755\n",
            "443/469 [===========================>..] - ETA: 10s - loss: 0.0807 - sparse_categorical_accuracy: 0.9755\n",
            "444/469 [===========================>..] - ETA: 10s - loss: 0.0807 - sparse_categorical_accuracy: 0.9755\n",
            "445/469 [===========================>..] - ETA: 10s - loss: 0.0808 - sparse_categorical_accuracy: 0.9755\n",
            "446/469 [===========================>..] - ETA: 9s - loss: 0.0808 - sparse_categorical_accuracy: 0.9755 \n",
            "447/469 [===========================>..] - ETA: 9s - loss: 0.0808 - sparse_categorical_accuracy: 0.9755\n",
            "448/469 [===========================>..] - ETA: 8s - loss: 0.0808 - sparse_categorical_accuracy: 0.9755\n",
            "449/469 [===========================>..] - ETA: 8s - loss: 0.0808 - sparse_categorical_accuracy: 0.9755\n",
            "450/469 [===========================>..] - ETA: 7s - loss: 0.0807 - sparse_categorical_accuracy: 0.9756\n",
            "451/469 [===========================>..] - ETA: 7s - loss: 0.0807 - sparse_categorical_accuracy: 0.9756\n",
            "452/469 [===========================>..] - ETA: 7s - loss: 0.0806 - sparse_categorical_accuracy: 0.9756\n",
            "453/469 [===========================>..] - ETA: 6s - loss: 0.0805 - sparse_categorical_accuracy: 0.9756\n",
            "454/469 [============================>.] - ETA: 6s - loss: 0.0807 - sparse_categorical_accuracy: 0.9756\n",
            "455/469 [============================>.] - ETA: 5s - loss: 0.0807 - sparse_categorical_accuracy: 0.9756\n",
            "456/469 [============================>.] - ETA: 5s - loss: 0.0806 - sparse_categorical_accuracy: 0.9756\n",
            "457/469 [============================>.] - ETA: 5s - loss: 0.0806 - sparse_categorical_accuracy: 0.9756\n",
            "458/469 [============================>.] - ETA: 4s - loss: 0.0806 - sparse_categorical_accuracy: 0.9756\n",
            "459/469 [============================>.] - ETA: 4s - loss: 0.0806 - sparse_categorical_accuracy: 0.9756\n",
            "460/469 [============================>.] - ETA: 3s - loss: 0.0807 - sparse_categorical_accuracy: 0.9756\n",
            "461/469 [============================>.] - ETA: 3s - loss: 0.0806 - sparse_categorical_accuracy: 0.9757\n",
            "462/469 [============================>.] - ETA: 2s - loss: 0.0805 - sparse_categorical_accuracy: 0.9756\n",
            "463/469 [============================>.] - ETA: 2s - loss: 0.0805 - sparse_categorical_accuracy: 0.9756\n",
            "464/469 [============================>.] - ETA: 2s - loss: 0.0805 - sparse_categorical_accuracy: 0.9756\n",
            "465/469 [============================>.] - ETA: 1s - loss: 0.0804 - sparse_categorical_accuracy: 0.9756\n",
            "466/469 [============================>.] - ETA: 1s - loss: 0.0804 - sparse_categorical_accuracy: 0.9756\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.0804 - sparse_categorical_accuracy: 0.9756\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0804 - sparse_categorical_accuracy: 0.9756\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0803 - sparse_categorical_accuracy: 0.9756\n",
            " 40%|████      | 2/5 [53:17<53:49, 1076.55s/trial, best loss: -0.9830999970436096]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/04/16 01:25:18 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 197s 421ms/step - loss: 0.0803 - sparse_categorical_accuracy: 0.9756\n",
            "\n",
            "Epoch 5/5\n",
            "\n",
            "  1/469 [..............................] - ETA: 3:31 - loss: 0.0286 - sparse_categorical_accuracy: 0.9922\n",
            "  2/469 [..............................] - ETA: 2:59 - loss: 0.0653 - sparse_categorical_accuracy: 0.9844\n",
            "  3/469 [..............................] - ETA: 2:58 - loss: 0.0567 - sparse_categorical_accuracy: 0.9818\n",
            "  4/469 [..............................] - ETA: 2:57 - loss: 0.0566 - sparse_categorical_accuracy: 0.9824\n",
            "  5/469 [..............................] - ETA: 2:56 - loss: 0.0559 - sparse_categorical_accuracy: 0.9844\n",
            "  6/469 [..............................] - ETA: 2:56 - loss: 0.0544 - sparse_categorical_accuracy: 0.9844\n",
            "  7/469 [..............................] - ETA: 2:55 - loss: 0.0571 - sparse_categorical_accuracy: 0.9821\n",
            "  8/469 [..............................] - ETA: 2:55 - loss: 0.0563 - sparse_categorical_accuracy: 0.9824\n",
            "  9/469 [..............................] - ETA: 2:55 - loss: 0.0641 - sparse_categorical_accuracy: 0.9818\n",
            " 10/469 [..............................] - ETA: 2:54 - loss: 0.0627 - sparse_categorical_accuracy: 0.9820\n",
            " 11/469 [..............................] - ETA: 2:54 - loss: 0.0598 - sparse_categorical_accuracy: 0.9830\n",
            " 12/469 [..............................] - ETA: 2:54 - loss: 0.0626 - sparse_categorical_accuracy: 0.9818\n",
            " 13/469 [..............................] - ETA: 2:58 - loss: 0.0615 - sparse_categorical_accuracy: 0.9820\n",
            " 14/469 [..............................] - ETA: 3:04 - loss: 0.0603 - sparse_categorical_accuracy: 0.9827\n",
            " 15/469 [..............................] - ETA: 3:10 - loss: 0.0611 - sparse_categorical_accuracy: 0.9812\n",
            " 16/469 [>.............................] - ETA: 3:17 - loss: 0.0629 - sparse_categorical_accuracy: 0.9795\n",
            " 17/469 [>.............................] - ETA: 3:20 - loss: 0.0640 - sparse_categorical_accuracy: 0.9793\n",
            " 18/469 [>.............................] - ETA: 3:23 - loss: 0.0653 - sparse_categorical_accuracy: 0.9796\n",
            " 19/469 [>.............................] - ETA: 3:23 - loss: 0.0663 - sparse_categorical_accuracy: 0.9790\n",
            " 20/469 [>.............................] - ETA: 3:21 - loss: 0.0697 - sparse_categorical_accuracy: 0.9781\n",
            " 21/469 [>.............................] - ETA: 3:20 - loss: 0.0714 - sparse_categorical_accuracy: 0.9777\n",
            " 22/469 [>.............................] - ETA: 3:18 - loss: 0.0700 - sparse_categorical_accuracy: 0.9783\n",
            " 23/469 [>.............................] - ETA: 3:16 - loss: 0.0710 - sparse_categorical_accuracy: 0.9776\n",
            " 24/469 [>.............................] - ETA: 3:14 - loss: 0.0687 - sparse_categorical_accuracy: 0.9785\n",
            " 25/469 [>.............................] - ETA: 3:12 - loss: 0.0698 - sparse_categorical_accuracy: 0.9778\n",
            " 26/469 [>.............................] - ETA: 3:11 - loss: 0.0715 - sparse_categorical_accuracy: 0.9775\n",
            " 27/469 [>.............................] - ETA: 3:10 - loss: 0.0716 - sparse_categorical_accuracy: 0.9774\n",
            " 28/469 [>.............................] - ETA: 3:09 - loss: 0.0703 - sparse_categorical_accuracy: 0.9780\n",
            " 29/469 [>.............................] - ETA: 3:08 - loss: 0.0708 - sparse_categorical_accuracy: 0.9779\n",
            " 30/469 [>.............................] - ETA: 3:07 - loss: 0.0706 - sparse_categorical_accuracy: 0.9781\n",
            " 31/469 [>.............................] - ETA: 3:06 - loss: 0.0709 - sparse_categorical_accuracy: 0.9781\n",
            " 32/469 [=>............................] - ETA: 3:05 - loss: 0.0693 - sparse_categorical_accuracy: 0.9788\n",
            " 33/469 [=>............................] - ETA: 3:05 - loss: 0.0692 - sparse_categorical_accuracy: 0.9785\n",
            " 34/469 [=>............................] - ETA: 3:04 - loss: 0.0683 - sparse_categorical_accuracy: 0.9789\n",
            " 35/469 [=>............................] - ETA: 3:03 - loss: 0.0700 - sparse_categorical_accuracy: 0.9786\n",
            " 36/469 [=>............................] - ETA: 3:02 - loss: 0.0690 - sparse_categorical_accuracy: 0.9789\n",
            " 37/469 [=>............................] - ETA: 3:01 - loss: 0.0691 - sparse_categorical_accuracy: 0.9789\n",
            " 38/469 [=>............................] - ETA: 3:00 - loss: 0.0694 - sparse_categorical_accuracy: 0.9788\n",
            " 39/469 [=>............................] - ETA: 3:00 - loss: 0.0692 - sparse_categorical_accuracy: 0.9788\n",
            " 40/469 [=>............................] - ETA: 2:59 - loss: 0.0692 - sparse_categorical_accuracy: 0.9785\n",
            " 41/469 [=>............................] - ETA: 2:58 - loss: 0.0682 - sparse_categorical_accuracy: 0.9788\n",
            " 42/469 [=>............................] - ETA: 2:57 - loss: 0.0711 - sparse_categorical_accuracy: 0.9784\n",
            " 43/469 [=>............................] - ETA: 2:56 - loss: 0.0717 - sparse_categorical_accuracy: 0.9778\n",
            " 44/469 [=>............................] - ETA: 2:56 - loss: 0.0705 - sparse_categorical_accuracy: 0.9783\n",
            " 45/469 [=>............................] - ETA: 2:57 - loss: 0.0698 - sparse_categorical_accuracy: 0.9785\n",
            " 46/469 [=>............................] - ETA: 2:58 - loss: 0.0694 - sparse_categorical_accuracy: 0.9786\n",
            " 47/469 [==>...........................] - ETA: 2:59 - loss: 0.0686 - sparse_categorical_accuracy: 0.9789\n",
            " 48/469 [==>...........................] - ETA: 3:00 - loss: 0.0695 - sparse_categorical_accuracy: 0.9785\n",
            " 49/469 [==>...........................] - ETA: 3:01 - loss: 0.0692 - sparse_categorical_accuracy: 0.9783\n",
            " 50/469 [==>...........................] - ETA: 3:02 - loss: 0.0686 - sparse_categorical_accuracy: 0.9786\n",
            " 51/469 [==>...........................] - ETA: 3:01 - loss: 0.0723 - sparse_categorical_accuracy: 0.9779\n",
            " 52/469 [==>...........................] - ETA: 3:00 - loss: 0.0721 - sparse_categorical_accuracy: 0.9781\n",
            " 53/469 [==>...........................] - ETA: 2:59 - loss: 0.0731 - sparse_categorical_accuracy: 0.9777\n",
            " 54/469 [==>...........................] - ETA: 2:59 - loss: 0.0722 - sparse_categorical_accuracy: 0.9782\n",
            " 55/469 [==>...........................] - ETA: 2:58 - loss: 0.0719 - sparse_categorical_accuracy: 0.9781\n",
            " 56/469 [==>...........................] - ETA: 2:57 - loss: 0.0718 - sparse_categorical_accuracy: 0.9782\n",
            " 57/469 [==>...........................] - ETA: 2:57 - loss: 0.0716 - sparse_categorical_accuracy: 0.9783\n",
            " 58/469 [==>...........................] - ETA: 2:56 - loss: 0.0719 - sparse_categorical_accuracy: 0.9783\n",
            " 59/469 [==>...........................] - ETA: 2:55 - loss: 0.0722 - sparse_categorical_accuracy: 0.9783\n",
            " 60/469 [==>...........................] - ETA: 2:54 - loss: 0.0727 - sparse_categorical_accuracy: 0.9779\n",
            " 61/469 [==>...........................] - ETA: 2:54 - loss: 0.0728 - sparse_categorical_accuracy: 0.9778\n",
            " 62/469 [==>...........................] - ETA: 2:53 - loss: 0.0727 - sparse_categorical_accuracy: 0.9779\n",
            " 63/469 [===>..........................] - ETA: 2:52 - loss: 0.0720 - sparse_categorical_accuracy: 0.9783\n",
            " 64/469 [===>..........................] - ETA: 2:52 - loss: 0.0719 - sparse_categorical_accuracy: 0.9781\n",
            " 65/469 [===>..........................] - ETA: 2:51 - loss: 0.0715 - sparse_categorical_accuracy: 0.9781\n",
            " 66/469 [===>..........................] - ETA: 2:50 - loss: 0.0711 - sparse_categorical_accuracy: 0.9782\n",
            " 67/469 [===>..........................] - ETA: 2:49 - loss: 0.0711 - sparse_categorical_accuracy: 0.9781\n",
            " 68/469 [===>..........................] - ETA: 2:49 - loss: 0.0706 - sparse_categorical_accuracy: 0.9783\n",
            " 69/469 [===>..........................] - ETA: 2:48 - loss: 0.0717 - sparse_categorical_accuracy: 0.9779\n",
            " 70/469 [===>..........................] - ETA: 2:48 - loss: 0.0714 - sparse_categorical_accuracy: 0.9780\n",
            " 71/469 [===>..........................] - ETA: 2:47 - loss: 0.0707 - sparse_categorical_accuracy: 0.9782\n",
            " 72/469 [===>..........................] - ETA: 2:46 - loss: 0.0703 - sparse_categorical_accuracy: 0.9784\n",
            " 73/469 [===>..........................] - ETA: 2:46 - loss: 0.0704 - sparse_categorical_accuracy: 0.9783\n",
            " 74/469 [===>..........................] - ETA: 2:45 - loss: 0.0700 - sparse_categorical_accuracy: 0.9784\n",
            " 75/469 [===>..........................] - ETA: 2:44 - loss: 0.0695 - sparse_categorical_accuracy: 0.9785\n",
            " 76/469 [===>..........................] - ETA: 2:44 - loss: 0.0702 - sparse_categorical_accuracy: 0.9781\n",
            " 77/469 [===>..........................] - ETA: 2:44 - loss: 0.0698 - sparse_categorical_accuracy: 0.9781\n",
            " 78/469 [===>..........................] - ETA: 2:44 - loss: 0.0709 - sparse_categorical_accuracy: 0.9780\n",
            " 79/469 [====>.........................] - ETA: 2:45 - loss: 0.0710 - sparse_categorical_accuracy: 0.9779\n",
            " 80/469 [====>.........................] - ETA: 2:45 - loss: 0.0704 - sparse_categorical_accuracy: 0.9782\n",
            " 81/469 [====>.........................] - ETA: 2:45 - loss: 0.0705 - sparse_categorical_accuracy: 0.9782\n",
            " 82/469 [====>.........................] - ETA: 2:46 - loss: 0.0701 - sparse_categorical_accuracy: 0.9784\n",
            " 83/469 [====>.........................] - ETA: 2:45 - loss: 0.0712 - sparse_categorical_accuracy: 0.9785\n",
            " 84/469 [====>.........................] - ETA: 2:44 - loss: 0.0708 - sparse_categorical_accuracy: 0.9787\n",
            " 85/469 [====>.........................] - ETA: 2:43 - loss: 0.0713 - sparse_categorical_accuracy: 0.9786\n",
            " 86/469 [====>.........................] - ETA: 2:43 - loss: 0.0714 - sparse_categorical_accuracy: 0.9786\n",
            " 87/469 [====>.........................] - ETA: 2:42 - loss: 0.0710 - sparse_categorical_accuracy: 0.9787\n",
            " 88/469 [====>.........................] - ETA: 2:41 - loss: 0.0707 - sparse_categorical_accuracy: 0.9788\n",
            " 89/469 [====>.........................] - ETA: 2:41 - loss: 0.0703 - sparse_categorical_accuracy: 0.9789\n",
            " 90/469 [====>.........................] - ETA: 2:40 - loss: 0.0701 - sparse_categorical_accuracy: 0.9789\n",
            " 91/469 [====>.........................] - ETA: 2:40 - loss: 0.0700 - sparse_categorical_accuracy: 0.9790\n",
            " 92/469 [====>.........................] - ETA: 2:39 - loss: 0.0704 - sparse_categorical_accuracy: 0.9790\n",
            " 93/469 [====>.........................] - ETA: 2:38 - loss: 0.0705 - sparse_categorical_accuracy: 0.9787\n",
            " 94/469 [=====>........................] - ETA: 2:38 - loss: 0.0704 - sparse_categorical_accuracy: 0.9788\n",
            " 95/469 [=====>........................] - ETA: 2:37 - loss: 0.0703 - sparse_categorical_accuracy: 0.9787\n",
            " 96/469 [=====>........................] - ETA: 2:37 - loss: 0.0701 - sparse_categorical_accuracy: 0.9788\n",
            " 97/469 [=====>........................] - ETA: 2:36 - loss: 0.0697 - sparse_categorical_accuracy: 0.9789\n",
            " 98/469 [=====>........................] - ETA: 2:35 - loss: 0.0696 - sparse_categorical_accuracy: 0.9790\n",
            " 99/469 [=====>........................] - ETA: 2:35 - loss: 0.0697 - sparse_categorical_accuracy: 0.9789\n",
            "100/469 [=====>........................] - ETA: 2:34 - loss: 0.0700 - sparse_categorical_accuracy: 0.9788\n",
            "101/469 [=====>........................] - ETA: 2:33 - loss: 0.0701 - sparse_categorical_accuracy: 0.9788\n",
            "102/469 [=====>........................] - ETA: 2:33 - loss: 0.0702 - sparse_categorical_accuracy: 0.9788\n",
            "103/469 [=====>........................] - ETA: 2:32 - loss: 0.0704 - sparse_categorical_accuracy: 0.9788\n",
            "104/469 [=====>........................] - ETA: 2:32 - loss: 0.0705 - sparse_categorical_accuracy: 0.9789\n",
            "105/469 [=====>........................] - ETA: 2:31 - loss: 0.0711 - sparse_categorical_accuracy: 0.9789\n",
            "106/469 [=====>........................] - ETA: 2:31 - loss: 0.0710 - sparse_categorical_accuracy: 0.9789\n",
            "107/469 [=====>........................] - ETA: 2:30 - loss: 0.0707 - sparse_categorical_accuracy: 0.9790\n",
            "108/469 [=====>........................] - ETA: 2:30 - loss: 0.0704 - sparse_categorical_accuracy: 0.9792\n",
            "109/469 [=====>........................] - ETA: 2:29 - loss: 0.0702 - sparse_categorical_accuracy: 0.9791\n",
            "110/469 [======>.......................] - ETA: 2:30 - loss: 0.0701 - sparse_categorical_accuracy: 0.9792\n",
            "111/469 [======>.......................] - ETA: 2:30 - loss: 0.0700 - sparse_categorical_accuracy: 0.9792\n",
            "112/469 [======>.......................] - ETA: 2:30 - loss: 0.0701 - sparse_categorical_accuracy: 0.9792\n",
            "113/469 [======>.......................] - ETA: 2:30 - loss: 0.0711 - sparse_categorical_accuracy: 0.9791\n",
            "114/469 [======>.......................] - ETA: 2:30 - loss: 0.0710 - sparse_categorical_accuracy: 0.9792\n",
            "115/469 [======>.......................] - ETA: 2:30 - loss: 0.0713 - sparse_categorical_accuracy: 0.9789\n",
            "116/469 [======>.......................] - ETA: 2:29 - loss: 0.0709 - sparse_categorical_accuracy: 0.9791\n",
            "117/469 [======>.......................] - ETA: 2:29 - loss: 0.0710 - sparse_categorical_accuracy: 0.9790\n",
            "118/469 [======>.......................] - ETA: 2:28 - loss: 0.0711 - sparse_categorical_accuracy: 0.9789\n",
            "119/469 [======>.......................] - ETA: 2:27 - loss: 0.0713 - sparse_categorical_accuracy: 0.9789\n",
            "120/469 [======>.......................] - ETA: 2:27 - loss: 0.0715 - sparse_categorical_accuracy: 0.9788\n",
            "121/469 [======>.......................] - ETA: 2:26 - loss: 0.0714 - sparse_categorical_accuracy: 0.9788\n",
            "122/469 [======>.......................] - ETA: 2:26 - loss: 0.0718 - sparse_categorical_accuracy: 0.9787\n",
            "123/469 [======>.......................] - ETA: 2:25 - loss: 0.0715 - sparse_categorical_accuracy: 0.9787\n",
            "124/469 [======>.......................] - ETA: 2:25 - loss: 0.0714 - sparse_categorical_accuracy: 0.9787\n",
            "125/469 [======>.......................] - ETA: 2:24 - loss: 0.0714 - sparse_categorical_accuracy: 0.9786\n",
            "126/469 [=======>......................] - ETA: 2:24 - loss: 0.0716 - sparse_categorical_accuracy: 0.9785\n",
            "127/469 [=======>......................] - ETA: 2:23 - loss: 0.0720 - sparse_categorical_accuracy: 0.9783\n",
            "128/469 [=======>......................] - ETA: 2:23 - loss: 0.0722 - sparse_categorical_accuracy: 0.9784\n",
            "129/469 [=======>......................] - ETA: 2:22 - loss: 0.0719 - sparse_categorical_accuracy: 0.9785\n",
            "130/469 [=======>......................] - ETA: 2:22 - loss: 0.0718 - sparse_categorical_accuracy: 0.9784\n",
            "131/469 [=======>......................] - ETA: 2:21 - loss: 0.0718 - sparse_categorical_accuracy: 0.9785\n",
            "132/469 [=======>......................] - ETA: 2:21 - loss: 0.0716 - sparse_categorical_accuracy: 0.9785\n",
            "133/469 [=======>......................] - ETA: 2:20 - loss: 0.0724 - sparse_categorical_accuracy: 0.9782\n",
            "134/469 [=======>......................] - ETA: 2:19 - loss: 0.0720 - sparse_categorical_accuracy: 0.9784\n",
            "135/469 [=======>......................] - ETA: 2:19 - loss: 0.0720 - sparse_categorical_accuracy: 0.9784\n",
            "136/469 [=======>......................] - ETA: 2:18 - loss: 0.0721 - sparse_categorical_accuracy: 0.9782\n",
            "137/469 [=======>......................] - ETA: 2:18 - loss: 0.0719 - sparse_categorical_accuracy: 0.9784\n",
            "138/469 [=======>......................] - ETA: 2:17 - loss: 0.0721 - sparse_categorical_accuracy: 0.9784\n",
            "139/469 [=======>......................] - ETA: 2:17 - loss: 0.0719 - sparse_categorical_accuracy: 0.9784\n",
            "140/469 [=======>......................] - ETA: 2:16 - loss: 0.0719 - sparse_categorical_accuracy: 0.9784\n",
            "141/469 [========>.....................] - ETA: 2:16 - loss: 0.0718 - sparse_categorical_accuracy: 0.9784\n",
            "142/469 [========>.....................] - ETA: 2:16 - loss: 0.0715 - sparse_categorical_accuracy: 0.9786\n",
            "143/469 [========>.....................] - ETA: 2:16 - loss: 0.0718 - sparse_categorical_accuracy: 0.9783\n",
            "144/469 [========>.....................] - ETA: 2:16 - loss: 0.0721 - sparse_categorical_accuracy: 0.9782\n",
            "145/469 [========>.....................] - ETA: 2:16 - loss: 0.0721 - sparse_categorical_accuracy: 0.9783\n",
            "146/469 [========>.....................] - ETA: 2:16 - loss: 0.0721 - sparse_categorical_accuracy: 0.9783\n",
            "147/469 [========>.....................] - ETA: 2:16 - loss: 0.0722 - sparse_categorical_accuracy: 0.9783\n",
            "148/469 [========>.....................] - ETA: 2:15 - loss: 0.0721 - sparse_categorical_accuracy: 0.9783\n",
            "149/469 [========>.....................] - ETA: 2:15 - loss: 0.0720 - sparse_categorical_accuracy: 0.9783\n",
            "150/469 [========>.....................] - ETA: 2:14 - loss: 0.0719 - sparse_categorical_accuracy: 0.9783\n",
            "151/469 [========>.....................] - ETA: 2:14 - loss: 0.0723 - sparse_categorical_accuracy: 0.9783\n",
            "152/469 [========>.....................] - ETA: 2:13 - loss: 0.0733 - sparse_categorical_accuracy: 0.9782\n",
            "153/469 [========>.....................] - ETA: 2:13 - loss: 0.0732 - sparse_categorical_accuracy: 0.9782\n",
            "154/469 [========>.....................] - ETA: 2:12 - loss: 0.0735 - sparse_categorical_accuracy: 0.9781\n",
            "155/469 [========>.....................] - ETA: 2:12 - loss: 0.0735 - sparse_categorical_accuracy: 0.9780\n",
            "156/469 [========>.....................] - ETA: 2:11 - loss: 0.0739 - sparse_categorical_accuracy: 0.9779\n",
            "157/469 [=========>....................] - ETA: 2:11 - loss: 0.0737 - sparse_categorical_accuracy: 0.9780\n",
            "158/469 [=========>....................] - ETA: 2:10 - loss: 0.0737 - sparse_categorical_accuracy: 0.9779\n",
            "159/469 [=========>....................] - ETA: 2:10 - loss: 0.0736 - sparse_categorical_accuracy: 0.9780\n",
            "160/469 [=========>....................] - ETA: 2:09 - loss: 0.0736 - sparse_categorical_accuracy: 0.9779\n",
            "161/469 [=========>....................] - ETA: 2:09 - loss: 0.0737 - sparse_categorical_accuracy: 0.9779\n",
            "162/469 [=========>....................] - ETA: 2:08 - loss: 0.0738 - sparse_categorical_accuracy: 0.9779\n",
            "163/469 [=========>....................] - ETA: 2:08 - loss: 0.0745 - sparse_categorical_accuracy: 0.9778\n",
            "164/469 [=========>....................] - ETA: 2:07 - loss: 0.0746 - sparse_categorical_accuracy: 0.9778\n",
            "165/469 [=========>....................] - ETA: 2:07 - loss: 0.0746 - sparse_categorical_accuracy: 0.9778\n",
            "166/469 [=========>....................] - ETA: 2:06 - loss: 0.0744 - sparse_categorical_accuracy: 0.9778\n",
            "167/469 [=========>....................] - ETA: 2:06 - loss: 0.0742 - sparse_categorical_accuracy: 0.9779\n",
            "168/469 [=========>....................] - ETA: 2:05 - loss: 0.0740 - sparse_categorical_accuracy: 0.9780\n",
            "169/469 [=========>....................] - ETA: 2:05 - loss: 0.0743 - sparse_categorical_accuracy: 0.9778\n",
            "170/469 [=========>....................] - ETA: 2:04 - loss: 0.0747 - sparse_categorical_accuracy: 0.9777\n",
            "171/469 [=========>....................] - ETA: 2:04 - loss: 0.0749 - sparse_categorical_accuracy: 0.9777\n",
            "172/469 [==========>...................] - ETA: 2:04 - loss: 0.0746 - sparse_categorical_accuracy: 0.9777\n",
            "173/469 [==========>...................] - ETA: 2:04 - loss: 0.0747 - sparse_categorical_accuracy: 0.9777\n",
            "174/469 [==========>...................] - ETA: 2:03 - loss: 0.0745 - sparse_categorical_accuracy: 0.9778\n",
            "175/469 [==========>...................] - ETA: 2:03 - loss: 0.0746 - sparse_categorical_accuracy: 0.9777\n",
            "176/469 [==========>...................] - ETA: 2:03 - loss: 0.0746 - sparse_categorical_accuracy: 0.9776\n",
            "177/469 [==========>...................] - ETA: 2:03 - loss: 0.0745 - sparse_categorical_accuracy: 0.9776\n",
            "178/469 [==========>...................] - ETA: 2:03 - loss: 0.0742 - sparse_categorical_accuracy: 0.9777\n",
            "179/469 [==========>...................] - ETA: 2:02 - loss: 0.0742 - sparse_categorical_accuracy: 0.9777\n",
            "180/469 [==========>...................] - ETA: 2:02 - loss: 0.0740 - sparse_categorical_accuracy: 0.9778\n",
            "181/469 [==========>...................] - ETA: 2:01 - loss: 0.0738 - sparse_categorical_accuracy: 0.9778\n",
            "182/469 [==========>...................] - ETA: 2:01 - loss: 0.0741 - sparse_categorical_accuracy: 0.9777\n",
            "183/469 [==========>...................] - ETA: 2:00 - loss: 0.0740 - sparse_categorical_accuracy: 0.9778\n",
            "184/469 [==========>...................] - ETA: 2:00 - loss: 0.0740 - sparse_categorical_accuracy: 0.9777\n",
            "185/469 [==========>...................] - ETA: 1:59 - loss: 0.0745 - sparse_categorical_accuracy: 0.9775\n",
            "186/469 [==========>...................] - ETA: 1:59 - loss: 0.0747 - sparse_categorical_accuracy: 0.9774\n",
            "187/469 [==========>...................] - ETA: 1:58 - loss: 0.0747 - sparse_categorical_accuracy: 0.9775\n",
            "188/469 [===========>..................] - ETA: 1:58 - loss: 0.0745 - sparse_categorical_accuracy: 0.9775\n",
            "189/469 [===========>..................] - ETA: 1:57 - loss: 0.0746 - sparse_categorical_accuracy: 0.9775\n",
            "190/469 [===========>..................] - ETA: 1:57 - loss: 0.0745 - sparse_categorical_accuracy: 0.9775\n",
            "191/469 [===========>..................] - ETA: 1:56 - loss: 0.0743 - sparse_categorical_accuracy: 0.9776\n",
            "192/469 [===========>..................] - ETA: 1:56 - loss: 0.0745 - sparse_categorical_accuracy: 0.9775\n",
            "193/469 [===========>..................] - ETA: 1:55 - loss: 0.0746 - sparse_categorical_accuracy: 0.9775\n",
            "194/469 [===========>..................] - ETA: 1:55 - loss: 0.0746 - sparse_categorical_accuracy: 0.9775\n",
            "195/469 [===========>..................] - ETA: 1:54 - loss: 0.0750 - sparse_categorical_accuracy: 0.9774\n",
            "196/469 [===========>..................] - ETA: 1:54 - loss: 0.0750 - sparse_categorical_accuracy: 0.9774\n",
            "197/469 [===========>..................] - ETA: 1:53 - loss: 0.0752 - sparse_categorical_accuracy: 0.9774\n",
            "198/469 [===========>..................] - ETA: 1:53 - loss: 0.0749 - sparse_categorical_accuracy: 0.9775\n",
            "199/469 [===========>..................] - ETA: 1:52 - loss: 0.0748 - sparse_categorical_accuracy: 0.9776\n",
            "200/469 [===========>..................] - ETA: 1:52 - loss: 0.0746 - sparse_categorical_accuracy: 0.9777\n",
            "201/469 [===========>..................] - ETA: 1:51 - loss: 0.0744 - sparse_categorical_accuracy: 0.9777\n",
            "202/469 [===========>..................] - ETA: 1:51 - loss: 0.0743 - sparse_categorical_accuracy: 0.9778\n",
            "203/469 [===========>..................] - ETA: 1:50 - loss: 0.0741 - sparse_categorical_accuracy: 0.9778\n",
            "204/469 [============>.................] - ETA: 1:50 - loss: 0.0741 - sparse_categorical_accuracy: 0.9778\n",
            "205/469 [============>.................] - ETA: 1:50 - loss: 0.0739 - sparse_categorical_accuracy: 0.9779\n",
            "206/469 [============>.................] - ETA: 1:49 - loss: 0.0738 - sparse_categorical_accuracy: 0.9779\n",
            "207/469 [============>.................] - ETA: 1:49 - loss: 0.0740 - sparse_categorical_accuracy: 0.9778\n",
            "208/469 [============>.................] - ETA: 1:49 - loss: 0.0740 - sparse_categorical_accuracy: 0.9778\n",
            "209/469 [============>.................] - ETA: 1:49 - loss: 0.0739 - sparse_categorical_accuracy: 0.9778\n",
            "210/469 [============>.................] - ETA: 1:49 - loss: 0.0742 - sparse_categorical_accuracy: 0.9778\n",
            "211/469 [============>.................] - ETA: 1:48 - loss: 0.0741 - sparse_categorical_accuracy: 0.9777\n",
            "212/469 [============>.................] - ETA: 1:48 - loss: 0.0741 - sparse_categorical_accuracy: 0.9778\n",
            "213/469 [============>.................] - ETA: 1:47 - loss: 0.0742 - sparse_categorical_accuracy: 0.9777\n",
            "214/469 [============>.................] - ETA: 1:47 - loss: 0.0745 - sparse_categorical_accuracy: 0.9776\n",
            "215/469 [============>.................] - ETA: 1:46 - loss: 0.0742 - sparse_categorical_accuracy: 0.9777\n",
            "216/469 [============>.................] - ETA: 1:46 - loss: 0.0742 - sparse_categorical_accuracy: 0.9777\n",
            "217/469 [============>.................] - ETA: 1:45 - loss: 0.0743 - sparse_categorical_accuracy: 0.9777\n",
            "218/469 [============>.................] - ETA: 1:45 - loss: 0.0742 - sparse_categorical_accuracy: 0.9777\n",
            "219/469 [=============>................] - ETA: 1:44 - loss: 0.0742 - sparse_categorical_accuracy: 0.9777\n",
            "220/469 [=============>................] - ETA: 1:44 - loss: 0.0743 - sparse_categorical_accuracy: 0.9776\n",
            "221/469 [=============>................] - ETA: 1:43 - loss: 0.0743 - sparse_categorical_accuracy: 0.9776\n",
            "222/469 [=============>................] - ETA: 1:43 - loss: 0.0745 - sparse_categorical_accuracy: 0.9776\n",
            "223/469 [=============>................] - ETA: 1:43 - loss: 0.0744 - sparse_categorical_accuracy: 0.9776\n",
            "224/469 [=============>................] - ETA: 1:42 - loss: 0.0745 - sparse_categorical_accuracy: 0.9776\n",
            "225/469 [=============>................] - ETA: 1:42 - loss: 0.0746 - sparse_categorical_accuracy: 0.9775\n",
            "226/469 [=============>................] - ETA: 1:41 - loss: 0.0748 - sparse_categorical_accuracy: 0.9775\n",
            "227/469 [=============>................] - ETA: 1:41 - loss: 0.0748 - sparse_categorical_accuracy: 0.9775\n",
            "228/469 [=============>................] - ETA: 1:40 - loss: 0.0745 - sparse_categorical_accuracy: 0.9776\n",
            "229/469 [=============>................] - ETA: 1:40 - loss: 0.0745 - sparse_categorical_accuracy: 0.9776\n",
            "230/469 [=============>................] - ETA: 1:39 - loss: 0.0748 - sparse_categorical_accuracy: 0.9775\n",
            "231/469 [=============>................] - ETA: 1:39 - loss: 0.0746 - sparse_categorical_accuracy: 0.9775\n",
            "232/469 [=============>................] - ETA: 1:38 - loss: 0.0746 - sparse_categorical_accuracy: 0.9776\n",
            "233/469 [=============>................] - ETA: 1:38 - loss: 0.0746 - sparse_categorical_accuracy: 0.9776\n",
            "234/469 [=============>................] - ETA: 1:37 - loss: 0.0746 - sparse_categorical_accuracy: 0.9776\n",
            "235/469 [==============>...............] - ETA: 1:37 - loss: 0.0745 - sparse_categorical_accuracy: 0.9776\n",
            "236/469 [==============>...............] - ETA: 1:37 - loss: 0.0743 - sparse_categorical_accuracy: 0.9777\n",
            "237/469 [==============>...............] - ETA: 1:36 - loss: 0.0743 - sparse_categorical_accuracy: 0.9777\n",
            "238/469 [==============>...............] - ETA: 1:36 - loss: 0.0741 - sparse_categorical_accuracy: 0.9778\n",
            "239/469 [==============>...............] - ETA: 1:35 - loss: 0.0740 - sparse_categorical_accuracy: 0.9778\n",
            "240/469 [==============>...............] - ETA: 1:35 - loss: 0.0739 - sparse_categorical_accuracy: 0.9779\n",
            "241/469 [==============>...............] - ETA: 1:35 - loss: 0.0737 - sparse_categorical_accuracy: 0.9780\n",
            "242/469 [==============>...............] - ETA: 1:35 - loss: 0.0735 - sparse_categorical_accuracy: 0.9780\n",
            "243/469 [==============>...............] - ETA: 1:34 - loss: 0.0733 - sparse_categorical_accuracy: 0.9781\n",
            "244/469 [==============>...............] - ETA: 1:34 - loss: 0.0733 - sparse_categorical_accuracy: 0.9780\n",
            "245/469 [==============>...............] - ETA: 1:34 - loss: 0.0731 - sparse_categorical_accuracy: 0.9781\n",
            "246/469 [==============>...............] - ETA: 1:33 - loss: 0.0733 - sparse_categorical_accuracy: 0.9781\n",
            "247/469 [==============>...............] - ETA: 1:33 - loss: 0.0732 - sparse_categorical_accuracy: 0.9781\n",
            "248/469 [==============>...............] - ETA: 1:32 - loss: 0.0730 - sparse_categorical_accuracy: 0.9781\n",
            "249/469 [==============>...............] - ETA: 1:32 - loss: 0.0729 - sparse_categorical_accuracy: 0.9782\n",
            "250/469 [==============>...............] - ETA: 1:31 - loss: 0.0729 - sparse_categorical_accuracy: 0.9781\n",
            "251/469 [===============>..............] - ETA: 1:31 - loss: 0.0731 - sparse_categorical_accuracy: 0.9781\n",
            "252/469 [===============>..............] - ETA: 1:31 - loss: 0.0730 - sparse_categorical_accuracy: 0.9782\n",
            "253/469 [===============>..............] - ETA: 1:30 - loss: 0.0730 - sparse_categorical_accuracy: 0.9781\n",
            "254/469 [===============>..............] - ETA: 1:30 - loss: 0.0729 - sparse_categorical_accuracy: 0.9782\n",
            "255/469 [===============>..............] - ETA: 1:29 - loss: 0.0727 - sparse_categorical_accuracy: 0.9782\n",
            "256/469 [===============>..............] - ETA: 1:29 - loss: 0.0727 - sparse_categorical_accuracy: 0.9783\n",
            "257/469 [===============>..............] - ETA: 1:28 - loss: 0.0726 - sparse_categorical_accuracy: 0.9782\n",
            "258/469 [===============>..............] - ETA: 1:28 - loss: 0.0726 - sparse_categorical_accuracy: 0.9782\n",
            "259/469 [===============>..............] - ETA: 1:27 - loss: 0.0726 - sparse_categorical_accuracy: 0.9782\n",
            "260/469 [===============>..............] - ETA: 1:27 - loss: 0.0725 - sparse_categorical_accuracy: 0.9782\n",
            "261/469 [===============>..............] - ETA: 1:26 - loss: 0.0724 - sparse_categorical_accuracy: 0.9782\n",
            "262/469 [===============>..............] - ETA: 1:26 - loss: 0.0725 - sparse_categorical_accuracy: 0.9782\n",
            "263/469 [===============>..............] - ETA: 1:26 - loss: 0.0725 - sparse_categorical_accuracy: 0.9782\n",
            "264/469 [===============>..............] - ETA: 1:25 - loss: 0.0727 - sparse_categorical_accuracy: 0.9781\n",
            "265/469 [===============>..............] - ETA: 1:25 - loss: 0.0730 - sparse_categorical_accuracy: 0.9780\n",
            "266/469 [================>.............] - ETA: 1:24 - loss: 0.0729 - sparse_categorical_accuracy: 0.9781\n",
            "267/469 [================>.............] - ETA: 1:24 - loss: 0.0732 - sparse_categorical_accuracy: 0.9780\n",
            "268/469 [================>.............] - ETA: 1:23 - loss: 0.0733 - sparse_categorical_accuracy: 0.9780\n",
            "269/469 [================>.............] - ETA: 1:23 - loss: 0.0733 - sparse_categorical_accuracy: 0.9779\n",
            "270/469 [================>.............] - ETA: 1:23 - loss: 0.0731 - sparse_categorical_accuracy: 0.9780\n",
            "271/469 [================>.............] - ETA: 1:22 - loss: 0.0731 - sparse_categorical_accuracy: 0.9779\n",
            "272/469 [================>.............] - ETA: 1:22 - loss: 0.0730 - sparse_categorical_accuracy: 0.9780\n",
            "273/469 [================>.............] - ETA: 1:22 - loss: 0.0728 - sparse_categorical_accuracy: 0.9780\n",
            "274/469 [================>.............] - ETA: 1:21 - loss: 0.0729 - sparse_categorical_accuracy: 0.9780\n",
            "275/469 [================>.............] - ETA: 1:21 - loss: 0.0728 - sparse_categorical_accuracy: 0.9780\n",
            "276/469 [================>.............] - ETA: 1:21 - loss: 0.0727 - sparse_categorical_accuracy: 0.9779\n",
            "277/469 [================>.............] - ETA: 1:20 - loss: 0.0727 - sparse_categorical_accuracy: 0.9779\n",
            "278/469 [================>.............] - ETA: 1:20 - loss: 0.0726 - sparse_categorical_accuracy: 0.9779\n",
            "279/469 [================>.............] - ETA: 1:19 - loss: 0.0725 - sparse_categorical_accuracy: 0.9780\n",
            "280/469 [================>.............] - ETA: 1:19 - loss: 0.0723 - sparse_categorical_accuracy: 0.9780\n",
            "281/469 [================>.............] - ETA: 1:18 - loss: 0.0725 - sparse_categorical_accuracy: 0.9780\n",
            "282/469 [=================>............] - ETA: 1:18 - loss: 0.0725 - sparse_categorical_accuracy: 0.9780\n",
            "283/469 [=================>............] - ETA: 1:17 - loss: 0.0724 - sparse_categorical_accuracy: 0.9779\n",
            "284/469 [=================>............] - ETA: 1:17 - loss: 0.0723 - sparse_categorical_accuracy: 0.9780\n",
            "285/469 [=================>............] - ETA: 1:17 - loss: 0.0726 - sparse_categorical_accuracy: 0.9779\n",
            "286/469 [=================>............] - ETA: 1:16 - loss: 0.0725 - sparse_categorical_accuracy: 0.9779\n",
            "287/469 [=================>............] - ETA: 1:16 - loss: 0.0725 - sparse_categorical_accuracy: 0.9779\n",
            "288/469 [=================>............] - ETA: 1:16 - loss: 0.0725 - sparse_categorical_accuracy: 0.9778\n",
            "289/469 [=================>............] - ETA: 1:15 - loss: 0.0726 - sparse_categorical_accuracy: 0.9778\n",
            "290/469 [=================>............] - ETA: 1:15 - loss: 0.0730 - sparse_categorical_accuracy: 0.9777\n",
            "291/469 [=================>............] - ETA: 1:14 - loss: 0.0729 - sparse_categorical_accuracy: 0.9777\n",
            "292/469 [=================>............] - ETA: 1:14 - loss: 0.0729 - sparse_categorical_accuracy: 0.9777\n",
            "293/469 [=================>............] - ETA: 1:13 - loss: 0.0728 - sparse_categorical_accuracy: 0.9778\n",
            "294/469 [=================>............] - ETA: 1:13 - loss: 0.0727 - sparse_categorical_accuracy: 0.9778\n",
            "295/469 [=================>............] - ETA: 1:12 - loss: 0.0726 - sparse_categorical_accuracy: 0.9778\n",
            "296/469 [=================>............] - ETA: 1:12 - loss: 0.0729 - sparse_categorical_accuracy: 0.9777\n",
            "297/469 [=================>............] - ETA: 1:12 - loss: 0.0731 - sparse_categorical_accuracy: 0.9776\n",
            "298/469 [==================>...........] - ETA: 1:11 - loss: 0.0731 - sparse_categorical_accuracy: 0.9776\n",
            "299/469 [==================>...........] - ETA: 1:11 - loss: 0.0731 - sparse_categorical_accuracy: 0.9776\n",
            "300/469 [==================>...........] - ETA: 1:10 - loss: 0.0730 - sparse_categorical_accuracy: 0.9777\n",
            "301/469 [==================>...........] - ETA: 1:10 - loss: 0.0731 - sparse_categorical_accuracy: 0.9777\n",
            "302/469 [==================>...........] - ETA: 1:09 - loss: 0.0731 - sparse_categorical_accuracy: 0.9776\n",
            "303/469 [==================>...........] - ETA: 1:09 - loss: 0.0733 - sparse_categorical_accuracy: 0.9776\n",
            "304/469 [==================>...........] - ETA: 1:09 - loss: 0.0733 - sparse_categorical_accuracy: 0.9776\n",
            "305/469 [==================>...........] - ETA: 1:09 - loss: 0.0733 - sparse_categorical_accuracy: 0.9776\n",
            "306/469 [==================>...........] - ETA: 1:08 - loss: 0.0734 - sparse_categorical_accuracy: 0.9776\n",
            "307/469 [==================>...........] - ETA: 1:08 - loss: 0.0735 - sparse_categorical_accuracy: 0.9776\n",
            "308/469 [==================>...........] - ETA: 1:07 - loss: 0.0734 - sparse_categorical_accuracy: 0.9777\n",
            "309/469 [==================>...........] - ETA: 1:07 - loss: 0.0735 - sparse_categorical_accuracy: 0.9776\n",
            "310/469 [==================>...........] - ETA: 1:06 - loss: 0.0736 - sparse_categorical_accuracy: 0.9776\n",
            "311/469 [==================>...........] - ETA: 1:06 - loss: 0.0734 - sparse_categorical_accuracy: 0.9776\n",
            "312/469 [==================>...........] - ETA: 1:06 - loss: 0.0737 - sparse_categorical_accuracy: 0.9775\n",
            "313/469 [===================>..........] - ETA: 1:05 - loss: 0.0738 - sparse_categorical_accuracy: 0.9775\n",
            "314/469 [===================>..........] - ETA: 1:05 - loss: 0.0738 - sparse_categorical_accuracy: 0.9775\n",
            "315/469 [===================>..........] - ETA: 1:04 - loss: 0.0737 - sparse_categorical_accuracy: 0.9775\n",
            "316/469 [===================>..........] - ETA: 1:04 - loss: 0.0737 - sparse_categorical_accuracy: 0.9775\n",
            "317/469 [===================>..........] - ETA: 1:03 - loss: 0.0738 - sparse_categorical_accuracy: 0.9775\n",
            "318/469 [===================>..........] - ETA: 1:03 - loss: 0.0739 - sparse_categorical_accuracy: 0.9774\n",
            "319/469 [===================>..........] - ETA: 1:03 - loss: 0.0739 - sparse_categorical_accuracy: 0.9774\n",
            "320/469 [===================>..........] - ETA: 1:02 - loss: 0.0740 - sparse_categorical_accuracy: 0.9774\n",
            "321/469 [===================>..........] - ETA: 1:02 - loss: 0.0739 - sparse_categorical_accuracy: 0.9774\n",
            "322/469 [===================>..........] - ETA: 1:01 - loss: 0.0738 - sparse_categorical_accuracy: 0.9775\n",
            "323/469 [===================>..........] - ETA: 1:01 - loss: 0.0737 - sparse_categorical_accuracy: 0.9775\n",
            "324/469 [===================>..........] - ETA: 1:00 - loss: 0.0737 - sparse_categorical_accuracy: 0.9775\n",
            "325/469 [===================>..........] - ETA: 1:00 - loss: 0.0738 - sparse_categorical_accuracy: 0.9775\n",
            "326/469 [===================>..........] - ETA: 59s - loss: 0.0737 - sparse_categorical_accuracy: 0.9775 \n",
            "327/469 [===================>..........] - ETA: 59s - loss: 0.0736 - sparse_categorical_accuracy: 0.9775\n",
            "328/469 [===================>..........] - ETA: 59s - loss: 0.0736 - sparse_categorical_accuracy: 0.9775\n",
            "329/469 [====================>.........] - ETA: 58s - loss: 0.0738 - sparse_categorical_accuracy: 0.9775\n",
            "330/469 [====================>.........] - ETA: 58s - loss: 0.0737 - sparse_categorical_accuracy: 0.9775\n",
            "331/469 [====================>.........] - ETA: 57s - loss: 0.0738 - sparse_categorical_accuracy: 0.9775\n",
            "332/469 [====================>.........] - ETA: 57s - loss: 0.0737 - sparse_categorical_accuracy: 0.9775\n",
            "333/469 [====================>.........] - ETA: 57s - loss: 0.0737 - sparse_categorical_accuracy: 0.9775\n",
            "334/469 [====================>.........] - ETA: 56s - loss: 0.0737 - sparse_categorical_accuracy: 0.9775\n",
            "335/469 [====================>.........] - ETA: 56s - loss: 0.0740 - sparse_categorical_accuracy: 0.9775\n",
            "336/469 [====================>.........] - ETA: 55s - loss: 0.0739 - sparse_categorical_accuracy: 0.9775\n",
            "337/469 [====================>.........] - ETA: 55s - loss: 0.0740 - sparse_categorical_accuracy: 0.9775\n",
            "338/469 [====================>.........] - ETA: 55s - loss: 0.0741 - sparse_categorical_accuracy: 0.9775\n",
            "339/469 [====================>.........] - ETA: 54s - loss: 0.0740 - sparse_categorical_accuracy: 0.9775\n",
            "340/469 [====================>.........] - ETA: 54s - loss: 0.0746 - sparse_categorical_accuracy: 0.9774\n",
            "341/469 [====================>.........] - ETA: 53s - loss: 0.0745 - sparse_categorical_accuracy: 0.9775\n",
            "342/469 [====================>.........] - ETA: 53s - loss: 0.0744 - sparse_categorical_accuracy: 0.9775\n",
            "343/469 [====================>.........] - ETA: 53s - loss: 0.0743 - sparse_categorical_accuracy: 0.9775\n",
            "344/469 [=====================>........] - ETA: 52s - loss: 0.0743 - sparse_categorical_accuracy: 0.9775\n",
            "345/469 [=====================>........] - ETA: 52s - loss: 0.0742 - sparse_categorical_accuracy: 0.9776\n",
            "346/469 [=====================>........] - ETA: 51s - loss: 0.0741 - sparse_categorical_accuracy: 0.9776\n",
            "347/469 [=====================>........] - ETA: 51s - loss: 0.0741 - sparse_categorical_accuracy: 0.9776\n",
            "348/469 [=====================>........] - ETA: 50s - loss: 0.0743 - sparse_categorical_accuracy: 0.9776\n",
            "349/469 [=====================>........] - ETA: 50s - loss: 0.0743 - sparse_categorical_accuracy: 0.9776\n",
            "350/469 [=====================>........] - ETA: 50s - loss: 0.0744 - sparse_categorical_accuracy: 0.9775\n",
            "351/469 [=====================>........] - ETA: 49s - loss: 0.0743 - sparse_categorical_accuracy: 0.9776\n",
            "352/469 [=====================>........] - ETA: 49s - loss: 0.0742 - sparse_categorical_accuracy: 0.9776\n",
            "353/469 [=====================>........] - ETA: 48s - loss: 0.0741 - sparse_categorical_accuracy: 0.9777\n",
            "354/469 [=====================>........] - ETA: 48s - loss: 0.0741 - sparse_categorical_accuracy: 0.9777\n",
            "355/469 [=====================>........] - ETA: 47s - loss: 0.0740 - sparse_categorical_accuracy: 0.9777\n",
            "356/469 [=====================>........] - ETA: 47s - loss: 0.0739 - sparse_categorical_accuracy: 0.9777\n",
            "357/469 [=====================>........] - ETA: 47s - loss: 0.0739 - sparse_categorical_accuracy: 0.9777\n",
            "358/469 [=====================>........] - ETA: 46s - loss: 0.0737 - sparse_categorical_accuracy: 0.9778\n",
            "359/469 [=====================>........] - ETA: 46s - loss: 0.0740 - sparse_categorical_accuracy: 0.9777\n",
            "360/469 [======================>.......] - ETA: 45s - loss: 0.0739 - sparse_categorical_accuracy: 0.9778\n",
            "361/469 [======================>.......] - ETA: 45s - loss: 0.0740 - sparse_categorical_accuracy: 0.9777\n",
            "362/469 [======================>.......] - ETA: 44s - loss: 0.0739 - sparse_categorical_accuracy: 0.9777\n",
            "363/469 [======================>.......] - ETA: 44s - loss: 0.0739 - sparse_categorical_accuracy: 0.9777\n",
            "364/469 [======================>.......] - ETA: 44s - loss: 0.0738 - sparse_categorical_accuracy: 0.9778\n",
            "365/469 [======================>.......] - ETA: 43s - loss: 0.0738 - sparse_categorical_accuracy: 0.9778\n",
            "366/469 [======================>.......] - ETA: 43s - loss: 0.0738 - sparse_categorical_accuracy: 0.9778\n",
            "367/469 [======================>.......] - ETA: 42s - loss: 0.0738 - sparse_categorical_accuracy: 0.9778\n",
            "368/469 [======================>.......] - ETA: 42s - loss: 0.0738 - sparse_categorical_accuracy: 0.9778\n",
            "369/469 [======================>.......] - ETA: 42s - loss: 0.0737 - sparse_categorical_accuracy: 0.9778\n",
            "370/469 [======================>.......] - ETA: 41s - loss: 0.0736 - sparse_categorical_accuracy: 0.9778\n",
            "371/469 [======================>.......] - ETA: 41s - loss: 0.0736 - sparse_categorical_accuracy: 0.9778\n",
            "372/469 [======================>.......] - ETA: 40s - loss: 0.0737 - sparse_categorical_accuracy: 0.9778\n",
            "373/469 [======================>.......] - ETA: 40s - loss: 0.0737 - sparse_categorical_accuracy: 0.9778\n",
            "374/469 [======================>.......] - ETA: 40s - loss: 0.0736 - sparse_categorical_accuracy: 0.9778\n",
            "375/469 [======================>.......] - ETA: 39s - loss: 0.0735 - sparse_categorical_accuracy: 0.9779\n",
            "376/469 [=======================>......] - ETA: 39s - loss: 0.0734 - sparse_categorical_accuracy: 0.9778\n",
            "377/469 [=======================>......] - ETA: 38s - loss: 0.0733 - sparse_categorical_accuracy: 0.9779\n",
            "378/469 [=======================>......] - ETA: 38s - loss: 0.0734 - sparse_categorical_accuracy: 0.9778\n",
            "379/469 [=======================>......] - ETA: 37s - loss: 0.0735 - sparse_categorical_accuracy: 0.9778\n",
            "380/469 [=======================>......] - ETA: 37s - loss: 0.0735 - sparse_categorical_accuracy: 0.9778\n",
            "381/469 [=======================>......] - ETA: 37s - loss: 0.0733 - sparse_categorical_accuracy: 0.9778\n",
            "382/469 [=======================>......] - ETA: 36s - loss: 0.0735 - sparse_categorical_accuracy: 0.9778\n",
            "383/469 [=======================>......] - ETA: 36s - loss: 0.0735 - sparse_categorical_accuracy: 0.9778\n",
            "384/469 [=======================>......] - ETA: 35s - loss: 0.0734 - sparse_categorical_accuracy: 0.9778\n",
            "385/469 [=======================>......] - ETA: 35s - loss: 0.0733 - sparse_categorical_accuracy: 0.9779\n",
            "386/469 [=======================>......] - ETA: 34s - loss: 0.0732 - sparse_categorical_accuracy: 0.9779\n",
            "387/469 [=======================>......] - ETA: 34s - loss: 0.0732 - sparse_categorical_accuracy: 0.9779\n",
            "388/469 [=======================>......] - ETA: 34s - loss: 0.0732 - sparse_categorical_accuracy: 0.9779\n",
            "389/469 [=======================>......] - ETA: 33s - loss: 0.0731 - sparse_categorical_accuracy: 0.9780\n",
            "390/469 [=======================>......] - ETA: 33s - loss: 0.0731 - sparse_categorical_accuracy: 0.9780\n",
            "391/469 [========================>.....] - ETA: 32s - loss: 0.0730 - sparse_categorical_accuracy: 0.9780\n",
            "392/469 [========================>.....] - ETA: 32s - loss: 0.0729 - sparse_categorical_accuracy: 0.9780\n",
            "393/469 [========================>.....] - ETA: 31s - loss: 0.0728 - sparse_categorical_accuracy: 0.9781\n",
            "394/469 [========================>.....] - ETA: 31s - loss: 0.0728 - sparse_categorical_accuracy: 0.9780\n",
            "395/469 [========================>.....] - ETA: 31s - loss: 0.0728 - sparse_categorical_accuracy: 0.9781\n",
            "396/469 [========================>.....] - ETA: 30s - loss: 0.0728 - sparse_categorical_accuracy: 0.9781\n",
            "397/469 [========================>.....] - ETA: 30s - loss: 0.0727 - sparse_categorical_accuracy: 0.9781\n",
            "398/469 [========================>.....] - ETA: 29s - loss: 0.0726 - sparse_categorical_accuracy: 0.9782\n",
            "399/469 [========================>.....] - ETA: 29s - loss: 0.0726 - sparse_categorical_accuracy: 0.9781\n",
            "400/469 [========================>.....] - ETA: 29s - loss: 0.0725 - sparse_categorical_accuracy: 0.9782\n",
            "401/469 [========================>.....] - ETA: 28s - loss: 0.0725 - sparse_categorical_accuracy: 0.9782\n",
            "402/469 [========================>.....] - ETA: 28s - loss: 0.0725 - sparse_categorical_accuracy: 0.9782\n",
            "403/469 [========================>.....] - ETA: 27s - loss: 0.0723 - sparse_categorical_accuracy: 0.9782\n",
            "404/469 [========================>.....] - ETA: 27s - loss: 0.0725 - sparse_categorical_accuracy: 0.9782\n",
            "405/469 [========================>.....] - ETA: 27s - loss: 0.0725 - sparse_categorical_accuracy: 0.9782\n",
            "406/469 [========================>.....] - ETA: 26s - loss: 0.0725 - sparse_categorical_accuracy: 0.9782\n",
            "407/469 [=========================>....] - ETA: 26s - loss: 0.0725 - sparse_categorical_accuracy: 0.9782\n",
            "408/469 [=========================>....] - ETA: 25s - loss: 0.0724 - sparse_categorical_accuracy: 0.9782\n",
            "409/469 [=========================>....] - ETA: 25s - loss: 0.0725 - sparse_categorical_accuracy: 0.9782\n",
            "410/469 [=========================>....] - ETA: 24s - loss: 0.0725 - sparse_categorical_accuracy: 0.9782\n",
            "411/469 [=========================>....] - ETA: 24s - loss: 0.0725 - sparse_categorical_accuracy: 0.9782\n",
            "412/469 [=========================>....] - ETA: 24s - loss: 0.0725 - sparse_categorical_accuracy: 0.9782\n",
            "413/469 [=========================>....] - ETA: 23s - loss: 0.0724 - sparse_categorical_accuracy: 0.9782\n",
            "414/469 [=========================>....] - ETA: 23s - loss: 0.0724 - sparse_categorical_accuracy: 0.9782\n",
            "415/469 [=========================>....] - ETA: 22s - loss: 0.0724 - sparse_categorical_accuracy: 0.9782\n",
            "416/469 [=========================>....] - ETA: 22s - loss: 0.0726 - sparse_categorical_accuracy: 0.9782\n",
            "417/469 [=========================>....] - ETA: 21s - loss: 0.0725 - sparse_categorical_accuracy: 0.9782\n",
            "418/469 [=========================>....] - ETA: 21s - loss: 0.0724 - sparse_categorical_accuracy: 0.9782\n",
            "419/469 [=========================>....] - ETA: 21s - loss: 0.0724 - sparse_categorical_accuracy: 0.9782\n",
            "420/469 [=========================>....] - ETA: 20s - loss: 0.0725 - sparse_categorical_accuracy: 0.9781\n",
            "421/469 [=========================>....] - ETA: 20s - loss: 0.0726 - sparse_categorical_accuracy: 0.9781\n",
            "422/469 [=========================>....] - ETA: 19s - loss: 0.0725 - sparse_categorical_accuracy: 0.9782\n",
            "423/469 [==========================>...] - ETA: 19s - loss: 0.0724 - sparse_categorical_accuracy: 0.9782\n",
            "424/469 [==========================>...] - ETA: 18s - loss: 0.0724 - sparse_categorical_accuracy: 0.9782\n",
            "425/469 [==========================>...] - ETA: 18s - loss: 0.0725 - sparse_categorical_accuracy: 0.9782\n",
            "426/469 [==========================>...] - ETA: 18s - loss: 0.0725 - sparse_categorical_accuracy: 0.9781\n",
            "427/469 [==========================>...] - ETA: 17s - loss: 0.0726 - sparse_categorical_accuracy: 0.9781\n",
            "428/469 [==========================>...] - ETA: 17s - loss: 0.0726 - sparse_categorical_accuracy: 0.9781\n",
            "429/469 [==========================>...] - ETA: 16s - loss: 0.0728 - sparse_categorical_accuracy: 0.9780\n",
            "430/469 [==========================>...] - ETA: 16s - loss: 0.0728 - sparse_categorical_accuracy: 0.9780\n",
            "431/469 [==========================>...] - ETA: 16s - loss: 0.0727 - sparse_categorical_accuracy: 0.9780\n",
            "432/469 [==========================>...] - ETA: 15s - loss: 0.0727 - sparse_categorical_accuracy: 0.9780\n",
            "433/469 [==========================>...] - ETA: 15s - loss: 0.0728 - sparse_categorical_accuracy: 0.9780\n",
            "434/469 [==========================>...] - ETA: 14s - loss: 0.0728 - sparse_categorical_accuracy: 0.9780\n",
            "435/469 [==========================>...] - ETA: 14s - loss: 0.0727 - sparse_categorical_accuracy: 0.9780\n",
            "436/469 [==========================>...] - ETA: 13s - loss: 0.0727 - sparse_categorical_accuracy: 0.9780\n",
            "437/469 [==========================>...] - ETA: 13s - loss: 0.0726 - sparse_categorical_accuracy: 0.9780\n",
            "438/469 [===========================>..] - ETA: 13s - loss: 0.0727 - sparse_categorical_accuracy: 0.9780\n",
            "439/469 [===========================>..] - ETA: 12s - loss: 0.0728 - sparse_categorical_accuracy: 0.9780\n",
            "440/469 [===========================>..] - ETA: 12s - loss: 0.0728 - sparse_categorical_accuracy: 0.9780\n",
            "441/469 [===========================>..] - ETA: 11s - loss: 0.0727 - sparse_categorical_accuracy: 0.9780\n",
            "442/469 [===========================>..] - ETA: 11s - loss: 0.0726 - sparse_categorical_accuracy: 0.9781\n",
            "443/469 [===========================>..] - ETA: 10s - loss: 0.0726 - sparse_categorical_accuracy: 0.9781\n",
            "444/469 [===========================>..] - ETA: 10s - loss: 0.0726 - sparse_categorical_accuracy: 0.9781\n",
            "445/469 [===========================>..] - ETA: 10s - loss: 0.0725 - sparse_categorical_accuracy: 0.9781\n",
            "446/469 [===========================>..] - ETA: 9s - loss: 0.0724 - sparse_categorical_accuracy: 0.9781 \n",
            "447/469 [===========================>..] - ETA: 9s - loss: 0.0723 - sparse_categorical_accuracy: 0.9781\n",
            "448/469 [===========================>..] - ETA: 8s - loss: 0.0723 - sparse_categorical_accuracy: 0.9781\n",
            "449/469 [===========================>..] - ETA: 8s - loss: 0.0723 - sparse_categorical_accuracy: 0.9781\n",
            "450/469 [===========================>..] - ETA: 7s - loss: 0.0723 - sparse_categorical_accuracy: 0.9781\n",
            "451/469 [===========================>..] - ETA: 7s - loss: 0.0723 - sparse_categorical_accuracy: 0.9781\n",
            "452/469 [===========================>..] - ETA: 7s - loss: 0.0722 - sparse_categorical_accuracy: 0.9781\n",
            "453/469 [===========================>..] - ETA: 6s - loss: 0.0721 - sparse_categorical_accuracy: 0.9781\n",
            "454/469 [============================>.] - ETA: 6s - loss: 0.0721 - sparse_categorical_accuracy: 0.9781\n",
            "455/469 [============================>.] - ETA: 5s - loss: 0.0722 - sparse_categorical_accuracy: 0.9781\n",
            "456/469 [============================>.] - ETA: 5s - loss: 0.0722 - sparse_categorical_accuracy: 0.9781\n",
            "457/469 [============================>.] - ETA: 5s - loss: 0.0722 - sparse_categorical_accuracy: 0.9781\n",
            "458/469 [============================>.] - ETA: 4s - loss: 0.0722 - sparse_categorical_accuracy: 0.9781\n",
            "459/469 [============================>.] - ETA: 4s - loss: 0.0722 - sparse_categorical_accuracy: 0.9781\n",
            "460/469 [============================>.] - ETA: 3s - loss: 0.0721 - sparse_categorical_accuracy: 0.9781\n",
            "461/469 [============================>.] - ETA: 3s - loss: 0.0720 - sparse_categorical_accuracy: 0.9781\n",
            "462/469 [============================>.] - ETA: 2s - loss: 0.0720 - sparse_categorical_accuracy: 0.9781\n",
            "463/469 [============================>.] - ETA: 2s - loss: 0.0719 - sparse_categorical_accuracy: 0.9781\n",
            "464/469 [============================>.] - ETA: 2s - loss: 0.0720 - sparse_categorical_accuracy: 0.9781\n",
            "465/469 [============================>.] - ETA: 1s - loss: 0.0720 - sparse_categorical_accuracy: 0.9781\n",
            "466/469 [============================>.] - ETA: 1s - loss: 0.0721 - sparse_categorical_accuracy: 0.9780\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.0720 - sparse_categorical_accuracy: 0.9781\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0720 - sparse_categorical_accuracy: 0.9780\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0719 - sparse_categorical_accuracy: 0.9781\n",
            " 40%|████      | 2/5 [56:35<53:49, 1076.55s/trial, best loss: -0.9830999970436096]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/04/16 01:28:36 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 198s 422ms/step - loss: 0.0719 - sparse_categorical_accuracy: 0.9781\n",
            "\n",
            "1/1 [==============================] - ETA: 0s\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "\n",
            " 40%|████      | 2/5 [56:35<53:49, 1076.55s/trial, best loss: -0.9830999970436096]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\n",
            "  1/469 [..............................] - ETA: 7:16 - loss: 4.1941 - sparse_categorical_accuracy: 0.0000e+00\n",
            "  2/469 [..............................] - ETA: 3:07 - loss: 4.1812 - sparse_categorical_accuracy: 0.0000e+00\n",
            "  3/469 [..............................] - ETA: 3:07 - loss: 4.1657 - sparse_categorical_accuracy: 0.0052    \n",
            "  4/469 [..............................] - ETA: 3:09 - loss: 4.1458 - sparse_categorical_accuracy: 0.0195\n",
            "  5/469 [..............................] - ETA: 3:08 - loss: 4.1218 - sparse_categorical_accuracy: 0.0437\n",
            "  6/469 [..............................] - ETA: 3:22 - loss: 4.0968 - sparse_categorical_accuracy: 0.0534\n",
            "  7/469 [..............................] - ETA: 3:36 - loss: 4.0684 - sparse_categorical_accuracy: 0.0614\n",
            "  8/469 [..............................] - ETA: 3:48 - loss: 4.0360 - sparse_categorical_accuracy: 0.0664\n",
            "  9/469 [..............................] - ETA: 3:57 - loss: 3.9991 - sparse_categorical_accuracy: 0.0677\n",
            " 10/469 [..............................] - ETA: 4:02 - loss: 3.9549 - sparse_categorical_accuracy: 0.0758\n",
            " 11/469 [..............................] - ETA: 4:06 - loss: 3.9013 - sparse_categorical_accuracy: 0.0817\n",
            " 12/469 [..............................] - ETA: 4:00 - loss: 3.8353 - sparse_categorical_accuracy: 0.0872\n",
            " 13/469 [..............................] - ETA: 3:56 - loss: 3.7561 - sparse_categorical_accuracy: 0.0944\n",
            " 14/469 [..............................] - ETA: 3:52 - loss: 3.6670 - sparse_categorical_accuracy: 0.1071\n",
            " 15/469 [..............................] - ETA: 3:48 - loss: 3.5823 - sparse_categorical_accuracy: 0.1130\n",
            " 16/469 [>.............................] - ETA: 3:45 - loss: 3.4952 - sparse_categorical_accuracy: 0.1245\n",
            " 17/469 [>.............................] - ETA: 3:42 - loss: 3.4102 - sparse_categorical_accuracy: 0.1360\n",
            " 18/469 [>.............................] - ETA: 3:39 - loss: 3.3326 - sparse_categorical_accuracy: 0.1489\n",
            " 19/469 [>.............................] - ETA: 3:36 - loss: 3.2587 - sparse_categorical_accuracy: 0.1637\n",
            " 20/469 [>.............................] - ETA: 3:34 - loss: 3.1849 - sparse_categorical_accuracy: 0.1801\n",
            " 21/469 [>.............................] - ETA: 3:32 - loss: 3.1152 - sparse_categorical_accuracy: 0.1931\n",
            " 22/469 [>.............................] - ETA: 3:30 - loss: 3.0477 - sparse_categorical_accuracy: 0.2060\n",
            " 23/469 [>.............................] - ETA: 3:28 - loss: 2.9798 - sparse_categorical_accuracy: 0.2204\n",
            " 24/469 [>.............................] - ETA: 3:26 - loss: 2.9163 - sparse_categorical_accuracy: 0.2370\n",
            " 25/469 [>.............................] - ETA: 3:25 - loss: 2.8487 - sparse_categorical_accuracy: 0.2525\n",
            " 26/469 [>.............................] - ETA: 3:23 - loss: 2.7856 - sparse_categorical_accuracy: 0.2671\n",
            " 27/469 [>.............................] - ETA: 3:22 - loss: 2.7286 - sparse_categorical_accuracy: 0.2778\n",
            " 28/469 [>.............................] - ETA: 3:21 - loss: 2.6701 - sparse_categorical_accuracy: 0.2907\n",
            " 29/469 [>.............................] - ETA: 3:20 - loss: 2.6175 - sparse_categorical_accuracy: 0.3041\n",
            " 30/469 [>.............................] - ETA: 3:18 - loss: 2.5704 - sparse_categorical_accuracy: 0.3146\n",
            " 31/469 [>.............................] - ETA: 3:17 - loss: 2.5284 - sparse_categorical_accuracy: 0.3236\n",
            " 32/469 [=>............................] - ETA: 3:16 - loss: 2.4827 - sparse_categorical_accuracy: 0.3352\n",
            " 33/469 [=>............................] - ETA: 3:15 - loss: 2.4412 - sparse_categorical_accuracy: 0.3440\n",
            " 34/469 [=>............................] - ETA: 3:14 - loss: 2.4001 - sparse_categorical_accuracy: 0.3513\n",
            " 35/469 [=>............................] - ETA: 3:13 - loss: 2.3592 - sparse_categorical_accuracy: 0.3603\n",
            " 36/469 [=>............................] - ETA: 3:13 - loss: 2.3267 - sparse_categorical_accuracy: 0.3665\n",
            " 37/469 [=>............................] - ETA: 3:14 - loss: 2.3004 - sparse_categorical_accuracy: 0.3742\n",
            " 38/469 [=>............................] - ETA: 3:16 - loss: 2.2942 - sparse_categorical_accuracy: 0.3803\n",
            " 39/469 [=>............................] - ETA: 3:18 - loss: 2.2726 - sparse_categorical_accuracy: 0.3870\n",
            " 40/469 [=>............................] - ETA: 3:19 - loss: 2.2473 - sparse_categorical_accuracy: 0.3947\n",
            " 41/469 [=>............................] - ETA: 3:20 - loss: 2.2114 - sparse_categorical_accuracy: 0.4022\n",
            " 42/469 [=>............................] - ETA: 3:20 - loss: 2.1865 - sparse_categorical_accuracy: 0.4068\n",
            " 43/469 [=>............................] - ETA: 3:19 - loss: 2.1640 - sparse_categorical_accuracy: 0.4152\n",
            " 44/469 [=>............................] - ETA: 3:18 - loss: 2.1322 - sparse_categorical_accuracy: 0.4231\n",
            " 45/469 [=>............................] - ETA: 3:17 - loss: 2.0980 - sparse_categorical_accuracy: 0.4321\n",
            " 46/469 [=>............................] - ETA: 3:16 - loss: 2.0628 - sparse_categorical_accuracy: 0.4416\n",
            " 47/469 [==>...........................] - ETA: 3:15 - loss: 2.0315 - sparse_categorical_accuracy: 0.4498\n",
            " 48/469 [==>...........................] - ETA: 3:14 - loss: 2.0072 - sparse_categorical_accuracy: 0.4549\n",
            " 49/469 [==>...........................] - ETA: 3:13 - loss: 1.9777 - sparse_categorical_accuracy: 0.4632\n",
            " 50/469 [==>...........................] - ETA: 3:12 - loss: 1.9489 - sparse_categorical_accuracy: 0.4717\n",
            " 51/469 [==>...........................] - ETA: 3:11 - loss: 1.9228 - sparse_categorical_accuracy: 0.4787\n",
            " 52/469 [==>...........................] - ETA: 3:10 - loss: 1.8920 - sparse_categorical_accuracy: 0.4871\n",
            " 53/469 [==>...........................] - ETA: 3:09 - loss: 1.8670 - sparse_categorical_accuracy: 0.4934\n",
            " 54/469 [==>...........................] - ETA: 3:08 - loss: 1.8450 - sparse_categorical_accuracy: 0.4984\n",
            " 55/469 [==>...........................] - ETA: 3:07 - loss: 1.8201 - sparse_categorical_accuracy: 0.5043\n",
            " 56/469 [==>...........................] - ETA: 3:06 - loss: 1.7959 - sparse_categorical_accuracy: 0.5107\n",
            " 57/469 [==>...........................] - ETA: 3:06 - loss: 1.7733 - sparse_categorical_accuracy: 0.5167\n",
            " 58/469 [==>...........................] - ETA: 3:05 - loss: 1.7510 - sparse_categorical_accuracy: 0.5229\n",
            " 59/469 [==>...........................] - ETA: 3:04 - loss: 1.7289 - sparse_categorical_accuracy: 0.5286\n",
            " 60/469 [==>...........................] - ETA: 3:03 - loss: 1.7079 - sparse_categorical_accuracy: 0.5344\n",
            " 61/469 [==>...........................] - ETA: 3:02 - loss: 1.6911 - sparse_categorical_accuracy: 0.5382\n",
            " 62/469 [==>...........................] - ETA: 3:01 - loss: 1.6719 - sparse_categorical_accuracy: 0.5435\n",
            " 63/469 [===>..........................] - ETA: 3:01 - loss: 1.6549 - sparse_categorical_accuracy: 0.5475\n",
            " 64/469 [===>..........................] - ETA: 3:00 - loss: 1.6358 - sparse_categorical_accuracy: 0.5527\n",
            " 65/469 [===>..........................] - ETA: 2:59 - loss: 1.6180 - sparse_categorical_accuracy: 0.5576\n",
            " 66/469 [===>..........................] - ETA: 2:58 - loss: 1.6018 - sparse_categorical_accuracy: 0.5620\n",
            " 67/469 [===>..........................] - ETA: 2:58 - loss: 1.5868 - sparse_categorical_accuracy: 0.5662\n",
            " 68/469 [===>..........................] - ETA: 2:59 - loss: 1.5718 - sparse_categorical_accuracy: 0.5704\n",
            " 69/469 [===>..........................] - ETA: 2:59 - loss: 1.5560 - sparse_categorical_accuracy: 0.5747\n",
            " 70/469 [===>..........................] - ETA: 3:00 - loss: 1.5402 - sparse_categorical_accuracy: 0.5787\n",
            " 71/469 [===>..........................] - ETA: 3:01 - loss: 1.5247 - sparse_categorical_accuracy: 0.5826\n",
            " 72/469 [===>..........................] - ETA: 3:01 - loss: 1.5104 - sparse_categorical_accuracy: 0.5858\n",
            " 73/469 [===>..........................] - ETA: 3:01 - loss: 1.4950 - sparse_categorical_accuracy: 0.5902\n",
            " 74/469 [===>..........................] - ETA: 3:00 - loss: 1.4813 - sparse_categorical_accuracy: 0.5936\n",
            " 75/469 [===>..........................] - ETA: 2:59 - loss: 1.4666 - sparse_categorical_accuracy: 0.5976\n",
            " 76/469 [===>..........................] - ETA: 2:59 - loss: 1.4534 - sparse_categorical_accuracy: 0.6013\n",
            " 77/469 [===>..........................] - ETA: 2:58 - loss: 1.4413 - sparse_categorical_accuracy: 0.6044\n",
            " 78/469 [===>..........................] - ETA: 2:57 - loss: 1.4270 - sparse_categorical_accuracy: 0.6079\n",
            " 79/469 [====>.........................] - ETA: 2:56 - loss: 1.4138 - sparse_categorical_accuracy: 0.6113\n",
            " 80/469 [====>.........................] - ETA: 2:56 - loss: 1.4019 - sparse_categorical_accuracy: 0.6145\n",
            " 81/469 [====>.........................] - ETA: 2:55 - loss: 1.3892 - sparse_categorical_accuracy: 0.6174\n",
            " 82/469 [====>.........................] - ETA: 2:54 - loss: 1.3772 - sparse_categorical_accuracy: 0.6206\n",
            " 83/469 [====>.........................] - ETA: 2:54 - loss: 1.3667 - sparse_categorical_accuracy: 0.6229\n",
            " 84/469 [====>.........................] - ETA: 2:53 - loss: 1.3545 - sparse_categorical_accuracy: 0.6260\n",
            " 85/469 [====>.........................] - ETA: 2:52 - loss: 1.3434 - sparse_categorical_accuracy: 0.6292\n",
            " 86/469 [====>.........................] - ETA: 2:52 - loss: 1.3307 - sparse_categorical_accuracy: 0.6328\n",
            " 87/469 [====>.........................] - ETA: 2:51 - loss: 1.3202 - sparse_categorical_accuracy: 0.6357\n",
            " 88/469 [====>.........................] - ETA: 2:50 - loss: 1.3110 - sparse_categorical_accuracy: 0.6381\n",
            " 89/469 [====>.........................] - ETA: 2:50 - loss: 1.3019 - sparse_categorical_accuracy: 0.6405\n",
            " 90/469 [====>.........................] - ETA: 2:49 - loss: 1.2911 - sparse_categorical_accuracy: 0.6433\n",
            " 91/469 [====>.........................] - ETA: 2:48 - loss: 1.2817 - sparse_categorical_accuracy: 0.6462\n",
            " 92/469 [====>.........................] - ETA: 2:48 - loss: 1.2713 - sparse_categorical_accuracy: 0.6489\n",
            " 93/469 [====>.........................] - ETA: 2:47 - loss: 1.2626 - sparse_categorical_accuracy: 0.6508\n",
            " 94/469 [=====>........................] - ETA: 2:46 - loss: 1.2532 - sparse_categorical_accuracy: 0.6531\n",
            " 95/469 [=====>........................] - ETA: 2:46 - loss: 1.2442 - sparse_categorical_accuracy: 0.6550\n",
            " 96/469 [=====>........................] - ETA: 2:45 - loss: 1.2349 - sparse_categorical_accuracy: 0.6572\n",
            " 97/469 [=====>........................] - ETA: 2:44 - loss: 1.2265 - sparse_categorical_accuracy: 0.6596\n",
            " 98/469 [=====>........................] - ETA: 2:44 - loss: 1.2194 - sparse_categorical_accuracy: 0.6614\n",
            " 99/469 [=====>........................] - ETA: 2:44 - loss: 1.2106 - sparse_categorical_accuracy: 0.6636\n",
            "100/469 [=====>........................] - ETA: 2:45 - loss: 1.2017 - sparse_categorical_accuracy: 0.6662\n",
            "101/469 [=====>........................] - ETA: 2:45 - loss: 1.1960 - sparse_categorical_accuracy: 0.6679\n",
            "102/469 [=====>........................] - ETA: 2:45 - loss: 1.1873 - sparse_categorical_accuracy: 0.6702\n",
            "103/469 [=====>........................] - ETA: 2:45 - loss: 1.1788 - sparse_categorical_accuracy: 0.6726\n",
            "104/469 [=====>........................] - ETA: 2:45 - loss: 1.1698 - sparse_categorical_accuracy: 0.6750\n",
            "105/469 [=====>........................] - ETA: 2:44 - loss: 1.1622 - sparse_categorical_accuracy: 0.6768\n",
            "106/469 [=====>........................] - ETA: 2:43 - loss: 1.1540 - sparse_categorical_accuracy: 0.6790\n",
            "107/469 [=====>........................] - ETA: 2:43 - loss: 1.1460 - sparse_categorical_accuracy: 0.6810\n",
            "108/469 [=====>........................] - ETA: 2:42 - loss: 1.1392 - sparse_categorical_accuracy: 0.6827\n",
            "109/469 [=====>........................] - ETA: 2:41 - loss: 1.1332 - sparse_categorical_accuracy: 0.6840\n",
            "110/469 [======>.......................] - ETA: 2:41 - loss: 1.1257 - sparse_categorical_accuracy: 0.6862\n",
            "111/469 [======>.......................] - ETA: 2:40 - loss: 1.1184 - sparse_categorical_accuracy: 0.6879\n",
            "112/469 [======>.......................] - ETA: 2:40 - loss: 1.1114 - sparse_categorical_accuracy: 0.6899\n",
            "113/469 [======>.......................] - ETA: 2:39 - loss: 1.1050 - sparse_categorical_accuracy: 0.6917\n",
            "114/469 [======>.......................] - ETA: 2:38 - loss: 1.0988 - sparse_categorical_accuracy: 0.6935\n",
            "115/469 [======>.......................] - ETA: 2:38 - loss: 1.0920 - sparse_categorical_accuracy: 0.6951\n",
            "116/469 [======>.......................] - ETA: 2:37 - loss: 1.0857 - sparse_categorical_accuracy: 0.6968\n",
            "117/469 [======>.......................] - ETA: 2:37 - loss: 1.0787 - sparse_categorical_accuracy: 0.6987\n",
            "118/469 [======>.......................] - ETA: 2:36 - loss: 1.0726 - sparse_categorical_accuracy: 0.7002\n",
            "119/469 [======>.......................] - ETA: 2:35 - loss: 1.0657 - sparse_categorical_accuracy: 0.7023\n",
            "120/469 [======>.......................] - ETA: 2:35 - loss: 1.0601 - sparse_categorical_accuracy: 0.7038\n",
            "121/469 [======>.......................] - ETA: 2:34 - loss: 1.0551 - sparse_categorical_accuracy: 0.7053\n",
            "122/469 [======>.......................] - ETA: 2:34 - loss: 1.0484 - sparse_categorical_accuracy: 0.7071\n",
            "123/469 [======>.......................] - ETA: 2:33 - loss: 1.0437 - sparse_categorical_accuracy: 0.7083\n",
            "124/469 [======>.......................] - ETA: 2:33 - loss: 1.0379 - sparse_categorical_accuracy: 0.7099\n",
            "125/469 [======>.......................] - ETA: 2:32 - loss: 1.0311 - sparse_categorical_accuracy: 0.7118\n",
            "126/469 [=======>......................] - ETA: 2:31 - loss: 1.0259 - sparse_categorical_accuracy: 0.7132\n",
            "127/469 [=======>......................] - ETA: 2:31 - loss: 1.0201 - sparse_categorical_accuracy: 0.7146\n",
            "128/469 [=======>......................] - ETA: 2:31 - loss: 1.0140 - sparse_categorical_accuracy: 0.7163\n",
            "129/469 [=======>......................] - ETA: 2:31 - loss: 1.0081 - sparse_categorical_accuracy: 0.7177\n",
            "130/469 [=======>......................] - ETA: 2:31 - loss: 1.0025 - sparse_categorical_accuracy: 0.7193\n",
            "131/469 [=======>......................] - ETA: 2:31 - loss: 0.9968 - sparse_categorical_accuracy: 0.7207\n",
            "132/469 [=======>......................] - ETA: 2:31 - loss: 0.9912 - sparse_categorical_accuracy: 0.7222\n",
            "133/469 [=======>......................] - ETA: 2:31 - loss: 0.9857 - sparse_categorical_accuracy: 0.7239\n",
            "134/469 [=======>......................] - ETA: 2:30 - loss: 0.9805 - sparse_categorical_accuracy: 0.7255\n",
            "135/469 [=======>......................] - ETA: 2:30 - loss: 0.9753 - sparse_categorical_accuracy: 0.7269\n",
            "136/469 [=======>......................] - ETA: 2:29 - loss: 0.9705 - sparse_categorical_accuracy: 0.7282\n",
            "137/469 [=======>......................] - ETA: 2:29 - loss: 0.9659 - sparse_categorical_accuracy: 0.7296\n",
            "138/469 [=======>......................] - ETA: 2:28 - loss: 0.9614 - sparse_categorical_accuracy: 0.7309\n",
            "139/469 [=======>......................] - ETA: 2:28 - loss: 0.9567 - sparse_categorical_accuracy: 0.7321\n",
            "140/469 [=======>......................] - ETA: 2:27 - loss: 0.9523 - sparse_categorical_accuracy: 0.7335\n",
            "141/469 [========>.....................] - ETA: 2:26 - loss: 0.9471 - sparse_categorical_accuracy: 0.7348\n",
            "142/469 [========>.....................] - ETA: 2:26 - loss: 0.9421 - sparse_categorical_accuracy: 0.7362\n",
            "143/469 [========>.....................] - ETA: 2:25 - loss: 0.9378 - sparse_categorical_accuracy: 0.7378\n",
            "144/469 [========>.....................] - ETA: 2:25 - loss: 0.9336 - sparse_categorical_accuracy: 0.7389\n",
            "145/469 [========>.....................] - ETA: 2:24 - loss: 0.9285 - sparse_categorical_accuracy: 0.7402\n",
            "146/469 [========>.....................] - ETA: 2:24 - loss: 0.9248 - sparse_categorical_accuracy: 0.7412\n",
            "147/469 [========>.....................] - ETA: 2:23 - loss: 0.9204 - sparse_categorical_accuracy: 0.7425\n",
            "148/469 [========>.....................] - ETA: 2:23 - loss: 0.9160 - sparse_categorical_accuracy: 0.7437\n",
            "149/469 [========>.....................] - ETA: 2:22 - loss: 0.9114 - sparse_categorical_accuracy: 0.7450\n",
            "150/469 [========>.....................] - ETA: 2:21 - loss: 0.9069 - sparse_categorical_accuracy: 0.7461\n",
            "151/469 [========>.....................] - ETA: 2:21 - loss: 0.9023 - sparse_categorical_accuracy: 0.7475\n",
            "152/469 [========>.....................] - ETA: 2:20 - loss: 0.8984 - sparse_categorical_accuracy: 0.7485\n",
            "153/469 [========>.....................] - ETA: 2:20 - loss: 0.8944 - sparse_categorical_accuracy: 0.7495\n",
            "154/469 [========>.....................] - ETA: 2:19 - loss: 0.8907 - sparse_categorical_accuracy: 0.7506\n",
            "155/469 [========>.....................] - ETA: 2:19 - loss: 0.8875 - sparse_categorical_accuracy: 0.7514\n",
            "156/469 [========>.....................] - ETA: 2:18 - loss: 0.8835 - sparse_categorical_accuracy: 0.7524\n",
            "157/469 [=========>....................] - ETA: 2:18 - loss: 0.8795 - sparse_categorical_accuracy: 0.7535\n",
            "158/469 [=========>....................] - ETA: 2:17 - loss: 0.8751 - sparse_categorical_accuracy: 0.7547\n",
            "159/469 [=========>....................] - ETA: 2:17 - loss: 0.8713 - sparse_categorical_accuracy: 0.7557\n",
            "160/469 [=========>....................] - ETA: 2:17 - loss: 0.8671 - sparse_categorical_accuracy: 0.7566\n",
            "161/469 [=========>....................] - ETA: 2:17 - loss: 0.8636 - sparse_categorical_accuracy: 0.7574\n",
            "162/469 [=========>....................] - ETA: 2:17 - loss: 0.8595 - sparse_categorical_accuracy: 0.7585\n",
            "163/469 [=========>....................] - ETA: 2:17 - loss: 0.8562 - sparse_categorical_accuracy: 0.7595\n",
            "164/469 [=========>....................] - ETA: 2:16 - loss: 0.8525 - sparse_categorical_accuracy: 0.7605\n",
            "165/469 [=========>....................] - ETA: 2:16 - loss: 0.8499 - sparse_categorical_accuracy: 0.7613\n",
            "166/469 [=========>....................] - ETA: 2:15 - loss: 0.8467 - sparse_categorical_accuracy: 0.7621\n",
            "167/469 [=========>....................] - ETA: 2:15 - loss: 0.8426 - sparse_categorical_accuracy: 0.7631\n",
            "168/469 [=========>....................] - ETA: 2:14 - loss: 0.8391 - sparse_categorical_accuracy: 0.7640\n",
            "169/469 [=========>....................] - ETA: 2:13 - loss: 0.8360 - sparse_categorical_accuracy: 0.7647\n",
            "170/469 [=========>....................] - ETA: 2:13 - loss: 0.8328 - sparse_categorical_accuracy: 0.7657\n",
            "171/469 [=========>....................] - ETA: 2:12 - loss: 0.8301 - sparse_categorical_accuracy: 0.7664\n",
            "172/469 [==========>...................] - ETA: 2:12 - loss: 0.8269 - sparse_categorical_accuracy: 0.7672\n",
            "173/469 [==========>...................] - ETA: 2:11 - loss: 0.8234 - sparse_categorical_accuracy: 0.7679\n",
            "174/469 [==========>...................] - ETA: 2:11 - loss: 0.8200 - sparse_categorical_accuracy: 0.7689\n",
            "175/469 [==========>...................] - ETA: 2:10 - loss: 0.8173 - sparse_categorical_accuracy: 0.7698\n",
            "176/469 [==========>...................] - ETA: 2:10 - loss: 0.8145 - sparse_categorical_accuracy: 0.7704\n",
            "177/469 [==========>...................] - ETA: 2:09 - loss: 0.8115 - sparse_categorical_accuracy: 0.7713\n",
            "178/469 [==========>...................] - ETA: 2:09 - loss: 0.8086 - sparse_categorical_accuracy: 0.7720\n",
            "179/469 [==========>...................] - ETA: 2:08 - loss: 0.8056 - sparse_categorical_accuracy: 0.7729\n",
            "180/469 [==========>...................] - ETA: 2:08 - loss: 0.8025 - sparse_categorical_accuracy: 0.7737\n",
            "181/469 [==========>...................] - ETA: 2:07 - loss: 0.8000 - sparse_categorical_accuracy: 0.7743\n",
            "182/469 [==========>...................] - ETA: 2:07 - loss: 0.7966 - sparse_categorical_accuracy: 0.7753\n",
            "183/469 [==========>...................] - ETA: 2:06 - loss: 0.7934 - sparse_categorical_accuracy: 0.7761\n",
            "184/469 [==========>...................] - ETA: 2:06 - loss: 0.7904 - sparse_categorical_accuracy: 0.7770\n",
            "185/469 [==========>...................] - ETA: 2:05 - loss: 0.7874 - sparse_categorical_accuracy: 0.7778\n",
            "186/469 [==========>...................] - ETA: 2:05 - loss: 0.7855 - sparse_categorical_accuracy: 0.7783\n",
            "187/469 [==========>...................] - ETA: 2:04 - loss: 0.7829 - sparse_categorical_accuracy: 0.7790\n",
            "188/469 [===========>..................] - ETA: 2:03 - loss: 0.7801 - sparse_categorical_accuracy: 0.7798\n",
            "189/469 [===========>..................] - ETA: 2:03 - loss: 0.7770 - sparse_categorical_accuracy: 0.7807\n",
            "190/469 [===========>..................] - ETA: 2:03 - loss: 0.7744 - sparse_categorical_accuracy: 0.7815\n",
            "191/469 [===========>..................] - ETA: 2:03 - loss: 0.7716 - sparse_categorical_accuracy: 0.7820\n",
            "192/469 [===========>..................] - ETA: 2:02 - loss: 0.7694 - sparse_categorical_accuracy: 0.7827\n",
            "193/469 [===========>..................] - ETA: 2:02 - loss: 0.7675 - sparse_categorical_accuracy: 0.7832\n",
            "194/469 [===========>..................] - ETA: 2:02 - loss: 0.7649 - sparse_categorical_accuracy: 0.7840\n",
            "195/469 [===========>..................] - ETA: 2:02 - loss: 0.7627 - sparse_categorical_accuracy: 0.7847\n",
            "196/469 [===========>..................] - ETA: 2:01 - loss: 0.7599 - sparse_categorical_accuracy: 0.7854\n",
            "197/469 [===========>..................] - ETA: 2:01 - loss: 0.7570 - sparse_categorical_accuracy: 0.7863\n",
            "198/469 [===========>..................] - ETA: 2:00 - loss: 0.7543 - sparse_categorical_accuracy: 0.7871\n",
            "199/469 [===========>..................] - ETA: 2:00 - loss: 0.7516 - sparse_categorical_accuracy: 0.7878\n",
            "200/469 [===========>..................] - ETA: 1:59 - loss: 0.7490 - sparse_categorical_accuracy: 0.7886\n",
            "201/469 [===========>..................] - ETA: 1:59 - loss: 0.7460 - sparse_categorical_accuracy: 0.7895\n",
            "202/469 [===========>..................] - ETA: 1:58 - loss: 0.7434 - sparse_categorical_accuracy: 0.7903\n",
            "203/469 [===========>..................] - ETA: 1:58 - loss: 0.7403 - sparse_categorical_accuracy: 0.7911\n",
            "204/469 [============>.................] - ETA: 1:57 - loss: 0.7379 - sparse_categorical_accuracy: 0.7919\n",
            "205/469 [============>.................] - ETA: 1:57 - loss: 0.7353 - sparse_categorical_accuracy: 0.7925\n",
            "206/469 [============>.................] - ETA: 1:56 - loss: 0.7328 - sparse_categorical_accuracy: 0.7933\n",
            "207/469 [============>.................] - ETA: 1:56 - loss: 0.7309 - sparse_categorical_accuracy: 0.7939\n",
            "208/469 [============>.................] - ETA: 1:55 - loss: 0.7283 - sparse_categorical_accuracy: 0.7948\n",
            "209/469 [============>.................] - ETA: 1:55 - loss: 0.7264 - sparse_categorical_accuracy: 0.7953\n",
            "210/469 [============>.................] - ETA: 1:54 - loss: 0.7239 - sparse_categorical_accuracy: 0.7960\n",
            "211/469 [============>.................] - ETA: 1:54 - loss: 0.7217 - sparse_categorical_accuracy: 0.7967\n",
            "212/469 [============>.................] - ETA: 1:53 - loss: 0.7189 - sparse_categorical_accuracy: 0.7975\n",
            "213/469 [============>.................] - ETA: 1:53 - loss: 0.7164 - sparse_categorical_accuracy: 0.7982\n",
            "214/469 [============>.................] - ETA: 1:52 - loss: 0.7144 - sparse_categorical_accuracy: 0.7987\n",
            "215/469 [============>.................] - ETA: 1:52 - loss: 0.7122 - sparse_categorical_accuracy: 0.7995\n",
            "216/469 [============>.................] - ETA: 1:51 - loss: 0.7103 - sparse_categorical_accuracy: 0.7999\n",
            "217/469 [============>.................] - ETA: 1:51 - loss: 0.7084 - sparse_categorical_accuracy: 0.8005\n",
            "218/469 [============>.................] - ETA: 1:50 - loss: 0.7058 - sparse_categorical_accuracy: 0.8012\n",
            "219/469 [=============>................] - ETA: 1:50 - loss: 0.7035 - sparse_categorical_accuracy: 0.8018\n",
            "220/469 [=============>................] - ETA: 1:50 - loss: 0.7012 - sparse_categorical_accuracy: 0.8025\n",
            "221/469 [=============>................] - ETA: 1:49 - loss: 0.6988 - sparse_categorical_accuracy: 0.8031\n",
            "222/469 [=============>................] - ETA: 1:49 - loss: 0.6964 - sparse_categorical_accuracy: 0.8037\n",
            "223/469 [=============>................] - ETA: 1:49 - loss: 0.6949 - sparse_categorical_accuracy: 0.8042\n",
            "224/469 [=============>................] - ETA: 1:49 - loss: 0.6924 - sparse_categorical_accuracy: 0.8049\n",
            "225/469 [=============>................] - ETA: 1:48 - loss: 0.6900 - sparse_categorical_accuracy: 0.8056\n",
            "226/469 [=============>................] - ETA: 1:48 - loss: 0.6878 - sparse_categorical_accuracy: 0.8062\n",
            "227/469 [=============>................] - ETA: 1:47 - loss: 0.6859 - sparse_categorical_accuracy: 0.8068\n",
            "228/469 [=============>................] - ETA: 1:47 - loss: 0.6837 - sparse_categorical_accuracy: 0.8075\n",
            "229/469 [=============>................] - ETA: 1:46 - loss: 0.6817 - sparse_categorical_accuracy: 0.8079\n",
            "230/469 [=============>................] - ETA: 1:46 - loss: 0.6795 - sparse_categorical_accuracy: 0.8086\n",
            "231/469 [=============>................] - ETA: 1:45 - loss: 0.6772 - sparse_categorical_accuracy: 0.8093\n",
            "232/469 [=============>................] - ETA: 1:45 - loss: 0.6750 - sparse_categorical_accuracy: 0.8100\n",
            "233/469 [=============>................] - ETA: 1:44 - loss: 0.6729 - sparse_categorical_accuracy: 0.8105\n",
            "234/469 [=============>................] - ETA: 1:44 - loss: 0.6711 - sparse_categorical_accuracy: 0.8110\n",
            "235/469 [==============>...............] - ETA: 1:43 - loss: 0.6691 - sparse_categorical_accuracy: 0.8116\n",
            "236/469 [==============>...............] - ETA: 1:43 - loss: 0.6670 - sparse_categorical_accuracy: 0.8122\n",
            "237/469 [==============>...............] - ETA: 1:43 - loss: 0.6654 - sparse_categorical_accuracy: 0.8125\n",
            "238/469 [==============>...............] - ETA: 1:42 - loss: 0.6631 - sparse_categorical_accuracy: 0.8131\n",
            "239/469 [==============>...............] - ETA: 1:42 - loss: 0.6609 - sparse_categorical_accuracy: 0.8137\n",
            "240/469 [==============>...............] - ETA: 1:41 - loss: 0.6592 - sparse_categorical_accuracy: 0.8141\n",
            "241/469 [==============>...............] - ETA: 1:41 - loss: 0.6570 - sparse_categorical_accuracy: 0.8147\n",
            "242/469 [==============>...............] - ETA: 1:40 - loss: 0.6548 - sparse_categorical_accuracy: 0.8152\n",
            "243/469 [==============>...............] - ETA: 1:40 - loss: 0.6531 - sparse_categorical_accuracy: 0.8157\n",
            "244/469 [==============>...............] - ETA: 1:39 - loss: 0.6511 - sparse_categorical_accuracy: 0.8161\n",
            "245/469 [==============>...............] - ETA: 1:39 - loss: 0.6494 - sparse_categorical_accuracy: 0.8164\n",
            "246/469 [==============>...............] - ETA: 1:38 - loss: 0.6474 - sparse_categorical_accuracy: 0.8169\n",
            "247/469 [==============>...............] - ETA: 1:38 - loss: 0.6460 - sparse_categorical_accuracy: 0.8173\n",
            "248/469 [==============>...............] - ETA: 1:37 - loss: 0.6438 - sparse_categorical_accuracy: 0.8179\n",
            "249/469 [==============>...............] - ETA: 1:37 - loss: 0.6417 - sparse_categorical_accuracy: 0.8185\n",
            "250/469 [==============>...............] - ETA: 1:36 - loss: 0.6398 - sparse_categorical_accuracy: 0.8191\n",
            "251/469 [===============>..............] - ETA: 1:36 - loss: 0.6379 - sparse_categorical_accuracy: 0.8197\n",
            "252/469 [===============>..............] - ETA: 1:36 - loss: 0.6363 - sparse_categorical_accuracy: 0.8200\n",
            "253/469 [===============>..............] - ETA: 1:35 - loss: 0.6347 - sparse_categorical_accuracy: 0.8204\n",
            "254/469 [===============>..............] - ETA: 1:35 - loss: 0.6327 - sparse_categorical_accuracy: 0.8210\n",
            "255/469 [===============>..............] - ETA: 1:35 - loss: 0.6310 - sparse_categorical_accuracy: 0.8214\n",
            "256/469 [===============>..............] - ETA: 1:34 - loss: 0.6295 - sparse_categorical_accuracy: 0.8218\n",
            "257/469 [===============>..............] - ETA: 1:34 - loss: 0.6276 - sparse_categorical_accuracy: 0.8223\n",
            "258/469 [===============>..............] - ETA: 1:33 - loss: 0.6258 - sparse_categorical_accuracy: 0.8229\n",
            "259/469 [===============>..............] - ETA: 1:33 - loss: 0.6240 - sparse_categorical_accuracy: 0.8234\n",
            "260/469 [===============>..............] - ETA: 1:33 - loss: 0.6225 - sparse_categorical_accuracy: 0.8238\n",
            "261/469 [===============>..............] - ETA: 1:32 - loss: 0.6210 - sparse_categorical_accuracy: 0.8241\n",
            "262/469 [===============>..............] - ETA: 1:32 - loss: 0.6193 - sparse_categorical_accuracy: 0.8247\n",
            "263/469 [===============>..............] - ETA: 1:31 - loss: 0.6175 - sparse_categorical_accuracy: 0.8252\n",
            "264/469 [===============>..............] - ETA: 1:31 - loss: 0.6161 - sparse_categorical_accuracy: 0.8256\n",
            "265/469 [===============>..............] - ETA: 1:30 - loss: 0.6142 - sparse_categorical_accuracy: 0.8262\n",
            "266/469 [================>.............] - ETA: 1:30 - loss: 0.6122 - sparse_categorical_accuracy: 0.8269\n",
            "267/469 [================>.............] - ETA: 1:29 - loss: 0.6105 - sparse_categorical_accuracy: 0.8272\n",
            "268/469 [================>.............] - ETA: 1:29 - loss: 0.6090 - sparse_categorical_accuracy: 0.8276\n",
            "269/469 [================>.............] - ETA: 1:28 - loss: 0.6071 - sparse_categorical_accuracy: 0.8282\n",
            "270/469 [================>.............] - ETA: 1:28 - loss: 0.6054 - sparse_categorical_accuracy: 0.8286\n",
            "271/469 [================>.............] - ETA: 1:27 - loss: 0.6036 - sparse_categorical_accuracy: 0.8291\n",
            "272/469 [================>.............] - ETA: 1:27 - loss: 0.6019 - sparse_categorical_accuracy: 0.8296\n",
            "273/469 [================>.............] - ETA: 1:26 - loss: 0.6003 - sparse_categorical_accuracy: 0.8300\n",
            "274/469 [================>.............] - ETA: 1:26 - loss: 0.5987 - sparse_categorical_accuracy: 0.8304\n",
            "275/469 [================>.............] - ETA: 1:25 - loss: 0.5971 - sparse_categorical_accuracy: 0.8309\n",
            "276/469 [================>.............] - ETA: 1:25 - loss: 0.5958 - sparse_categorical_accuracy: 0.8314\n",
            "277/469 [================>.............] - ETA: 1:24 - loss: 0.5942 - sparse_categorical_accuracy: 0.8319\n",
            "278/469 [================>.............] - ETA: 1:24 - loss: 0.5927 - sparse_categorical_accuracy: 0.8323\n",
            "279/469 [================>.............] - ETA: 1:24 - loss: 0.5910 - sparse_categorical_accuracy: 0.8328\n",
            "280/469 [================>.............] - ETA: 1:23 - loss: 0.5896 - sparse_categorical_accuracy: 0.8333\n",
            "281/469 [================>.............] - ETA: 1:23 - loss: 0.5886 - sparse_categorical_accuracy: 0.8335\n",
            "282/469 [=================>............] - ETA: 1:22 - loss: 0.5874 - sparse_categorical_accuracy: 0.8339\n",
            "283/469 [=================>............] - ETA: 1:22 - loss: 0.5859 - sparse_categorical_accuracy: 0.8344\n",
            "284/469 [=================>............] - ETA: 1:22 - loss: 0.5845 - sparse_categorical_accuracy: 0.8348\n",
            "285/469 [=================>............] - ETA: 1:21 - loss: 0.5828 - sparse_categorical_accuracy: 0.8352\n",
            "286/469 [=================>............] - ETA: 1:21 - loss: 0.5815 - sparse_categorical_accuracy: 0.8355\n",
            "287/469 [=================>............] - ETA: 1:21 - loss: 0.5800 - sparse_categorical_accuracy: 0.8360\n",
            "288/469 [=================>............] - ETA: 1:20 - loss: 0.5786 - sparse_categorical_accuracy: 0.8364\n",
            "289/469 [=================>............] - ETA: 1:20 - loss: 0.5770 - sparse_categorical_accuracy: 0.8369\n",
            "290/469 [=================>............] - ETA: 1:19 - loss: 0.5759 - sparse_categorical_accuracy: 0.8372\n",
            "291/469 [=================>............] - ETA: 1:19 - loss: 0.5747 - sparse_categorical_accuracy: 0.8375\n",
            "292/469 [=================>............] - ETA: 1:18 - loss: 0.5733 - sparse_categorical_accuracy: 0.8379\n",
            "293/469 [=================>............] - ETA: 1:18 - loss: 0.5719 - sparse_categorical_accuracy: 0.8382\n",
            "294/469 [=================>............] - ETA: 1:17 - loss: 0.5706 - sparse_categorical_accuracy: 0.8386\n",
            "295/469 [=================>............] - ETA: 1:17 - loss: 0.5691 - sparse_categorical_accuracy: 0.8390\n",
            "296/469 [=================>............] - ETA: 1:16 - loss: 0.5678 - sparse_categorical_accuracy: 0.8394\n",
            "297/469 [=================>............] - ETA: 1:16 - loss: 0.5667 - sparse_categorical_accuracy: 0.8398\n",
            "298/469 [==================>...........] - ETA: 1:15 - loss: 0.5655 - sparse_categorical_accuracy: 0.8401\n",
            "299/469 [==================>...........] - ETA: 1:15 - loss: 0.5642 - sparse_categorical_accuracy: 0.8404\n",
            "300/469 [==================>...........] - ETA: 1:15 - loss: 0.5631 - sparse_categorical_accuracy: 0.8408\n",
            "301/469 [==================>...........] - ETA: 1:14 - loss: 0.5617 - sparse_categorical_accuracy: 0.8411\n",
            "302/469 [==================>...........] - ETA: 1:14 - loss: 0.5605 - sparse_categorical_accuracy: 0.8415\n",
            "303/469 [==================>...........] - ETA: 1:13 - loss: 0.5591 - sparse_categorical_accuracy: 0.8419\n",
            "304/469 [==================>...........] - ETA: 1:13 - loss: 0.5579 - sparse_categorical_accuracy: 0.8422\n",
            "305/469 [==================>...........] - ETA: 1:12 - loss: 0.5566 - sparse_categorical_accuracy: 0.8425\n",
            "306/469 [==================>...........] - ETA: 1:12 - loss: 0.5555 - sparse_categorical_accuracy: 0.8429\n",
            "307/469 [==================>...........] - ETA: 1:11 - loss: 0.5542 - sparse_categorical_accuracy: 0.8432\n",
            "308/469 [==================>...........] - ETA: 1:11 - loss: 0.5528 - sparse_categorical_accuracy: 0.8436\n",
            "309/469 [==================>...........] - ETA: 1:10 - loss: 0.5518 - sparse_categorical_accuracy: 0.8439\n",
            "310/469 [==================>...........] - ETA: 1:10 - loss: 0.5505 - sparse_categorical_accuracy: 0.8443\n",
            "311/469 [==================>...........] - ETA: 1:09 - loss: 0.5495 - sparse_categorical_accuracy: 0.8446\n",
            "312/469 [==================>...........] - ETA: 1:09 - loss: 0.5485 - sparse_categorical_accuracy: 0.8449\n",
            "313/469 [===================>..........] - ETA: 1:09 - loss: 0.5473 - sparse_categorical_accuracy: 0.8452\n",
            "314/469 [===================>..........] - ETA: 1:08 - loss: 0.5463 - sparse_categorical_accuracy: 0.8454\n",
            "315/469 [===================>..........] - ETA: 1:08 - loss: 0.5454 - sparse_categorical_accuracy: 0.8456\n",
            "316/469 [===================>..........] - ETA: 1:08 - loss: 0.5442 - sparse_categorical_accuracy: 0.8460\n",
            "317/469 [===================>..........] - ETA: 1:07 - loss: 0.5434 - sparse_categorical_accuracy: 0.8462\n",
            "318/469 [===================>..........] - ETA: 1:07 - loss: 0.5424 - sparse_categorical_accuracy: 0.8464\n",
            "319/469 [===================>..........] - ETA: 1:06 - loss: 0.5412 - sparse_categorical_accuracy: 0.8467\n",
            "320/469 [===================>..........] - ETA: 1:06 - loss: 0.5401 - sparse_categorical_accuracy: 0.8470\n",
            "321/469 [===================>..........] - ETA: 1:05 - loss: 0.5387 - sparse_categorical_accuracy: 0.8475\n",
            "322/469 [===================>..........] - ETA: 1:05 - loss: 0.5376 - sparse_categorical_accuracy: 0.8478\n",
            "323/469 [===================>..........] - ETA: 1:04 - loss: 0.5365 - sparse_categorical_accuracy: 0.8481\n",
            "324/469 [===================>..........] - ETA: 1:04 - loss: 0.5353 - sparse_categorical_accuracy: 0.8484\n",
            "325/469 [===================>..........] - ETA: 1:04 - loss: 0.5344 - sparse_categorical_accuracy: 0.8486\n",
            "326/469 [===================>..........] - ETA: 1:03 - loss: 0.5331 - sparse_categorical_accuracy: 0.8490\n",
            "327/469 [===================>..........] - ETA: 1:03 - loss: 0.5318 - sparse_categorical_accuracy: 0.8494\n",
            "328/469 [===================>..........] - ETA: 1:02 - loss: 0.5308 - sparse_categorical_accuracy: 0.8496\n",
            "329/469 [====================>.........] - ETA: 1:02 - loss: 0.5297 - sparse_categorical_accuracy: 0.8499\n",
            "330/469 [====================>.........] - ETA: 1:01 - loss: 0.5286 - sparse_categorical_accuracy: 0.8502\n",
            "331/469 [====================>.........] - ETA: 1:01 - loss: 0.5275 - sparse_categorical_accuracy: 0.8505\n",
            "332/469 [====================>.........] - ETA: 1:00 - loss: 0.5263 - sparse_categorical_accuracy: 0.8508\n",
            "333/469 [====================>.........] - ETA: 1:00 - loss: 0.5251 - sparse_categorical_accuracy: 0.8511\n",
            "334/469 [====================>.........] - ETA: 59s - loss: 0.5238 - sparse_categorical_accuracy: 0.8515 \n",
            "335/469 [====================>.........] - ETA: 59s - loss: 0.5229 - sparse_categorical_accuracy: 0.8518\n",
            "336/469 [====================>.........] - ETA: 58s - loss: 0.5218 - sparse_categorical_accuracy: 0.8522\n",
            "337/469 [====================>.........] - ETA: 58s - loss: 0.5208 - sparse_categorical_accuracy: 0.8524\n",
            "338/469 [====================>.........] - ETA: 58s - loss: 0.5198 - sparse_categorical_accuracy: 0.8527\n",
            "339/469 [====================>.........] - ETA: 57s - loss: 0.5186 - sparse_categorical_accuracy: 0.8531\n",
            "340/469 [====================>.........] - ETA: 57s - loss: 0.5175 - sparse_categorical_accuracy: 0.8533\n",
            "341/469 [====================>.........] - ETA: 56s - loss: 0.5166 - sparse_categorical_accuracy: 0.8537\n",
            "342/469 [====================>.........] - ETA: 56s - loss: 0.5153 - sparse_categorical_accuracy: 0.8540\n",
            "343/469 [====================>.........] - ETA: 55s - loss: 0.5143 - sparse_categorical_accuracy: 0.8543\n",
            "344/469 [=====================>........] - ETA: 55s - loss: 0.5131 - sparse_categorical_accuracy: 0.8547\n",
            "345/469 [=====================>........] - ETA: 55s - loss: 0.5121 - sparse_categorical_accuracy: 0.8550\n",
            "346/469 [=====================>........] - ETA: 54s - loss: 0.5110 - sparse_categorical_accuracy: 0.8553\n",
            "347/469 [=====================>........] - ETA: 54s - loss: 0.5099 - sparse_categorical_accuracy: 0.8556\n",
            "348/469 [=====================>........] - ETA: 53s - loss: 0.5089 - sparse_categorical_accuracy: 0.8559\n",
            "349/469 [=====================>........] - ETA: 53s - loss: 0.5077 - sparse_categorical_accuracy: 0.8562\n",
            "350/469 [=====================>........] - ETA: 53s - loss: 0.5067 - sparse_categorical_accuracy: 0.8565\n",
            "351/469 [=====================>........] - ETA: 52s - loss: 0.5057 - sparse_categorical_accuracy: 0.8567\n",
            "352/469 [=====================>........] - ETA: 52s - loss: 0.5052 - sparse_categorical_accuracy: 0.8569\n",
            "353/469 [=====================>........] - ETA: 51s - loss: 0.5045 - sparse_categorical_accuracy: 0.8571\n",
            "354/469 [=====================>........] - ETA: 51s - loss: 0.5036 - sparse_categorical_accuracy: 0.8574\n",
            "355/469 [=====================>........] - ETA: 50s - loss: 0.5028 - sparse_categorical_accuracy: 0.8577\n",
            "356/469 [=====================>........] - ETA: 50s - loss: 0.5019 - sparse_categorical_accuracy: 0.8580\n",
            "357/469 [=====================>........] - ETA: 49s - loss: 0.5008 - sparse_categorical_accuracy: 0.8583\n",
            "358/469 [=====================>........] - ETA: 49s - loss: 0.5001 - sparse_categorical_accuracy: 0.8585\n",
            "359/469 [=====================>........] - ETA: 48s - loss: 0.4991 - sparse_categorical_accuracy: 0.8587\n",
            "360/469 [======================>.......] - ETA: 48s - loss: 0.4987 - sparse_categorical_accuracy: 0.8589\n",
            "361/469 [======================>.......] - ETA: 48s - loss: 0.4975 - sparse_categorical_accuracy: 0.8592\n",
            "362/469 [======================>.......] - ETA: 47s - loss: 0.4966 - sparse_categorical_accuracy: 0.8595\n",
            "363/469 [======================>.......] - ETA: 47s - loss: 0.4956 - sparse_categorical_accuracy: 0.8598\n",
            "364/469 [======================>.......] - ETA: 46s - loss: 0.4948 - sparse_categorical_accuracy: 0.8600\n",
            "365/469 [======================>.......] - ETA: 46s - loss: 0.4937 - sparse_categorical_accuracy: 0.8603\n",
            "366/469 [======================>.......] - ETA: 45s - loss: 0.4929 - sparse_categorical_accuracy: 0.8605\n",
            "367/469 [======================>.......] - ETA: 45s - loss: 0.4919 - sparse_categorical_accuracy: 0.8608\n",
            "368/469 [======================>.......] - ETA: 44s - loss: 0.4909 - sparse_categorical_accuracy: 0.8611\n",
            "369/469 [======================>.......] - ETA: 44s - loss: 0.4899 - sparse_categorical_accuracy: 0.8614\n",
            "370/469 [======================>.......] - ETA: 43s - loss: 0.4892 - sparse_categorical_accuracy: 0.8616\n",
            "371/469 [======================>.......] - ETA: 43s - loss: 0.4883 - sparse_categorical_accuracy: 0.8618\n",
            "372/469 [======================>.......] - ETA: 43s - loss: 0.4874 - sparse_categorical_accuracy: 0.8620\n",
            "373/469 [======================>.......] - ETA: 42s - loss: 0.4866 - sparse_categorical_accuracy: 0.8622\n",
            "374/469 [======================>.......] - ETA: 42s - loss: 0.4855 - sparse_categorical_accuracy: 0.8626\n",
            "375/469 [======================>.......] - ETA: 41s - loss: 0.4846 - sparse_categorical_accuracy: 0.8628\n",
            "376/469 [=======================>......] - ETA: 41s - loss: 0.4838 - sparse_categorical_accuracy: 0.8630\n",
            "377/469 [=======================>......] - ETA: 41s - loss: 0.4830 - sparse_categorical_accuracy: 0.8632\n",
            "378/469 [=======================>......] - ETA: 40s - loss: 0.4821 - sparse_categorical_accuracy: 0.8634\n",
            "379/469 [=======================>......] - ETA: 40s - loss: 0.4813 - sparse_categorical_accuracy: 0.8637\n",
            "380/469 [=======================>......] - ETA: 39s - loss: 0.4805 - sparse_categorical_accuracy: 0.8640\n",
            "381/469 [=======================>......] - ETA: 39s - loss: 0.4801 - sparse_categorical_accuracy: 0.8641\n",
            "382/469 [=======================>......] - ETA: 38s - loss: 0.4794 - sparse_categorical_accuracy: 0.8642\n",
            "383/469 [=======================>......] - ETA: 38s - loss: 0.4785 - sparse_categorical_accuracy: 0.8644\n",
            "384/469 [=======================>......] - ETA: 37s - loss: 0.4776 - sparse_categorical_accuracy: 0.8647\n",
            "385/469 [=======================>......] - ETA: 37s - loss: 0.4768 - sparse_categorical_accuracy: 0.8649\n",
            "386/469 [=======================>......] - ETA: 36s - loss: 0.4759 - sparse_categorical_accuracy: 0.8651\n",
            "387/469 [=======================>......] - ETA: 36s - loss: 0.4751 - sparse_categorical_accuracy: 0.8654\n",
            "388/469 [=======================>......] - ETA: 36s - loss: 0.4743 - sparse_categorical_accuracy: 0.8656\n",
            "389/469 [=======================>......] - ETA: 35s - loss: 0.4736 - sparse_categorical_accuracy: 0.8658\n",
            "390/469 [=======================>......] - ETA: 35s - loss: 0.4726 - sparse_categorical_accuracy: 0.8661\n",
            "391/469 [========================>.....] - ETA: 34s - loss: 0.4717 - sparse_categorical_accuracy: 0.8664\n",
            "392/469 [========================>.....] - ETA: 34s - loss: 0.4708 - sparse_categorical_accuracy: 0.8666\n",
            "393/469 [========================>.....] - ETA: 33s - loss: 0.4700 - sparse_categorical_accuracy: 0.8668\n",
            "394/469 [========================>.....] - ETA: 33s - loss: 0.4693 - sparse_categorical_accuracy: 0.8670\n",
            "395/469 [========================>.....] - ETA: 32s - loss: 0.4687 - sparse_categorical_accuracy: 0.8671\n",
            "396/469 [========================>.....] - ETA: 32s - loss: 0.4679 - sparse_categorical_accuracy: 0.8674\n",
            "397/469 [========================>.....] - ETA: 31s - loss: 0.4670 - sparse_categorical_accuracy: 0.8676\n",
            "398/469 [========================>.....] - ETA: 31s - loss: 0.4661 - sparse_categorical_accuracy: 0.8679\n",
            "399/469 [========================>.....] - ETA: 31s - loss: 0.4654 - sparse_categorical_accuracy: 0.8681\n",
            "400/469 [========================>.....] - ETA: 30s - loss: 0.4646 - sparse_categorical_accuracy: 0.8683\n",
            "401/469 [========================>.....] - ETA: 30s - loss: 0.4637 - sparse_categorical_accuracy: 0.8685\n",
            "402/469 [========================>.....] - ETA: 29s - loss: 0.4628 - sparse_categorical_accuracy: 0.8687\n",
            "403/469 [========================>.....] - ETA: 29s - loss: 0.4621 - sparse_categorical_accuracy: 0.8689\n",
            "404/469 [========================>.....] - ETA: 28s - loss: 0.4614 - sparse_categorical_accuracy: 0.8691\n",
            "405/469 [========================>.....] - ETA: 28s - loss: 0.4606 - sparse_categorical_accuracy: 0.8693\n",
            "406/469 [========================>.....] - ETA: 28s - loss: 0.4598 - sparse_categorical_accuracy: 0.8696\n",
            "407/469 [=========================>....] - ETA: 27s - loss: 0.4591 - sparse_categorical_accuracy: 0.8697\n",
            "408/469 [=========================>....] - ETA: 27s - loss: 0.4584 - sparse_categorical_accuracy: 0.8699\n",
            "409/469 [=========================>....] - ETA: 26s - loss: 0.4576 - sparse_categorical_accuracy: 0.8701\n",
            "410/469 [=========================>....] - ETA: 26s - loss: 0.4567 - sparse_categorical_accuracy: 0.8704\n",
            "411/469 [=========================>....] - ETA: 25s - loss: 0.4558 - sparse_categorical_accuracy: 0.8707\n",
            "412/469 [=========================>....] - ETA: 25s - loss: 0.4554 - sparse_categorical_accuracy: 0.8708\n",
            "413/469 [=========================>....] - ETA: 24s - loss: 0.4546 - sparse_categorical_accuracy: 0.8710\n",
            "414/469 [=========================>....] - ETA: 24s - loss: 0.4537 - sparse_categorical_accuracy: 0.8713\n",
            "415/469 [=========================>....] - ETA: 24s - loss: 0.4529 - sparse_categorical_accuracy: 0.8715\n",
            "416/469 [=========================>....] - ETA: 23s - loss: 0.4521 - sparse_categorical_accuracy: 0.8718\n",
            "417/469 [=========================>....] - ETA: 23s - loss: 0.4513 - sparse_categorical_accuracy: 0.8720\n",
            "418/469 [=========================>....] - ETA: 22s - loss: 0.4505 - sparse_categorical_accuracy: 0.8722\n",
            "419/469 [=========================>....] - ETA: 22s - loss: 0.4499 - sparse_categorical_accuracy: 0.8724\n",
            "420/469 [=========================>....] - ETA: 21s - loss: 0.4489 - sparse_categorical_accuracy: 0.8726\n",
            "421/469 [=========================>....] - ETA: 21s - loss: 0.4481 - sparse_categorical_accuracy: 0.8728\n",
            "422/469 [=========================>....] - ETA: 20s - loss: 0.4474 - sparse_categorical_accuracy: 0.8731\n",
            "423/469 [==========================>...] - ETA: 20s - loss: 0.4466 - sparse_categorical_accuracy: 0.8732\n",
            "424/469 [==========================>...] - ETA: 20s - loss: 0.4458 - sparse_categorical_accuracy: 0.8735\n",
            "425/469 [==========================>...] - ETA: 19s - loss: 0.4450 - sparse_categorical_accuracy: 0.8737\n",
            "426/469 [==========================>...] - ETA: 19s - loss: 0.4442 - sparse_categorical_accuracy: 0.8739\n",
            "427/469 [==========================>...] - ETA: 18s - loss: 0.4435 - sparse_categorical_accuracy: 0.8741\n",
            "428/469 [==========================>...] - ETA: 18s - loss: 0.4427 - sparse_categorical_accuracy: 0.8743\n",
            "429/469 [==========================>...] - ETA: 17s - loss: 0.4418 - sparse_categorical_accuracy: 0.8746\n",
            "430/469 [==========================>...] - ETA: 17s - loss: 0.4409 - sparse_categorical_accuracy: 0.8749\n",
            "431/469 [==========================>...] - ETA: 16s - loss: 0.4402 - sparse_categorical_accuracy: 0.8750\n",
            "432/469 [==========================>...] - ETA: 16s - loss: 0.4394 - sparse_categorical_accuracy: 0.8753\n",
            "433/469 [==========================>...] - ETA: 16s - loss: 0.4385 - sparse_categorical_accuracy: 0.8755\n",
            "434/469 [==========================>...] - ETA: 15s - loss: 0.4377 - sparse_categorical_accuracy: 0.8758\n",
            "435/469 [==========================>...] - ETA: 15s - loss: 0.4370 - sparse_categorical_accuracy: 0.8760\n",
            "436/469 [==========================>...] - ETA: 14s - loss: 0.4363 - sparse_categorical_accuracy: 0.8761\n",
            "437/469 [==========================>...] - ETA: 14s - loss: 0.4357 - sparse_categorical_accuracy: 0.8763\n",
            "438/469 [===========================>..] - ETA: 13s - loss: 0.4350 - sparse_categorical_accuracy: 0.8765\n",
            "439/469 [===========================>..] - ETA: 13s - loss: 0.4342 - sparse_categorical_accuracy: 0.8767\n",
            "440/469 [===========================>..] - ETA: 12s - loss: 0.4334 - sparse_categorical_accuracy: 0.8769\n",
            "441/469 [===========================>..] - ETA: 12s - loss: 0.4326 - sparse_categorical_accuracy: 0.8772\n",
            "442/469 [===========================>..] - ETA: 12s - loss: 0.4320 - sparse_categorical_accuracy: 0.8773\n",
            "443/469 [===========================>..] - ETA: 11s - loss: 0.4315 - sparse_categorical_accuracy: 0.8775\n",
            "444/469 [===========================>..] - ETA: 11s - loss: 0.4310 - sparse_categorical_accuracy: 0.8776\n",
            "445/469 [===========================>..] - ETA: 10s - loss: 0.4303 - sparse_categorical_accuracy: 0.8778\n",
            "446/469 [===========================>..] - ETA: 10s - loss: 0.4298 - sparse_categorical_accuracy: 0.8780\n",
            "447/469 [===========================>..] - ETA: 9s - loss: 0.4292 - sparse_categorical_accuracy: 0.8782 \n",
            "448/469 [===========================>..] - ETA: 9s - loss: 0.4286 - sparse_categorical_accuracy: 0.8783\n",
            "449/469 [===========================>..] - ETA: 8s - loss: 0.4279 - sparse_categorical_accuracy: 0.8785\n",
            "450/469 [===========================>..] - ETA: 8s - loss: 0.4271 - sparse_categorical_accuracy: 0.8787\n",
            "451/469 [===========================>..] - ETA: 8s - loss: 0.4265 - sparse_categorical_accuracy: 0.8788\n",
            "452/469 [===========================>..] - ETA: 7s - loss: 0.4259 - sparse_categorical_accuracy: 0.8790\n",
            "453/469 [===========================>..] - ETA: 7s - loss: 0.4252 - sparse_categorical_accuracy: 0.8793\n",
            "454/469 [============================>.] - ETA: 6s - loss: 0.4245 - sparse_categorical_accuracy: 0.8795\n",
            "455/469 [============================>.] - ETA: 6s - loss: 0.4240 - sparse_categorical_accuracy: 0.8796\n",
            "456/469 [============================>.] - ETA: 5s - loss: 0.4233 - sparse_categorical_accuracy: 0.8798\n",
            "457/469 [============================>.] - ETA: 5s - loss: 0.4225 - sparse_categorical_accuracy: 0.8801\n",
            "458/469 [============================>.] - ETA: 4s - loss: 0.4220 - sparse_categorical_accuracy: 0.8802\n",
            "459/469 [============================>.] - ETA: 4s - loss: 0.4213 - sparse_categorical_accuracy: 0.8804\n",
            "460/469 [============================>.] - ETA: 4s - loss: 0.4207 - sparse_categorical_accuracy: 0.8806\n",
            "461/469 [============================>.] - ETA: 3s - loss: 0.4200 - sparse_categorical_accuracy: 0.8808\n",
            "462/469 [============================>.] - ETA: 3s - loss: 0.4194 - sparse_categorical_accuracy: 0.8810\n",
            "463/469 [============================>.] - ETA: 2s - loss: 0.4187 - sparse_categorical_accuracy: 0.8812\n",
            "464/469 [============================>.] - ETA: 2s - loss: 0.4180 - sparse_categorical_accuracy: 0.8814\n",
            "465/469 [============================>.] - ETA: 1s - loss: 0.4174 - sparse_categorical_accuracy: 0.8816\n",
            "466/469 [============================>.] - ETA: 1s - loss: 0.4167 - sparse_categorical_accuracy: 0.8817\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.4160 - sparse_categorical_accuracy: 0.8819\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.4153 - sparse_categorical_accuracy: 0.8821\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.4148 - sparse_categorical_accuracy: 0.8823\n",
            " 60%|██████    | 3/5 [1:00:24<34:52, 1046.39s/trial, best loss: -0.9839000105857849]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/04/16 01:32:25 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 210s 447ms/step - loss: 0.4148 - sparse_categorical_accuracy: 0.8823\n",
            "\n",
            "Epoch 2/5\n",
            "\n",
            "  1/469 [..............................] - ETA: 3:40 - loss: 0.2191 - sparse_categorical_accuracy: 0.9141\n",
            "  2/469 [..............................] - ETA: 3:05 - loss: 0.1468 - sparse_categorical_accuracy: 0.9414\n",
            "  3/469 [..............................] - ETA: 3:03 - loss: 0.1311 - sparse_categorical_accuracy: 0.9557\n",
            "  4/469 [..............................] - ETA: 3:07 - loss: 0.1266 - sparse_categorical_accuracy: 0.9570\n",
            "  5/469 [..............................] - ETA: 3:05 - loss: 0.1277 - sparse_categorical_accuracy: 0.9563\n",
            "  6/469 [..............................] - ETA: 3:05 - loss: 0.1190 - sparse_categorical_accuracy: 0.9596\n",
            "  7/469 [..............................] - ETA: 3:05 - loss: 0.1135 - sparse_categorical_accuracy: 0.9609\n",
            "  8/469 [..............................] - ETA: 3:04 - loss: 0.1234 - sparse_categorical_accuracy: 0.9600\n",
            "  9/469 [..............................] - ETA: 3:04 - loss: 0.1290 - sparse_categorical_accuracy: 0.9592\n",
            " 10/469 [..............................] - ETA: 3:03 - loss: 0.1247 - sparse_categorical_accuracy: 0.9609\n",
            " 11/469 [..............................] - ETA: 3:05 - loss: 0.1302 - sparse_categorical_accuracy: 0.9581\n",
            " 12/469 [..............................] - ETA: 3:04 - loss: 0.1258 - sparse_categorical_accuracy: 0.9596\n",
            " 13/469 [..............................] - ETA: 3:03 - loss: 0.1252 - sparse_categorical_accuracy: 0.9597\n",
            " 14/469 [..............................] - ETA: 3:03 - loss: 0.1206 - sparse_categorical_accuracy: 0.9609\n",
            " 15/469 [..............................] - ETA: 3:02 - loss: 0.1230 - sparse_categorical_accuracy: 0.9599\n",
            " 16/469 [>.............................] - ETA: 3:02 - loss: 0.1203 - sparse_categorical_accuracy: 0.9604\n",
            " 17/469 [>.............................] - ETA: 3:01 - loss: 0.1195 - sparse_categorical_accuracy: 0.9605\n",
            " 18/469 [>.............................] - ETA: 3:01 - loss: 0.1183 - sparse_categorical_accuracy: 0.9605\n",
            " 19/469 [>.............................] - ETA: 3:01 - loss: 0.1162 - sparse_categorical_accuracy: 0.9609\n",
            " 20/469 [>.............................] - ETA: 3:01 - loss: 0.1159 - sparse_categorical_accuracy: 0.9613\n",
            " 21/469 [>.............................] - ETA: 3:00 - loss: 0.1143 - sparse_categorical_accuracy: 0.9621\n",
            " 22/469 [>.............................] - ETA: 3:00 - loss: 0.1146 - sparse_categorical_accuracy: 0.9616\n",
            " 23/469 [>.............................] - ETA: 2:59 - loss: 0.1124 - sparse_categorical_accuracy: 0.9626\n",
            " 24/469 [>.............................] - ETA: 3:02 - loss: 0.1158 - sparse_categorical_accuracy: 0.9616\n",
            " 25/469 [>.............................] - ETA: 3:06 - loss: 0.1180 - sparse_categorical_accuracy: 0.9613\n",
            " 26/469 [>.............................] - ETA: 3:09 - loss: 0.1182 - sparse_categorical_accuracy: 0.9609\n",
            " 27/469 [>.............................] - ETA: 3:12 - loss: 0.1206 - sparse_categorical_accuracy: 0.9601\n",
            " 28/469 [>.............................] - ETA: 3:15 - loss: 0.1193 - sparse_categorical_accuracy: 0.9607\n",
            " 29/469 [>.............................] - ETA: 3:16 - loss: 0.1203 - sparse_categorical_accuracy: 0.9604\n",
            " 30/469 [>.............................] - ETA: 3:14 - loss: 0.1195 - sparse_categorical_accuracy: 0.9607\n",
            " 31/469 [>.............................] - ETA: 3:13 - loss: 0.1190 - sparse_categorical_accuracy: 0.9612\n",
            " 32/469 [=>............................] - ETA: 3:12 - loss: 0.1213 - sparse_categorical_accuracy: 0.9604\n",
            " 33/469 [=>............................] - ETA: 3:11 - loss: 0.1206 - sparse_categorical_accuracy: 0.9609\n",
            " 34/469 [=>............................] - ETA: 3:10 - loss: 0.1214 - sparse_categorical_accuracy: 0.9607\n",
            " 35/469 [=>............................] - ETA: 3:09 - loss: 0.1208 - sparse_categorical_accuracy: 0.9609\n",
            " 36/469 [=>............................] - ETA: 3:08 - loss: 0.1190 - sparse_categorical_accuracy: 0.9620\n",
            " 37/469 [=>............................] - ETA: 3:07 - loss: 0.1209 - sparse_categorical_accuracy: 0.9618\n",
            " 38/469 [=>............................] - ETA: 3:06 - loss: 0.1217 - sparse_categorical_accuracy: 0.9618\n",
            " 39/469 [=>............................] - ETA: 3:05 - loss: 0.1220 - sparse_categorical_accuracy: 0.9611\n",
            " 40/469 [=>............................] - ETA: 3:05 - loss: 0.1225 - sparse_categorical_accuracy: 0.9609\n",
            " 41/469 [=>............................] - ETA: 3:04 - loss: 0.1233 - sparse_categorical_accuracy: 0.9607\n",
            " 42/469 [=>............................] - ETA: 3:03 - loss: 0.1248 - sparse_categorical_accuracy: 0.9602\n",
            " 43/469 [=>............................] - ETA: 3:02 - loss: 0.1242 - sparse_categorical_accuracy: 0.9602\n",
            " 44/469 [=>............................] - ETA: 3:01 - loss: 0.1243 - sparse_categorical_accuracy: 0.9600\n",
            " 45/469 [=>............................] - ETA: 3:01 - loss: 0.1237 - sparse_categorical_accuracy: 0.9602\n",
            " 46/469 [=>............................] - ETA: 3:00 - loss: 0.1222 - sparse_categorical_accuracy: 0.9608\n",
            " 47/469 [==>...........................] - ETA: 2:59 - loss: 0.1206 - sparse_categorical_accuracy: 0.9614\n",
            " 48/469 [==>...........................] - ETA: 2:58 - loss: 0.1207 - sparse_categorical_accuracy: 0.9616\n",
            " 49/469 [==>...........................] - ETA: 2:58 - loss: 0.1210 - sparse_categorical_accuracy: 0.9613\n",
            " 50/469 [==>...........................] - ETA: 2:57 - loss: 0.1199 - sparse_categorical_accuracy: 0.9617\n",
            " 51/469 [==>...........................] - ETA: 2:56 - loss: 0.1192 - sparse_categorical_accuracy: 0.9622\n",
            " 52/469 [==>...........................] - ETA: 2:56 - loss: 0.1181 - sparse_categorical_accuracy: 0.9626\n",
            " 53/469 [==>...........................] - ETA: 2:55 - loss: 0.1175 - sparse_categorical_accuracy: 0.9626\n",
            " 54/469 [==>...........................] - ETA: 2:54 - loss: 0.1170 - sparse_categorical_accuracy: 0.9628\n",
            " 55/469 [==>...........................] - ETA: 2:55 - loss: 0.1173 - sparse_categorical_accuracy: 0.9625\n",
            " 56/469 [==>...........................] - ETA: 2:56 - loss: 0.1178 - sparse_categorical_accuracy: 0.9626\n",
            " 57/469 [==>...........................] - ETA: 2:57 - loss: 0.1188 - sparse_categorical_accuracy: 0.9623\n",
            " 58/469 [==>...........................] - ETA: 2:58 - loss: 0.1179 - sparse_categorical_accuracy: 0.9630\n",
            " 59/469 [==>...........................] - ETA: 2:59 - loss: 0.1177 - sparse_categorical_accuracy: 0.9633\n",
            " 60/469 [==>...........................] - ETA: 2:59 - loss: 0.1173 - sparse_categorical_accuracy: 0.9634\n",
            " 61/469 [==>...........................] - ETA: 2:58 - loss: 0.1173 - sparse_categorical_accuracy: 0.9632\n",
            " 62/469 [==>...........................] - ETA: 2:58 - loss: 0.1173 - sparse_categorical_accuracy: 0.9632\n",
            " 63/469 [===>..........................] - ETA: 2:57 - loss: 0.1170 - sparse_categorical_accuracy: 0.9630\n",
            " 64/469 [===>..........................] - ETA: 2:56 - loss: 0.1166 - sparse_categorical_accuracy: 0.9631\n",
            " 65/469 [===>..........................] - ETA: 2:55 - loss: 0.1165 - sparse_categorical_accuracy: 0.9631\n",
            " 66/469 [===>..........................] - ETA: 2:55 - loss: 0.1158 - sparse_categorical_accuracy: 0.9634\n",
            " 67/469 [===>..........................] - ETA: 2:54 - loss: 0.1163 - sparse_categorical_accuracy: 0.9634\n",
            " 68/469 [===>..........................] - ETA: 2:54 - loss: 0.1159 - sparse_categorical_accuracy: 0.9634\n",
            " 69/469 [===>..........................] - ETA: 2:53 - loss: 0.1188 - sparse_categorical_accuracy: 0.9624\n",
            " 70/469 [===>..........................] - ETA: 2:52 - loss: 0.1190 - sparse_categorical_accuracy: 0.9625\n",
            " 71/469 [===>..........................] - ETA: 2:52 - loss: 0.1192 - sparse_categorical_accuracy: 0.9625\n",
            " 72/469 [===>..........................] - ETA: 2:51 - loss: 0.1192 - sparse_categorical_accuracy: 0.9625\n",
            " 73/469 [===>..........................] - ETA: 2:50 - loss: 0.1189 - sparse_categorical_accuracy: 0.9625\n",
            " 74/469 [===>..........................] - ETA: 2:50 - loss: 0.1207 - sparse_categorical_accuracy: 0.9623\n",
            " 75/469 [===>..........................] - ETA: 2:49 - loss: 0.1211 - sparse_categorical_accuracy: 0.9621\n",
            " 76/469 [===>..........................] - ETA: 2:48 - loss: 0.1214 - sparse_categorical_accuracy: 0.9619\n",
            " 77/469 [===>..........................] - ETA: 2:48 - loss: 0.1210 - sparse_categorical_accuracy: 0.9619\n",
            " 78/469 [===>..........................] - ETA: 2:47 - loss: 0.1205 - sparse_categorical_accuracy: 0.9619\n",
            " 79/469 [====>.........................] - ETA: 2:47 - loss: 0.1215 - sparse_categorical_accuracy: 0.9620\n",
            " 80/469 [====>.........................] - ETA: 2:46 - loss: 0.1214 - sparse_categorical_accuracy: 0.9620\n",
            " 81/469 [====>.........................] - ETA: 2:45 - loss: 0.1214 - sparse_categorical_accuracy: 0.9622\n",
            " 82/469 [====>.........................] - ETA: 2:45 - loss: 0.1211 - sparse_categorical_accuracy: 0.9624\n",
            " 83/469 [====>.........................] - ETA: 2:44 - loss: 0.1207 - sparse_categorical_accuracy: 0.9625\n",
            " 84/469 [====>.........................] - ETA: 2:44 - loss: 0.1213 - sparse_categorical_accuracy: 0.9624\n",
            " 85/469 [====>.........................] - ETA: 2:44 - loss: 0.1223 - sparse_categorical_accuracy: 0.9622\n",
            " 86/469 [====>.........................] - ETA: 2:44 - loss: 0.1219 - sparse_categorical_accuracy: 0.9623\n",
            " 87/469 [====>.........................] - ETA: 2:45 - loss: 0.1227 - sparse_categorical_accuracy: 0.9621\n",
            " 88/469 [====>.........................] - ETA: 2:45 - loss: 0.1219 - sparse_categorical_accuracy: 0.9624\n",
            " 89/469 [====>.........................] - ETA: 2:45 - loss: 0.1241 - sparse_categorical_accuracy: 0.9617\n",
            " 90/469 [====>.........................] - ETA: 2:45 - loss: 0.1246 - sparse_categorical_accuracy: 0.9617\n",
            " 91/469 [====>.........................] - ETA: 2:45 - loss: 0.1244 - sparse_categorical_accuracy: 0.9618\n",
            " 92/469 [====>.........................] - ETA: 2:45 - loss: 0.1242 - sparse_categorical_accuracy: 0.9618\n",
            " 93/469 [====>.........................] - ETA: 2:44 - loss: 0.1257 - sparse_categorical_accuracy: 0.9614\n",
            " 94/469 [=====>........................] - ETA: 2:43 - loss: 0.1254 - sparse_categorical_accuracy: 0.9614\n",
            " 95/469 [=====>........................] - ETA: 2:43 - loss: 0.1250 - sparse_categorical_accuracy: 0.9616\n",
            " 96/469 [=====>........................] - ETA: 2:42 - loss: 0.1245 - sparse_categorical_accuracy: 0.9618\n",
            " 97/469 [=====>........................] - ETA: 2:42 - loss: 0.1245 - sparse_categorical_accuracy: 0.9616\n",
            " 98/469 [=====>........................] - ETA: 2:41 - loss: 0.1239 - sparse_categorical_accuracy: 0.9618\n",
            " 99/469 [=====>........................] - ETA: 2:41 - loss: 0.1241 - sparse_categorical_accuracy: 0.9618\n",
            "100/469 [=====>........................] - ETA: 2:40 - loss: 0.1237 - sparse_categorical_accuracy: 0.9620\n",
            "101/469 [=====>........................] - ETA: 2:39 - loss: 0.1238 - sparse_categorical_accuracy: 0.9619\n",
            "102/469 [=====>........................] - ETA: 2:39 - loss: 0.1239 - sparse_categorical_accuracy: 0.9619\n",
            "103/469 [=====>........................] - ETA: 2:38 - loss: 0.1233 - sparse_categorical_accuracy: 0.9620\n",
            "104/469 [=====>........................] - ETA: 2:38 - loss: 0.1232 - sparse_categorical_accuracy: 0.9619\n",
            "105/469 [=====>........................] - ETA: 2:37 - loss: 0.1231 - sparse_categorical_accuracy: 0.9619\n",
            "106/469 [=====>........................] - ETA: 2:37 - loss: 0.1229 - sparse_categorical_accuracy: 0.9620\n",
            "107/469 [=====>........................] - ETA: 2:36 - loss: 0.1235 - sparse_categorical_accuracy: 0.9619\n",
            "108/469 [=====>........................] - ETA: 2:36 - loss: 0.1237 - sparse_categorical_accuracy: 0.9619\n",
            "109/469 [=====>........................] - ETA: 2:35 - loss: 0.1232 - sparse_categorical_accuracy: 0.9621\n",
            "110/469 [======>.......................] - ETA: 2:35 - loss: 0.1236 - sparse_categorical_accuracy: 0.9619\n",
            "111/469 [======>.......................] - ETA: 2:34 - loss: 0.1242 - sparse_categorical_accuracy: 0.9616\n",
            "112/469 [======>.......................] - ETA: 2:33 - loss: 0.1246 - sparse_categorical_accuracy: 0.9614\n",
            "113/469 [======>.......................] - ETA: 2:33 - loss: 0.1244 - sparse_categorical_accuracy: 0.9614\n",
            "114/469 [======>.......................] - ETA: 2:32 - loss: 0.1239 - sparse_categorical_accuracy: 0.9616\n",
            "115/469 [======>.......................] - ETA: 2:32 - loss: 0.1241 - sparse_categorical_accuracy: 0.9615\n",
            "116/469 [======>.......................] - ETA: 2:32 - loss: 0.1240 - sparse_categorical_accuracy: 0.9615\n",
            "117/469 [======>.......................] - ETA: 2:32 - loss: 0.1240 - sparse_categorical_accuracy: 0.9614\n",
            "118/469 [======>.......................] - ETA: 2:32 - loss: 0.1244 - sparse_categorical_accuracy: 0.9613\n",
            "119/469 [======>.......................] - ETA: 2:32 - loss: 0.1249 - sparse_categorical_accuracy: 0.9611\n",
            "120/469 [======>.......................] - ETA: 2:32 - loss: 0.1247 - sparse_categorical_accuracy: 0.9611\n",
            "121/469 [======>.......................] - ETA: 2:32 - loss: 0.1250 - sparse_categorical_accuracy: 0.9609\n",
            "122/469 [======>.......................] - ETA: 2:32 - loss: 0.1252 - sparse_categorical_accuracy: 0.9608\n",
            "123/469 [======>.......................] - ETA: 2:31 - loss: 0.1247 - sparse_categorical_accuracy: 0.9609\n",
            "124/469 [======>.......................] - ETA: 2:31 - loss: 0.1251 - sparse_categorical_accuracy: 0.9609\n",
            "125/469 [======>.......................] - ETA: 2:30 - loss: 0.1247 - sparse_categorical_accuracy: 0.9611\n",
            "126/469 [=======>......................] - ETA: 2:29 - loss: 0.1247 - sparse_categorical_accuracy: 0.9610\n",
            "127/469 [=======>......................] - ETA: 2:29 - loss: 0.1245 - sparse_categorical_accuracy: 0.9610\n",
            "128/469 [=======>......................] - ETA: 2:28 - loss: 0.1247 - sparse_categorical_accuracy: 0.9609\n",
            "129/469 [=======>......................] - ETA: 2:28 - loss: 0.1248 - sparse_categorical_accuracy: 0.9608\n",
            "130/469 [=======>......................] - ETA: 2:27 - loss: 0.1247 - sparse_categorical_accuracy: 0.9609\n",
            "131/469 [=======>......................] - ETA: 2:27 - loss: 0.1244 - sparse_categorical_accuracy: 0.9610\n",
            "132/469 [=======>......................] - ETA: 2:26 - loss: 0.1239 - sparse_categorical_accuracy: 0.9612\n",
            "133/469 [=======>......................] - ETA: 2:26 - loss: 0.1248 - sparse_categorical_accuracy: 0.9610\n",
            "134/469 [=======>......................] - ETA: 2:25 - loss: 0.1248 - sparse_categorical_accuracy: 0.9611\n",
            "135/469 [=======>......................] - ETA: 2:25 - loss: 0.1248 - sparse_categorical_accuracy: 0.9610\n",
            "136/469 [=======>......................] - ETA: 2:24 - loss: 0.1246 - sparse_categorical_accuracy: 0.9611\n",
            "137/469 [=======>......................] - ETA: 2:24 - loss: 0.1245 - sparse_categorical_accuracy: 0.9611\n",
            "138/469 [=======>......................] - ETA: 2:23 - loss: 0.1249 - sparse_categorical_accuracy: 0.9611\n",
            "139/469 [=======>......................] - ETA: 2:22 - loss: 0.1248 - sparse_categorical_accuracy: 0.9610\n",
            "140/469 [=======>......................] - ETA: 2:22 - loss: 0.1246 - sparse_categorical_accuracy: 0.9611\n",
            "141/469 [========>.....................] - ETA: 2:21 - loss: 0.1253 - sparse_categorical_accuracy: 0.9609\n",
            "142/469 [========>.....................] - ETA: 2:21 - loss: 0.1252 - sparse_categorical_accuracy: 0.9608\n",
            "143/469 [========>.....................] - ETA: 2:20 - loss: 0.1251 - sparse_categorical_accuracy: 0.9609\n",
            "144/469 [========>.....................] - ETA: 2:20 - loss: 0.1248 - sparse_categorical_accuracy: 0.9610\n",
            "145/469 [========>.....................] - ETA: 2:19 - loss: 0.1243 - sparse_categorical_accuracy: 0.9612\n",
            "146/469 [========>.....................] - ETA: 2:19 - loss: 0.1239 - sparse_categorical_accuracy: 0.9613\n",
            "147/469 [========>.....................] - ETA: 2:19 - loss: 0.1238 - sparse_categorical_accuracy: 0.9614\n",
            "148/469 [========>.....................] - ETA: 2:19 - loss: 0.1236 - sparse_categorical_accuracy: 0.9615\n",
            "149/469 [========>.....................] - ETA: 2:19 - loss: 0.1239 - sparse_categorical_accuracy: 0.9613\n",
            "150/469 [========>.....................] - ETA: 2:19 - loss: 0.1235 - sparse_categorical_accuracy: 0.9615\n",
            "151/469 [========>.....................] - ETA: 2:19 - loss: 0.1238 - sparse_categorical_accuracy: 0.9614\n",
            "152/469 [========>.....................] - ETA: 2:19 - loss: 0.1236 - sparse_categorical_accuracy: 0.9615\n",
            "153/469 [========>.....................] - ETA: 2:18 - loss: 0.1233 - sparse_categorical_accuracy: 0.9616\n",
            "154/469 [========>.....................] - ETA: 2:17 - loss: 0.1238 - sparse_categorical_accuracy: 0.9614\n",
            "155/469 [========>.....................] - ETA: 2:17 - loss: 0.1237 - sparse_categorical_accuracy: 0.9613\n",
            "156/469 [========>.....................] - ETA: 2:16 - loss: 0.1240 - sparse_categorical_accuracy: 0.9612\n",
            "157/469 [=========>....................] - ETA: 2:16 - loss: 0.1236 - sparse_categorical_accuracy: 0.9613\n",
            "158/469 [=========>....................] - ETA: 2:15 - loss: 0.1234 - sparse_categorical_accuracy: 0.9614\n",
            "159/469 [=========>....................] - ETA: 2:15 - loss: 0.1231 - sparse_categorical_accuracy: 0.9616\n",
            "160/469 [=========>....................] - ETA: 2:14 - loss: 0.1228 - sparse_categorical_accuracy: 0.9616\n",
            "161/469 [=========>....................] - ETA: 2:14 - loss: 0.1225 - sparse_categorical_accuracy: 0.9617\n",
            "162/469 [=========>....................] - ETA: 2:13 - loss: 0.1228 - sparse_categorical_accuracy: 0.9616\n",
            "163/469 [=========>....................] - ETA: 2:13 - loss: 0.1230 - sparse_categorical_accuracy: 0.9615\n",
            "164/469 [=========>....................] - ETA: 2:12 - loss: 0.1231 - sparse_categorical_accuracy: 0.9615\n",
            "165/469 [=========>....................] - ETA: 2:12 - loss: 0.1228 - sparse_categorical_accuracy: 0.9616\n",
            "166/469 [=========>....................] - ETA: 2:11 - loss: 0.1226 - sparse_categorical_accuracy: 0.9616\n",
            "167/469 [=========>....................] - ETA: 2:11 - loss: 0.1230 - sparse_categorical_accuracy: 0.9615\n",
            "168/469 [=========>....................] - ETA: 2:10 - loss: 0.1225 - sparse_categorical_accuracy: 0.9618\n",
            "169/469 [=========>....................] - ETA: 2:10 - loss: 0.1222 - sparse_categorical_accuracy: 0.9619\n",
            "170/469 [=========>....................] - ETA: 2:09 - loss: 0.1219 - sparse_categorical_accuracy: 0.9619\n",
            "171/469 [=========>....................] - ETA: 2:09 - loss: 0.1217 - sparse_categorical_accuracy: 0.9620\n",
            "172/469 [==========>...................] - ETA: 2:08 - loss: 0.1216 - sparse_categorical_accuracy: 0.9621\n",
            "173/469 [==========>...................] - ETA: 2:08 - loss: 0.1211 - sparse_categorical_accuracy: 0.9622\n",
            "174/469 [==========>...................] - ETA: 2:07 - loss: 0.1209 - sparse_categorical_accuracy: 0.9623\n",
            "175/469 [==========>...................] - ETA: 2:07 - loss: 0.1205 - sparse_categorical_accuracy: 0.9624\n",
            "176/469 [==========>...................] - ETA: 2:06 - loss: 0.1206 - sparse_categorical_accuracy: 0.9624\n",
            "177/469 [==========>...................] - ETA: 2:06 - loss: 0.1202 - sparse_categorical_accuracy: 0.9625\n",
            "178/469 [==========>...................] - ETA: 2:06 - loss: 0.1199 - sparse_categorical_accuracy: 0.9626\n",
            "179/469 [==========>...................] - ETA: 2:06 - loss: 0.1197 - sparse_categorical_accuracy: 0.9626\n",
            "180/469 [==========>...................] - ETA: 2:06 - loss: 0.1197 - sparse_categorical_accuracy: 0.9626\n",
            "181/469 [==========>...................] - ETA: 2:05 - loss: 0.1195 - sparse_categorical_accuracy: 0.9626\n",
            "182/469 [==========>...................] - ETA: 2:05 - loss: 0.1198 - sparse_categorical_accuracy: 0.9625\n",
            "183/469 [==========>...................] - ETA: 2:05 - loss: 0.1201 - sparse_categorical_accuracy: 0.9624\n",
            "184/469 [==========>...................] - ETA: 2:05 - loss: 0.1203 - sparse_categorical_accuracy: 0.9623\n",
            "185/469 [==========>...................] - ETA: 2:04 - loss: 0.1198 - sparse_categorical_accuracy: 0.9624\n",
            "186/469 [==========>...................] - ETA: 2:04 - loss: 0.1197 - sparse_categorical_accuracy: 0.9625\n",
            "187/469 [==========>...................] - ETA: 2:03 - loss: 0.1199 - sparse_categorical_accuracy: 0.9624\n",
            "188/469 [===========>..................] - ETA: 2:03 - loss: 0.1197 - sparse_categorical_accuracy: 0.9624\n",
            "189/469 [===========>..................] - ETA: 2:02 - loss: 0.1195 - sparse_categorical_accuracy: 0.9625\n",
            "190/469 [===========>..................] - ETA: 2:02 - loss: 0.1194 - sparse_categorical_accuracy: 0.9625\n",
            "191/469 [===========>..................] - ETA: 2:01 - loss: 0.1193 - sparse_categorical_accuracy: 0.9624\n",
            "192/469 [===========>..................] - ETA: 2:01 - loss: 0.1196 - sparse_categorical_accuracy: 0.9624\n",
            "193/469 [===========>..................] - ETA: 2:00 - loss: 0.1194 - sparse_categorical_accuracy: 0.9624\n",
            "194/469 [===========>..................] - ETA: 2:00 - loss: 0.1199 - sparse_categorical_accuracy: 0.9623\n",
            "195/469 [===========>..................] - ETA: 1:59 - loss: 0.1198 - sparse_categorical_accuracy: 0.9623\n",
            "196/469 [===========>..................] - ETA: 1:59 - loss: 0.1197 - sparse_categorical_accuracy: 0.9624\n",
            "197/469 [===========>..................] - ETA: 1:58 - loss: 0.1196 - sparse_categorical_accuracy: 0.9624\n",
            "198/469 [===========>..................] - ETA: 1:58 - loss: 0.1199 - sparse_categorical_accuracy: 0.9623\n",
            "199/469 [===========>..................] - ETA: 1:57 - loss: 0.1199 - sparse_categorical_accuracy: 0.9624\n",
            "200/469 [===========>..................] - ETA: 1:57 - loss: 0.1197 - sparse_categorical_accuracy: 0.9625\n",
            "201/469 [===========>..................] - ETA: 1:56 - loss: 0.1196 - sparse_categorical_accuracy: 0.9625\n",
            "202/469 [===========>..................] - ETA: 1:56 - loss: 0.1196 - sparse_categorical_accuracy: 0.9625\n",
            "203/469 [===========>..................] - ETA: 1:55 - loss: 0.1195 - sparse_categorical_accuracy: 0.9625\n",
            "204/469 [============>.................] - ETA: 1:55 - loss: 0.1194 - sparse_categorical_accuracy: 0.9625\n",
            "205/469 [============>.................] - ETA: 1:54 - loss: 0.1194 - sparse_categorical_accuracy: 0.9625\n",
            "206/469 [============>.................] - ETA: 1:54 - loss: 0.1194 - sparse_categorical_accuracy: 0.9625\n",
            "207/469 [============>.................] - ETA: 1:53 - loss: 0.1193 - sparse_categorical_accuracy: 0.9625\n",
            "208/469 [============>.................] - ETA: 1:53 - loss: 0.1194 - sparse_categorical_accuracy: 0.9625\n",
            "209/469 [============>.................] - ETA: 1:53 - loss: 0.1191 - sparse_categorical_accuracy: 0.9625\n",
            "210/469 [============>.................] - ETA: 1:52 - loss: 0.1189 - sparse_categorical_accuracy: 0.9627\n",
            "211/469 [============>.................] - ETA: 1:52 - loss: 0.1190 - sparse_categorical_accuracy: 0.9627\n",
            "212/469 [============>.................] - ETA: 1:52 - loss: 0.1187 - sparse_categorical_accuracy: 0.9629\n",
            "213/469 [============>.................] - ETA: 1:52 - loss: 0.1187 - sparse_categorical_accuracy: 0.9628\n",
            "214/469 [============>.................] - ETA: 1:51 - loss: 0.1187 - sparse_categorical_accuracy: 0.9628\n",
            "215/469 [============>.................] - ETA: 1:51 - loss: 0.1186 - sparse_categorical_accuracy: 0.9628\n",
            "216/469 [============>.................] - ETA: 1:50 - loss: 0.1186 - sparse_categorical_accuracy: 0.9627\n",
            "217/469 [============>.................] - ETA: 1:50 - loss: 0.1186 - sparse_categorical_accuracy: 0.9628\n",
            "218/469 [============>.................] - ETA: 1:49 - loss: 0.1187 - sparse_categorical_accuracy: 0.9628\n",
            "219/469 [=============>................] - ETA: 1:49 - loss: 0.1186 - sparse_categorical_accuracy: 0.9628\n",
            "220/469 [=============>................] - ETA: 1:48 - loss: 0.1185 - sparse_categorical_accuracy: 0.9629\n",
            "221/469 [=============>................] - ETA: 1:48 - loss: 0.1188 - sparse_categorical_accuracy: 0.9627\n",
            "222/469 [=============>................] - ETA: 1:47 - loss: 0.1185 - sparse_categorical_accuracy: 0.9628\n",
            "223/469 [=============>................] - ETA: 1:47 - loss: 0.1183 - sparse_categorical_accuracy: 0.9629\n",
            "224/469 [=============>................] - ETA: 1:47 - loss: 0.1184 - sparse_categorical_accuracy: 0.9629\n",
            "225/469 [=============>................] - ETA: 1:46 - loss: 0.1182 - sparse_categorical_accuracy: 0.9629\n",
            "226/469 [=============>................] - ETA: 1:46 - loss: 0.1181 - sparse_categorical_accuracy: 0.9630\n",
            "227/469 [=============>................] - ETA: 1:45 - loss: 0.1180 - sparse_categorical_accuracy: 0.9630\n",
            "228/469 [=============>................] - ETA: 1:45 - loss: 0.1178 - sparse_categorical_accuracy: 0.9630\n",
            "229/469 [=============>................] - ETA: 1:44 - loss: 0.1178 - sparse_categorical_accuracy: 0.9631\n",
            "230/469 [=============>................] - ETA: 1:44 - loss: 0.1180 - sparse_categorical_accuracy: 0.9631\n",
            "231/469 [=============>................] - ETA: 1:43 - loss: 0.1182 - sparse_categorical_accuracy: 0.9630\n",
            "232/469 [=============>................] - ETA: 1:43 - loss: 0.1181 - sparse_categorical_accuracy: 0.9631\n",
            "233/469 [=============>................] - ETA: 1:42 - loss: 0.1179 - sparse_categorical_accuracy: 0.9631\n",
            "234/469 [=============>................] - ETA: 1:42 - loss: 0.1178 - sparse_categorical_accuracy: 0.9631\n",
            "235/469 [==============>...............] - ETA: 1:41 - loss: 0.1177 - sparse_categorical_accuracy: 0.9632\n",
            "236/469 [==============>...............] - ETA: 1:41 - loss: 0.1175 - sparse_categorical_accuracy: 0.9632\n",
            "237/469 [==============>...............] - ETA: 1:40 - loss: 0.1177 - sparse_categorical_accuracy: 0.9632\n",
            "238/469 [==============>...............] - ETA: 1:40 - loss: 0.1178 - sparse_categorical_accuracy: 0.9632\n",
            "239/469 [==============>...............] - ETA: 1:39 - loss: 0.1181 - sparse_categorical_accuracy: 0.9631\n",
            "240/469 [==============>...............] - ETA: 1:39 - loss: 0.1178 - sparse_categorical_accuracy: 0.9632\n",
            "241/469 [==============>...............] - ETA: 1:39 - loss: 0.1178 - sparse_categorical_accuracy: 0.9632\n",
            "242/469 [==============>...............] - ETA: 1:39 - loss: 0.1177 - sparse_categorical_accuracy: 0.9633\n",
            "243/469 [==============>...............] - ETA: 1:38 - loss: 0.1174 - sparse_categorical_accuracy: 0.9634\n",
            "244/469 [==============>...............] - ETA: 1:38 - loss: 0.1174 - sparse_categorical_accuracy: 0.9634\n",
            "245/469 [==============>...............] - ETA: 1:38 - loss: 0.1176 - sparse_categorical_accuracy: 0.9634\n",
            "246/469 [==============>...............] - ETA: 1:37 - loss: 0.1177 - sparse_categorical_accuracy: 0.9633\n",
            "247/469 [==============>...............] - ETA: 1:37 - loss: 0.1175 - sparse_categorical_accuracy: 0.9634\n",
            "248/469 [==============>...............] - ETA: 1:36 - loss: 0.1174 - sparse_categorical_accuracy: 0.9634\n",
            "249/469 [==============>...............] - ETA: 1:36 - loss: 0.1172 - sparse_categorical_accuracy: 0.9634\n",
            "250/469 [==============>...............] - ETA: 1:35 - loss: 0.1170 - sparse_categorical_accuracy: 0.9634\n",
            "251/469 [===============>..............] - ETA: 1:35 - loss: 0.1167 - sparse_categorical_accuracy: 0.9636\n",
            "252/469 [===============>..............] - ETA: 1:34 - loss: 0.1166 - sparse_categorical_accuracy: 0.9636\n",
            "253/469 [===============>..............] - ETA: 1:34 - loss: 0.1164 - sparse_categorical_accuracy: 0.9637\n",
            "254/469 [===============>..............] - ETA: 1:33 - loss: 0.1164 - sparse_categorical_accuracy: 0.9636\n",
            "255/469 [===============>..............] - ETA: 1:33 - loss: 0.1163 - sparse_categorical_accuracy: 0.9636\n",
            "256/469 [===============>..............] - ETA: 1:32 - loss: 0.1162 - sparse_categorical_accuracy: 0.9636\n",
            "257/469 [===============>..............] - ETA: 1:32 - loss: 0.1161 - sparse_categorical_accuracy: 0.9636\n",
            "258/469 [===============>..............] - ETA: 1:31 - loss: 0.1161 - sparse_categorical_accuracy: 0.9636\n",
            "259/469 [===============>..............] - ETA: 1:31 - loss: 0.1162 - sparse_categorical_accuracy: 0.9635\n",
            "260/469 [===============>..............] - ETA: 1:30 - loss: 0.1161 - sparse_categorical_accuracy: 0.9635\n",
            "261/469 [===============>..............] - ETA: 1:30 - loss: 0.1162 - sparse_categorical_accuracy: 0.9635\n",
            "262/469 [===============>..............] - ETA: 1:30 - loss: 0.1160 - sparse_categorical_accuracy: 0.9636\n",
            "263/469 [===============>..............] - ETA: 1:29 - loss: 0.1157 - sparse_categorical_accuracy: 0.9636\n",
            "264/469 [===============>..............] - ETA: 1:29 - loss: 0.1158 - sparse_categorical_accuracy: 0.9636\n",
            "265/469 [===============>..............] - ETA: 1:28 - loss: 0.1156 - sparse_categorical_accuracy: 0.9636\n",
            "266/469 [================>.............] - ETA: 1:28 - loss: 0.1156 - sparse_categorical_accuracy: 0.9636\n",
            "267/469 [================>.............] - ETA: 1:27 - loss: 0.1156 - sparse_categorical_accuracy: 0.9636\n",
            "268/469 [================>.............] - ETA: 1:27 - loss: 0.1157 - sparse_categorical_accuracy: 0.9636\n",
            "269/469 [================>.............] - ETA: 1:26 - loss: 0.1155 - sparse_categorical_accuracy: 0.9636\n",
            "270/469 [================>.............] - ETA: 1:26 - loss: 0.1155 - sparse_categorical_accuracy: 0.9637\n",
            "271/469 [================>.............] - ETA: 1:26 - loss: 0.1152 - sparse_categorical_accuracy: 0.9638\n",
            "272/469 [================>.............] - ETA: 1:25 - loss: 0.1151 - sparse_categorical_accuracy: 0.9638\n",
            "273/469 [================>.............] - ETA: 1:25 - loss: 0.1149 - sparse_categorical_accuracy: 0.9639\n",
            "274/469 [================>.............] - ETA: 1:25 - loss: 0.1148 - sparse_categorical_accuracy: 0.9638\n",
            "275/469 [================>.............] - ETA: 1:24 - loss: 0.1148 - sparse_categorical_accuracy: 0.9638\n",
            "276/469 [================>.............] - ETA: 1:24 - loss: 0.1146 - sparse_categorical_accuracy: 0.9639\n",
            "277/469 [================>.............] - ETA: 1:24 - loss: 0.1143 - sparse_categorical_accuracy: 0.9640\n",
            "278/469 [================>.............] - ETA: 1:23 - loss: 0.1141 - sparse_categorical_accuracy: 0.9641\n",
            "279/469 [================>.............] - ETA: 1:23 - loss: 0.1140 - sparse_categorical_accuracy: 0.9641\n",
            "280/469 [================>.............] - ETA: 1:22 - loss: 0.1139 - sparse_categorical_accuracy: 0.9641\n",
            "281/469 [================>.............] - ETA: 1:22 - loss: 0.1138 - sparse_categorical_accuracy: 0.9642\n",
            "282/469 [=================>............] - ETA: 1:21 - loss: 0.1135 - sparse_categorical_accuracy: 0.9643\n",
            "283/469 [=================>............] - ETA: 1:21 - loss: 0.1133 - sparse_categorical_accuracy: 0.9644\n",
            "284/469 [=================>............] - ETA: 1:20 - loss: 0.1136 - sparse_categorical_accuracy: 0.9643\n",
            "285/469 [=================>............] - ETA: 1:20 - loss: 0.1136 - sparse_categorical_accuracy: 0.9643\n",
            "286/469 [=================>............] - ETA: 1:19 - loss: 0.1136 - sparse_categorical_accuracy: 0.9642\n",
            "287/469 [=================>............] - ETA: 1:19 - loss: 0.1137 - sparse_categorical_accuracy: 0.9642\n",
            "288/469 [=================>............] - ETA: 1:18 - loss: 0.1137 - sparse_categorical_accuracy: 0.9641\n",
            "289/469 [=================>............] - ETA: 1:18 - loss: 0.1135 - sparse_categorical_accuracy: 0.9642\n",
            "290/469 [=================>............] - ETA: 1:18 - loss: 0.1134 - sparse_categorical_accuracy: 0.9642\n",
            "291/469 [=================>............] - ETA: 1:17 - loss: 0.1133 - sparse_categorical_accuracy: 0.9642\n",
            "292/469 [=================>............] - ETA: 1:17 - loss: 0.1131 - sparse_categorical_accuracy: 0.9643\n",
            "293/469 [=================>............] - ETA: 1:16 - loss: 0.1133 - sparse_categorical_accuracy: 0.9641\n",
            "294/469 [=================>............] - ETA: 1:16 - loss: 0.1133 - sparse_categorical_accuracy: 0.9642\n",
            "295/469 [=================>............] - ETA: 1:15 - loss: 0.1132 - sparse_categorical_accuracy: 0.9642\n",
            "296/469 [=================>............] - ETA: 1:15 - loss: 0.1131 - sparse_categorical_accuracy: 0.9642\n",
            "297/469 [=================>............] - ETA: 1:14 - loss: 0.1132 - sparse_categorical_accuracy: 0.9642\n",
            "298/469 [==================>...........] - ETA: 1:14 - loss: 0.1131 - sparse_categorical_accuracy: 0.9642\n",
            "299/469 [==================>...........] - ETA: 1:13 - loss: 0.1130 - sparse_categorical_accuracy: 0.9643\n",
            "300/469 [==================>...........] - ETA: 1:13 - loss: 0.1127 - sparse_categorical_accuracy: 0.9644\n",
            "301/469 [==================>...........] - ETA: 1:13 - loss: 0.1126 - sparse_categorical_accuracy: 0.9644\n",
            "302/469 [==================>...........] - ETA: 1:12 - loss: 0.1125 - sparse_categorical_accuracy: 0.9645\n",
            "303/469 [==================>...........] - ETA: 1:12 - loss: 0.1123 - sparse_categorical_accuracy: 0.9645\n",
            "304/469 [==================>...........] - ETA: 1:12 - loss: 0.1127 - sparse_categorical_accuracy: 0.9645\n",
            "305/469 [==================>...........] - ETA: 1:11 - loss: 0.1129 - sparse_categorical_accuracy: 0.9645\n",
            "306/469 [==================>...........] - ETA: 1:11 - loss: 0.1129 - sparse_categorical_accuracy: 0.9645\n",
            "307/469 [==================>...........] - ETA: 1:10 - loss: 0.1128 - sparse_categorical_accuracy: 0.9645\n",
            "308/469 [==================>...........] - ETA: 1:10 - loss: 0.1126 - sparse_categorical_accuracy: 0.9645\n",
            "309/469 [==================>...........] - ETA: 1:10 - loss: 0.1128 - sparse_categorical_accuracy: 0.9645\n",
            "310/469 [==================>...........] - ETA: 1:09 - loss: 0.1128 - sparse_categorical_accuracy: 0.9645\n",
            "311/469 [==================>...........] - ETA: 1:09 - loss: 0.1126 - sparse_categorical_accuracy: 0.9645\n",
            "312/469 [==================>...........] - ETA: 1:08 - loss: 0.1124 - sparse_categorical_accuracy: 0.9646\n",
            "313/469 [===================>..........] - ETA: 1:08 - loss: 0.1125 - sparse_categorical_accuracy: 0.9646\n",
            "314/469 [===================>..........] - ETA: 1:07 - loss: 0.1125 - sparse_categorical_accuracy: 0.9646\n",
            "315/469 [===================>..........] - ETA: 1:07 - loss: 0.1126 - sparse_categorical_accuracy: 0.9647\n",
            "316/469 [===================>..........] - ETA: 1:06 - loss: 0.1129 - sparse_categorical_accuracy: 0.9646\n",
            "317/469 [===================>..........] - ETA: 1:06 - loss: 0.1127 - sparse_categorical_accuracy: 0.9647\n",
            "318/469 [===================>..........] - ETA: 1:05 - loss: 0.1126 - sparse_categorical_accuracy: 0.9647\n",
            "319/469 [===================>..........] - ETA: 1:05 - loss: 0.1126 - sparse_categorical_accuracy: 0.9647\n",
            "320/469 [===================>..........] - ETA: 1:05 - loss: 0.1124 - sparse_categorical_accuracy: 0.9648\n",
            "321/469 [===================>..........] - ETA: 1:04 - loss: 0.1124 - sparse_categorical_accuracy: 0.9648\n",
            "322/469 [===================>..........] - ETA: 1:04 - loss: 0.1124 - sparse_categorical_accuracy: 0.9648\n",
            "323/469 [===================>..........] - ETA: 1:03 - loss: 0.1123 - sparse_categorical_accuracy: 0.9649\n",
            "324/469 [===================>..........] - ETA: 1:03 - loss: 0.1127 - sparse_categorical_accuracy: 0.9648\n",
            "325/469 [===================>..........] - ETA: 1:02 - loss: 0.1125 - sparse_categorical_accuracy: 0.9649\n",
            "326/469 [===================>..........] - ETA: 1:02 - loss: 0.1125 - sparse_categorical_accuracy: 0.9649\n",
            "327/469 [===================>..........] - ETA: 1:01 - loss: 0.1126 - sparse_categorical_accuracy: 0.9648\n",
            "328/469 [===================>..........] - ETA: 1:01 - loss: 0.1126 - sparse_categorical_accuracy: 0.9647\n",
            "329/469 [====================>.........] - ETA: 1:00 - loss: 0.1126 - sparse_categorical_accuracy: 0.9647\n",
            "330/469 [====================>.........] - ETA: 1:00 - loss: 0.1127 - sparse_categorical_accuracy: 0.9647\n",
            "331/469 [====================>.........] - ETA: 1:00 - loss: 0.1128 - sparse_categorical_accuracy: 0.9647\n",
            "332/469 [====================>.........] - ETA: 59s - loss: 0.1130 - sparse_categorical_accuracy: 0.9646 \n",
            "333/469 [====================>.........] - ETA: 59s - loss: 0.1130 - sparse_categorical_accuracy: 0.9647\n",
            "334/469 [====================>.........] - ETA: 59s - loss: 0.1129 - sparse_categorical_accuracy: 0.9647\n",
            "335/469 [====================>.........] - ETA: 58s - loss: 0.1127 - sparse_categorical_accuracy: 0.9647\n",
            "336/469 [====================>.........] - ETA: 58s - loss: 0.1127 - sparse_categorical_accuracy: 0.9648\n",
            "337/469 [====================>.........] - ETA: 57s - loss: 0.1125 - sparse_categorical_accuracy: 0.9648\n",
            "338/469 [====================>.........] - ETA: 57s - loss: 0.1124 - sparse_categorical_accuracy: 0.9649\n",
            "339/469 [====================>.........] - ETA: 56s - loss: 0.1124 - sparse_categorical_accuracy: 0.9649\n",
            "340/469 [====================>.........] - ETA: 56s - loss: 0.1123 - sparse_categorical_accuracy: 0.9649\n",
            "341/469 [====================>.........] - ETA: 56s - loss: 0.1122 - sparse_categorical_accuracy: 0.9650\n",
            "342/469 [====================>.........] - ETA: 55s - loss: 0.1122 - sparse_categorical_accuracy: 0.9650\n",
            "343/469 [====================>.........] - ETA: 55s - loss: 0.1121 - sparse_categorical_accuracy: 0.9650\n",
            "344/469 [=====================>........] - ETA: 54s - loss: 0.1123 - sparse_categorical_accuracy: 0.9649\n",
            "345/469 [=====================>........] - ETA: 54s - loss: 0.1122 - sparse_categorical_accuracy: 0.9650\n",
            "346/469 [=====================>........] - ETA: 53s - loss: 0.1121 - sparse_categorical_accuracy: 0.9650\n",
            "347/469 [=====================>........] - ETA: 53s - loss: 0.1124 - sparse_categorical_accuracy: 0.9649\n",
            "348/469 [=====================>........] - ETA: 52s - loss: 0.1126 - sparse_categorical_accuracy: 0.9649\n",
            "349/469 [=====================>........] - ETA: 52s - loss: 0.1126 - sparse_categorical_accuracy: 0.9649\n",
            "350/469 [=====================>........] - ETA: 52s - loss: 0.1126 - sparse_categorical_accuracy: 0.9649\n",
            "351/469 [=====================>........] - ETA: 51s - loss: 0.1124 - sparse_categorical_accuracy: 0.9650\n",
            "352/469 [=====================>........] - ETA: 51s - loss: 0.1126 - sparse_categorical_accuracy: 0.9649\n",
            "353/469 [=====================>........] - ETA: 50s - loss: 0.1126 - sparse_categorical_accuracy: 0.9650\n",
            "354/469 [=====================>........] - ETA: 50s - loss: 0.1124 - sparse_categorical_accuracy: 0.9650\n",
            "355/469 [=====================>........] - ETA: 49s - loss: 0.1126 - sparse_categorical_accuracy: 0.9650\n",
            "356/469 [=====================>........] - ETA: 49s - loss: 0.1124 - sparse_categorical_accuracy: 0.9651\n",
            "357/469 [=====================>........] - ETA: 48s - loss: 0.1123 - sparse_categorical_accuracy: 0.9651\n",
            "358/469 [=====================>........] - ETA: 48s - loss: 0.1123 - sparse_categorical_accuracy: 0.9651\n",
            "359/469 [=====================>........] - ETA: 47s - loss: 0.1125 - sparse_categorical_accuracy: 0.9650\n",
            "360/469 [======================>.......] - ETA: 47s - loss: 0.1124 - sparse_categorical_accuracy: 0.9651\n",
            "361/469 [======================>.......] - ETA: 47s - loss: 0.1123 - sparse_categorical_accuracy: 0.9651\n",
            "362/469 [======================>.......] - ETA: 46s - loss: 0.1122 - sparse_categorical_accuracy: 0.9651\n",
            "363/469 [======================>.......] - ETA: 46s - loss: 0.1123 - sparse_categorical_accuracy: 0.9651\n",
            "364/469 [======================>.......] - ETA: 45s - loss: 0.1122 - sparse_categorical_accuracy: 0.9652\n",
            "365/469 [======================>.......] - ETA: 45s - loss: 0.1123 - sparse_categorical_accuracy: 0.9652\n",
            "366/469 [======================>.......] - ETA: 45s - loss: 0.1124 - sparse_categorical_accuracy: 0.9651\n",
            "367/469 [======================>.......] - ETA: 44s - loss: 0.1123 - sparse_categorical_accuracy: 0.9652\n",
            "368/469 [======================>.......] - ETA: 44s - loss: 0.1122 - sparse_categorical_accuracy: 0.9652\n",
            "369/469 [======================>.......] - ETA: 43s - loss: 0.1122 - sparse_categorical_accuracy: 0.9652\n",
            "370/469 [======================>.......] - ETA: 43s - loss: 0.1120 - sparse_categorical_accuracy: 0.9653\n",
            "371/469 [======================>.......] - ETA: 42s - loss: 0.1119 - sparse_categorical_accuracy: 0.9653\n",
            "372/469 [======================>.......] - ETA: 42s - loss: 0.1117 - sparse_categorical_accuracy: 0.9654\n",
            "373/469 [======================>.......] - ETA: 42s - loss: 0.1118 - sparse_categorical_accuracy: 0.9654\n",
            "374/469 [======================>.......] - ETA: 41s - loss: 0.1117 - sparse_categorical_accuracy: 0.9654\n",
            "375/469 [======================>.......] - ETA: 41s - loss: 0.1116 - sparse_categorical_accuracy: 0.9654\n",
            "376/469 [=======================>......] - ETA: 40s - loss: 0.1115 - sparse_categorical_accuracy: 0.9654\n",
            "377/469 [=======================>......] - ETA: 40s - loss: 0.1117 - sparse_categorical_accuracy: 0.9654\n",
            "378/469 [=======================>......] - ETA: 39s - loss: 0.1119 - sparse_categorical_accuracy: 0.9653\n",
            "379/469 [=======================>......] - ETA: 39s - loss: 0.1120 - sparse_categorical_accuracy: 0.9653\n",
            "380/469 [=======================>......] - ETA: 38s - loss: 0.1119 - sparse_categorical_accuracy: 0.9653\n",
            "381/469 [=======================>......] - ETA: 38s - loss: 0.1118 - sparse_categorical_accuracy: 0.9653\n",
            "382/469 [=======================>......] - ETA: 38s - loss: 0.1117 - sparse_categorical_accuracy: 0.9653\n",
            "383/469 [=======================>......] - ETA: 37s - loss: 0.1118 - sparse_categorical_accuracy: 0.9653\n",
            "384/469 [=======================>......] - ETA: 37s - loss: 0.1117 - sparse_categorical_accuracy: 0.9653\n",
            "385/469 [=======================>......] - ETA: 36s - loss: 0.1116 - sparse_categorical_accuracy: 0.9653\n",
            "386/469 [=======================>......] - ETA: 36s - loss: 0.1115 - sparse_categorical_accuracy: 0.9654\n",
            "387/469 [=======================>......] - ETA: 35s - loss: 0.1116 - sparse_categorical_accuracy: 0.9653\n",
            "388/469 [=======================>......] - ETA: 35s - loss: 0.1114 - sparse_categorical_accuracy: 0.9654\n",
            "389/469 [=======================>......] - ETA: 34s - loss: 0.1116 - sparse_categorical_accuracy: 0.9653\n",
            "390/469 [=======================>......] - ETA: 34s - loss: 0.1116 - sparse_categorical_accuracy: 0.9653\n",
            "391/469 [========================>.....] - ETA: 34s - loss: 0.1114 - sparse_categorical_accuracy: 0.9654\n",
            "392/469 [========================>.....] - ETA: 33s - loss: 0.1113 - sparse_categorical_accuracy: 0.9654\n",
            "393/469 [========================>.....] - ETA: 33s - loss: 0.1113 - sparse_categorical_accuracy: 0.9655\n",
            "394/469 [========================>.....] - ETA: 32s - loss: 0.1112 - sparse_categorical_accuracy: 0.9655\n",
            "395/469 [========================>.....] - ETA: 32s - loss: 0.1111 - sparse_categorical_accuracy: 0.9655\n",
            "396/469 [========================>.....] - ETA: 32s - loss: 0.1111 - sparse_categorical_accuracy: 0.9655\n",
            "397/469 [========================>.....] - ETA: 31s - loss: 0.1109 - sparse_categorical_accuracy: 0.9656\n",
            "398/469 [========================>.....] - ETA: 31s - loss: 0.1109 - sparse_categorical_accuracy: 0.9656\n",
            "399/469 [========================>.....] - ETA: 30s - loss: 0.1107 - sparse_categorical_accuracy: 0.9657\n",
            "400/469 [========================>.....] - ETA: 30s - loss: 0.1107 - sparse_categorical_accuracy: 0.9657\n",
            "401/469 [========================>.....] - ETA: 29s - loss: 0.1105 - sparse_categorical_accuracy: 0.9657\n",
            "402/469 [========================>.....] - ETA: 29s - loss: 0.1104 - sparse_categorical_accuracy: 0.9658\n",
            "403/469 [========================>.....] - ETA: 28s - loss: 0.1103 - sparse_categorical_accuracy: 0.9658\n",
            "404/469 [========================>.....] - ETA: 28s - loss: 0.1103 - sparse_categorical_accuracy: 0.9658\n",
            "405/469 [========================>.....] - ETA: 28s - loss: 0.1104 - sparse_categorical_accuracy: 0.9658\n",
            "406/469 [========================>.....] - ETA: 27s - loss: 0.1105 - sparse_categorical_accuracy: 0.9658\n",
            "407/469 [=========================>....] - ETA: 27s - loss: 0.1105 - sparse_categorical_accuracy: 0.9658\n",
            "408/469 [=========================>....] - ETA: 26s - loss: 0.1104 - sparse_categorical_accuracy: 0.9659\n",
            "409/469 [=========================>....] - ETA: 26s - loss: 0.1102 - sparse_categorical_accuracy: 0.9659\n",
            "410/469 [=========================>....] - ETA: 25s - loss: 0.1100 - sparse_categorical_accuracy: 0.9659\n",
            "411/469 [=========================>....] - ETA: 25s - loss: 0.1099 - sparse_categorical_accuracy: 0.9660\n",
            "412/469 [=========================>....] - ETA: 24s - loss: 0.1099 - sparse_categorical_accuracy: 0.9660\n",
            "413/469 [=========================>....] - ETA: 24s - loss: 0.1099 - sparse_categorical_accuracy: 0.9660\n",
            "414/469 [=========================>....] - ETA: 24s - loss: 0.1097 - sparse_categorical_accuracy: 0.9660\n",
            "415/469 [=========================>....] - ETA: 23s - loss: 0.1100 - sparse_categorical_accuracy: 0.9660\n",
            "416/469 [=========================>....] - ETA: 23s - loss: 0.1100 - sparse_categorical_accuracy: 0.9660\n",
            "417/469 [=========================>....] - ETA: 22s - loss: 0.1099 - sparse_categorical_accuracy: 0.9660\n",
            "418/469 [=========================>....] - ETA: 22s - loss: 0.1098 - sparse_categorical_accuracy: 0.9661\n",
            "419/469 [=========================>....] - ETA: 21s - loss: 0.1097 - sparse_categorical_accuracy: 0.9661\n",
            "420/469 [=========================>....] - ETA: 21s - loss: 0.1096 - sparse_categorical_accuracy: 0.9661\n",
            "421/469 [=========================>....] - ETA: 20s - loss: 0.1097 - sparse_categorical_accuracy: 0.9661\n",
            "422/469 [=========================>....] - ETA: 20s - loss: 0.1098 - sparse_categorical_accuracy: 0.9661\n",
            "423/469 [==========================>...] - ETA: 20s - loss: 0.1095 - sparse_categorical_accuracy: 0.9662\n",
            "424/469 [==========================>...] - ETA: 19s - loss: 0.1095 - sparse_categorical_accuracy: 0.9662\n",
            "425/469 [==========================>...] - ETA: 19s - loss: 0.1094 - sparse_categorical_accuracy: 0.9662\n",
            "426/469 [==========================>...] - ETA: 18s - loss: 0.1097 - sparse_categorical_accuracy: 0.9662\n",
            "427/469 [==========================>...] - ETA: 18s - loss: 0.1095 - sparse_categorical_accuracy: 0.9662\n",
            "428/469 [==========================>...] - ETA: 18s - loss: 0.1095 - sparse_categorical_accuracy: 0.9662\n",
            "429/469 [==========================>...] - ETA: 17s - loss: 0.1097 - sparse_categorical_accuracy: 0.9662\n",
            "430/469 [==========================>...] - ETA: 17s - loss: 0.1096 - sparse_categorical_accuracy: 0.9662\n",
            "431/469 [==========================>...] - ETA: 16s - loss: 0.1096 - sparse_categorical_accuracy: 0.9662\n",
            "432/469 [==========================>...] - ETA: 16s - loss: 0.1097 - sparse_categorical_accuracy: 0.9662\n",
            "433/469 [==========================>...] - ETA: 15s - loss: 0.1097 - sparse_categorical_accuracy: 0.9662\n",
            "434/469 [==========================>...] - ETA: 15s - loss: 0.1095 - sparse_categorical_accuracy: 0.9663\n",
            "435/469 [==========================>...] - ETA: 14s - loss: 0.1093 - sparse_categorical_accuracy: 0.9663\n",
            "436/469 [==========================>...] - ETA: 14s - loss: 0.1093 - sparse_categorical_accuracy: 0.9663\n",
            "437/469 [==========================>...] - ETA: 14s - loss: 0.1093 - sparse_categorical_accuracy: 0.9663\n",
            "438/469 [===========================>..] - ETA: 13s - loss: 0.1094 - sparse_categorical_accuracy: 0.9663\n",
            "439/469 [===========================>..] - ETA: 13s - loss: 0.1094 - sparse_categorical_accuracy: 0.9663\n",
            "440/469 [===========================>..] - ETA: 12s - loss: 0.1094 - sparse_categorical_accuracy: 0.9663\n",
            "441/469 [===========================>..] - ETA: 12s - loss: 0.1092 - sparse_categorical_accuracy: 0.9663\n",
            "442/469 [===========================>..] - ETA: 11s - loss: 0.1094 - sparse_categorical_accuracy: 0.9663\n",
            "443/469 [===========================>..] - ETA: 11s - loss: 0.1093 - sparse_categorical_accuracy: 0.9664\n",
            "444/469 [===========================>..] - ETA: 10s - loss: 0.1092 - sparse_categorical_accuracy: 0.9664\n",
            "445/469 [===========================>..] - ETA: 10s - loss: 0.1091 - sparse_categorical_accuracy: 0.9664\n",
            "446/469 [===========================>..] - ETA: 10s - loss: 0.1091 - sparse_categorical_accuracy: 0.9664\n",
            "447/469 [===========================>..] - ETA: 9s - loss: 0.1093 - sparse_categorical_accuracy: 0.9663 \n",
            "448/469 [===========================>..] - ETA: 9s - loss: 0.1092 - sparse_categorical_accuracy: 0.9664\n",
            "449/469 [===========================>..] - ETA: 8s - loss: 0.1092 - sparse_categorical_accuracy: 0.9664\n",
            "450/469 [===========================>..] - ETA: 8s - loss: 0.1091 - sparse_categorical_accuracy: 0.9664\n",
            "451/469 [===========================>..] - ETA: 7s - loss: 0.1090 - sparse_categorical_accuracy: 0.9664\n",
            "452/469 [===========================>..] - ETA: 7s - loss: 0.1090 - sparse_categorical_accuracy: 0.9664\n",
            "453/469 [===========================>..] - ETA: 7s - loss: 0.1090 - sparse_categorical_accuracy: 0.9664\n",
            "454/469 [============================>.] - ETA: 6s - loss: 0.1088 - sparse_categorical_accuracy: 0.9664\n",
            "455/469 [============================>.] - ETA: 6s - loss: 0.1088 - sparse_categorical_accuracy: 0.9664\n",
            "456/469 [============================>.] - ETA: 5s - loss: 0.1087 - sparse_categorical_accuracy: 0.9665\n",
            "457/469 [============================>.] - ETA: 5s - loss: 0.1087 - sparse_categorical_accuracy: 0.9665\n",
            "458/469 [============================>.] - ETA: 4s - loss: 0.1085 - sparse_categorical_accuracy: 0.9665\n",
            "459/469 [============================>.] - ETA: 4s - loss: 0.1085 - sparse_categorical_accuracy: 0.9665\n",
            "460/469 [============================>.] - ETA: 3s - loss: 0.1086 - sparse_categorical_accuracy: 0.9664\n",
            "461/469 [============================>.] - ETA: 3s - loss: 0.1085 - sparse_categorical_accuracy: 0.9664\n",
            "462/469 [============================>.] - ETA: 3s - loss: 0.1084 - sparse_categorical_accuracy: 0.9665\n",
            "463/469 [============================>.] - ETA: 2s - loss: 0.1085 - sparse_categorical_accuracy: 0.9664\n",
            "464/469 [============================>.] - ETA: 2s - loss: 0.1085 - sparse_categorical_accuracy: 0.9664\n",
            "465/469 [============================>.] - ETA: 1s - loss: 0.1084 - sparse_categorical_accuracy: 0.9665\n",
            "466/469 [============================>.] - ETA: 1s - loss: 0.1083 - sparse_categorical_accuracy: 0.9665\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.1084 - sparse_categorical_accuracy: 0.9665\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.1085 - sparse_categorical_accuracy: 0.9665\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1086 - sparse_categorical_accuracy: 0.9665\n",
            " 60%|██████    | 3/5 [1:03:50<34:52, 1046.39s/trial, best loss: -0.9839000105857849]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/04/16 01:35:51 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 206s 439ms/step - loss: 0.1086 - sparse_categorical_accuracy: 0.9665\n",
            "\n",
            "Epoch 3/5\n",
            "\n",
            "  1/469 [..............................] - ETA: 3:49 - loss: 0.0879 - sparse_categorical_accuracy: 0.9453\n",
            "  2/469 [..............................] - ETA: 3:00 - loss: 0.1335 - sparse_categorical_accuracy: 0.9375\n",
            "  3/469 [..............................] - ETA: 3:00 - loss: 0.1295 - sparse_categorical_accuracy: 0.9479\n",
            "  4/469 [..............................] - ETA: 3:01 - loss: 0.1257 - sparse_categorical_accuracy: 0.9531\n",
            "  5/469 [..............................] - ETA: 3:01 - loss: 0.1248 - sparse_categorical_accuracy: 0.9547\n",
            "  6/469 [..............................] - ETA: 3:02 - loss: 0.1154 - sparse_categorical_accuracy: 0.9583\n",
            "  7/469 [..............................] - ETA: 3:01 - loss: 0.1113 - sparse_categorical_accuracy: 0.9576\n",
            "  8/469 [..............................] - ETA: 3:00 - loss: 0.1117 - sparse_categorical_accuracy: 0.9590\n",
            "  9/469 [..............................] - ETA: 3:01 - loss: 0.1072 - sparse_categorical_accuracy: 0.9601\n",
            " 10/469 [..............................] - ETA: 3:00 - loss: 0.1030 - sparse_categorical_accuracy: 0.9625\n",
            " 11/469 [..............................] - ETA: 2:59 - loss: 0.1076 - sparse_categorical_accuracy: 0.9638\n",
            " 12/469 [..............................] - ETA: 2:59 - loss: 0.1049 - sparse_categorical_accuracy: 0.9635\n",
            " 13/469 [..............................] - ETA: 2:58 - loss: 0.1030 - sparse_categorical_accuracy: 0.9639\n",
            " 14/469 [..............................] - ETA: 2:59 - loss: 0.1052 - sparse_categorical_accuracy: 0.9637\n",
            " 15/469 [..............................] - ETA: 3:07 - loss: 0.1003 - sparse_categorical_accuracy: 0.9661\n",
            " 16/469 [>.............................] - ETA: 3:14 - loss: 0.0967 - sparse_categorical_accuracy: 0.9673\n",
            " 17/469 [>.............................] - ETA: 3:19 - loss: 0.0938 - sparse_categorical_accuracy: 0.9688\n",
            " 18/469 [>.............................] - ETA: 3:25 - loss: 0.0938 - sparse_categorical_accuracy: 0.9688\n",
            " 19/469 [>.............................] - ETA: 3:27 - loss: 0.0921 - sparse_categorical_accuracy: 0.9696\n",
            " 20/469 [>.............................] - ETA: 3:25 - loss: 0.0938 - sparse_categorical_accuracy: 0.9695\n",
            " 21/469 [>.............................] - ETA: 3:22 - loss: 0.0920 - sparse_categorical_accuracy: 0.9702\n",
            " 22/469 [>.............................] - ETA: 3:21 - loss: 0.0915 - sparse_categorical_accuracy: 0.9705\n",
            " 23/469 [>.............................] - ETA: 3:19 - loss: 0.0895 - sparse_categorical_accuracy: 0.9711\n",
            " 24/469 [>.............................] - ETA: 3:17 - loss: 0.0877 - sparse_categorical_accuracy: 0.9720\n",
            " 25/469 [>.............................] - ETA: 3:16 - loss: 0.0865 - sparse_categorical_accuracy: 0.9725\n",
            " 26/469 [>.............................] - ETA: 3:14 - loss: 0.0878 - sparse_categorical_accuracy: 0.9715\n",
            " 27/469 [>.............................] - ETA: 3:13 - loss: 0.0895 - sparse_categorical_accuracy: 0.9711\n",
            " 28/469 [>.............................] - ETA: 3:12 - loss: 0.0882 - sparse_categorical_accuracy: 0.9718\n",
            " 29/469 [>.............................] - ETA: 3:11 - loss: 0.0893 - sparse_categorical_accuracy: 0.9712\n",
            " 30/469 [>.............................] - ETA: 3:10 - loss: 0.0907 - sparse_categorical_accuracy: 0.9703\n",
            " 31/469 [>.............................] - ETA: 3:09 - loss: 0.0918 - sparse_categorical_accuracy: 0.9698\n",
            " 32/469 [=>............................] - ETA: 3:08 - loss: 0.0907 - sparse_categorical_accuracy: 0.9700\n",
            " 33/469 [=>............................] - ETA: 3:07 - loss: 0.0905 - sparse_categorical_accuracy: 0.9697\n",
            " 34/469 [=>............................] - ETA: 3:06 - loss: 0.0909 - sparse_categorical_accuracy: 0.9697\n",
            " 35/469 [=>............................] - ETA: 3:05 - loss: 0.0894 - sparse_categorical_accuracy: 0.9703\n",
            " 36/469 [=>............................] - ETA: 3:04 - loss: 0.0895 - sparse_categorical_accuracy: 0.9703\n",
            " 37/469 [=>............................] - ETA: 3:03 - loss: 0.0890 - sparse_categorical_accuracy: 0.9704\n",
            " 38/469 [=>............................] - ETA: 3:02 - loss: 0.0889 - sparse_categorical_accuracy: 0.9704\n",
            " 39/469 [=>............................] - ETA: 3:01 - loss: 0.0886 - sparse_categorical_accuracy: 0.9706\n",
            " 40/469 [=>............................] - ETA: 3:00 - loss: 0.0875 - sparse_categorical_accuracy: 0.9709\n",
            " 41/469 [=>............................] - ETA: 3:00 - loss: 0.0864 - sparse_categorical_accuracy: 0.9712\n",
            " 42/469 [=>............................] - ETA: 2:59 - loss: 0.0861 - sparse_categorical_accuracy: 0.9715\n",
            " 43/469 [=>............................] - ETA: 2:58 - loss: 0.0859 - sparse_categorical_accuracy: 0.9715\n",
            " 44/469 [=>............................] - ETA: 2:58 - loss: 0.0860 - sparse_categorical_accuracy: 0.9712\n",
            " 45/469 [=>............................] - ETA: 2:58 - loss: 0.0853 - sparse_categorical_accuracy: 0.9714\n",
            " 46/469 [=>............................] - ETA: 3:00 - loss: 0.0844 - sparse_categorical_accuracy: 0.9716\n",
            " 47/469 [==>...........................] - ETA: 3:01 - loss: 0.0853 - sparse_categorical_accuracy: 0.9714\n",
            " 48/469 [==>...........................] - ETA: 3:02 - loss: 0.0859 - sparse_categorical_accuracy: 0.9714\n",
            " 49/469 [==>...........................] - ETA: 3:03 - loss: 0.0858 - sparse_categorical_accuracy: 0.9713\n",
            " 50/469 [==>...........................] - ETA: 3:04 - loss: 0.0860 - sparse_categorical_accuracy: 0.9712\n",
            " 51/469 [==>...........................] - ETA: 3:03 - loss: 0.0872 - sparse_categorical_accuracy: 0.9710\n",
            " 52/469 [==>...........................] - ETA: 3:03 - loss: 0.0863 - sparse_categorical_accuracy: 0.9713\n",
            " 53/469 [==>...........................] - ETA: 3:02 - loss: 0.0865 - sparse_categorical_accuracy: 0.9714\n",
            " 54/469 [==>...........................] - ETA: 3:01 - loss: 0.0867 - sparse_categorical_accuracy: 0.9712\n",
            " 55/469 [==>...........................] - ETA: 3:00 - loss: 0.0863 - sparse_categorical_accuracy: 0.9713\n",
            " 56/469 [==>...........................] - ETA: 3:00 - loss: 0.0862 - sparse_categorical_accuracy: 0.9714\n",
            " 57/469 [==>...........................] - ETA: 2:59 - loss: 0.0865 - sparse_categorical_accuracy: 0.9712\n",
            " 58/469 [==>...........................] - ETA: 2:58 - loss: 0.0857 - sparse_categorical_accuracy: 0.9714\n",
            " 59/469 [==>...........................] - ETA: 2:57 - loss: 0.0851 - sparse_categorical_accuracy: 0.9717\n",
            " 60/469 [==>...........................] - ETA: 2:57 - loss: 0.0856 - sparse_categorical_accuracy: 0.9717\n",
            " 61/469 [==>...........................] - ETA: 2:56 - loss: 0.0846 - sparse_categorical_accuracy: 0.9722\n",
            " 62/469 [==>...........................] - ETA: 2:55 - loss: 0.0845 - sparse_categorical_accuracy: 0.9722\n",
            " 63/469 [===>..........................] - ETA: 2:55 - loss: 0.0849 - sparse_categorical_accuracy: 0.9719\n",
            " 64/469 [===>..........................] - ETA: 2:54 - loss: 0.0847 - sparse_categorical_accuracy: 0.9719\n",
            " 65/469 [===>..........................] - ETA: 2:53 - loss: 0.0851 - sparse_categorical_accuracy: 0.9719\n",
            " 66/469 [===>..........................] - ETA: 2:53 - loss: 0.0848 - sparse_categorical_accuracy: 0.9719\n",
            " 67/469 [===>..........................] - ETA: 2:52 - loss: 0.0841 - sparse_categorical_accuracy: 0.9722\n",
            " 68/469 [===>..........................] - ETA: 2:52 - loss: 0.0837 - sparse_categorical_accuracy: 0.9724\n",
            " 69/469 [===>..........................] - ETA: 2:51 - loss: 0.0839 - sparse_categorical_accuracy: 0.9724\n",
            " 70/469 [===>..........................] - ETA: 2:50 - loss: 0.0846 - sparse_categorical_accuracy: 0.9722\n",
            " 71/469 [===>..........................] - ETA: 2:50 - loss: 0.0845 - sparse_categorical_accuracy: 0.9724\n",
            " 72/469 [===>..........................] - ETA: 2:49 - loss: 0.0839 - sparse_categorical_accuracy: 0.9727\n",
            " 73/469 [===>..........................] - ETA: 2:48 - loss: 0.0837 - sparse_categorical_accuracy: 0.9726\n",
            " 74/469 [===>..........................] - ETA: 2:48 - loss: 0.0843 - sparse_categorical_accuracy: 0.9727\n",
            " 75/469 [===>..........................] - ETA: 2:47 - loss: 0.0854 - sparse_categorical_accuracy: 0.9720\n",
            " 76/469 [===>..........................] - ETA: 2:48 - loss: 0.0857 - sparse_categorical_accuracy: 0.9718\n",
            " 77/469 [===>..........................] - ETA: 2:48 - loss: 0.0863 - sparse_categorical_accuracy: 0.9718\n",
            " 78/469 [===>..........................] - ETA: 2:49 - loss: 0.0873 - sparse_categorical_accuracy: 0.9718\n",
            " 79/469 [====>.........................] - ETA: 2:50 - loss: 0.0869 - sparse_categorical_accuracy: 0.9719\n",
            " 80/469 [====>.........................] - ETA: 2:50 - loss: 0.0871 - sparse_categorical_accuracy: 0.9717\n",
            " 81/469 [====>.........................] - ETA: 2:50 - loss: 0.0871 - sparse_categorical_accuracy: 0.9718\n",
            " 82/469 [====>.........................] - ETA: 2:49 - loss: 0.0869 - sparse_categorical_accuracy: 0.9719\n",
            " 83/469 [====>.........................] - ETA: 2:49 - loss: 0.0869 - sparse_categorical_accuracy: 0.9720\n",
            " 84/469 [====>.........................] - ETA: 2:48 - loss: 0.0884 - sparse_categorical_accuracy: 0.9717\n",
            " 85/469 [====>.........................] - ETA: 2:47 - loss: 0.0884 - sparse_categorical_accuracy: 0.9718\n",
            " 86/469 [====>.........................] - ETA: 2:47 - loss: 0.0882 - sparse_categorical_accuracy: 0.9717\n",
            " 87/469 [====>.........................] - ETA: 2:46 - loss: 0.0879 - sparse_categorical_accuracy: 0.9719\n",
            " 88/469 [====>.........................] - ETA: 2:46 - loss: 0.0875 - sparse_categorical_accuracy: 0.9721\n",
            " 89/469 [====>.........................] - ETA: 2:45 - loss: 0.0870 - sparse_categorical_accuracy: 0.9723\n",
            " 90/469 [====>.........................] - ETA: 2:44 - loss: 0.0869 - sparse_categorical_accuracy: 0.9724\n",
            " 91/469 [====>.........................] - ETA: 2:44 - loss: 0.0864 - sparse_categorical_accuracy: 0.9726\n",
            " 92/469 [====>.........................] - ETA: 2:43 - loss: 0.0865 - sparse_categorical_accuracy: 0.9727\n",
            " 93/469 [====>.........................] - ETA: 2:43 - loss: 0.0864 - sparse_categorical_accuracy: 0.9728\n",
            " 94/469 [=====>........................] - ETA: 2:42 - loss: 0.0862 - sparse_categorical_accuracy: 0.9728\n",
            " 95/469 [=====>........................] - ETA: 2:41 - loss: 0.0855 - sparse_categorical_accuracy: 0.9731\n",
            " 96/469 [=====>........................] - ETA: 2:41 - loss: 0.0849 - sparse_categorical_accuracy: 0.9733\n",
            " 97/469 [=====>........................] - ETA: 2:40 - loss: 0.0852 - sparse_categorical_accuracy: 0.9733\n",
            " 98/469 [=====>........................] - ETA: 2:40 - loss: 0.0852 - sparse_categorical_accuracy: 0.9735\n",
            " 99/469 [=====>........................] - ETA: 2:39 - loss: 0.0851 - sparse_categorical_accuracy: 0.9735\n",
            "100/469 [=====>........................] - ETA: 2:39 - loss: 0.0849 - sparse_categorical_accuracy: 0.9734\n",
            "101/469 [=====>........................] - ETA: 2:38 - loss: 0.0849 - sparse_categorical_accuracy: 0.9735\n",
            "102/469 [=====>........................] - ETA: 2:37 - loss: 0.0844 - sparse_categorical_accuracy: 0.9737\n",
            "103/469 [=====>........................] - ETA: 2:37 - loss: 0.0844 - sparse_categorical_accuracy: 0.9736\n",
            "104/469 [=====>........................] - ETA: 2:36 - loss: 0.0840 - sparse_categorical_accuracy: 0.9737\n",
            "105/469 [=====>........................] - ETA: 2:36 - loss: 0.0839 - sparse_categorical_accuracy: 0.9739\n",
            "106/469 [=====>........................] - ETA: 2:36 - loss: 0.0843 - sparse_categorical_accuracy: 0.9738\n",
            "107/469 [=====>........................] - ETA: 2:36 - loss: 0.0840 - sparse_categorical_accuracy: 0.9739\n",
            "108/469 [=====>........................] - ETA: 2:36 - loss: 0.0836 - sparse_categorical_accuracy: 0.9739\n",
            "109/469 [=====>........................] - ETA: 2:36 - loss: 0.0836 - sparse_categorical_accuracy: 0.9738\n",
            "110/469 [======>.......................] - ETA: 2:36 - loss: 0.0843 - sparse_categorical_accuracy: 0.9735\n",
            "111/469 [======>.......................] - ETA: 2:37 - loss: 0.0841 - sparse_categorical_accuracy: 0.9736\n",
            "112/469 [======>.......................] - ETA: 2:36 - loss: 0.0839 - sparse_categorical_accuracy: 0.9736\n",
            "113/469 [======>.......................] - ETA: 2:35 - loss: 0.0838 - sparse_categorical_accuracy: 0.9737\n",
            "114/469 [======>.......................] - ETA: 2:35 - loss: 0.0835 - sparse_categorical_accuracy: 0.9738\n",
            "115/469 [======>.......................] - ETA: 2:34 - loss: 0.0833 - sparse_categorical_accuracy: 0.9738\n",
            "116/469 [======>.......................] - ETA: 2:34 - loss: 0.0829 - sparse_categorical_accuracy: 0.9739\n",
            "117/469 [======>.......................] - ETA: 2:33 - loss: 0.0833 - sparse_categorical_accuracy: 0.9739\n",
            "118/469 [======>.......................] - ETA: 2:33 - loss: 0.0845 - sparse_categorical_accuracy: 0.9735\n",
            "119/469 [======>.......................] - ETA: 2:32 - loss: 0.0854 - sparse_categorical_accuracy: 0.9734\n",
            "120/469 [======>.......................] - ETA: 2:32 - loss: 0.0850 - sparse_categorical_accuracy: 0.9736\n",
            "121/469 [======>.......................] - ETA: 2:31 - loss: 0.0847 - sparse_categorical_accuracy: 0.9737\n",
            "122/469 [======>.......................] - ETA: 2:30 - loss: 0.0847 - sparse_categorical_accuracy: 0.9736\n",
            "123/469 [======>.......................] - ETA: 2:30 - loss: 0.0849 - sparse_categorical_accuracy: 0.9736\n",
            "124/469 [======>.......................] - ETA: 2:29 - loss: 0.0848 - sparse_categorical_accuracy: 0.9735\n",
            "125/469 [======>.......................] - ETA: 2:29 - loss: 0.0848 - sparse_categorical_accuracy: 0.9735\n",
            "126/469 [=======>......................] - ETA: 2:28 - loss: 0.0853 - sparse_categorical_accuracy: 0.9733\n",
            "127/469 [=======>......................] - ETA: 2:28 - loss: 0.0856 - sparse_categorical_accuracy: 0.9732\n",
            "128/469 [=======>......................] - ETA: 2:27 - loss: 0.0857 - sparse_categorical_accuracy: 0.9732\n",
            "129/469 [=======>......................] - ETA: 2:26 - loss: 0.0858 - sparse_categorical_accuracy: 0.9732\n",
            "130/469 [=======>......................] - ETA: 2:26 - loss: 0.0857 - sparse_categorical_accuracy: 0.9732\n",
            "131/469 [=======>......................] - ETA: 2:25 - loss: 0.0858 - sparse_categorical_accuracy: 0.9732\n",
            "132/469 [=======>......................] - ETA: 2:25 - loss: 0.0855 - sparse_categorical_accuracy: 0.9733\n",
            "133/469 [=======>......................] - ETA: 2:24 - loss: 0.0858 - sparse_categorical_accuracy: 0.9732\n",
            "134/469 [=======>......................] - ETA: 2:24 - loss: 0.0855 - sparse_categorical_accuracy: 0.9732\n",
            "135/469 [=======>......................] - ETA: 2:23 - loss: 0.0853 - sparse_categorical_accuracy: 0.9733\n",
            "136/469 [=======>......................] - ETA: 2:23 - loss: 0.0853 - sparse_categorical_accuracy: 0.9735\n",
            "137/469 [=======>......................] - ETA: 2:22 - loss: 0.0854 - sparse_categorical_accuracy: 0.9734\n",
            "138/469 [=======>......................] - ETA: 2:22 - loss: 0.0856 - sparse_categorical_accuracy: 0.9734\n",
            "139/469 [=======>......................] - ETA: 2:22 - loss: 0.0854 - sparse_categorical_accuracy: 0.9735\n",
            "140/469 [=======>......................] - ETA: 2:22 - loss: 0.0856 - sparse_categorical_accuracy: 0.9734\n",
            "141/469 [========>.....................] - ETA: 2:22 - loss: 0.0858 - sparse_categorical_accuracy: 0.9733\n",
            "142/469 [========>.....................] - ETA: 2:22 - loss: 0.0860 - sparse_categorical_accuracy: 0.9733\n",
            "143/469 [========>.....................] - ETA: 2:22 - loss: 0.0859 - sparse_categorical_accuracy: 0.9734\n",
            "144/469 [========>.....................] - ETA: 2:21 - loss: 0.0858 - sparse_categorical_accuracy: 0.9734\n",
            "145/469 [========>.....................] - ETA: 2:21 - loss: 0.0858 - sparse_categorical_accuracy: 0.9734\n",
            "146/469 [========>.....................] - ETA: 2:20 - loss: 0.0858 - sparse_categorical_accuracy: 0.9732\n",
            "147/469 [========>.....................] - ETA: 2:20 - loss: 0.0858 - sparse_categorical_accuracy: 0.9733\n",
            "148/469 [========>.....................] - ETA: 2:19 - loss: 0.0859 - sparse_categorical_accuracy: 0.9733\n",
            "149/469 [========>.....................] - ETA: 2:19 - loss: 0.0855 - sparse_categorical_accuracy: 0.9734\n",
            "150/469 [========>.....................] - ETA: 2:18 - loss: 0.0853 - sparse_categorical_accuracy: 0.9735\n",
            "151/469 [========>.....................] - ETA: 2:18 - loss: 0.0853 - sparse_categorical_accuracy: 0.9735\n",
            "152/469 [========>.....................] - ETA: 2:17 - loss: 0.0860 - sparse_categorical_accuracy: 0.9734\n",
            "153/469 [========>.....................] - ETA: 2:17 - loss: 0.0857 - sparse_categorical_accuracy: 0.9735\n",
            "154/469 [========>.....................] - ETA: 2:16 - loss: 0.0854 - sparse_categorical_accuracy: 0.9736\n",
            "155/469 [========>.....................] - ETA: 2:16 - loss: 0.0854 - sparse_categorical_accuracy: 0.9737\n",
            "156/469 [========>.....................] - ETA: 2:15 - loss: 0.0856 - sparse_categorical_accuracy: 0.9737\n",
            "157/469 [=========>....................] - ETA: 2:15 - loss: 0.0853 - sparse_categorical_accuracy: 0.9738\n",
            "158/469 [=========>....................] - ETA: 2:14 - loss: 0.0855 - sparse_categorical_accuracy: 0.9737\n",
            "159/469 [=========>....................] - ETA: 2:14 - loss: 0.0856 - sparse_categorical_accuracy: 0.9738\n",
            "160/469 [=========>....................] - ETA: 2:13 - loss: 0.0855 - sparse_categorical_accuracy: 0.9738\n",
            "161/469 [=========>....................] - ETA: 2:13 - loss: 0.0855 - sparse_categorical_accuracy: 0.9737\n",
            "162/469 [=========>....................] - ETA: 2:12 - loss: 0.0853 - sparse_categorical_accuracy: 0.9738\n",
            "163/469 [=========>....................] - ETA: 2:12 - loss: 0.0859 - sparse_categorical_accuracy: 0.9737\n",
            "164/469 [=========>....................] - ETA: 2:11 - loss: 0.0859 - sparse_categorical_accuracy: 0.9736\n",
            "165/469 [=========>....................] - ETA: 2:11 - loss: 0.0860 - sparse_categorical_accuracy: 0.9736\n",
            "166/469 [=========>....................] - ETA: 2:10 - loss: 0.0860 - sparse_categorical_accuracy: 0.9735\n",
            "167/469 [=========>....................] - ETA: 2:10 - loss: 0.0867 - sparse_categorical_accuracy: 0.9734\n",
            "168/469 [=========>....................] - ETA: 2:09 - loss: 0.0865 - sparse_categorical_accuracy: 0.9734\n",
            "169/469 [=========>....................] - ETA: 2:09 - loss: 0.0862 - sparse_categorical_accuracy: 0.9734\n",
            "170/469 [=========>....................] - ETA: 2:09 - loss: 0.0858 - sparse_categorical_accuracy: 0.9736\n",
            "171/469 [=========>....................] - ETA: 2:09 - loss: 0.0858 - sparse_categorical_accuracy: 0.9736\n",
            "172/469 [==========>...................] - ETA: 2:09 - loss: 0.0856 - sparse_categorical_accuracy: 0.9736\n",
            "173/469 [==========>...................] - ETA: 2:09 - loss: 0.0859 - sparse_categorical_accuracy: 0.9735\n",
            "174/469 [==========>...................] - ETA: 2:08 - loss: 0.0862 - sparse_categorical_accuracy: 0.9734\n",
            "175/469 [==========>...................] - ETA: 2:08 - loss: 0.0861 - sparse_categorical_accuracy: 0.9735\n",
            "176/469 [==========>...................] - ETA: 2:07 - loss: 0.0861 - sparse_categorical_accuracy: 0.9735\n",
            "177/469 [==========>...................] - ETA: 2:07 - loss: 0.0858 - sparse_categorical_accuracy: 0.9736\n",
            "178/469 [==========>...................] - ETA: 2:06 - loss: 0.0856 - sparse_categorical_accuracy: 0.9737\n",
            "179/469 [==========>...................] - ETA: 2:06 - loss: 0.0854 - sparse_categorical_accuracy: 0.9737\n",
            "180/469 [==========>...................] - ETA: 2:05 - loss: 0.0854 - sparse_categorical_accuracy: 0.9738\n",
            "181/469 [==========>...................] - ETA: 2:05 - loss: 0.0853 - sparse_categorical_accuracy: 0.9738\n",
            "182/469 [==========>...................] - ETA: 2:04 - loss: 0.0858 - sparse_categorical_accuracy: 0.9737\n",
            "183/469 [==========>...................] - ETA: 2:04 - loss: 0.0856 - sparse_categorical_accuracy: 0.9737\n",
            "184/469 [==========>...................] - ETA: 2:03 - loss: 0.0855 - sparse_categorical_accuracy: 0.9738\n",
            "185/469 [==========>...................] - ETA: 2:03 - loss: 0.0856 - sparse_categorical_accuracy: 0.9738\n",
            "186/469 [==========>...................] - ETA: 2:02 - loss: 0.0858 - sparse_categorical_accuracy: 0.9736\n",
            "187/469 [==========>...................] - ETA: 2:02 - loss: 0.0856 - sparse_categorical_accuracy: 0.9736\n",
            "188/469 [===========>..................] - ETA: 2:01 - loss: 0.0854 - sparse_categorical_accuracy: 0.9737\n",
            "189/469 [===========>..................] - ETA: 2:01 - loss: 0.0856 - sparse_categorical_accuracy: 0.9737\n",
            "190/469 [===========>..................] - ETA: 2:00 - loss: 0.0856 - sparse_categorical_accuracy: 0.9737\n",
            "191/469 [===========>..................] - ETA: 2:00 - loss: 0.0854 - sparse_categorical_accuracy: 0.9737\n",
            "192/469 [===========>..................] - ETA: 2:00 - loss: 0.0853 - sparse_categorical_accuracy: 0.9737\n",
            "193/469 [===========>..................] - ETA: 1:59 - loss: 0.0858 - sparse_categorical_accuracy: 0.9736\n",
            "194/469 [===========>..................] - ETA: 1:59 - loss: 0.0855 - sparse_categorical_accuracy: 0.9737\n",
            "195/469 [===========>..................] - ETA: 1:58 - loss: 0.0855 - sparse_categorical_accuracy: 0.9737\n",
            "196/469 [===========>..................] - ETA: 1:58 - loss: 0.0856 - sparse_categorical_accuracy: 0.9737\n",
            "197/469 [===========>..................] - ETA: 1:57 - loss: 0.0856 - sparse_categorical_accuracy: 0.9737\n",
            "198/469 [===========>..................] - ETA: 1:57 - loss: 0.0859 - sparse_categorical_accuracy: 0.9736\n",
            "199/469 [===========>..................] - ETA: 1:56 - loss: 0.0857 - sparse_categorical_accuracy: 0.9737\n",
            "200/469 [===========>..................] - ETA: 1:56 - loss: 0.0855 - sparse_categorical_accuracy: 0.9737\n",
            "201/469 [===========>..................] - ETA: 1:56 - loss: 0.0854 - sparse_categorical_accuracy: 0.9737\n",
            "202/469 [===========>..................] - ETA: 1:56 - loss: 0.0856 - sparse_categorical_accuracy: 0.9737\n",
            "203/469 [===========>..................] - ETA: 1:56 - loss: 0.0854 - sparse_categorical_accuracy: 0.9738\n",
            "204/469 [============>.................] - ETA: 1:55 - loss: 0.0853 - sparse_categorical_accuracy: 0.9738\n",
            "205/469 [============>.................] - ETA: 1:55 - loss: 0.0854 - sparse_categorical_accuracy: 0.9738\n",
            "206/469 [============>.................] - ETA: 1:54 - loss: 0.0854 - sparse_categorical_accuracy: 0.9738\n",
            "207/469 [============>.................] - ETA: 1:54 - loss: 0.0855 - sparse_categorical_accuracy: 0.9738\n",
            "208/469 [============>.................] - ETA: 1:53 - loss: 0.0853 - sparse_categorical_accuracy: 0.9738\n",
            "209/469 [============>.................] - ETA: 1:53 - loss: 0.0851 - sparse_categorical_accuracy: 0.9739\n",
            "210/469 [============>.................] - ETA: 1:53 - loss: 0.0848 - sparse_categorical_accuracy: 0.9740\n",
            "211/469 [============>.................] - ETA: 1:52 - loss: 0.0850 - sparse_categorical_accuracy: 0.9740\n",
            "212/469 [============>.................] - ETA: 1:52 - loss: 0.0849 - sparse_categorical_accuracy: 0.9740\n",
            "213/469 [============>.................] - ETA: 1:51 - loss: 0.0851 - sparse_categorical_accuracy: 0.9740\n",
            "214/469 [============>.................] - ETA: 1:51 - loss: 0.0849 - sparse_categorical_accuracy: 0.9740\n",
            "215/469 [============>.................] - ETA: 1:50 - loss: 0.0851 - sparse_categorical_accuracy: 0.9740\n",
            "216/469 [============>.................] - ETA: 1:50 - loss: 0.0853 - sparse_categorical_accuracy: 0.9740\n",
            "217/469 [============>.................] - ETA: 1:49 - loss: 0.0857 - sparse_categorical_accuracy: 0.9740\n",
            "218/469 [============>.................] - ETA: 1:49 - loss: 0.0856 - sparse_categorical_accuracy: 0.9740\n",
            "219/469 [=============>................] - ETA: 1:48 - loss: 0.0861 - sparse_categorical_accuracy: 0.9740\n",
            "220/469 [=============>................] - ETA: 1:48 - loss: 0.0862 - sparse_categorical_accuracy: 0.9740\n",
            "221/469 [=============>................] - ETA: 1:47 - loss: 0.0862 - sparse_categorical_accuracy: 0.9740\n",
            "222/469 [=============>................] - ETA: 1:47 - loss: 0.0866 - sparse_categorical_accuracy: 0.9740\n",
            "223/469 [=============>................] - ETA: 1:46 - loss: 0.0864 - sparse_categorical_accuracy: 0.9740\n",
            "224/469 [=============>................] - ETA: 1:46 - loss: 0.0862 - sparse_categorical_accuracy: 0.9741\n",
            "225/469 [=============>................] - ETA: 1:45 - loss: 0.0861 - sparse_categorical_accuracy: 0.9740\n",
            "226/469 [=============>................] - ETA: 1:45 - loss: 0.0861 - sparse_categorical_accuracy: 0.9740\n",
            "227/469 [=============>................] - ETA: 1:44 - loss: 0.0862 - sparse_categorical_accuracy: 0.9739\n",
            "228/469 [=============>................] - ETA: 1:44 - loss: 0.0860 - sparse_categorical_accuracy: 0.9740\n",
            "229/469 [=============>................] - ETA: 1:44 - loss: 0.0859 - sparse_categorical_accuracy: 0.9740\n",
            "230/469 [=============>................] - ETA: 1:43 - loss: 0.0858 - sparse_categorical_accuracy: 0.9740\n",
            "231/469 [=============>................] - ETA: 1:43 - loss: 0.0857 - sparse_categorical_accuracy: 0.9741\n",
            "232/469 [=============>................] - ETA: 1:43 - loss: 0.0860 - sparse_categorical_accuracy: 0.9741\n",
            "233/469 [=============>................] - ETA: 1:42 - loss: 0.0859 - sparse_categorical_accuracy: 0.9741\n",
            "234/469 [=============>................] - ETA: 1:42 - loss: 0.0859 - sparse_categorical_accuracy: 0.9741\n",
            "235/469 [==============>...............] - ETA: 1:42 - loss: 0.0858 - sparse_categorical_accuracy: 0.9741\n",
            "236/469 [==============>...............] - ETA: 1:41 - loss: 0.0856 - sparse_categorical_accuracy: 0.9742\n",
            "237/469 [==============>...............] - ETA: 1:41 - loss: 0.0860 - sparse_categorical_accuracy: 0.9741\n",
            "238/469 [==============>...............] - ETA: 1:40 - loss: 0.0859 - sparse_categorical_accuracy: 0.9741\n",
            "239/469 [==============>...............] - ETA: 1:40 - loss: 0.0858 - sparse_categorical_accuracy: 0.9741\n",
            "240/469 [==============>...............] - ETA: 1:40 - loss: 0.0858 - sparse_categorical_accuracy: 0.9741\n",
            "241/469 [==============>...............] - ETA: 1:39 - loss: 0.0859 - sparse_categorical_accuracy: 0.9741\n",
            "242/469 [==============>...............] - ETA: 1:39 - loss: 0.0861 - sparse_categorical_accuracy: 0.9740\n",
            "243/469 [==============>...............] - ETA: 1:38 - loss: 0.0861 - sparse_categorical_accuracy: 0.9740\n",
            "244/469 [==============>...............] - ETA: 1:38 - loss: 0.0859 - sparse_categorical_accuracy: 0.9740\n",
            "245/469 [==============>...............] - ETA: 1:37 - loss: 0.0859 - sparse_categorical_accuracy: 0.9740\n",
            "246/469 [==============>...............] - ETA: 1:37 - loss: 0.0857 - sparse_categorical_accuracy: 0.9741\n",
            "247/469 [==============>...............] - ETA: 1:36 - loss: 0.0856 - sparse_categorical_accuracy: 0.9741\n",
            "248/469 [==============>...............] - ETA: 1:36 - loss: 0.0858 - sparse_categorical_accuracy: 0.9740\n",
            "249/469 [==============>...............] - ETA: 1:35 - loss: 0.0856 - sparse_categorical_accuracy: 0.9740\n",
            "250/469 [==============>...............] - ETA: 1:35 - loss: 0.0854 - sparse_categorical_accuracy: 0.9740\n",
            "251/469 [===============>..............] - ETA: 1:34 - loss: 0.0855 - sparse_categorical_accuracy: 0.9740\n",
            "252/469 [===============>..............] - ETA: 1:34 - loss: 0.0853 - sparse_categorical_accuracy: 0.9741\n",
            "253/469 [===============>..............] - ETA: 1:33 - loss: 0.0853 - sparse_categorical_accuracy: 0.9740\n",
            "254/469 [===============>..............] - ETA: 1:33 - loss: 0.0853 - sparse_categorical_accuracy: 0.9740\n",
            "255/469 [===============>..............] - ETA: 1:32 - loss: 0.0852 - sparse_categorical_accuracy: 0.9740\n",
            "256/469 [===============>..............] - ETA: 1:32 - loss: 0.0852 - sparse_categorical_accuracy: 0.9741\n",
            "257/469 [===============>..............] - ETA: 1:32 - loss: 0.0852 - sparse_categorical_accuracy: 0.9740\n",
            "258/469 [===============>..............] - ETA: 1:31 - loss: 0.0851 - sparse_categorical_accuracy: 0.9740\n",
            "259/469 [===============>..............] - ETA: 1:31 - loss: 0.0850 - sparse_categorical_accuracy: 0.9740\n",
            "260/469 [===============>..............] - ETA: 1:30 - loss: 0.0851 - sparse_categorical_accuracy: 0.9740\n",
            "261/469 [===============>..............] - ETA: 1:30 - loss: 0.0850 - sparse_categorical_accuracy: 0.9740\n",
            "262/469 [===============>..............] - ETA: 1:29 - loss: 0.0850 - sparse_categorical_accuracy: 0.9739\n",
            "263/469 [===============>..............] - ETA: 1:29 - loss: 0.0849 - sparse_categorical_accuracy: 0.9739\n",
            "264/469 [===============>..............] - ETA: 1:29 - loss: 0.0849 - sparse_categorical_accuracy: 0.9740\n",
            "265/469 [===============>..............] - ETA: 1:28 - loss: 0.0848 - sparse_categorical_accuracy: 0.9740\n",
            "266/469 [================>.............] - ETA: 1:28 - loss: 0.0848 - sparse_categorical_accuracy: 0.9740\n",
            "267/469 [================>.............] - ETA: 1:28 - loss: 0.0849 - sparse_categorical_accuracy: 0.9740\n",
            "268/469 [================>.............] - ETA: 1:27 - loss: 0.0848 - sparse_categorical_accuracy: 0.9741\n",
            "269/469 [================>.............] - ETA: 1:27 - loss: 0.0847 - sparse_categorical_accuracy: 0.9741\n",
            "270/469 [================>.............] - ETA: 1:26 - loss: 0.0848 - sparse_categorical_accuracy: 0.9740\n",
            "271/469 [================>.............] - ETA: 1:26 - loss: 0.0848 - sparse_categorical_accuracy: 0.9740\n",
            "272/469 [================>.............] - ETA: 1:26 - loss: 0.0847 - sparse_categorical_accuracy: 0.9740\n",
            "273/469 [================>.............] - ETA: 1:25 - loss: 0.0845 - sparse_categorical_accuracy: 0.9741\n",
            "274/469 [================>.............] - ETA: 1:25 - loss: 0.0845 - sparse_categorical_accuracy: 0.9741\n",
            "275/469 [================>.............] - ETA: 1:24 - loss: 0.0845 - sparse_categorical_accuracy: 0.9740\n",
            "276/469 [================>.............] - ETA: 1:24 - loss: 0.0848 - sparse_categorical_accuracy: 0.9739\n",
            "277/469 [================>.............] - ETA: 1:23 - loss: 0.0850 - sparse_categorical_accuracy: 0.9739\n",
            "278/469 [================>.............] - ETA: 1:23 - loss: 0.0850 - sparse_categorical_accuracy: 0.9739\n",
            "279/469 [================>.............] - ETA: 1:22 - loss: 0.0850 - sparse_categorical_accuracy: 0.9739\n",
            "280/469 [================>.............] - ETA: 1:22 - loss: 0.0849 - sparse_categorical_accuracy: 0.9739\n",
            "281/469 [================>.............] - ETA: 1:21 - loss: 0.0850 - sparse_categorical_accuracy: 0.9739\n",
            "282/469 [=================>............] - ETA: 1:21 - loss: 0.0853 - sparse_categorical_accuracy: 0.9739\n",
            "283/469 [=================>............] - ETA: 1:21 - loss: 0.0852 - sparse_categorical_accuracy: 0.9739\n",
            "284/469 [=================>............] - ETA: 1:20 - loss: 0.0850 - sparse_categorical_accuracy: 0.9740\n",
            "285/469 [=================>............] - ETA: 1:20 - loss: 0.0849 - sparse_categorical_accuracy: 0.9740\n",
            "286/469 [=================>............] - ETA: 1:19 - loss: 0.0852 - sparse_categorical_accuracy: 0.9739\n",
            "287/469 [=================>............] - ETA: 1:19 - loss: 0.0851 - sparse_categorical_accuracy: 0.9739\n",
            "288/469 [=================>............] - ETA: 1:18 - loss: 0.0850 - sparse_categorical_accuracy: 0.9740\n",
            "289/469 [=================>............] - ETA: 1:18 - loss: 0.0851 - sparse_categorical_accuracy: 0.9739\n",
            "290/469 [=================>............] - ETA: 1:17 - loss: 0.0850 - sparse_categorical_accuracy: 0.9739\n",
            "291/469 [=================>............] - ETA: 1:17 - loss: 0.0847 - sparse_categorical_accuracy: 0.9740\n",
            "292/469 [=================>............] - ETA: 1:16 - loss: 0.0849 - sparse_categorical_accuracy: 0.9740\n",
            "293/469 [=================>............] - ETA: 1:16 - loss: 0.0850 - sparse_categorical_accuracy: 0.9739\n",
            "294/469 [=================>............] - ETA: 1:16 - loss: 0.0849 - sparse_categorical_accuracy: 0.9739\n",
            "295/469 [=================>............] - ETA: 1:16 - loss: 0.0848 - sparse_categorical_accuracy: 0.9740\n",
            "296/469 [=================>............] - ETA: 1:15 - loss: 0.0847 - sparse_categorical_accuracy: 0.9741\n",
            "297/469 [=================>............] - ETA: 1:15 - loss: 0.0845 - sparse_categorical_accuracy: 0.9741\n",
            "298/469 [==================>...........] - ETA: 1:14 - loss: 0.0846 - sparse_categorical_accuracy: 0.9741\n",
            "299/469 [==================>...........] - ETA: 1:14 - loss: 0.0845 - sparse_categorical_accuracy: 0.9741\n",
            "300/469 [==================>...........] - ETA: 1:14 - loss: 0.0846 - sparse_categorical_accuracy: 0.9741\n",
            "301/469 [==================>...........] - ETA: 1:13 - loss: 0.0846 - sparse_categorical_accuracy: 0.9741\n",
            "302/469 [==================>...........] - ETA: 1:13 - loss: 0.0845 - sparse_categorical_accuracy: 0.9741\n",
            "303/469 [==================>...........] - ETA: 1:12 - loss: 0.0844 - sparse_categorical_accuracy: 0.9741\n",
            "304/469 [==================>...........] - ETA: 1:12 - loss: 0.0844 - sparse_categorical_accuracy: 0.9741\n",
            "305/469 [==================>...........] - ETA: 1:11 - loss: 0.0843 - sparse_categorical_accuracy: 0.9741\n",
            "306/469 [==================>...........] - ETA: 1:11 - loss: 0.0842 - sparse_categorical_accuracy: 0.9741\n",
            "307/469 [==================>...........] - ETA: 1:10 - loss: 0.0841 - sparse_categorical_accuracy: 0.9741\n",
            "308/469 [==================>...........] - ETA: 1:10 - loss: 0.0839 - sparse_categorical_accuracy: 0.9742\n",
            "309/469 [==================>...........] - ETA: 1:09 - loss: 0.0839 - sparse_categorical_accuracy: 0.9742\n",
            "310/469 [==================>...........] - ETA: 1:09 - loss: 0.0838 - sparse_categorical_accuracy: 0.9743\n",
            "311/469 [==================>...........] - ETA: 1:09 - loss: 0.0839 - sparse_categorical_accuracy: 0.9742\n",
            "312/469 [==================>...........] - ETA: 1:08 - loss: 0.0839 - sparse_categorical_accuracy: 0.9742\n",
            "313/469 [===================>..........] - ETA: 1:08 - loss: 0.0840 - sparse_categorical_accuracy: 0.9742\n",
            "314/469 [===================>..........] - ETA: 1:07 - loss: 0.0840 - sparse_categorical_accuracy: 0.9741\n",
            "315/469 [===================>..........] - ETA: 1:07 - loss: 0.0841 - sparse_categorical_accuracy: 0.9741\n",
            "316/469 [===================>..........] - ETA: 1:06 - loss: 0.0840 - sparse_categorical_accuracy: 0.9742\n",
            "317/469 [===================>..........] - ETA: 1:06 - loss: 0.0841 - sparse_categorical_accuracy: 0.9741\n",
            "318/469 [===================>..........] - ETA: 1:05 - loss: 0.0839 - sparse_categorical_accuracy: 0.9741\n",
            "319/469 [===================>..........] - ETA: 1:05 - loss: 0.0838 - sparse_categorical_accuracy: 0.9742\n",
            "320/469 [===================>..........] - ETA: 1:04 - loss: 0.0839 - sparse_categorical_accuracy: 0.9742\n",
            "321/469 [===================>..........] - ETA: 1:04 - loss: 0.0837 - sparse_categorical_accuracy: 0.9743\n",
            "322/469 [===================>..........] - ETA: 1:04 - loss: 0.0839 - sparse_categorical_accuracy: 0.9743\n",
            "323/469 [===================>..........] - ETA: 1:03 - loss: 0.0838 - sparse_categorical_accuracy: 0.9743\n",
            "324/469 [===================>..........] - ETA: 1:03 - loss: 0.0836 - sparse_categorical_accuracy: 0.9743\n",
            "325/469 [===================>..........] - ETA: 1:03 - loss: 0.0837 - sparse_categorical_accuracy: 0.9743\n",
            "326/469 [===================>..........] - ETA: 1:02 - loss: 0.0836 - sparse_categorical_accuracy: 0.9743\n",
            "327/469 [===================>..........] - ETA: 1:02 - loss: 0.0835 - sparse_categorical_accuracy: 0.9743\n",
            "328/469 [===================>..........] - ETA: 1:01 - loss: 0.0836 - sparse_categorical_accuracy: 0.9743\n",
            "329/469 [====================>.........] - ETA: 1:01 - loss: 0.0836 - sparse_categorical_accuracy: 0.9744\n",
            "330/469 [====================>.........] - ETA: 1:01 - loss: 0.0838 - sparse_categorical_accuracy: 0.9743\n",
            "331/469 [====================>.........] - ETA: 1:00 - loss: 0.0837 - sparse_categorical_accuracy: 0.9743\n",
            "332/469 [====================>.........] - ETA: 1:00 - loss: 0.0837 - sparse_categorical_accuracy: 0.9743\n",
            "333/469 [====================>.........] - ETA: 59s - loss: 0.0838 - sparse_categorical_accuracy: 0.9743 \n",
            "334/469 [====================>.........] - ETA: 59s - loss: 0.0837 - sparse_categorical_accuracy: 0.9744\n",
            "335/469 [====================>.........] - ETA: 58s - loss: 0.0839 - sparse_categorical_accuracy: 0.9743\n",
            "336/469 [====================>.........] - ETA: 58s - loss: 0.0837 - sparse_categorical_accuracy: 0.9744\n",
            "337/469 [====================>.........] - ETA: 57s - loss: 0.0837 - sparse_categorical_accuracy: 0.9744\n",
            "338/469 [====================>.........] - ETA: 57s - loss: 0.0838 - sparse_categorical_accuracy: 0.9743\n",
            "339/469 [====================>.........] - ETA: 56s - loss: 0.0838 - sparse_categorical_accuracy: 0.9743\n",
            "340/469 [====================>.........] - ETA: 56s - loss: 0.0838 - sparse_categorical_accuracy: 0.9743\n",
            "341/469 [====================>.........] - ETA: 56s - loss: 0.0836 - sparse_categorical_accuracy: 0.9744\n",
            "342/469 [====================>.........] - ETA: 55s - loss: 0.0836 - sparse_categorical_accuracy: 0.9744\n",
            "343/469 [====================>.........] - ETA: 55s - loss: 0.0834 - sparse_categorical_accuracy: 0.9744\n",
            "344/469 [=====================>........] - ETA: 54s - loss: 0.0833 - sparse_categorical_accuracy: 0.9745\n",
            "345/469 [=====================>........] - ETA: 54s - loss: 0.0834 - sparse_categorical_accuracy: 0.9745\n",
            "346/469 [=====================>........] - ETA: 53s - loss: 0.0836 - sparse_categorical_accuracy: 0.9744\n",
            "347/469 [=====================>........] - ETA: 53s - loss: 0.0835 - sparse_categorical_accuracy: 0.9745\n",
            "348/469 [=====================>........] - ETA: 52s - loss: 0.0840 - sparse_categorical_accuracy: 0.9745\n",
            "349/469 [=====================>........] - ETA: 52s - loss: 0.0839 - sparse_categorical_accuracy: 0.9745\n",
            "350/469 [=====================>........] - ETA: 51s - loss: 0.0839 - sparse_categorical_accuracy: 0.9745\n",
            "351/469 [=====================>........] - ETA: 51s - loss: 0.0838 - sparse_categorical_accuracy: 0.9744\n",
            "352/469 [=====================>........] - ETA: 51s - loss: 0.0838 - sparse_categorical_accuracy: 0.9744\n",
            "353/469 [=====================>........] - ETA: 50s - loss: 0.0838 - sparse_categorical_accuracy: 0.9744\n",
            "354/469 [=====================>........] - ETA: 50s - loss: 0.0837 - sparse_categorical_accuracy: 0.9744\n",
            "355/469 [=====================>........] - ETA: 49s - loss: 0.0836 - sparse_categorical_accuracy: 0.9744\n",
            "356/469 [=====================>........] - ETA: 49s - loss: 0.0836 - sparse_categorical_accuracy: 0.9745\n",
            "357/469 [=====================>........] - ETA: 49s - loss: 0.0836 - sparse_categorical_accuracy: 0.9745\n",
            "358/469 [=====================>........] - ETA: 48s - loss: 0.0835 - sparse_categorical_accuracy: 0.9745\n",
            "359/469 [=====================>........] - ETA: 48s - loss: 0.0838 - sparse_categorical_accuracy: 0.9744\n",
            "360/469 [======================>.......] - ETA: 47s - loss: 0.0836 - sparse_categorical_accuracy: 0.9745\n",
            "361/469 [======================>.......] - ETA: 47s - loss: 0.0840 - sparse_categorical_accuracy: 0.9744\n",
            "362/469 [======================>.......] - ETA: 46s - loss: 0.0838 - sparse_categorical_accuracy: 0.9745\n",
            "363/469 [======================>.......] - ETA: 46s - loss: 0.0839 - sparse_categorical_accuracy: 0.9745\n",
            "364/469 [======================>.......] - ETA: 46s - loss: 0.0838 - sparse_categorical_accuracy: 0.9745\n",
            "365/469 [======================>.......] - ETA: 45s - loss: 0.0839 - sparse_categorical_accuracy: 0.9745\n",
            "366/469 [======================>.......] - ETA: 45s - loss: 0.0839 - sparse_categorical_accuracy: 0.9745\n",
            "367/469 [======================>.......] - ETA: 44s - loss: 0.0839 - sparse_categorical_accuracy: 0.9745\n",
            "368/469 [======================>.......] - ETA: 44s - loss: 0.0838 - sparse_categorical_accuracy: 0.9745\n",
            "369/469 [======================>.......] - ETA: 43s - loss: 0.0839 - sparse_categorical_accuracy: 0.9745\n",
            "370/469 [======================>.......] - ETA: 43s - loss: 0.0838 - sparse_categorical_accuracy: 0.9745\n",
            "371/469 [======================>.......] - ETA: 42s - loss: 0.0837 - sparse_categorical_accuracy: 0.9745\n",
            "372/469 [======================>.......] - ETA: 42s - loss: 0.0835 - sparse_categorical_accuracy: 0.9745\n",
            "373/469 [======================>.......] - ETA: 42s - loss: 0.0835 - sparse_categorical_accuracy: 0.9746\n",
            "374/469 [======================>.......] - ETA: 41s - loss: 0.0837 - sparse_categorical_accuracy: 0.9746\n",
            "375/469 [======================>.......] - ETA: 41s - loss: 0.0837 - sparse_categorical_accuracy: 0.9746\n",
            "376/469 [=======================>......] - ETA: 40s - loss: 0.0838 - sparse_categorical_accuracy: 0.9745\n",
            "377/469 [=======================>......] - ETA: 40s - loss: 0.0836 - sparse_categorical_accuracy: 0.9746\n",
            "378/469 [=======================>......] - ETA: 39s - loss: 0.0836 - sparse_categorical_accuracy: 0.9746\n",
            "379/469 [=======================>......] - ETA: 39s - loss: 0.0836 - sparse_categorical_accuracy: 0.9746\n",
            "380/469 [=======================>......] - ETA: 38s - loss: 0.0835 - sparse_categorical_accuracy: 0.9747\n",
            "381/469 [=======================>......] - ETA: 38s - loss: 0.0833 - sparse_categorical_accuracy: 0.9747\n",
            "382/469 [=======================>......] - ETA: 38s - loss: 0.0832 - sparse_categorical_accuracy: 0.9748\n",
            "383/469 [=======================>......] - ETA: 37s - loss: 0.0833 - sparse_categorical_accuracy: 0.9747\n",
            "384/469 [=======================>......] - ETA: 37s - loss: 0.0831 - sparse_categorical_accuracy: 0.9748\n",
            "385/469 [=======================>......] - ETA: 36s - loss: 0.0832 - sparse_categorical_accuracy: 0.9747\n",
            "386/469 [=======================>......] - ETA: 36s - loss: 0.0831 - sparse_categorical_accuracy: 0.9748\n",
            "387/469 [=======================>......] - ETA: 36s - loss: 0.0830 - sparse_categorical_accuracy: 0.9748\n",
            "388/469 [=======================>......] - ETA: 35s - loss: 0.0831 - sparse_categorical_accuracy: 0.9747\n",
            "389/469 [=======================>......] - ETA: 35s - loss: 0.0830 - sparse_categorical_accuracy: 0.9747\n",
            "390/469 [=======================>......] - ETA: 34s - loss: 0.0830 - sparse_categorical_accuracy: 0.9747\n",
            "391/469 [========================>.....] - ETA: 34s - loss: 0.0829 - sparse_categorical_accuracy: 0.9748\n",
            "392/469 [========================>.....] - ETA: 33s - loss: 0.0829 - sparse_categorical_accuracy: 0.9748\n",
            "393/469 [========================>.....] - ETA: 33s - loss: 0.0830 - sparse_categorical_accuracy: 0.9747\n",
            "394/469 [========================>.....] - ETA: 32s - loss: 0.0829 - sparse_categorical_accuracy: 0.9747\n",
            "395/469 [========================>.....] - ETA: 32s - loss: 0.0830 - sparse_categorical_accuracy: 0.9747\n",
            "396/469 [========================>.....] - ETA: 32s - loss: 0.0830 - sparse_categorical_accuracy: 0.9747\n",
            "397/469 [========================>.....] - ETA: 31s - loss: 0.0831 - sparse_categorical_accuracy: 0.9747\n",
            "398/469 [========================>.....] - ETA: 31s - loss: 0.0831 - sparse_categorical_accuracy: 0.9747\n",
            "399/469 [========================>.....] - ETA: 30s - loss: 0.0832 - sparse_categorical_accuracy: 0.9747\n",
            "400/469 [========================>.....] - ETA: 30s - loss: 0.0830 - sparse_categorical_accuracy: 0.9748\n",
            "401/469 [========================>.....] - ETA: 29s - loss: 0.0829 - sparse_categorical_accuracy: 0.9748\n",
            "402/469 [========================>.....] - ETA: 29s - loss: 0.0829 - sparse_categorical_accuracy: 0.9748\n",
            "403/469 [========================>.....] - ETA: 28s - loss: 0.0829 - sparse_categorical_accuracy: 0.9748\n",
            "404/469 [========================>.....] - ETA: 28s - loss: 0.0828 - sparse_categorical_accuracy: 0.9749\n",
            "405/469 [========================>.....] - ETA: 28s - loss: 0.0828 - sparse_categorical_accuracy: 0.9749\n",
            "406/469 [========================>.....] - ETA: 27s - loss: 0.0828 - sparse_categorical_accuracy: 0.9749\n",
            "407/469 [=========================>....] - ETA: 27s - loss: 0.0829 - sparse_categorical_accuracy: 0.9748\n",
            "408/469 [=========================>....] - ETA: 26s - loss: 0.0828 - sparse_categorical_accuracy: 0.9749\n",
            "409/469 [=========================>....] - ETA: 26s - loss: 0.0828 - sparse_categorical_accuracy: 0.9748\n",
            "410/469 [=========================>....] - ETA: 25s - loss: 0.0826 - sparse_categorical_accuracy: 0.9749\n",
            "411/469 [=========================>....] - ETA: 25s - loss: 0.0825 - sparse_categorical_accuracy: 0.9749\n",
            "412/469 [=========================>....] - ETA: 24s - loss: 0.0827 - sparse_categorical_accuracy: 0.9748\n",
            "413/469 [=========================>....] - ETA: 24s - loss: 0.0826 - sparse_categorical_accuracy: 0.9749\n",
            "414/469 [=========================>....] - ETA: 24s - loss: 0.0825 - sparse_categorical_accuracy: 0.9749\n",
            "415/469 [=========================>....] - ETA: 23s - loss: 0.0825 - sparse_categorical_accuracy: 0.9749\n",
            "416/469 [=========================>....] - ETA: 23s - loss: 0.0825 - sparse_categorical_accuracy: 0.9749\n",
            "417/469 [=========================>....] - ETA: 22s - loss: 0.0825 - sparse_categorical_accuracy: 0.9749\n",
            "418/469 [=========================>....] - ETA: 22s - loss: 0.0824 - sparse_categorical_accuracy: 0.9749\n",
            "419/469 [=========================>....] - ETA: 22s - loss: 0.0824 - sparse_categorical_accuracy: 0.9749\n",
            "420/469 [=========================>....] - ETA: 21s - loss: 0.0825 - sparse_categorical_accuracy: 0.9749\n",
            "421/469 [=========================>....] - ETA: 21s - loss: 0.0826 - sparse_categorical_accuracy: 0.9749\n",
            "422/469 [=========================>....] - ETA: 20s - loss: 0.0825 - sparse_categorical_accuracy: 0.9749\n",
            "423/469 [==========================>...] - ETA: 20s - loss: 0.0825 - sparse_categorical_accuracy: 0.9749\n",
            "424/469 [==========================>...] - ETA: 19s - loss: 0.0827 - sparse_categorical_accuracy: 0.9749\n",
            "425/469 [==========================>...] - ETA: 19s - loss: 0.0828 - sparse_categorical_accuracy: 0.9748\n",
            "426/469 [==========================>...] - ETA: 18s - loss: 0.0828 - sparse_categorical_accuracy: 0.9749\n",
            "427/469 [==========================>...] - ETA: 18s - loss: 0.0827 - sparse_categorical_accuracy: 0.9749\n",
            "428/469 [==========================>...] - ETA: 18s - loss: 0.0827 - sparse_categorical_accuracy: 0.9749\n",
            "429/469 [==========================>...] - ETA: 17s - loss: 0.0827 - sparse_categorical_accuracy: 0.9749\n",
            "430/469 [==========================>...] - ETA: 17s - loss: 0.0828 - sparse_categorical_accuracy: 0.9749\n",
            "431/469 [==========================>...] - ETA: 16s - loss: 0.0828 - sparse_categorical_accuracy: 0.9749\n",
            "432/469 [==========================>...] - ETA: 16s - loss: 0.0827 - sparse_categorical_accuracy: 0.9749\n",
            "433/469 [==========================>...] - ETA: 15s - loss: 0.0828 - sparse_categorical_accuracy: 0.9749\n",
            "434/469 [==========================>...] - ETA: 15s - loss: 0.0827 - sparse_categorical_accuracy: 0.9749\n",
            "435/469 [==========================>...] - ETA: 14s - loss: 0.0826 - sparse_categorical_accuracy: 0.9750\n",
            "436/469 [==========================>...] - ETA: 14s - loss: 0.0826 - sparse_categorical_accuracy: 0.9749\n",
            "437/469 [==========================>...] - ETA: 14s - loss: 0.0827 - sparse_categorical_accuracy: 0.9749\n",
            "438/469 [===========================>..] - ETA: 13s - loss: 0.0827 - sparse_categorical_accuracy: 0.9749\n",
            "439/469 [===========================>..] - ETA: 13s - loss: 0.0828 - sparse_categorical_accuracy: 0.9749\n",
            "440/469 [===========================>..] - ETA: 12s - loss: 0.0828 - sparse_categorical_accuracy: 0.9748\n",
            "441/469 [===========================>..] - ETA: 12s - loss: 0.0829 - sparse_categorical_accuracy: 0.9748\n",
            "442/469 [===========================>..] - ETA: 11s - loss: 0.0829 - sparse_categorical_accuracy: 0.9748\n",
            "443/469 [===========================>..] - ETA: 11s - loss: 0.0829 - sparse_categorical_accuracy: 0.9748\n",
            "444/469 [===========================>..] - ETA: 10s - loss: 0.0829 - sparse_categorical_accuracy: 0.9748\n",
            "445/469 [===========================>..] - ETA: 10s - loss: 0.0828 - sparse_categorical_accuracy: 0.9748\n",
            "446/469 [===========================>..] - ETA: 10s - loss: 0.0827 - sparse_categorical_accuracy: 0.9749\n",
            "447/469 [===========================>..] - ETA: 9s - loss: 0.0828 - sparse_categorical_accuracy: 0.9748 \n",
            "448/469 [===========================>..] - ETA: 9s - loss: 0.0827 - sparse_categorical_accuracy: 0.9748\n",
            "449/469 [===========================>..] - ETA: 8s - loss: 0.0828 - sparse_categorical_accuracy: 0.9748\n",
            "450/469 [===========================>..] - ETA: 8s - loss: 0.0828 - sparse_categorical_accuracy: 0.9748\n",
            "451/469 [===========================>..] - ETA: 7s - loss: 0.0827 - sparse_categorical_accuracy: 0.9748\n",
            "452/469 [===========================>..] - ETA: 7s - loss: 0.0826 - sparse_categorical_accuracy: 0.9749\n",
            "453/469 [===========================>..] - ETA: 7s - loss: 0.0826 - sparse_categorical_accuracy: 0.9749\n",
            "454/469 [============================>.] - ETA: 6s - loss: 0.0825 - sparse_categorical_accuracy: 0.9749\n",
            "455/469 [============================>.] - ETA: 6s - loss: 0.0824 - sparse_categorical_accuracy: 0.9749\n",
            "456/469 [============================>.] - ETA: 5s - loss: 0.0824 - sparse_categorical_accuracy: 0.9750\n",
            "457/469 [============================>.] - ETA: 5s - loss: 0.0823 - sparse_categorical_accuracy: 0.9750\n",
            "458/469 [============================>.] - ETA: 4s - loss: 0.0823 - sparse_categorical_accuracy: 0.9750\n",
            "459/469 [============================>.] - ETA: 4s - loss: 0.0822 - sparse_categorical_accuracy: 0.9750\n",
            "460/469 [============================>.] - ETA: 3s - loss: 0.0821 - sparse_categorical_accuracy: 0.9751\n",
            "461/469 [============================>.] - ETA: 3s - loss: 0.0821 - sparse_categorical_accuracy: 0.9750\n",
            "462/469 [============================>.] - ETA: 3s - loss: 0.0820 - sparse_categorical_accuracy: 0.9751\n",
            "463/469 [============================>.] - ETA: 2s - loss: 0.0819 - sparse_categorical_accuracy: 0.9751\n",
            "464/469 [============================>.] - ETA: 2s - loss: 0.0820 - sparse_categorical_accuracy: 0.9751\n",
            "465/469 [============================>.] - ETA: 1s - loss: 0.0820 - sparse_categorical_accuracy: 0.9751\n",
            "466/469 [============================>.] - ETA: 1s - loss: 0.0820 - sparse_categorical_accuracy: 0.9750\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.0820 - sparse_categorical_accuracy: 0.9750\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0820 - sparse_categorical_accuracy: 0.9750\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0820 - sparse_categorical_accuracy: 0.9750\n",
            " 60%|██████    | 3/5 [1:07:17<34:52, 1046.39s/trial, best loss: -0.9839000105857849]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/04/16 01:39:17 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 206s 440ms/step - loss: 0.0820 - sparse_categorical_accuracy: 0.9750\n",
            "\n",
            "Epoch 4/5\n",
            "\n",
            "  1/469 [..............................] - ETA: 3:52 - loss: 0.0554 - sparse_categorical_accuracy: 0.9766\n",
            "  2/469 [..............................] - ETA: 3:00 - loss: 0.0930 - sparse_categorical_accuracy: 0.9727\n",
            "  3/469 [..............................] - ETA: 3:06 - loss: 0.0816 - sparse_categorical_accuracy: 0.9766\n",
            "  4/469 [..............................] - ETA: 3:40 - loss: 0.0958 - sparse_categorical_accuracy: 0.9766\n",
            "  5/469 [..............................] - ETA: 3:52 - loss: 0.0824 - sparse_categorical_accuracy: 0.9812\n",
            "  6/469 [..............................] - ETA: 4:04 - loss: 0.0844 - sparse_categorical_accuracy: 0.9805\n",
            "  7/469 [..............................] - ETA: 4:13 - loss: 0.0797 - sparse_categorical_accuracy: 0.9810\n",
            "  8/469 [..............................] - ETA: 4:16 - loss: 0.0725 - sparse_categorical_accuracy: 0.9834\n",
            "  9/469 [..............................] - ETA: 4:18 - loss: 0.0749 - sparse_categorical_accuracy: 0.9818\n",
            " 10/469 [..............................] - ETA: 4:16 - loss: 0.0748 - sparse_categorical_accuracy: 0.9805\n",
            " 11/469 [..............................] - ETA: 4:08 - loss: 0.0737 - sparse_categorical_accuracy: 0.9794\n",
            " 12/469 [..............................] - ETA: 4:01 - loss: 0.0866 - sparse_categorical_accuracy: 0.9746\n",
            " 13/469 [..............................] - ETA: 3:55 - loss: 0.0844 - sparse_categorical_accuracy: 0.9754\n",
            " 14/469 [..............................] - ETA: 3:50 - loss: 0.0848 - sparse_categorical_accuracy: 0.9749\n",
            " 15/469 [..............................] - ETA: 3:46 - loss: 0.0844 - sparse_categorical_accuracy: 0.9750\n",
            " 16/469 [>.............................] - ETA: 3:42 - loss: 0.0820 - sparse_categorical_accuracy: 0.9756\n",
            " 17/469 [>.............................] - ETA: 3:39 - loss: 0.0794 - sparse_categorical_accuracy: 0.9761\n",
            " 18/469 [>.............................] - ETA: 3:36 - loss: 0.0764 - sparse_categorical_accuracy: 0.9774\n",
            " 19/469 [>.............................] - ETA: 3:34 - loss: 0.0752 - sparse_categorical_accuracy: 0.9770\n",
            " 20/469 [>.............................] - ETA: 3:31 - loss: 0.0739 - sparse_categorical_accuracy: 0.9766\n",
            " 21/469 [>.............................] - ETA: 3:29 - loss: 0.0723 - sparse_categorical_accuracy: 0.9769\n",
            " 22/469 [>.............................] - ETA: 3:27 - loss: 0.0727 - sparse_categorical_accuracy: 0.9762\n",
            " 23/469 [>.............................] - ETA: 3:25 - loss: 0.0712 - sparse_categorical_accuracy: 0.9769\n",
            " 24/469 [>.............................] - ETA: 3:23 - loss: 0.0740 - sparse_categorical_accuracy: 0.9766\n",
            " 25/469 [>.............................] - ETA: 3:21 - loss: 0.0731 - sparse_categorical_accuracy: 0.9766\n",
            " 26/469 [>.............................] - ETA: 3:20 - loss: 0.0716 - sparse_categorical_accuracy: 0.9769\n",
            " 27/469 [>.............................] - ETA: 3:19 - loss: 0.0704 - sparse_categorical_accuracy: 0.9771\n",
            " 28/469 [>.............................] - ETA: 3:17 - loss: 0.0725 - sparse_categorical_accuracy: 0.9766\n",
            " 29/469 [>.............................] - ETA: 3:16 - loss: 0.0719 - sparse_categorical_accuracy: 0.9766\n",
            " 30/469 [>.............................] - ETA: 3:15 - loss: 0.0723 - sparse_categorical_accuracy: 0.9766\n",
            " 31/469 [>.............................] - ETA: 3:14 - loss: 0.0716 - sparse_categorical_accuracy: 0.9768\n",
            " 32/469 [=>............................] - ETA: 3:12 - loss: 0.0701 - sparse_categorical_accuracy: 0.9773\n",
            " 33/469 [=>............................] - ETA: 3:11 - loss: 0.0687 - sparse_categorical_accuracy: 0.9777\n",
            " 34/469 [=>............................] - ETA: 3:10 - loss: 0.0680 - sparse_categorical_accuracy: 0.9782\n",
            " 35/469 [=>............................] - ETA: 3:10 - loss: 0.0677 - sparse_categorical_accuracy: 0.9779\n",
            " 36/469 [=>............................] - ETA: 3:11 - loss: 0.0690 - sparse_categorical_accuracy: 0.9770\n",
            " 37/469 [=>............................] - ETA: 3:13 - loss: 0.0680 - sparse_categorical_accuracy: 0.9774\n",
            " 38/469 [=>............................] - ETA: 3:15 - loss: 0.0676 - sparse_categorical_accuracy: 0.9776\n",
            " 39/469 [=>............................] - ETA: 3:17 - loss: 0.0674 - sparse_categorical_accuracy: 0.9778\n",
            " 40/469 [=>............................] - ETA: 3:18 - loss: 0.0669 - sparse_categorical_accuracy: 0.9779\n",
            " 41/469 [=>............................] - ETA: 3:18 - loss: 0.0677 - sparse_categorical_accuracy: 0.9777\n",
            " 42/469 [=>............................] - ETA: 3:16 - loss: 0.0673 - sparse_categorical_accuracy: 0.9779\n",
            " 43/469 [=>............................] - ETA: 3:15 - loss: 0.0674 - sparse_categorical_accuracy: 0.9782\n",
            " 44/469 [=>............................] - ETA: 3:14 - loss: 0.0698 - sparse_categorical_accuracy: 0.9776\n",
            " 45/469 [=>............................] - ETA: 3:13 - loss: 0.0692 - sparse_categorical_accuracy: 0.9778\n",
            " 46/469 [=>............................] - ETA: 3:12 - loss: 0.0690 - sparse_categorical_accuracy: 0.9779\n",
            " 47/469 [==>...........................] - ETA: 3:11 - loss: 0.0693 - sparse_categorical_accuracy: 0.9779\n",
            " 48/469 [==>...........................] - ETA: 3:10 - loss: 0.0690 - sparse_categorical_accuracy: 0.9780\n",
            " 49/469 [==>...........................] - ETA: 3:09 - loss: 0.0681 - sparse_categorical_accuracy: 0.9783\n",
            " 50/469 [==>...........................] - ETA: 3:09 - loss: 0.0685 - sparse_categorical_accuracy: 0.9781\n",
            " 51/469 [==>...........................] - ETA: 3:08 - loss: 0.0680 - sparse_categorical_accuracy: 0.9784\n",
            " 52/469 [==>...........................] - ETA: 3:07 - loss: 0.0686 - sparse_categorical_accuracy: 0.9785\n",
            " 53/469 [==>...........................] - ETA: 3:06 - loss: 0.0679 - sparse_categorical_accuracy: 0.9789\n",
            " 54/469 [==>...........................] - ETA: 3:05 - loss: 0.0680 - sparse_categorical_accuracy: 0.9787\n",
            " 55/469 [==>...........................] - ETA: 3:04 - loss: 0.0681 - sparse_categorical_accuracy: 0.9783\n",
            " 56/469 [==>...........................] - ETA: 3:04 - loss: 0.0680 - sparse_categorical_accuracy: 0.9782\n",
            " 57/469 [==>...........................] - ETA: 3:03 - loss: 0.0674 - sparse_categorical_accuracy: 0.9785\n",
            " 58/469 [==>...........................] - ETA: 3:02 - loss: 0.0677 - sparse_categorical_accuracy: 0.9783\n",
            " 59/469 [==>...........................] - ETA: 3:01 - loss: 0.0674 - sparse_categorical_accuracy: 0.9785\n",
            " 60/469 [==>...........................] - ETA: 3:00 - loss: 0.0679 - sparse_categorical_accuracy: 0.9784\n",
            " 61/469 [==>...........................] - ETA: 3:00 - loss: 0.0682 - sparse_categorical_accuracy: 0.9782\n",
            " 62/469 [==>...........................] - ETA: 2:59 - loss: 0.0689 - sparse_categorical_accuracy: 0.9779\n",
            " 63/469 [===>..........................] - ETA: 2:58 - loss: 0.0689 - sparse_categorical_accuracy: 0.9778\n",
            " 64/469 [===>..........................] - ETA: 2:58 - loss: 0.0687 - sparse_categorical_accuracy: 0.9777\n",
            " 65/469 [===>..........................] - ETA: 2:57 - loss: 0.0692 - sparse_categorical_accuracy: 0.9775\n",
            " 66/469 [===>..........................] - ETA: 2:57 - loss: 0.0685 - sparse_categorical_accuracy: 0.9779\n",
            " 67/469 [===>..........................] - ETA: 2:58 - loss: 0.0683 - sparse_categorical_accuracy: 0.9777\n",
            " 68/469 [===>..........................] - ETA: 2:58 - loss: 0.0681 - sparse_categorical_accuracy: 0.9778\n",
            " 69/469 [===>..........................] - ETA: 2:59 - loss: 0.0688 - sparse_categorical_accuracy: 0.9778\n",
            " 70/469 [===>..........................] - ETA: 3:00 - loss: 0.0687 - sparse_categorical_accuracy: 0.9779\n",
            " 71/469 [===>..........................] - ETA: 3:00 - loss: 0.0687 - sparse_categorical_accuracy: 0.9779\n",
            " 72/469 [===>..........................] - ETA: 2:59 - loss: 0.0688 - sparse_categorical_accuracy: 0.9779\n",
            " 73/469 [===>..........................] - ETA: 2:58 - loss: 0.0687 - sparse_categorical_accuracy: 0.9778\n",
            " 74/469 [===>..........................] - ETA: 2:58 - loss: 0.0690 - sparse_categorical_accuracy: 0.9779\n",
            " 75/469 [===>..........................] - ETA: 2:57 - loss: 0.0689 - sparse_categorical_accuracy: 0.9780\n",
            " 76/469 [===>..........................] - ETA: 2:56 - loss: 0.0685 - sparse_categorical_accuracy: 0.9782\n",
            " 77/469 [===>..........................] - ETA: 2:55 - loss: 0.0689 - sparse_categorical_accuracy: 0.9782\n",
            " 78/469 [===>..........................] - ETA: 2:55 - loss: 0.0686 - sparse_categorical_accuracy: 0.9783\n",
            " 79/469 [====>.........................] - ETA: 2:54 - loss: 0.0681 - sparse_categorical_accuracy: 0.9784\n",
            " 80/469 [====>.........................] - ETA: 2:53 - loss: 0.0682 - sparse_categorical_accuracy: 0.9784\n",
            " 81/469 [====>.........................] - ETA: 2:53 - loss: 0.0687 - sparse_categorical_accuracy: 0.9783\n",
            " 82/469 [====>.........................] - ETA: 2:52 - loss: 0.0686 - sparse_categorical_accuracy: 0.9783\n",
            " 83/469 [====>.........................] - ETA: 2:51 - loss: 0.0686 - sparse_categorical_accuracy: 0.9784\n",
            " 84/469 [====>.........................] - ETA: 2:51 - loss: 0.0686 - sparse_categorical_accuracy: 0.9785\n",
            " 85/469 [====>.........................] - ETA: 2:50 - loss: 0.0682 - sparse_categorical_accuracy: 0.9786\n",
            " 86/469 [====>.........................] - ETA: 2:49 - loss: 0.0677 - sparse_categorical_accuracy: 0.9788\n",
            " 87/469 [====>.........................] - ETA: 2:49 - loss: 0.0679 - sparse_categorical_accuracy: 0.9789\n",
            " 88/469 [====>.........................] - ETA: 2:48 - loss: 0.0677 - sparse_categorical_accuracy: 0.9789\n",
            " 89/469 [====>.........................] - ETA: 2:48 - loss: 0.0690 - sparse_categorical_accuracy: 0.9787\n",
            " 90/469 [====>.........................] - ETA: 2:47 - loss: 0.0685 - sparse_categorical_accuracy: 0.9788\n",
            " 91/469 [====>.........................] - ETA: 2:46 - loss: 0.0687 - sparse_categorical_accuracy: 0.9788\n",
            " 92/469 [====>.........................] - ETA: 2:46 - loss: 0.0690 - sparse_categorical_accuracy: 0.9787\n",
            " 93/469 [====>.........................] - ETA: 2:45 - loss: 0.0698 - sparse_categorical_accuracy: 0.9786\n",
            " 94/469 [=====>........................] - ETA: 2:45 - loss: 0.0697 - sparse_categorical_accuracy: 0.9786\n",
            " 95/469 [=====>........................] - ETA: 2:44 - loss: 0.0694 - sparse_categorical_accuracy: 0.9788\n",
            " 96/469 [=====>........................] - ETA: 2:44 - loss: 0.0692 - sparse_categorical_accuracy: 0.9788\n",
            " 97/469 [=====>........................] - ETA: 2:44 - loss: 0.0687 - sparse_categorical_accuracy: 0.9790\n",
            " 98/469 [=====>........................] - ETA: 2:44 - loss: 0.0687 - sparse_categorical_accuracy: 0.9790\n",
            " 99/469 [=====>........................] - ETA: 2:45 - loss: 0.0691 - sparse_categorical_accuracy: 0.9790\n",
            "100/469 [=====>........................] - ETA: 2:45 - loss: 0.0692 - sparse_categorical_accuracy: 0.9789\n",
            "101/469 [=====>........................] - ETA: 2:45 - loss: 0.0689 - sparse_categorical_accuracy: 0.9790\n",
            "102/469 [=====>........................] - ETA: 2:44 - loss: 0.0688 - sparse_categorical_accuracy: 0.9789\n",
            "103/469 [=====>........................] - ETA: 2:44 - loss: 0.0685 - sparse_categorical_accuracy: 0.9789\n",
            "104/469 [=====>........................] - ETA: 2:43 - loss: 0.0688 - sparse_categorical_accuracy: 0.9789\n",
            "105/469 [=====>........................] - ETA: 2:42 - loss: 0.0691 - sparse_categorical_accuracy: 0.9789\n",
            "106/469 [=====>........................] - ETA: 2:42 - loss: 0.0703 - sparse_categorical_accuracy: 0.9788\n",
            "107/469 [=====>........................] - ETA: 2:41 - loss: 0.0700 - sparse_categorical_accuracy: 0.9788\n",
            "108/469 [=====>........................] - ETA: 2:41 - loss: 0.0696 - sparse_categorical_accuracy: 0.9789\n",
            "109/469 [=====>........................] - ETA: 2:40 - loss: 0.0696 - sparse_categorical_accuracy: 0.9789\n",
            "110/469 [======>.......................] - ETA: 2:39 - loss: 0.0694 - sparse_categorical_accuracy: 0.9790\n",
            "111/469 [======>.......................] - ETA: 2:39 - loss: 0.0691 - sparse_categorical_accuracy: 0.9791\n",
            "112/469 [======>.......................] - ETA: 2:38 - loss: 0.0697 - sparse_categorical_accuracy: 0.9790\n",
            "113/469 [======>.......................] - ETA: 2:38 - loss: 0.0697 - sparse_categorical_accuracy: 0.9789\n",
            "114/469 [======>.......................] - ETA: 2:37 - loss: 0.0698 - sparse_categorical_accuracy: 0.9788\n",
            "115/469 [======>.......................] - ETA: 2:36 - loss: 0.0696 - sparse_categorical_accuracy: 0.9788\n",
            "116/469 [======>.......................] - ETA: 2:36 - loss: 0.0702 - sparse_categorical_accuracy: 0.9786\n",
            "117/469 [======>.......................] - ETA: 2:35 - loss: 0.0707 - sparse_categorical_accuracy: 0.9784\n",
            "118/469 [======>.......................] - ETA: 2:35 - loss: 0.0712 - sparse_categorical_accuracy: 0.9782\n",
            "119/469 [======>.......................] - ETA: 2:34 - loss: 0.0713 - sparse_categorical_accuracy: 0.9782\n",
            "120/469 [======>.......................] - ETA: 2:33 - loss: 0.0709 - sparse_categorical_accuracy: 0.9784\n",
            "121/469 [======>.......................] - ETA: 2:33 - loss: 0.0712 - sparse_categorical_accuracy: 0.9783\n",
            "122/469 [======>.......................] - ETA: 2:32 - loss: 0.0725 - sparse_categorical_accuracy: 0.9782\n",
            "123/469 [======>.......................] - ETA: 2:32 - loss: 0.0723 - sparse_categorical_accuracy: 0.9782\n",
            "124/469 [======>.......................] - ETA: 2:31 - loss: 0.0725 - sparse_categorical_accuracy: 0.9781\n",
            "125/469 [======>.......................] - ETA: 2:31 - loss: 0.0722 - sparse_categorical_accuracy: 0.9782\n",
            "126/469 [=======>......................] - ETA: 2:30 - loss: 0.0718 - sparse_categorical_accuracy: 0.9783\n",
            "127/469 [=======>......................] - ETA: 2:30 - loss: 0.0717 - sparse_categorical_accuracy: 0.9783\n",
            "128/469 [=======>......................] - ETA: 2:30 - loss: 0.0716 - sparse_categorical_accuracy: 0.9782\n",
            "129/469 [=======>......................] - ETA: 2:30 - loss: 0.0713 - sparse_categorical_accuracy: 0.9783\n",
            "130/469 [=======>......................] - ETA: 2:30 - loss: 0.0712 - sparse_categorical_accuracy: 0.9783\n",
            "131/469 [=======>......................] - ETA: 2:30 - loss: 0.0716 - sparse_categorical_accuracy: 0.9784\n",
            "132/469 [=======>......................] - ETA: 2:30 - loss: 0.0720 - sparse_categorical_accuracy: 0.9782\n",
            "133/469 [=======>......................] - ETA: 2:29 - loss: 0.0721 - sparse_categorical_accuracy: 0.9781\n",
            "134/469 [=======>......................] - ETA: 2:29 - loss: 0.0717 - sparse_categorical_accuracy: 0.9783\n",
            "135/469 [=======>......................] - ETA: 2:28 - loss: 0.0714 - sparse_categorical_accuracy: 0.9784\n",
            "136/469 [=======>......................] - ETA: 2:28 - loss: 0.0717 - sparse_categorical_accuracy: 0.9783\n",
            "137/469 [=======>......................] - ETA: 2:27 - loss: 0.0717 - sparse_categorical_accuracy: 0.9782\n",
            "138/469 [=======>......................] - ETA: 2:26 - loss: 0.0714 - sparse_categorical_accuracy: 0.9784\n",
            "139/469 [=======>......................] - ETA: 2:26 - loss: 0.0719 - sparse_categorical_accuracy: 0.9782\n",
            "140/469 [=======>......................] - ETA: 2:25 - loss: 0.0717 - sparse_categorical_accuracy: 0.9783\n",
            "141/469 [========>.....................] - ETA: 2:25 - loss: 0.0714 - sparse_categorical_accuracy: 0.9784\n",
            "142/469 [========>.....................] - ETA: 2:24 - loss: 0.0714 - sparse_categorical_accuracy: 0.9784\n",
            "143/469 [========>.....................] - ETA: 2:24 - loss: 0.0717 - sparse_categorical_accuracy: 0.9783\n",
            "144/469 [========>.....................] - ETA: 2:23 - loss: 0.0721 - sparse_categorical_accuracy: 0.9781\n",
            "145/469 [========>.....................] - ETA: 2:23 - loss: 0.0719 - sparse_categorical_accuracy: 0.9782\n",
            "146/469 [========>.....................] - ETA: 2:22 - loss: 0.0716 - sparse_categorical_accuracy: 0.9783\n",
            "147/469 [========>.....................] - ETA: 2:22 - loss: 0.0714 - sparse_categorical_accuracy: 0.9784\n",
            "148/469 [========>.....................] - ETA: 2:21 - loss: 0.0711 - sparse_categorical_accuracy: 0.9785\n",
            "149/469 [========>.....................] - ETA: 2:21 - loss: 0.0712 - sparse_categorical_accuracy: 0.9784\n",
            "150/469 [========>.....................] - ETA: 2:20 - loss: 0.0710 - sparse_categorical_accuracy: 0.9785\n",
            "151/469 [========>.....................] - ETA: 2:20 - loss: 0.0714 - sparse_categorical_accuracy: 0.9785\n",
            "152/469 [========>.....................] - ETA: 2:19 - loss: 0.0711 - sparse_categorical_accuracy: 0.9786\n",
            "153/469 [========>.....................] - ETA: 2:18 - loss: 0.0712 - sparse_categorical_accuracy: 0.9786\n",
            "154/469 [========>.....................] - ETA: 2:18 - loss: 0.0717 - sparse_categorical_accuracy: 0.9784\n",
            "155/469 [========>.....................] - ETA: 2:17 - loss: 0.0717 - sparse_categorical_accuracy: 0.9785\n",
            "156/469 [========>.....................] - ETA: 2:17 - loss: 0.0717 - sparse_categorical_accuracy: 0.9785\n",
            "157/469 [=========>....................] - ETA: 2:16 - loss: 0.0716 - sparse_categorical_accuracy: 0.9785\n",
            "158/469 [=========>....................] - ETA: 2:16 - loss: 0.0722 - sparse_categorical_accuracy: 0.9783\n",
            "159/469 [=========>....................] - ETA: 2:16 - loss: 0.0726 - sparse_categorical_accuracy: 0.9783\n",
            "160/469 [=========>....................] - ETA: 2:16 - loss: 0.0727 - sparse_categorical_accuracy: 0.9782\n",
            "161/469 [=========>....................] - ETA: 2:16 - loss: 0.0727 - sparse_categorical_accuracy: 0.9782\n",
            "162/469 [=========>....................] - ETA: 2:16 - loss: 0.0731 - sparse_categorical_accuracy: 0.9781\n",
            "163/469 [=========>....................] - ETA: 2:16 - loss: 0.0736 - sparse_categorical_accuracy: 0.9779\n",
            "164/469 [=========>....................] - ETA: 2:15 - loss: 0.0733 - sparse_categorical_accuracy: 0.9780\n",
            "165/469 [=========>....................] - ETA: 2:15 - loss: 0.0733 - sparse_categorical_accuracy: 0.9779\n",
            "166/469 [=========>....................] - ETA: 2:14 - loss: 0.0731 - sparse_categorical_accuracy: 0.9780\n",
            "167/469 [=========>....................] - ETA: 2:14 - loss: 0.0730 - sparse_categorical_accuracy: 0.9780\n",
            "168/469 [=========>....................] - ETA: 2:13 - loss: 0.0732 - sparse_categorical_accuracy: 0.9780\n",
            "169/469 [=========>....................] - ETA: 2:13 - loss: 0.0729 - sparse_categorical_accuracy: 0.9780\n",
            "170/469 [=========>....................] - ETA: 2:12 - loss: 0.0727 - sparse_categorical_accuracy: 0.9781\n",
            "171/469 [=========>....................] - ETA: 2:12 - loss: 0.0728 - sparse_categorical_accuracy: 0.9781\n",
            "172/469 [==========>...................] - ETA: 2:11 - loss: 0.0732 - sparse_categorical_accuracy: 0.9780\n",
            "173/469 [==========>...................] - ETA: 2:11 - loss: 0.0729 - sparse_categorical_accuracy: 0.9781\n",
            "174/469 [==========>...................] - ETA: 2:10 - loss: 0.0727 - sparse_categorical_accuracy: 0.9782\n",
            "175/469 [==========>...................] - ETA: 2:10 - loss: 0.0726 - sparse_categorical_accuracy: 0.9782\n",
            "176/469 [==========>...................] - ETA: 2:09 - loss: 0.0729 - sparse_categorical_accuracy: 0.9781\n",
            "177/469 [==========>...................] - ETA: 2:09 - loss: 0.0731 - sparse_categorical_accuracy: 0.9781\n",
            "178/469 [==========>...................] - ETA: 2:08 - loss: 0.0732 - sparse_categorical_accuracy: 0.9780\n",
            "179/469 [==========>...................] - ETA: 2:08 - loss: 0.0732 - sparse_categorical_accuracy: 0.9780\n",
            "180/469 [==========>...................] - ETA: 2:07 - loss: 0.0730 - sparse_categorical_accuracy: 0.9780\n",
            "181/469 [==========>...................] - ETA: 2:07 - loss: 0.0730 - sparse_categorical_accuracy: 0.9780\n",
            "182/469 [==========>...................] - ETA: 2:06 - loss: 0.0730 - sparse_categorical_accuracy: 0.9780\n",
            "183/469 [==========>...................] - ETA: 2:06 - loss: 0.0731 - sparse_categorical_accuracy: 0.9779\n",
            "184/469 [==========>...................] - ETA: 2:05 - loss: 0.0730 - sparse_categorical_accuracy: 0.9780\n",
            "185/469 [==========>...................] - ETA: 2:05 - loss: 0.0730 - sparse_categorical_accuracy: 0.9780\n",
            "186/469 [==========>...................] - ETA: 2:04 - loss: 0.0729 - sparse_categorical_accuracy: 0.9779\n",
            "187/469 [==========>...................] - ETA: 2:04 - loss: 0.0730 - sparse_categorical_accuracy: 0.9779\n",
            "188/469 [===========>..................] - ETA: 2:03 - loss: 0.0727 - sparse_categorical_accuracy: 0.9780\n",
            "189/469 [===========>..................] - ETA: 2:03 - loss: 0.0725 - sparse_categorical_accuracy: 0.9781\n",
            "190/469 [===========>..................] - ETA: 2:03 - loss: 0.0724 - sparse_categorical_accuracy: 0.9781\n",
            "191/469 [===========>..................] - ETA: 2:03 - loss: 0.0725 - sparse_categorical_accuracy: 0.9780\n",
            "192/469 [===========>..................] - ETA: 2:03 - loss: 0.0725 - sparse_categorical_accuracy: 0.9780\n",
            "193/469 [===========>..................] - ETA: 2:02 - loss: 0.0724 - sparse_categorical_accuracy: 0.9780\n",
            "194/469 [===========>..................] - ETA: 2:02 - loss: 0.0723 - sparse_categorical_accuracy: 0.9780\n",
            "195/469 [===========>..................] - ETA: 2:01 - loss: 0.0724 - sparse_categorical_accuracy: 0.9780\n",
            "196/469 [===========>..................] - ETA: 2:01 - loss: 0.0727 - sparse_categorical_accuracy: 0.9778\n",
            "197/469 [===========>..................] - ETA: 2:00 - loss: 0.0728 - sparse_categorical_accuracy: 0.9778\n",
            "198/469 [===========>..................] - ETA: 2:00 - loss: 0.0727 - sparse_categorical_accuracy: 0.9778\n",
            "199/469 [===========>..................] - ETA: 2:00 - loss: 0.0727 - sparse_categorical_accuracy: 0.9778\n",
            "200/469 [===========>..................] - ETA: 1:59 - loss: 0.0725 - sparse_categorical_accuracy: 0.9779\n",
            "201/469 [===========>..................] - ETA: 1:59 - loss: 0.0722 - sparse_categorical_accuracy: 0.9779\n",
            "202/469 [===========>..................] - ETA: 1:58 - loss: 0.0721 - sparse_categorical_accuracy: 0.9780\n",
            "203/469 [===========>..................] - ETA: 1:58 - loss: 0.0720 - sparse_categorical_accuracy: 0.9780\n",
            "204/469 [============>.................] - ETA: 1:57 - loss: 0.0719 - sparse_categorical_accuracy: 0.9781\n",
            "205/469 [============>.................] - ETA: 1:57 - loss: 0.0719 - sparse_categorical_accuracy: 0.9781\n",
            "206/469 [============>.................] - ETA: 1:56 - loss: 0.0720 - sparse_categorical_accuracy: 0.9780\n",
            "207/469 [============>.................] - ETA: 1:56 - loss: 0.0718 - sparse_categorical_accuracy: 0.9781\n",
            "208/469 [============>.................] - ETA: 1:55 - loss: 0.0717 - sparse_categorical_accuracy: 0.9781\n",
            "209/469 [============>.................] - ETA: 1:55 - loss: 0.0719 - sparse_categorical_accuracy: 0.9781\n",
            "210/469 [============>.................] - ETA: 1:54 - loss: 0.0719 - sparse_categorical_accuracy: 0.9782\n",
            "211/469 [============>.................] - ETA: 1:54 - loss: 0.0717 - sparse_categorical_accuracy: 0.9783\n",
            "212/469 [============>.................] - ETA: 1:53 - loss: 0.0715 - sparse_categorical_accuracy: 0.9783\n",
            "213/469 [============>.................] - ETA: 1:53 - loss: 0.0713 - sparse_categorical_accuracy: 0.9784\n",
            "214/469 [============>.................] - ETA: 1:52 - loss: 0.0713 - sparse_categorical_accuracy: 0.9784\n",
            "215/469 [============>.................] - ETA: 1:52 - loss: 0.0711 - sparse_categorical_accuracy: 0.9785\n",
            "216/469 [============>.................] - ETA: 1:51 - loss: 0.0711 - sparse_categorical_accuracy: 0.9785\n",
            "217/469 [============>.................] - ETA: 1:51 - loss: 0.0710 - sparse_categorical_accuracy: 0.9785\n",
            "218/469 [============>.................] - ETA: 1:51 - loss: 0.0709 - sparse_categorical_accuracy: 0.9785\n",
            "219/469 [=============>................] - ETA: 1:50 - loss: 0.0710 - sparse_categorical_accuracy: 0.9784\n",
            "220/469 [=============>................] - ETA: 1:50 - loss: 0.0707 - sparse_categorical_accuracy: 0.9785\n",
            "221/469 [=============>................] - ETA: 1:50 - loss: 0.0709 - sparse_categorical_accuracy: 0.9785\n",
            "222/469 [=============>................] - ETA: 1:50 - loss: 0.0710 - sparse_categorical_accuracy: 0.9784\n",
            "223/469 [=============>................] - ETA: 1:49 - loss: 0.0715 - sparse_categorical_accuracy: 0.9785\n",
            "224/469 [=============>................] - ETA: 1:49 - loss: 0.0717 - sparse_categorical_accuracy: 0.9784\n",
            "225/469 [=============>................] - ETA: 1:48 - loss: 0.0715 - sparse_categorical_accuracy: 0.9784\n",
            "226/469 [=============>................] - ETA: 1:48 - loss: 0.0715 - sparse_categorical_accuracy: 0.9784\n",
            "227/469 [=============>................] - ETA: 1:47 - loss: 0.0716 - sparse_categorical_accuracy: 0.9784\n",
            "228/469 [=============>................] - ETA: 1:47 - loss: 0.0716 - sparse_categorical_accuracy: 0.9784\n",
            "229/469 [=============>................] - ETA: 1:46 - loss: 0.0717 - sparse_categorical_accuracy: 0.9783\n",
            "230/469 [=============>................] - ETA: 1:46 - loss: 0.0718 - sparse_categorical_accuracy: 0.9782\n",
            "231/469 [=============>................] - ETA: 1:45 - loss: 0.0718 - sparse_categorical_accuracy: 0.9782\n",
            "232/469 [=============>................] - ETA: 1:45 - loss: 0.0718 - sparse_categorical_accuracy: 0.9782\n",
            "233/469 [=============>................] - ETA: 1:45 - loss: 0.0717 - sparse_categorical_accuracy: 0.9782\n",
            "234/469 [=============>................] - ETA: 1:44 - loss: 0.0719 - sparse_categorical_accuracy: 0.9782\n",
            "235/469 [==============>...............] - ETA: 1:44 - loss: 0.0718 - sparse_categorical_accuracy: 0.9782\n",
            "236/469 [==============>...............] - ETA: 1:43 - loss: 0.0718 - sparse_categorical_accuracy: 0.9782\n",
            "237/469 [==============>...............] - ETA: 1:43 - loss: 0.0718 - sparse_categorical_accuracy: 0.9781\n",
            "238/469 [==============>...............] - ETA: 1:42 - loss: 0.0719 - sparse_categorical_accuracy: 0.9781\n",
            "239/469 [==============>...............] - ETA: 1:42 - loss: 0.0717 - sparse_categorical_accuracy: 0.9782\n",
            "240/469 [==============>...............] - ETA: 1:41 - loss: 0.0717 - sparse_categorical_accuracy: 0.9783\n",
            "241/469 [==============>...............] - ETA: 1:41 - loss: 0.0716 - sparse_categorical_accuracy: 0.9783\n",
            "242/469 [==============>...............] - ETA: 1:40 - loss: 0.0717 - sparse_categorical_accuracy: 0.9782\n",
            "243/469 [==============>...............] - ETA: 1:40 - loss: 0.0716 - sparse_categorical_accuracy: 0.9782\n",
            "244/469 [==============>...............] - ETA: 1:39 - loss: 0.0715 - sparse_categorical_accuracy: 0.9782\n",
            "245/469 [==============>...............] - ETA: 1:39 - loss: 0.0714 - sparse_categorical_accuracy: 0.9782\n",
            "246/469 [==============>...............] - ETA: 1:38 - loss: 0.0715 - sparse_categorical_accuracy: 0.9781\n",
            "247/469 [==============>...............] - ETA: 1:38 - loss: 0.0714 - sparse_categorical_accuracy: 0.9782\n",
            "248/469 [==============>...............] - ETA: 1:37 - loss: 0.0712 - sparse_categorical_accuracy: 0.9782\n",
            "249/469 [==============>...............] - ETA: 1:37 - loss: 0.0716 - sparse_categorical_accuracy: 0.9782\n",
            "250/469 [==============>...............] - ETA: 1:37 - loss: 0.0716 - sparse_categorical_accuracy: 0.9782\n",
            "251/469 [===============>..............] - ETA: 1:37 - loss: 0.0715 - sparse_categorical_accuracy: 0.9783\n",
            "252/469 [===============>..............] - ETA: 1:36 - loss: 0.0715 - sparse_categorical_accuracy: 0.9782\n",
            "253/469 [===============>..............] - ETA: 1:36 - loss: 0.0714 - sparse_categorical_accuracy: 0.9782\n",
            "254/469 [===============>..............] - ETA: 1:35 - loss: 0.0714 - sparse_categorical_accuracy: 0.9783\n",
            "255/469 [===============>..............] - ETA: 1:35 - loss: 0.0713 - sparse_categorical_accuracy: 0.9782\n",
            "256/469 [===============>..............] - ETA: 1:35 - loss: 0.0714 - sparse_categorical_accuracy: 0.9782\n",
            "257/469 [===============>..............] - ETA: 1:34 - loss: 0.0714 - sparse_categorical_accuracy: 0.9782\n",
            "258/469 [===============>..............] - ETA: 1:34 - loss: 0.0713 - sparse_categorical_accuracy: 0.9782\n",
            "259/469 [===============>..............] - ETA: 1:33 - loss: 0.0711 - sparse_categorical_accuracy: 0.9783\n",
            "260/469 [===============>..............] - ETA: 1:33 - loss: 0.0711 - sparse_categorical_accuracy: 0.9784\n",
            "261/469 [===============>..............] - ETA: 1:32 - loss: 0.0709 - sparse_categorical_accuracy: 0.9784\n",
            "262/469 [===============>..............] - ETA: 1:32 - loss: 0.0709 - sparse_categorical_accuracy: 0.9784\n",
            "263/469 [===============>..............] - ETA: 1:31 - loss: 0.0710 - sparse_categorical_accuracy: 0.9784\n",
            "264/469 [===============>..............] - ETA: 1:31 - loss: 0.0710 - sparse_categorical_accuracy: 0.9783\n",
            "265/469 [===============>..............] - ETA: 1:30 - loss: 0.0709 - sparse_categorical_accuracy: 0.9783\n",
            "266/469 [================>.............] - ETA: 1:30 - loss: 0.0707 - sparse_categorical_accuracy: 0.9784\n",
            "267/469 [================>.............] - ETA: 1:29 - loss: 0.0707 - sparse_categorical_accuracy: 0.9784\n",
            "268/469 [================>.............] - ETA: 1:29 - loss: 0.0706 - sparse_categorical_accuracy: 0.9785\n",
            "269/469 [================>.............] - ETA: 1:28 - loss: 0.0704 - sparse_categorical_accuracy: 0.9785\n",
            "270/469 [================>.............] - ETA: 1:28 - loss: 0.0706 - sparse_categorical_accuracy: 0.9784\n",
            "271/469 [================>.............] - ETA: 1:27 - loss: 0.0709 - sparse_categorical_accuracy: 0.9784\n",
            "272/469 [================>.............] - ETA: 1:27 - loss: 0.0711 - sparse_categorical_accuracy: 0.9783\n",
            "273/469 [================>.............] - ETA: 1:26 - loss: 0.0711 - sparse_categorical_accuracy: 0.9784\n",
            "274/469 [================>.............] - ETA: 1:26 - loss: 0.0710 - sparse_categorical_accuracy: 0.9784\n",
            "275/469 [================>.............] - ETA: 1:25 - loss: 0.0708 - sparse_categorical_accuracy: 0.9784\n",
            "276/469 [================>.............] - ETA: 1:25 - loss: 0.0707 - sparse_categorical_accuracy: 0.9785\n",
            "277/469 [================>.............] - ETA: 1:25 - loss: 0.0707 - sparse_categorical_accuracy: 0.9785\n",
            "278/469 [================>.............] - ETA: 1:24 - loss: 0.0710 - sparse_categorical_accuracy: 0.9784\n",
            "279/469 [================>.............] - ETA: 1:24 - loss: 0.0713 - sparse_categorical_accuracy: 0.9784\n",
            "280/469 [================>.............] - ETA: 1:24 - loss: 0.0711 - sparse_categorical_accuracy: 0.9785\n",
            "281/469 [================>.............] - ETA: 1:23 - loss: 0.0710 - sparse_categorical_accuracy: 0.9785\n",
            "282/469 [=================>............] - ETA: 1:23 - loss: 0.0711 - sparse_categorical_accuracy: 0.9785\n",
            "283/469 [=================>............] - ETA: 1:23 - loss: 0.0711 - sparse_categorical_accuracy: 0.9786\n",
            "284/469 [=================>............] - ETA: 1:22 - loss: 0.0710 - sparse_categorical_accuracy: 0.9786\n",
            "285/469 [=================>............] - ETA: 1:22 - loss: 0.0709 - sparse_categorical_accuracy: 0.9787\n",
            "286/469 [=================>............] - ETA: 1:21 - loss: 0.0709 - sparse_categorical_accuracy: 0.9787\n",
            "287/469 [=================>............] - ETA: 1:21 - loss: 0.0708 - sparse_categorical_accuracy: 0.9788\n",
            "288/469 [=================>............] - ETA: 1:20 - loss: 0.0706 - sparse_categorical_accuracy: 0.9788\n",
            "289/469 [=================>............] - ETA: 1:20 - loss: 0.0706 - sparse_categorical_accuracy: 0.9788\n",
            "290/469 [=================>............] - ETA: 1:19 - loss: 0.0708 - sparse_categorical_accuracy: 0.9787\n",
            "291/469 [=================>............] - ETA: 1:19 - loss: 0.0711 - sparse_categorical_accuracy: 0.9786\n",
            "292/469 [=================>............] - ETA: 1:18 - loss: 0.0710 - sparse_categorical_accuracy: 0.9786\n",
            "293/469 [=================>............] - ETA: 1:18 - loss: 0.0711 - sparse_categorical_accuracy: 0.9786\n",
            "294/469 [=================>............] - ETA: 1:17 - loss: 0.0716 - sparse_categorical_accuracy: 0.9785\n",
            "295/469 [=================>............] - ETA: 1:17 - loss: 0.0715 - sparse_categorical_accuracy: 0.9785\n",
            "296/469 [=================>............] - ETA: 1:16 - loss: 0.0716 - sparse_categorical_accuracy: 0.9785\n",
            "297/469 [=================>............] - ETA: 1:16 - loss: 0.0715 - sparse_categorical_accuracy: 0.9785\n",
            "298/469 [==================>...........] - ETA: 1:16 - loss: 0.0716 - sparse_categorical_accuracy: 0.9785\n",
            "299/469 [==================>...........] - ETA: 1:15 - loss: 0.0715 - sparse_categorical_accuracy: 0.9785\n",
            "300/469 [==================>...........] - ETA: 1:15 - loss: 0.0713 - sparse_categorical_accuracy: 0.9786\n",
            "301/469 [==================>...........] - ETA: 1:14 - loss: 0.0714 - sparse_categorical_accuracy: 0.9785\n",
            "302/469 [==================>...........] - ETA: 1:14 - loss: 0.0716 - sparse_categorical_accuracy: 0.9785\n",
            "303/469 [==================>...........] - ETA: 1:13 - loss: 0.0715 - sparse_categorical_accuracy: 0.9785\n",
            "304/469 [==================>...........] - ETA: 1:13 - loss: 0.0715 - sparse_categorical_accuracy: 0.9785\n",
            "305/469 [==================>...........] - ETA: 1:12 - loss: 0.0714 - sparse_categorical_accuracy: 0.9785\n",
            "306/469 [==================>...........] - ETA: 1:12 - loss: 0.0714 - sparse_categorical_accuracy: 0.9785\n",
            "307/469 [==================>...........] - ETA: 1:11 - loss: 0.0715 - sparse_categorical_accuracy: 0.9784\n",
            "308/469 [==================>...........] - ETA: 1:11 - loss: 0.0715 - sparse_categorical_accuracy: 0.9785\n",
            "309/469 [==================>...........] - ETA: 1:11 - loss: 0.0714 - sparse_categorical_accuracy: 0.9785\n",
            "310/469 [==================>...........] - ETA: 1:10 - loss: 0.0714 - sparse_categorical_accuracy: 0.9785\n",
            "311/469 [==================>...........] - ETA: 1:10 - loss: 0.0715 - sparse_categorical_accuracy: 0.9784\n",
            "312/469 [==================>...........] - ETA: 1:10 - loss: 0.0715 - sparse_categorical_accuracy: 0.9784\n",
            "313/469 [===================>..........] - ETA: 1:09 - loss: 0.0715 - sparse_categorical_accuracy: 0.9783\n",
            "314/469 [===================>..........] - ETA: 1:09 - loss: 0.0714 - sparse_categorical_accuracy: 0.9784\n",
            "315/469 [===================>..........] - ETA: 1:08 - loss: 0.0715 - sparse_categorical_accuracy: 0.9783\n",
            "316/469 [===================>..........] - ETA: 1:08 - loss: 0.0716 - sparse_categorical_accuracy: 0.9783\n",
            "317/469 [===================>..........] - ETA: 1:07 - loss: 0.0717 - sparse_categorical_accuracy: 0.9783\n",
            "318/469 [===================>..........] - ETA: 1:07 - loss: 0.0716 - sparse_categorical_accuracy: 0.9783\n",
            "319/469 [===================>..........] - ETA: 1:07 - loss: 0.0716 - sparse_categorical_accuracy: 0.9784\n",
            "320/469 [===================>..........] - ETA: 1:06 - loss: 0.0716 - sparse_categorical_accuracy: 0.9783\n",
            "321/469 [===================>..........] - ETA: 1:06 - loss: 0.0715 - sparse_categorical_accuracy: 0.9784\n",
            "322/469 [===================>..........] - ETA: 1:05 - loss: 0.0715 - sparse_categorical_accuracy: 0.9784\n",
            "323/469 [===================>..........] - ETA: 1:05 - loss: 0.0717 - sparse_categorical_accuracy: 0.9784\n",
            "324/469 [===================>..........] - ETA: 1:04 - loss: 0.0716 - sparse_categorical_accuracy: 0.9784\n",
            "325/469 [===================>..........] - ETA: 1:04 - loss: 0.0715 - sparse_categorical_accuracy: 0.9784\n",
            "326/469 [===================>..........] - ETA: 1:03 - loss: 0.0714 - sparse_categorical_accuracy: 0.9785\n",
            "327/469 [===================>..........] - ETA: 1:03 - loss: 0.0713 - sparse_categorical_accuracy: 0.9785\n",
            "328/469 [===================>..........] - ETA: 1:02 - loss: 0.0713 - sparse_categorical_accuracy: 0.9785\n",
            "329/469 [====================>.........] - ETA: 1:02 - loss: 0.0714 - sparse_categorical_accuracy: 0.9785\n",
            "330/469 [====================>.........] - ETA: 1:01 - loss: 0.0713 - sparse_categorical_accuracy: 0.9786\n",
            "331/469 [====================>.........] - ETA: 1:01 - loss: 0.0712 - sparse_categorical_accuracy: 0.9786\n",
            "332/469 [====================>.........] - ETA: 1:00 - loss: 0.0712 - sparse_categorical_accuracy: 0.9786\n",
            "333/469 [====================>.........] - ETA: 1:00 - loss: 0.0712 - sparse_categorical_accuracy: 0.9785\n",
            "334/469 [====================>.........] - ETA: 1:00 - loss: 0.0712 - sparse_categorical_accuracy: 0.9786\n",
            "335/469 [====================>.........] - ETA: 59s - loss: 0.0710 - sparse_categorical_accuracy: 0.9786 \n",
            "336/469 [====================>.........] - ETA: 59s - loss: 0.0708 - sparse_categorical_accuracy: 0.9787\n",
            "337/469 [====================>.........] - ETA: 58s - loss: 0.0709 - sparse_categorical_accuracy: 0.9786\n",
            "338/469 [====================>.........] - ETA: 58s - loss: 0.0708 - sparse_categorical_accuracy: 0.9787\n",
            "339/469 [====================>.........] - ETA: 57s - loss: 0.0707 - sparse_categorical_accuracy: 0.9787\n",
            "340/469 [====================>.........] - ETA: 57s - loss: 0.0706 - sparse_categorical_accuracy: 0.9787\n",
            "341/469 [====================>.........] - ETA: 57s - loss: 0.0706 - sparse_categorical_accuracy: 0.9787\n",
            "342/469 [====================>.........] - ETA: 56s - loss: 0.0705 - sparse_categorical_accuracy: 0.9788\n",
            "343/469 [====================>.........] - ETA: 56s - loss: 0.0705 - sparse_categorical_accuracy: 0.9787\n",
            "344/469 [=====================>........] - ETA: 55s - loss: 0.0704 - sparse_categorical_accuracy: 0.9788\n",
            "345/469 [=====================>........] - ETA: 55s - loss: 0.0703 - sparse_categorical_accuracy: 0.9788\n",
            "346/469 [=====================>........] - ETA: 55s - loss: 0.0703 - sparse_categorical_accuracy: 0.9788\n",
            "347/469 [=====================>........] - ETA: 54s - loss: 0.0702 - sparse_categorical_accuracy: 0.9788\n",
            "348/469 [=====================>........] - ETA: 54s - loss: 0.0701 - sparse_categorical_accuracy: 0.9788\n",
            "349/469 [=====================>........] - ETA: 53s - loss: 0.0702 - sparse_categorical_accuracy: 0.9788\n",
            "350/469 [=====================>........] - ETA: 53s - loss: 0.0702 - sparse_categorical_accuracy: 0.9788\n",
            "351/469 [=====================>........] - ETA: 52s - loss: 0.0701 - sparse_categorical_accuracy: 0.9788\n",
            "352/469 [=====================>........] - ETA: 52s - loss: 0.0701 - sparse_categorical_accuracy: 0.9788\n",
            "353/469 [=====================>........] - ETA: 51s - loss: 0.0700 - sparse_categorical_accuracy: 0.9788\n",
            "354/469 [=====================>........] - ETA: 51s - loss: 0.0700 - sparse_categorical_accuracy: 0.9788\n",
            "355/469 [=====================>........] - ETA: 50s - loss: 0.0702 - sparse_categorical_accuracy: 0.9788\n",
            "356/469 [=====================>........] - ETA: 50s - loss: 0.0705 - sparse_categorical_accuracy: 0.9787\n",
            "357/469 [=====================>........] - ETA: 49s - loss: 0.0706 - sparse_categorical_accuracy: 0.9786\n",
            "358/469 [=====================>........] - ETA: 49s - loss: 0.0706 - sparse_categorical_accuracy: 0.9786\n",
            "359/469 [=====================>........] - ETA: 49s - loss: 0.0706 - sparse_categorical_accuracy: 0.9786\n",
            "360/469 [======================>.......] - ETA: 48s - loss: 0.0707 - sparse_categorical_accuracy: 0.9786\n",
            "361/469 [======================>.......] - ETA: 48s - loss: 0.0707 - sparse_categorical_accuracy: 0.9786\n",
            "362/469 [======================>.......] - ETA: 47s - loss: 0.0707 - sparse_categorical_accuracy: 0.9785\n",
            "363/469 [======================>.......] - ETA: 47s - loss: 0.0707 - sparse_categorical_accuracy: 0.9785\n",
            "364/469 [======================>.......] - ETA: 46s - loss: 0.0707 - sparse_categorical_accuracy: 0.9785\n",
            "365/469 [======================>.......] - ETA: 46s - loss: 0.0706 - sparse_categorical_accuracy: 0.9785\n",
            "366/469 [======================>.......] - ETA: 45s - loss: 0.0707 - sparse_categorical_accuracy: 0.9785\n",
            "367/469 [======================>.......] - ETA: 45s - loss: 0.0707 - sparse_categorical_accuracy: 0.9785\n",
            "368/469 [======================>.......] - ETA: 44s - loss: 0.0708 - sparse_categorical_accuracy: 0.9785\n",
            "369/469 [======================>.......] - ETA: 44s - loss: 0.0707 - sparse_categorical_accuracy: 0.9785\n",
            "370/469 [======================>.......] - ETA: 44s - loss: 0.0706 - sparse_categorical_accuracy: 0.9785\n",
            "371/469 [======================>.......] - ETA: 43s - loss: 0.0705 - sparse_categorical_accuracy: 0.9785\n",
            "372/469 [======================>.......] - ETA: 43s - loss: 0.0706 - sparse_categorical_accuracy: 0.9785\n",
            "373/469 [======================>.......] - ETA: 42s - loss: 0.0705 - sparse_categorical_accuracy: 0.9785\n",
            "374/469 [======================>.......] - ETA: 42s - loss: 0.0706 - sparse_categorical_accuracy: 0.9785\n",
            "375/469 [======================>.......] - ETA: 42s - loss: 0.0705 - sparse_categorical_accuracy: 0.9786\n",
            "376/469 [=======================>......] - ETA: 41s - loss: 0.0706 - sparse_categorical_accuracy: 0.9785\n",
            "377/469 [=======================>......] - ETA: 41s - loss: 0.0706 - sparse_categorical_accuracy: 0.9785\n",
            "378/469 [=======================>......] - ETA: 40s - loss: 0.0705 - sparse_categorical_accuracy: 0.9785\n",
            "379/469 [=======================>......] - ETA: 40s - loss: 0.0704 - sparse_categorical_accuracy: 0.9786\n",
            "380/469 [=======================>......] - ETA: 39s - loss: 0.0704 - sparse_categorical_accuracy: 0.9786\n",
            "381/469 [=======================>......] - ETA: 39s - loss: 0.0706 - sparse_categorical_accuracy: 0.9786\n",
            "382/469 [=======================>......] - ETA: 38s - loss: 0.0706 - sparse_categorical_accuracy: 0.9785\n",
            "383/469 [=======================>......] - ETA: 38s - loss: 0.0706 - sparse_categorical_accuracy: 0.9785\n",
            "384/469 [=======================>......] - ETA: 37s - loss: 0.0709 - sparse_categorical_accuracy: 0.9784\n",
            "385/469 [=======================>......] - ETA: 37s - loss: 0.0709 - sparse_categorical_accuracy: 0.9784\n",
            "386/469 [=======================>......] - ETA: 37s - loss: 0.0710 - sparse_categorical_accuracy: 0.9784\n",
            "387/469 [=======================>......] - ETA: 36s - loss: 0.0710 - sparse_categorical_accuracy: 0.9784\n",
            "388/469 [=======================>......] - ETA: 36s - loss: 0.0709 - sparse_categorical_accuracy: 0.9784\n",
            "389/469 [=======================>......] - ETA: 35s - loss: 0.0708 - sparse_categorical_accuracy: 0.9784\n",
            "390/469 [=======================>......] - ETA: 35s - loss: 0.0707 - sparse_categorical_accuracy: 0.9784\n",
            "391/469 [========================>.....] - ETA: 34s - loss: 0.0706 - sparse_categorical_accuracy: 0.9785\n",
            "392/469 [========================>.....] - ETA: 34s - loss: 0.0707 - sparse_categorical_accuracy: 0.9784\n",
            "393/469 [========================>.....] - ETA: 33s - loss: 0.0707 - sparse_categorical_accuracy: 0.9785\n",
            "394/469 [========================>.....] - ETA: 33s - loss: 0.0708 - sparse_categorical_accuracy: 0.9784\n",
            "395/469 [========================>.....] - ETA: 32s - loss: 0.0708 - sparse_categorical_accuracy: 0.9784\n",
            "396/469 [========================>.....] - ETA: 32s - loss: 0.0708 - sparse_categorical_accuracy: 0.9784\n",
            "397/469 [========================>.....] - ETA: 32s - loss: 0.0708 - sparse_categorical_accuracy: 0.9784\n",
            "398/469 [========================>.....] - ETA: 31s - loss: 0.0707 - sparse_categorical_accuracy: 0.9784\n",
            "399/469 [========================>.....] - ETA: 31s - loss: 0.0706 - sparse_categorical_accuracy: 0.9784\n",
            "400/469 [========================>.....] - ETA: 30s - loss: 0.0705 - sparse_categorical_accuracy: 0.9785\n",
            "401/469 [========================>.....] - ETA: 30s - loss: 0.0705 - sparse_categorical_accuracy: 0.9785\n",
            "402/469 [========================>.....] - ETA: 29s - loss: 0.0704 - sparse_categorical_accuracy: 0.9785\n",
            "403/469 [========================>.....] - ETA: 29s - loss: 0.0705 - sparse_categorical_accuracy: 0.9785\n",
            "404/469 [========================>.....] - ETA: 29s - loss: 0.0705 - sparse_categorical_accuracy: 0.9786\n",
            "405/469 [========================>.....] - ETA: 28s - loss: 0.0705 - sparse_categorical_accuracy: 0.9786\n",
            "406/469 [========================>.....] - ETA: 28s - loss: 0.0706 - sparse_categorical_accuracy: 0.9785\n",
            "407/469 [=========================>....] - ETA: 27s - loss: 0.0707 - sparse_categorical_accuracy: 0.9785\n",
            "408/469 [=========================>....] - ETA: 27s - loss: 0.0706 - sparse_categorical_accuracy: 0.9785\n",
            "409/469 [=========================>....] - ETA: 26s - loss: 0.0707 - sparse_categorical_accuracy: 0.9785\n",
            "410/469 [=========================>....] - ETA: 26s - loss: 0.0708 - sparse_categorical_accuracy: 0.9785\n",
            "411/469 [=========================>....] - ETA: 25s - loss: 0.0707 - sparse_categorical_accuracy: 0.9785\n",
            "412/469 [=========================>....] - ETA: 25s - loss: 0.0706 - sparse_categorical_accuracy: 0.9786\n",
            "413/469 [=========================>....] - ETA: 24s - loss: 0.0705 - sparse_categorical_accuracy: 0.9786\n",
            "414/469 [=========================>....] - ETA: 24s - loss: 0.0705 - sparse_categorical_accuracy: 0.9786\n",
            "415/469 [=========================>....] - ETA: 24s - loss: 0.0706 - sparse_categorical_accuracy: 0.9786\n",
            "416/469 [=========================>....] - ETA: 23s - loss: 0.0709 - sparse_categorical_accuracy: 0.9785\n",
            "417/469 [=========================>....] - ETA: 23s - loss: 0.0709 - sparse_categorical_accuracy: 0.9785\n",
            "418/469 [=========================>....] - ETA: 22s - loss: 0.0709 - sparse_categorical_accuracy: 0.9785\n",
            "419/469 [=========================>....] - ETA: 22s - loss: 0.0709 - sparse_categorical_accuracy: 0.9785\n",
            "420/469 [=========================>....] - ETA: 21s - loss: 0.0708 - sparse_categorical_accuracy: 0.9785\n",
            "421/469 [=========================>....] - ETA: 21s - loss: 0.0707 - sparse_categorical_accuracy: 0.9785\n",
            "422/469 [=========================>....] - ETA: 20s - loss: 0.0706 - sparse_categorical_accuracy: 0.9786\n",
            "423/469 [==========================>...] - ETA: 20s - loss: 0.0706 - sparse_categorical_accuracy: 0.9786\n",
            "424/469 [==========================>...] - ETA: 20s - loss: 0.0705 - sparse_categorical_accuracy: 0.9786\n",
            "425/469 [==========================>...] - ETA: 19s - loss: 0.0704 - sparse_categorical_accuracy: 0.9786\n",
            "426/469 [==========================>...] - ETA: 19s - loss: 0.0704 - sparse_categorical_accuracy: 0.9786\n",
            "427/469 [==========================>...] - ETA: 18s - loss: 0.0702 - sparse_categorical_accuracy: 0.9787\n",
            "428/469 [==========================>...] - ETA: 18s - loss: 0.0703 - sparse_categorical_accuracy: 0.9787\n",
            "429/469 [==========================>...] - ETA: 17s - loss: 0.0702 - sparse_categorical_accuracy: 0.9787\n",
            "430/469 [==========================>...] - ETA: 17s - loss: 0.0702 - sparse_categorical_accuracy: 0.9787\n",
            "431/469 [==========================>...] - ETA: 16s - loss: 0.0702 - sparse_categorical_accuracy: 0.9787\n",
            "432/469 [==========================>...] - ETA: 16s - loss: 0.0703 - sparse_categorical_accuracy: 0.9786\n",
            "433/469 [==========================>...] - ETA: 16s - loss: 0.0702 - sparse_categorical_accuracy: 0.9787\n",
            "434/469 [==========================>...] - ETA: 15s - loss: 0.0702 - sparse_categorical_accuracy: 0.9787\n",
            "435/469 [==========================>...] - ETA: 15s - loss: 0.0702 - sparse_categorical_accuracy: 0.9787\n",
            "436/469 [==========================>...] - ETA: 14s - loss: 0.0701 - sparse_categorical_accuracy: 0.9787\n",
            "437/469 [==========================>...] - ETA: 14s - loss: 0.0702 - sparse_categorical_accuracy: 0.9787\n",
            "438/469 [===========================>..] - ETA: 13s - loss: 0.0701 - sparse_categorical_accuracy: 0.9787\n",
            "439/469 [===========================>..] - ETA: 13s - loss: 0.0701 - sparse_categorical_accuracy: 0.9787\n",
            "440/469 [===========================>..] - ETA: 12s - loss: 0.0702 - sparse_categorical_accuracy: 0.9787\n",
            "441/469 [===========================>..] - ETA: 12s - loss: 0.0702 - sparse_categorical_accuracy: 0.9787\n",
            "442/469 [===========================>..] - ETA: 12s - loss: 0.0701 - sparse_categorical_accuracy: 0.9787\n",
            "443/469 [===========================>..] - ETA: 11s - loss: 0.0700 - sparse_categorical_accuracy: 0.9787\n",
            "444/469 [===========================>..] - ETA: 11s - loss: 0.0700 - sparse_categorical_accuracy: 0.9787\n",
            "445/469 [===========================>..] - ETA: 10s - loss: 0.0701 - sparse_categorical_accuracy: 0.9787\n",
            "446/469 [===========================>..] - ETA: 10s - loss: 0.0701 - sparse_categorical_accuracy: 0.9787\n",
            "447/469 [===========================>..] - ETA: 9s - loss: 0.0701 - sparse_categorical_accuracy: 0.9787 \n",
            "448/469 [===========================>..] - ETA: 9s - loss: 0.0701 - sparse_categorical_accuracy: 0.9787\n",
            "449/469 [===========================>..] - ETA: 8s - loss: 0.0701 - sparse_categorical_accuracy: 0.9787\n",
            "450/469 [===========================>..] - ETA: 8s - loss: 0.0700 - sparse_categorical_accuracy: 0.9788\n",
            "451/469 [===========================>..] - ETA: 8s - loss: 0.0700 - sparse_categorical_accuracy: 0.9788\n",
            "452/469 [===========================>..] - ETA: 7s - loss: 0.0699 - sparse_categorical_accuracy: 0.9788\n",
            "453/469 [===========================>..] - ETA: 7s - loss: 0.0698 - sparse_categorical_accuracy: 0.9788\n",
            "454/469 [============================>.] - ETA: 6s - loss: 0.0699 - sparse_categorical_accuracy: 0.9788\n",
            "455/469 [============================>.] - ETA: 6s - loss: 0.0699 - sparse_categorical_accuracy: 0.9789\n",
            "456/469 [============================>.] - ETA: 5s - loss: 0.0699 - sparse_categorical_accuracy: 0.9788\n",
            "457/469 [============================>.] - ETA: 5s - loss: 0.0699 - sparse_categorical_accuracy: 0.9788\n",
            "458/469 [============================>.] - ETA: 4s - loss: 0.0699 - sparse_categorical_accuracy: 0.9788\n",
            "459/469 [============================>.] - ETA: 4s - loss: 0.0699 - sparse_categorical_accuracy: 0.9788\n",
            "460/469 [============================>.] - ETA: 4s - loss: 0.0700 - sparse_categorical_accuracy: 0.9788\n",
            "461/469 [============================>.] - ETA: 3s - loss: 0.0699 - sparse_categorical_accuracy: 0.9788\n",
            "462/469 [============================>.] - ETA: 3s - loss: 0.0699 - sparse_categorical_accuracy: 0.9788\n",
            "463/469 [============================>.] - ETA: 2s - loss: 0.0699 - sparse_categorical_accuracy: 0.9788\n",
            "464/469 [============================>.] - ETA: 2s - loss: 0.0699 - sparse_categorical_accuracy: 0.9788\n",
            "465/469 [============================>.] - ETA: 1s - loss: 0.0699 - sparse_categorical_accuracy: 0.9788\n",
            "466/469 [============================>.] - ETA: 1s - loss: 0.0699 - sparse_categorical_accuracy: 0.9788\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.0699 - sparse_categorical_accuracy: 0.9788\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0699 - sparse_categorical_accuracy: 0.9788\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0699 - sparse_categorical_accuracy: 0.9788\n",
            " 60%|██████    | 3/5 [1:10:46<34:52, 1046.39s/trial, best loss: -0.9839000105857849]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/04/16 01:42:47 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 210s 447ms/step - loss: 0.0699 - sparse_categorical_accuracy: 0.9788\n",
            "\n",
            "Epoch 5/5\n",
            "\n",
            "  1/469 [..............................] - ETA: 3:48 - loss: 0.0451 - sparse_categorical_accuracy: 0.9844\n",
            "  2/469 [..............................] - ETA: 3:03 - loss: 0.0803 - sparse_categorical_accuracy: 0.9727\n",
            "  3/469 [..............................] - ETA: 3:01 - loss: 0.0678 - sparse_categorical_accuracy: 0.9766\n",
            "  4/469 [..............................] - ETA: 3:01 - loss: 0.0707 - sparse_categorical_accuracy: 0.9746\n",
            "  5/469 [..............................] - ETA: 3:02 - loss: 0.0698 - sparse_categorical_accuracy: 0.9750\n",
            "  6/469 [..............................] - ETA: 3:01 - loss: 0.0686 - sparse_categorical_accuracy: 0.9766\n",
            "  7/469 [..............................] - ETA: 3:00 - loss: 0.0688 - sparse_categorical_accuracy: 0.9777\n",
            "  8/469 [..............................] - ETA: 3:00 - loss: 0.0638 - sparse_categorical_accuracy: 0.9795\n",
            "  9/469 [..............................] - ETA: 3:01 - loss: 0.0699 - sparse_categorical_accuracy: 0.9783\n",
            " 10/469 [..............................] - ETA: 3:00 - loss: 0.0693 - sparse_categorical_accuracy: 0.9773\n",
            " 11/469 [..............................] - ETA: 3:00 - loss: 0.0652 - sparse_categorical_accuracy: 0.9787\n",
            " 12/469 [..............................] - ETA: 2:59 - loss: 0.0645 - sparse_categorical_accuracy: 0.9792\n",
            " 13/469 [..............................] - ETA: 2:59 - loss: 0.0618 - sparse_categorical_accuracy: 0.9802\n",
            " 14/469 [..............................] - ETA: 2:58 - loss: 0.0604 - sparse_categorical_accuracy: 0.9810\n",
            " 15/469 [..............................] - ETA: 2:57 - loss: 0.0610 - sparse_categorical_accuracy: 0.9802\n",
            " 16/469 [>.............................] - ETA: 2:58 - loss: 0.0610 - sparse_categorical_accuracy: 0.9800\n",
            " 17/469 [>.............................] - ETA: 2:57 - loss: 0.0618 - sparse_categorical_accuracy: 0.9798\n",
            " 18/469 [>.............................] - ETA: 2:57 - loss: 0.0631 - sparse_categorical_accuracy: 0.9796\n",
            " 19/469 [>.............................] - ETA: 2:56 - loss: 0.0628 - sparse_categorical_accuracy: 0.9799\n",
            " 20/469 [>.............................] - ETA: 2:57 - loss: 0.0641 - sparse_categorical_accuracy: 0.9797\n",
            " 21/469 [>.............................] - ETA: 3:01 - loss: 0.0630 - sparse_categorical_accuracy: 0.9799\n",
            " 22/469 [>.............................] - ETA: 3:05 - loss: 0.0613 - sparse_categorical_accuracy: 0.9805\n",
            " 23/469 [>.............................] - ETA: 3:09 - loss: 0.0619 - sparse_categorical_accuracy: 0.9800\n",
            " 24/469 [>.............................] - ETA: 3:13 - loss: 0.0603 - sparse_categorical_accuracy: 0.9805\n",
            " 25/469 [>.............................] - ETA: 3:15 - loss: 0.0617 - sparse_categorical_accuracy: 0.9797\n",
            " 26/469 [>.............................] - ETA: 3:17 - loss: 0.0619 - sparse_categorical_accuracy: 0.9796\n",
            " 27/469 [>.............................] - ETA: 3:16 - loss: 0.0619 - sparse_categorical_accuracy: 0.9792\n",
            " 28/469 [>.............................] - ETA: 3:15 - loss: 0.0602 - sparse_categorical_accuracy: 0.9799\n",
            " 29/469 [>.............................] - ETA: 3:14 - loss: 0.0602 - sparse_categorical_accuracy: 0.9798\n",
            " 30/469 [>.............................] - ETA: 3:13 - loss: 0.0598 - sparse_categorical_accuracy: 0.9799\n",
            " 31/469 [>.............................] - ETA: 3:12 - loss: 0.0600 - sparse_categorical_accuracy: 0.9798\n",
            " 32/469 [=>............................] - ETA: 3:11 - loss: 0.0588 - sparse_categorical_accuracy: 0.9805\n",
            " 33/469 [=>............................] - ETA: 3:10 - loss: 0.0586 - sparse_categorical_accuracy: 0.9804\n",
            " 34/469 [=>............................] - ETA: 3:09 - loss: 0.0576 - sparse_categorical_accuracy: 0.9809\n",
            " 35/469 [=>............................] - ETA: 3:08 - loss: 0.0607 - sparse_categorical_accuracy: 0.9804\n",
            " 36/469 [=>............................] - ETA: 3:07 - loss: 0.0602 - sparse_categorical_accuracy: 0.9805\n",
            " 37/469 [=>............................] - ETA: 3:06 - loss: 0.0598 - sparse_categorical_accuracy: 0.9808\n",
            " 38/469 [=>............................] - ETA: 3:06 - loss: 0.0596 - sparse_categorical_accuracy: 0.9811\n",
            " 39/469 [=>............................] - ETA: 3:05 - loss: 0.0593 - sparse_categorical_accuracy: 0.9808\n",
            " 40/469 [=>............................] - ETA: 3:04 - loss: 0.0586 - sparse_categorical_accuracy: 0.9811\n",
            " 41/469 [=>............................] - ETA: 3:04 - loss: 0.0576 - sparse_categorical_accuracy: 0.9815\n",
            " 42/469 [=>............................] - ETA: 3:03 - loss: 0.0598 - sparse_categorical_accuracy: 0.9814\n",
            " 43/469 [=>............................] - ETA: 3:02 - loss: 0.0599 - sparse_categorical_accuracy: 0.9813\n",
            " 44/469 [=>............................] - ETA: 3:02 - loss: 0.0591 - sparse_categorical_accuracy: 0.9814\n",
            " 45/469 [=>............................] - ETA: 3:01 - loss: 0.0583 - sparse_categorical_accuracy: 0.9818\n",
            " 46/469 [=>............................] - ETA: 3:01 - loss: 0.0577 - sparse_categorical_accuracy: 0.9820\n",
            " 47/469 [==>...........................] - ETA: 3:00 - loss: 0.0571 - sparse_categorical_accuracy: 0.9822\n",
            " 48/469 [==>...........................] - ETA: 2:59 - loss: 0.0571 - sparse_categorical_accuracy: 0.9823\n",
            " 49/469 [==>...........................] - ETA: 2:59 - loss: 0.0570 - sparse_categorical_accuracy: 0.9821\n",
            " 50/469 [==>...........................] - ETA: 2:58 - loss: 0.0563 - sparse_categorical_accuracy: 0.9823\n",
            " 51/469 [==>...........................] - ETA: 2:59 - loss: 0.0585 - sparse_categorical_accuracy: 0.9818\n",
            " 52/469 [==>...........................] - ETA: 3:00 - loss: 0.0579 - sparse_categorical_accuracy: 0.9820\n",
            " 53/469 [==>...........................] - ETA: 3:01 - loss: 0.0589 - sparse_categorical_accuracy: 0.9816\n",
            " 54/469 [==>...........................] - ETA: 3:02 - loss: 0.0584 - sparse_categorical_accuracy: 0.9818\n",
            " 55/469 [==>...........................] - ETA: 3:03 - loss: 0.0582 - sparse_categorical_accuracy: 0.9820\n",
            " 56/469 [==>...........................] - ETA: 3:04 - loss: 0.0582 - sparse_categorical_accuracy: 0.9819\n",
            " 57/469 [==>...........................] - ETA: 3:03 - loss: 0.0576 - sparse_categorical_accuracy: 0.9822\n",
            " 58/469 [==>...........................] - ETA: 3:03 - loss: 0.0584 - sparse_categorical_accuracy: 0.9820\n",
            " 59/469 [==>...........................] - ETA: 3:02 - loss: 0.0587 - sparse_categorical_accuracy: 0.9820\n",
            " 60/469 [==>...........................] - ETA: 3:01 - loss: 0.0590 - sparse_categorical_accuracy: 0.9816\n",
            " 61/469 [==>...........................] - ETA: 3:01 - loss: 0.0593 - sparse_categorical_accuracy: 0.9818\n",
            " 62/469 [==>...........................] - ETA: 3:00 - loss: 0.0589 - sparse_categorical_accuracy: 0.9820\n",
            " 63/469 [===>..........................] - ETA: 2:59 - loss: 0.0582 - sparse_categorical_accuracy: 0.9823\n",
            " 64/469 [===>..........................] - ETA: 2:58 - loss: 0.0577 - sparse_categorical_accuracy: 0.9824\n",
            " 65/469 [===>..........................] - ETA: 2:58 - loss: 0.0573 - sparse_categorical_accuracy: 0.9826\n",
            " 66/469 [===>..........................] - ETA: 2:57 - loss: 0.0569 - sparse_categorical_accuracy: 0.9827\n",
            " 67/469 [===>..........................] - ETA: 2:57 - loss: 0.0572 - sparse_categorical_accuracy: 0.9826\n",
            " 68/469 [===>..........................] - ETA: 2:56 - loss: 0.0571 - sparse_categorical_accuracy: 0.9824\n",
            " 69/469 [===>..........................] - ETA: 2:55 - loss: 0.0581 - sparse_categorical_accuracy: 0.9820\n",
            " 70/469 [===>..........................] - ETA: 2:54 - loss: 0.0584 - sparse_categorical_accuracy: 0.9820\n",
            " 71/469 [===>..........................] - ETA: 2:54 - loss: 0.0578 - sparse_categorical_accuracy: 0.9823\n",
            " 72/469 [===>..........................] - ETA: 2:53 - loss: 0.0574 - sparse_categorical_accuracy: 0.9824\n",
            " 73/469 [===>..........................] - ETA: 2:53 - loss: 0.0573 - sparse_categorical_accuracy: 0.9822\n",
            " 74/469 [===>..........................] - ETA: 2:52 - loss: 0.0570 - sparse_categorical_accuracy: 0.9823\n",
            " 75/469 [===>..........................] - ETA: 2:53 - loss: 0.0565 - sparse_categorical_accuracy: 0.9824\n",
            " 76/469 [===>..........................] - ETA: 2:52 - loss: 0.0579 - sparse_categorical_accuracy: 0.9820\n",
            " 77/469 [===>..........................] - ETA: 2:51 - loss: 0.0577 - sparse_categorical_accuracy: 0.9819\n",
            " 78/469 [===>..........................] - ETA: 2:51 - loss: 0.0588 - sparse_categorical_accuracy: 0.9817\n",
            " 79/469 [====>.........................] - ETA: 2:50 - loss: 0.0589 - sparse_categorical_accuracy: 0.9817\n",
            " 80/469 [====>.........................] - ETA: 2:49 - loss: 0.0584 - sparse_categorical_accuracy: 0.9819\n",
            " 81/469 [====>.........................] - ETA: 2:50 - loss: 0.0589 - sparse_categorical_accuracy: 0.9819\n",
            " 82/469 [====>.........................] - ETA: 2:50 - loss: 0.0586 - sparse_categorical_accuracy: 0.9820\n",
            " 83/469 [====>.........................] - ETA: 2:50 - loss: 0.0600 - sparse_categorical_accuracy: 0.9821\n",
            " 84/469 [====>.........................] - ETA: 2:51 - loss: 0.0598 - sparse_categorical_accuracy: 0.9822\n",
            " 85/469 [====>.........................] - ETA: 2:51 - loss: 0.0596 - sparse_categorical_accuracy: 0.9822\n",
            " 86/469 [====>.........................] - ETA: 2:52 - loss: 0.0597 - sparse_categorical_accuracy: 0.9820\n",
            " 87/469 [====>.........................] - ETA: 2:51 - loss: 0.0592 - sparse_categorical_accuracy: 0.9822\n",
            " 88/469 [====>.........................] - ETA: 2:50 - loss: 0.0590 - sparse_categorical_accuracy: 0.9823\n",
            " 89/469 [====>.........................] - ETA: 2:50 - loss: 0.0586 - sparse_categorical_accuracy: 0.9824\n",
            " 90/469 [====>.........................] - ETA: 2:49 - loss: 0.0585 - sparse_categorical_accuracy: 0.9825\n",
            " 91/469 [====>.........................] - ETA: 2:49 - loss: 0.0585 - sparse_categorical_accuracy: 0.9826\n",
            " 92/469 [====>.........................] - ETA: 2:48 - loss: 0.0587 - sparse_categorical_accuracy: 0.9825\n",
            " 93/469 [====>.........................] - ETA: 2:47 - loss: 0.0592 - sparse_categorical_accuracy: 0.9824\n",
            " 94/469 [=====>........................] - ETA: 2:47 - loss: 0.0589 - sparse_categorical_accuracy: 0.9825\n",
            " 95/469 [=====>........................] - ETA: 2:46 - loss: 0.0589 - sparse_categorical_accuracy: 0.9826\n",
            " 96/469 [=====>........................] - ETA: 2:45 - loss: 0.0590 - sparse_categorical_accuracy: 0.9825\n",
            " 97/469 [=====>........................] - ETA: 2:45 - loss: 0.0588 - sparse_categorical_accuracy: 0.9825\n",
            " 98/469 [=====>........................] - ETA: 2:44 - loss: 0.0588 - sparse_categorical_accuracy: 0.9825\n",
            " 99/469 [=====>........................] - ETA: 2:44 - loss: 0.0588 - sparse_categorical_accuracy: 0.9825\n",
            "100/469 [=====>........................] - ETA: 2:43 - loss: 0.0592 - sparse_categorical_accuracy: 0.9824\n",
            "101/469 [=====>........................] - ETA: 2:43 - loss: 0.0593 - sparse_categorical_accuracy: 0.9824\n",
            "102/469 [=====>........................] - ETA: 2:42 - loss: 0.0593 - sparse_categorical_accuracy: 0.9824\n",
            "103/469 [=====>........................] - ETA: 2:41 - loss: 0.0594 - sparse_categorical_accuracy: 0.9823\n",
            "104/469 [=====>........................] - ETA: 2:41 - loss: 0.0597 - sparse_categorical_accuracy: 0.9823\n",
            "105/469 [=====>........................] - ETA: 2:40 - loss: 0.0596 - sparse_categorical_accuracy: 0.9823\n",
            "106/469 [=====>........................] - ETA: 2:40 - loss: 0.0598 - sparse_categorical_accuracy: 0.9822\n",
            "107/469 [=====>........................] - ETA: 2:39 - loss: 0.0595 - sparse_categorical_accuracy: 0.9823\n",
            "108/469 [=====>........................] - ETA: 2:38 - loss: 0.0591 - sparse_categorical_accuracy: 0.9824\n",
            "109/469 [=====>........................] - ETA: 2:38 - loss: 0.0591 - sparse_categorical_accuracy: 0.9824\n",
            "110/469 [======>.......................] - ETA: 2:37 - loss: 0.0592 - sparse_categorical_accuracy: 0.9823\n",
            "111/469 [======>.......................] - ETA: 2:37 - loss: 0.0590 - sparse_categorical_accuracy: 0.9824\n",
            "112/469 [======>.......................] - ETA: 2:37 - loss: 0.0592 - sparse_categorical_accuracy: 0.9823\n",
            "113/469 [======>.......................] - ETA: 2:38 - loss: 0.0596 - sparse_categorical_accuracy: 0.9822\n",
            "114/469 [======>.......................] - ETA: 2:38 - loss: 0.0598 - sparse_categorical_accuracy: 0.9821\n",
            "115/469 [======>.......................] - ETA: 2:38 - loss: 0.0601 - sparse_categorical_accuracy: 0.9821\n",
            "116/469 [======>.......................] - ETA: 2:38 - loss: 0.0596 - sparse_categorical_accuracy: 0.9823\n",
            "117/469 [======>.......................] - ETA: 2:37 - loss: 0.0598 - sparse_categorical_accuracy: 0.9822\n",
            "118/469 [======>.......................] - ETA: 2:36 - loss: 0.0598 - sparse_categorical_accuracy: 0.9821\n",
            "119/469 [======>.......................] - ETA: 2:36 - loss: 0.0600 - sparse_categorical_accuracy: 0.9820\n",
            "120/469 [======>.......................] - ETA: 2:35 - loss: 0.0603 - sparse_categorical_accuracy: 0.9820\n",
            "121/469 [======>.......................] - ETA: 2:35 - loss: 0.0604 - sparse_categorical_accuracy: 0.9820\n",
            "122/469 [======>.......................] - ETA: 2:34 - loss: 0.0606 - sparse_categorical_accuracy: 0.9819\n",
            "123/469 [======>.......................] - ETA: 2:33 - loss: 0.0604 - sparse_categorical_accuracy: 0.9820\n",
            "124/469 [======>.......................] - ETA: 2:33 - loss: 0.0604 - sparse_categorical_accuracy: 0.9819\n",
            "125/469 [======>.......................] - ETA: 2:32 - loss: 0.0605 - sparse_categorical_accuracy: 0.9819\n",
            "126/469 [=======>......................] - ETA: 2:32 - loss: 0.0610 - sparse_categorical_accuracy: 0.9817\n",
            "127/469 [=======>......................] - ETA: 2:31 - loss: 0.0610 - sparse_categorical_accuracy: 0.9816\n",
            "128/469 [=======>......................] - ETA: 2:31 - loss: 0.0611 - sparse_categorical_accuracy: 0.9815\n",
            "129/469 [=======>......................] - ETA: 2:30 - loss: 0.0609 - sparse_categorical_accuracy: 0.9816\n",
            "130/469 [=======>......................] - ETA: 2:29 - loss: 0.0609 - sparse_categorical_accuracy: 0.9816\n",
            "131/469 [=======>......................] - ETA: 2:29 - loss: 0.0609 - sparse_categorical_accuracy: 0.9816\n",
            "132/469 [=======>......................] - ETA: 2:28 - loss: 0.0607 - sparse_categorical_accuracy: 0.9817\n",
            "133/469 [=======>......................] - ETA: 2:28 - loss: 0.0613 - sparse_categorical_accuracy: 0.9813\n",
            "134/469 [=======>......................] - ETA: 2:27 - loss: 0.0611 - sparse_categorical_accuracy: 0.9814\n",
            "135/469 [=======>......................] - ETA: 2:27 - loss: 0.0610 - sparse_categorical_accuracy: 0.9814\n",
            "136/469 [=======>......................] - ETA: 2:26 - loss: 0.0613 - sparse_categorical_accuracy: 0.9813\n",
            "137/469 [=======>......................] - ETA: 2:26 - loss: 0.0612 - sparse_categorical_accuracy: 0.9814\n",
            "138/469 [=======>......................] - ETA: 2:25 - loss: 0.0616 - sparse_categorical_accuracy: 0.9813\n",
            "139/469 [=======>......................] - ETA: 2:24 - loss: 0.0613 - sparse_categorical_accuracy: 0.9815\n",
            "140/469 [=======>......................] - ETA: 2:24 - loss: 0.0612 - sparse_categorical_accuracy: 0.9815\n",
            "141/469 [========>.....................] - ETA: 2:23 - loss: 0.0611 - sparse_categorical_accuracy: 0.9814\n",
            "142/469 [========>.....................] - ETA: 2:23 - loss: 0.0608 - sparse_categorical_accuracy: 0.9816\n",
            "143/469 [========>.....................] - ETA: 2:23 - loss: 0.0610 - sparse_categorical_accuracy: 0.9815\n",
            "144/469 [========>.....................] - ETA: 2:23 - loss: 0.0614 - sparse_categorical_accuracy: 0.9814\n",
            "145/469 [========>.....................] - ETA: 2:23 - loss: 0.0613 - sparse_categorical_accuracy: 0.9814\n",
            "146/469 [========>.....................] - ETA: 2:23 - loss: 0.0612 - sparse_categorical_accuracy: 0.9814\n",
            "147/469 [========>.....................] - ETA: 2:23 - loss: 0.0614 - sparse_categorical_accuracy: 0.9813\n",
            "148/469 [========>.....................] - ETA: 2:22 - loss: 0.0616 - sparse_categorical_accuracy: 0.9813\n",
            "149/469 [========>.....................] - ETA: 2:22 - loss: 0.0615 - sparse_categorical_accuracy: 0.9813\n",
            "150/469 [========>.....................] - ETA: 2:21 - loss: 0.0615 - sparse_categorical_accuracy: 0.9812\n",
            "151/469 [========>.....................] - ETA: 2:21 - loss: 0.0616 - sparse_categorical_accuracy: 0.9812\n",
            "152/469 [========>.....................] - ETA: 2:20 - loss: 0.0622 - sparse_categorical_accuracy: 0.9810\n",
            "153/469 [========>.....................] - ETA: 2:20 - loss: 0.0623 - sparse_categorical_accuracy: 0.9810\n",
            "154/469 [========>.....................] - ETA: 2:19 - loss: 0.0624 - sparse_categorical_accuracy: 0.9810\n",
            "155/469 [========>.....................] - ETA: 2:19 - loss: 0.0622 - sparse_categorical_accuracy: 0.9810\n",
            "156/469 [========>.....................] - ETA: 2:18 - loss: 0.0626 - sparse_categorical_accuracy: 0.9810\n",
            "157/469 [=========>....................] - ETA: 2:18 - loss: 0.0624 - sparse_categorical_accuracy: 0.9810\n",
            "158/469 [=========>....................] - ETA: 2:17 - loss: 0.0622 - sparse_categorical_accuracy: 0.9811\n",
            "159/469 [=========>....................] - ETA: 2:17 - loss: 0.0622 - sparse_categorical_accuracy: 0.9811\n",
            "160/469 [=========>....................] - ETA: 2:16 - loss: 0.0622 - sparse_categorical_accuracy: 0.9812\n",
            "161/469 [=========>....................] - ETA: 2:16 - loss: 0.0623 - sparse_categorical_accuracy: 0.9810\n",
            "162/469 [=========>....................] - ETA: 2:15 - loss: 0.0625 - sparse_categorical_accuracy: 0.9810\n",
            "163/469 [=========>....................] - ETA: 2:15 - loss: 0.0633 - sparse_categorical_accuracy: 0.9809\n",
            "164/469 [=========>....................] - ETA: 2:14 - loss: 0.0633 - sparse_categorical_accuracy: 0.9810\n",
            "165/469 [=========>....................] - ETA: 2:14 - loss: 0.0632 - sparse_categorical_accuracy: 0.9810\n",
            "166/469 [=========>....................] - ETA: 2:13 - loss: 0.0632 - sparse_categorical_accuracy: 0.9810\n",
            "167/469 [=========>....................] - ETA: 2:13 - loss: 0.0630 - sparse_categorical_accuracy: 0.9810\n",
            "168/469 [=========>....................] - ETA: 2:12 - loss: 0.0628 - sparse_categorical_accuracy: 0.9811\n",
            "169/469 [=========>....................] - ETA: 2:12 - loss: 0.0632 - sparse_categorical_accuracy: 0.9809\n",
            "170/469 [=========>....................] - ETA: 2:11 - loss: 0.0634 - sparse_categorical_accuracy: 0.9807\n",
            "171/469 [=========>....................] - ETA: 2:11 - loss: 0.0636 - sparse_categorical_accuracy: 0.9807\n",
            "172/469 [==========>...................] - ETA: 2:10 - loss: 0.0633 - sparse_categorical_accuracy: 0.9808\n",
            "173/469 [==========>...................] - ETA: 2:10 - loss: 0.0638 - sparse_categorical_accuracy: 0.9808\n",
            "174/469 [==========>...................] - ETA: 2:10 - loss: 0.0636 - sparse_categorical_accuracy: 0.9808\n",
            "175/469 [==========>...................] - ETA: 2:10 - loss: 0.0636 - sparse_categorical_accuracy: 0.9808\n",
            "176/469 [==========>...................] - ETA: 2:10 - loss: 0.0636 - sparse_categorical_accuracy: 0.9808\n",
            "177/469 [==========>...................] - ETA: 2:10 - loss: 0.0636 - sparse_categorical_accuracy: 0.9808\n",
            "178/469 [==========>...................] - ETA: 2:09 - loss: 0.0634 - sparse_categorical_accuracy: 0.9808\n",
            "179/469 [==========>...................] - ETA: 2:09 - loss: 0.0634 - sparse_categorical_accuracy: 0.9808\n",
            "180/469 [==========>...................] - ETA: 2:08 - loss: 0.0635 - sparse_categorical_accuracy: 0.9808\n",
            "181/469 [==========>...................] - ETA: 2:08 - loss: 0.0633 - sparse_categorical_accuracy: 0.9808\n",
            "182/469 [==========>...................] - ETA: 2:07 - loss: 0.0636 - sparse_categorical_accuracy: 0.9808\n",
            "183/469 [==========>...................] - ETA: 2:07 - loss: 0.0634 - sparse_categorical_accuracy: 0.9808\n",
            "184/469 [==========>...................] - ETA: 2:06 - loss: 0.0633 - sparse_categorical_accuracy: 0.9809\n",
            "185/469 [==========>...................] - ETA: 2:06 - loss: 0.0635 - sparse_categorical_accuracy: 0.9807\n",
            "186/469 [==========>...................] - ETA: 2:05 - loss: 0.0638 - sparse_categorical_accuracy: 0.9806\n",
            "187/469 [==========>...................] - ETA: 2:05 - loss: 0.0638 - sparse_categorical_accuracy: 0.9806\n",
            "188/469 [===========>..................] - ETA: 2:04 - loss: 0.0638 - sparse_categorical_accuracy: 0.9806\n",
            "189/469 [===========>..................] - ETA: 2:04 - loss: 0.0639 - sparse_categorical_accuracy: 0.9806\n",
            "190/469 [===========>..................] - ETA: 2:03 - loss: 0.0637 - sparse_categorical_accuracy: 0.9806\n",
            "191/469 [===========>..................] - ETA: 2:03 - loss: 0.0636 - sparse_categorical_accuracy: 0.9807\n",
            "192/469 [===========>..................] - ETA: 2:02 - loss: 0.0636 - sparse_categorical_accuracy: 0.9806\n",
            "193/469 [===========>..................] - ETA: 2:02 - loss: 0.0638 - sparse_categorical_accuracy: 0.9804\n",
            "194/469 [===========>..................] - ETA: 2:01 - loss: 0.0638 - sparse_categorical_accuracy: 0.9805\n",
            "195/469 [===========>..................] - ETA: 2:01 - loss: 0.0641 - sparse_categorical_accuracy: 0.9805\n",
            "196/469 [===========>..................] - ETA: 2:00 - loss: 0.0641 - sparse_categorical_accuracy: 0.9805\n",
            "197/469 [===========>..................] - ETA: 2:00 - loss: 0.0643 - sparse_categorical_accuracy: 0.9804\n",
            "198/469 [===========>..................] - ETA: 1:59 - loss: 0.0640 - sparse_categorical_accuracy: 0.9805\n",
            "199/469 [===========>..................] - ETA: 1:59 - loss: 0.0638 - sparse_categorical_accuracy: 0.9806\n",
            "200/469 [===========>..................] - ETA: 1:58 - loss: 0.0637 - sparse_categorical_accuracy: 0.9806\n",
            "201/469 [===========>..................] - ETA: 1:58 - loss: 0.0635 - sparse_categorical_accuracy: 0.9807\n",
            "202/469 [===========>..................] - ETA: 1:58 - loss: 0.0633 - sparse_categorical_accuracy: 0.9808\n",
            "203/469 [===========>..................] - ETA: 1:57 - loss: 0.0632 - sparse_categorical_accuracy: 0.9808\n",
            "204/469 [============>.................] - ETA: 1:57 - loss: 0.0633 - sparse_categorical_accuracy: 0.9807\n",
            "205/469 [============>.................] - ETA: 1:57 - loss: 0.0631 - sparse_categorical_accuracy: 0.9808\n",
            "206/469 [============>.................] - ETA: 1:57 - loss: 0.0630 - sparse_categorical_accuracy: 0.9808\n",
            "207/469 [============>.................] - ETA: 1:57 - loss: 0.0632 - sparse_categorical_accuracy: 0.9808\n",
            "208/469 [============>.................] - ETA: 1:56 - loss: 0.0631 - sparse_categorical_accuracy: 0.9808\n",
            "209/469 [============>.................] - ETA: 1:56 - loss: 0.0630 - sparse_categorical_accuracy: 0.9808\n",
            "210/469 [============>.................] - ETA: 1:55 - loss: 0.0630 - sparse_categorical_accuracy: 0.9808\n",
            "211/469 [============>.................] - ETA: 1:55 - loss: 0.0629 - sparse_categorical_accuracy: 0.9809\n",
            "212/469 [============>.................] - ETA: 1:54 - loss: 0.0628 - sparse_categorical_accuracy: 0.9809\n",
            "213/469 [============>.................] - ETA: 1:54 - loss: 0.0628 - sparse_categorical_accuracy: 0.9809\n",
            "214/469 [============>.................] - ETA: 1:53 - loss: 0.0629 - sparse_categorical_accuracy: 0.9808\n",
            "215/469 [============>.................] - ETA: 1:53 - loss: 0.0627 - sparse_categorical_accuracy: 0.9809\n",
            "216/469 [============>.................] - ETA: 1:52 - loss: 0.0626 - sparse_categorical_accuracy: 0.9809\n",
            "217/469 [============>.................] - ETA: 1:52 - loss: 0.0628 - sparse_categorical_accuracy: 0.9808\n",
            "218/469 [============>.................] - ETA: 1:51 - loss: 0.0628 - sparse_categorical_accuracy: 0.9808\n",
            "219/469 [=============>................] - ETA: 1:51 - loss: 0.0627 - sparse_categorical_accuracy: 0.9808\n",
            "220/469 [=============>................] - ETA: 1:50 - loss: 0.0627 - sparse_categorical_accuracy: 0.9808\n",
            "221/469 [=============>................] - ETA: 1:50 - loss: 0.0626 - sparse_categorical_accuracy: 0.9809\n",
            "222/469 [=============>................] - ETA: 1:49 - loss: 0.0626 - sparse_categorical_accuracy: 0.9809\n",
            "223/469 [=============>................] - ETA: 1:49 - loss: 0.0625 - sparse_categorical_accuracy: 0.9809\n",
            "224/469 [=============>................] - ETA: 1:48 - loss: 0.0625 - sparse_categorical_accuracy: 0.9809\n",
            "225/469 [=============>................] - ETA: 1:48 - loss: 0.0627 - sparse_categorical_accuracy: 0.9807\n",
            "226/469 [=============>................] - ETA: 1:47 - loss: 0.0629 - sparse_categorical_accuracy: 0.9806\n",
            "227/469 [=============>................] - ETA: 1:47 - loss: 0.0628 - sparse_categorical_accuracy: 0.9806\n",
            "228/469 [=============>................] - ETA: 1:46 - loss: 0.0627 - sparse_categorical_accuracy: 0.9806\n",
            "229/469 [=============>................] - ETA: 1:46 - loss: 0.0627 - sparse_categorical_accuracy: 0.9806\n",
            "230/469 [=============>................] - ETA: 1:45 - loss: 0.0627 - sparse_categorical_accuracy: 0.9806\n",
            "231/469 [=============>................] - ETA: 1:45 - loss: 0.0627 - sparse_categorical_accuracy: 0.9806\n",
            "232/469 [=============>................] - ETA: 1:45 - loss: 0.0627 - sparse_categorical_accuracy: 0.9806\n",
            "233/469 [=============>................] - ETA: 1:44 - loss: 0.0627 - sparse_categorical_accuracy: 0.9806\n",
            "234/469 [=============>................] - ETA: 1:44 - loss: 0.0627 - sparse_categorical_accuracy: 0.9806\n",
            "235/469 [==============>...............] - ETA: 1:44 - loss: 0.0627 - sparse_categorical_accuracy: 0.9806\n",
            "236/469 [==============>...............] - ETA: 1:44 - loss: 0.0626 - sparse_categorical_accuracy: 0.9806\n",
            "237/469 [==============>...............] - ETA: 1:43 - loss: 0.0627 - sparse_categorical_accuracy: 0.9807\n",
            "238/469 [==============>...............] - ETA: 1:43 - loss: 0.0625 - sparse_categorical_accuracy: 0.9807\n",
            "239/469 [==============>...............] - ETA: 1:42 - loss: 0.0623 - sparse_categorical_accuracy: 0.9807\n",
            "240/469 [==============>...............] - ETA: 1:42 - loss: 0.0623 - sparse_categorical_accuracy: 0.9808\n",
            "241/469 [==============>...............] - ETA: 1:41 - loss: 0.0621 - sparse_categorical_accuracy: 0.9809\n",
            "242/469 [==============>...............] - ETA: 1:41 - loss: 0.0619 - sparse_categorical_accuracy: 0.9810\n",
            "243/469 [==============>...............] - ETA: 1:40 - loss: 0.0618 - sparse_categorical_accuracy: 0.9810\n",
            "244/469 [==============>...............] - ETA: 1:40 - loss: 0.0618 - sparse_categorical_accuracy: 0.9810\n",
            "245/469 [==============>...............] - ETA: 1:40 - loss: 0.0617 - sparse_categorical_accuracy: 0.9810\n",
            "246/469 [==============>...............] - ETA: 1:39 - loss: 0.0619 - sparse_categorical_accuracy: 0.9810\n",
            "247/469 [==============>...............] - ETA: 1:39 - loss: 0.0619 - sparse_categorical_accuracy: 0.9809\n",
            "248/469 [==============>...............] - ETA: 1:38 - loss: 0.0618 - sparse_categorical_accuracy: 0.9810\n",
            "249/469 [==============>...............] - ETA: 1:38 - loss: 0.0618 - sparse_categorical_accuracy: 0.9810\n",
            "250/469 [==============>...............] - ETA: 1:37 - loss: 0.0618 - sparse_categorical_accuracy: 0.9810\n",
            "251/469 [===============>..............] - ETA: 1:37 - loss: 0.0619 - sparse_categorical_accuracy: 0.9810\n",
            "252/469 [===============>..............] - ETA: 1:36 - loss: 0.0618 - sparse_categorical_accuracy: 0.9810\n",
            "253/469 [===============>..............] - ETA: 1:36 - loss: 0.0617 - sparse_categorical_accuracy: 0.9810\n",
            "254/469 [===============>..............] - ETA: 1:35 - loss: 0.0616 - sparse_categorical_accuracy: 0.9811\n",
            "255/469 [===============>..............] - ETA: 1:35 - loss: 0.0615 - sparse_categorical_accuracy: 0.9811\n",
            "256/469 [===============>..............] - ETA: 1:34 - loss: 0.0614 - sparse_categorical_accuracy: 0.9812\n",
            "257/469 [===============>..............] - ETA: 1:34 - loss: 0.0613 - sparse_categorical_accuracy: 0.9812\n",
            "258/469 [===============>..............] - ETA: 1:33 - loss: 0.0613 - sparse_categorical_accuracy: 0.9812\n",
            "259/469 [===============>..............] - ETA: 1:33 - loss: 0.0613 - sparse_categorical_accuracy: 0.9812\n",
            "260/469 [===============>..............] - ETA: 1:32 - loss: 0.0612 - sparse_categorical_accuracy: 0.9812\n",
            "261/469 [===============>..............] - ETA: 1:32 - loss: 0.0611 - sparse_categorical_accuracy: 0.9812\n",
            "262/469 [===============>..............] - ETA: 1:31 - loss: 0.0612 - sparse_categorical_accuracy: 0.9811\n",
            "263/469 [===============>..............] - ETA: 1:31 - loss: 0.0613 - sparse_categorical_accuracy: 0.9811\n",
            "264/469 [===============>..............] - ETA: 1:31 - loss: 0.0612 - sparse_categorical_accuracy: 0.9811\n",
            "265/469 [===============>..............] - ETA: 1:30 - loss: 0.0615 - sparse_categorical_accuracy: 0.9811\n",
            "266/469 [================>.............] - ETA: 1:30 - loss: 0.0614 - sparse_categorical_accuracy: 0.9811\n",
            "267/469 [================>.............] - ETA: 1:30 - loss: 0.0616 - sparse_categorical_accuracy: 0.9810\n",
            "268/469 [================>.............] - ETA: 1:29 - loss: 0.0617 - sparse_categorical_accuracy: 0.9809\n",
            "269/469 [================>.............] - ETA: 1:29 - loss: 0.0617 - sparse_categorical_accuracy: 0.9809\n",
            "270/469 [================>.............] - ETA: 1:28 - loss: 0.0616 - sparse_categorical_accuracy: 0.9809\n",
            "271/469 [================>.............] - ETA: 1:28 - loss: 0.0617 - sparse_categorical_accuracy: 0.9809\n",
            "272/469 [================>.............] - ETA: 1:27 - loss: 0.0616 - sparse_categorical_accuracy: 0.9810\n",
            "273/469 [================>.............] - ETA: 1:27 - loss: 0.0616 - sparse_categorical_accuracy: 0.9810\n",
            "274/469 [================>.............] - ETA: 1:26 - loss: 0.0616 - sparse_categorical_accuracy: 0.9809\n",
            "275/469 [================>.............] - ETA: 1:26 - loss: 0.0616 - sparse_categorical_accuracy: 0.9809\n",
            "276/469 [================>.............] - ETA: 1:25 - loss: 0.0614 - sparse_categorical_accuracy: 0.9810\n",
            "277/469 [================>.............] - ETA: 1:25 - loss: 0.0614 - sparse_categorical_accuracy: 0.9810\n",
            "278/469 [================>.............] - ETA: 1:24 - loss: 0.0613 - sparse_categorical_accuracy: 0.9810\n",
            "279/469 [================>.............] - ETA: 1:24 - loss: 0.0612 - sparse_categorical_accuracy: 0.9810\n",
            "280/469 [================>.............] - ETA: 1:23 - loss: 0.0610 - sparse_categorical_accuracy: 0.9811\n",
            "281/469 [================>.............] - ETA: 1:23 - loss: 0.0610 - sparse_categorical_accuracy: 0.9810\n",
            "282/469 [=================>............] - ETA: 1:22 - loss: 0.0611 - sparse_categorical_accuracy: 0.9810\n",
            "283/469 [=================>............] - ETA: 1:22 - loss: 0.0611 - sparse_categorical_accuracy: 0.9810\n",
            "284/469 [=================>............] - ETA: 1:22 - loss: 0.0610 - sparse_categorical_accuracy: 0.9810\n",
            "285/469 [=================>............] - ETA: 1:21 - loss: 0.0614 - sparse_categorical_accuracy: 0.9809\n",
            "286/469 [=================>............] - ETA: 1:21 - loss: 0.0614 - sparse_categorical_accuracy: 0.9809\n",
            "287/469 [=================>............] - ETA: 1:20 - loss: 0.0613 - sparse_categorical_accuracy: 0.9809\n",
            "288/469 [=================>............] - ETA: 1:20 - loss: 0.0613 - sparse_categorical_accuracy: 0.9809\n",
            "289/469 [=================>............] - ETA: 1:19 - loss: 0.0615 - sparse_categorical_accuracy: 0.9808\n",
            "290/469 [=================>............] - ETA: 1:19 - loss: 0.0618 - sparse_categorical_accuracy: 0.9808\n",
            "291/469 [=================>............] - ETA: 1:18 - loss: 0.0618 - sparse_categorical_accuracy: 0.9808\n",
            "292/469 [=================>............] - ETA: 1:18 - loss: 0.0617 - sparse_categorical_accuracy: 0.9808\n",
            "293/469 [=================>............] - ETA: 1:17 - loss: 0.0616 - sparse_categorical_accuracy: 0.9809\n",
            "294/469 [=================>............] - ETA: 1:17 - loss: 0.0615 - sparse_categorical_accuracy: 0.9809\n",
            "295/469 [=================>............] - ETA: 1:17 - loss: 0.0614 - sparse_categorical_accuracy: 0.9810\n",
            "296/469 [=================>............] - ETA: 1:16 - loss: 0.0615 - sparse_categorical_accuracy: 0.9809\n",
            "297/469 [=================>............] - ETA: 1:16 - loss: 0.0616 - sparse_categorical_accuracy: 0.9809\n",
            "298/469 [==================>...........] - ETA: 1:16 - loss: 0.0616 - sparse_categorical_accuracy: 0.9809\n",
            "299/469 [==================>...........] - ETA: 1:15 - loss: 0.0617 - sparse_categorical_accuracy: 0.9809\n",
            "300/469 [==================>...........] - ETA: 1:15 - loss: 0.0617 - sparse_categorical_accuracy: 0.9809\n",
            "301/469 [==================>...........] - ETA: 1:14 - loss: 0.0617 - sparse_categorical_accuracy: 0.9809\n",
            "302/469 [==================>...........] - ETA: 1:14 - loss: 0.0617 - sparse_categorical_accuracy: 0.9809\n",
            "303/469 [==================>...........] - ETA: 1:13 - loss: 0.0617 - sparse_categorical_accuracy: 0.9809\n",
            "304/469 [==================>...........] - ETA: 1:13 - loss: 0.0617 - sparse_categorical_accuracy: 0.9809\n",
            "305/469 [==================>...........] - ETA: 1:12 - loss: 0.0616 - sparse_categorical_accuracy: 0.9810\n",
            "306/469 [==================>...........] - ETA: 1:12 - loss: 0.0617 - sparse_categorical_accuracy: 0.9810\n",
            "307/469 [==================>...........] - ETA: 1:11 - loss: 0.0617 - sparse_categorical_accuracy: 0.9810\n",
            "308/469 [==================>...........] - ETA: 1:11 - loss: 0.0616 - sparse_categorical_accuracy: 0.9810\n",
            "309/469 [==================>...........] - ETA: 1:10 - loss: 0.0618 - sparse_categorical_accuracy: 0.9810\n",
            "310/469 [==================>...........] - ETA: 1:10 - loss: 0.0617 - sparse_categorical_accuracy: 0.9810\n",
            "311/469 [==================>...........] - ETA: 1:10 - loss: 0.0616 - sparse_categorical_accuracy: 0.9810\n",
            "312/469 [==================>...........] - ETA: 1:09 - loss: 0.0617 - sparse_categorical_accuracy: 0.9809\n",
            "313/469 [===================>..........] - ETA: 1:09 - loss: 0.0618 - sparse_categorical_accuracy: 0.9809\n",
            "314/469 [===================>..........] - ETA: 1:08 - loss: 0.0617 - sparse_categorical_accuracy: 0.9809\n",
            "315/469 [===================>..........] - ETA: 1:08 - loss: 0.0616 - sparse_categorical_accuracy: 0.9809\n",
            "316/469 [===================>..........] - ETA: 1:07 - loss: 0.0615 - sparse_categorical_accuracy: 0.9809\n",
            "317/469 [===================>..........] - ETA: 1:07 - loss: 0.0617 - sparse_categorical_accuracy: 0.9809\n",
            "318/469 [===================>..........] - ETA: 1:06 - loss: 0.0618 - sparse_categorical_accuracy: 0.9809\n",
            "319/469 [===================>..........] - ETA: 1:06 - loss: 0.0617 - sparse_categorical_accuracy: 0.9809\n",
            "320/469 [===================>..........] - ETA: 1:05 - loss: 0.0619 - sparse_categorical_accuracy: 0.9809\n",
            "321/469 [===================>..........] - ETA: 1:05 - loss: 0.0617 - sparse_categorical_accuracy: 0.9809\n",
            "322/469 [===================>..........] - ETA: 1:04 - loss: 0.0616 - sparse_categorical_accuracy: 0.9810\n",
            "323/469 [===================>..........] - ETA: 1:04 - loss: 0.0616 - sparse_categorical_accuracy: 0.9810\n",
            "324/469 [===================>..........] - ETA: 1:03 - loss: 0.0617 - sparse_categorical_accuracy: 0.9809\n",
            "325/469 [===================>..........] - ETA: 1:03 - loss: 0.0619 - sparse_categorical_accuracy: 0.9809\n",
            "326/469 [===================>..........] - ETA: 1:03 - loss: 0.0619 - sparse_categorical_accuracy: 0.9809\n",
            "327/469 [===================>..........] - ETA: 1:02 - loss: 0.0619 - sparse_categorical_accuracy: 0.9809\n",
            "328/469 [===================>..........] - ETA: 1:02 - loss: 0.0618 - sparse_categorical_accuracy: 0.9809\n",
            "329/469 [====================>.........] - ETA: 1:02 - loss: 0.0619 - sparse_categorical_accuracy: 0.9809\n",
            "330/469 [====================>.........] - ETA: 1:01 - loss: 0.0619 - sparse_categorical_accuracy: 0.9809\n",
            "331/469 [====================>.........] - ETA: 1:01 - loss: 0.0620 - sparse_categorical_accuracy: 0.9809\n",
            "332/469 [====================>.........] - ETA: 1:00 - loss: 0.0619 - sparse_categorical_accuracy: 0.9809\n",
            "333/469 [====================>.........] - ETA: 1:00 - loss: 0.0621 - sparse_categorical_accuracy: 0.9808\n",
            "334/469 [====================>.........] - ETA: 59s - loss: 0.0621 - sparse_categorical_accuracy: 0.9808 \n",
            "335/469 [====================>.........] - ETA: 59s - loss: 0.0623 - sparse_categorical_accuracy: 0.9808\n",
            "336/469 [====================>.........] - ETA: 58s - loss: 0.0623 - sparse_categorical_accuracy: 0.9807\n",
            "337/469 [====================>.........] - ETA: 58s - loss: 0.0624 - sparse_categorical_accuracy: 0.9807\n",
            "338/469 [====================>.........] - ETA: 58s - loss: 0.0625 - sparse_categorical_accuracy: 0.9807\n",
            "339/469 [====================>.........] - ETA: 57s - loss: 0.0624 - sparse_categorical_accuracy: 0.9807\n",
            "340/469 [====================>.........] - ETA: 57s - loss: 0.0630 - sparse_categorical_accuracy: 0.9805\n",
            "341/469 [====================>.........] - ETA: 56s - loss: 0.0630 - sparse_categorical_accuracy: 0.9805\n",
            "342/469 [====================>.........] - ETA: 56s - loss: 0.0629 - sparse_categorical_accuracy: 0.9806\n",
            "343/469 [====================>.........] - ETA: 55s - loss: 0.0628 - sparse_categorical_accuracy: 0.9806\n",
            "344/469 [=====================>........] - ETA: 55s - loss: 0.0628 - sparse_categorical_accuracy: 0.9806\n",
            "345/469 [=====================>........] - ETA: 54s - loss: 0.0627 - sparse_categorical_accuracy: 0.9806\n",
            "346/469 [=====================>........] - ETA: 54s - loss: 0.0626 - sparse_categorical_accuracy: 0.9806\n",
            "347/469 [=====================>........] - ETA: 53s - loss: 0.0626 - sparse_categorical_accuracy: 0.9807\n",
            "348/469 [=====================>........] - ETA: 53s - loss: 0.0625 - sparse_categorical_accuracy: 0.9807\n",
            "349/469 [=====================>........] - ETA: 53s - loss: 0.0626 - sparse_categorical_accuracy: 0.9807\n",
            "350/469 [=====================>........] - ETA: 52s - loss: 0.0626 - sparse_categorical_accuracy: 0.9807\n",
            "351/469 [=====================>........] - ETA: 52s - loss: 0.0625 - sparse_categorical_accuracy: 0.9807\n",
            "352/469 [=====================>........] - ETA: 51s - loss: 0.0625 - sparse_categorical_accuracy: 0.9807\n",
            "353/469 [=====================>........] - ETA: 51s - loss: 0.0623 - sparse_categorical_accuracy: 0.9808\n",
            "354/469 [=====================>........] - ETA: 50s - loss: 0.0623 - sparse_categorical_accuracy: 0.9808\n",
            "355/469 [=====================>........] - ETA: 50s - loss: 0.0622 - sparse_categorical_accuracy: 0.9808\n",
            "356/469 [=====================>........] - ETA: 49s - loss: 0.0621 - sparse_categorical_accuracy: 0.9808\n",
            "357/469 [=====================>........] - ETA: 49s - loss: 0.0620 - sparse_categorical_accuracy: 0.9809\n",
            "358/469 [=====================>........] - ETA: 49s - loss: 0.0619 - sparse_categorical_accuracy: 0.9809\n",
            "359/469 [=====================>........] - ETA: 48s - loss: 0.0621 - sparse_categorical_accuracy: 0.9808\n",
            "360/469 [======================>.......] - ETA: 48s - loss: 0.0621 - sparse_categorical_accuracy: 0.9808\n",
            "361/469 [======================>.......] - ETA: 47s - loss: 0.0621 - sparse_categorical_accuracy: 0.9808\n",
            "362/469 [======================>.......] - ETA: 47s - loss: 0.0622 - sparse_categorical_accuracy: 0.9808\n",
            "363/469 [======================>.......] - ETA: 47s - loss: 0.0621 - sparse_categorical_accuracy: 0.9808\n",
            "364/469 [======================>.......] - ETA: 46s - loss: 0.0621 - sparse_categorical_accuracy: 0.9808\n",
            "365/469 [======================>.......] - ETA: 46s - loss: 0.0620 - sparse_categorical_accuracy: 0.9808\n",
            "366/469 [======================>.......] - ETA: 45s - loss: 0.0620 - sparse_categorical_accuracy: 0.9809\n",
            "367/469 [======================>.......] - ETA: 45s - loss: 0.0619 - sparse_categorical_accuracy: 0.9809\n",
            "368/469 [======================>.......] - ETA: 44s - loss: 0.0620 - sparse_categorical_accuracy: 0.9808\n",
            "369/469 [======================>.......] - ETA: 44s - loss: 0.0619 - sparse_categorical_accuracy: 0.9809\n",
            "370/469 [======================>.......] - ETA: 43s - loss: 0.0619 - sparse_categorical_accuracy: 0.9808\n",
            "371/469 [======================>.......] - ETA: 43s - loss: 0.0619 - sparse_categorical_accuracy: 0.9809\n",
            "372/469 [======================>.......] - ETA: 42s - loss: 0.0619 - sparse_categorical_accuracy: 0.9809\n",
            "373/469 [======================>.......] - ETA: 42s - loss: 0.0619 - sparse_categorical_accuracy: 0.9809\n",
            "374/469 [======================>.......] - ETA: 41s - loss: 0.0618 - sparse_categorical_accuracy: 0.9809\n",
            "375/469 [======================>.......] - ETA: 41s - loss: 0.0617 - sparse_categorical_accuracy: 0.9810\n",
            "376/469 [=======================>......] - ETA: 41s - loss: 0.0617 - sparse_categorical_accuracy: 0.9809\n",
            "377/469 [=======================>......] - ETA: 40s - loss: 0.0616 - sparse_categorical_accuracy: 0.9809\n",
            "378/469 [=======================>......] - ETA: 40s - loss: 0.0617 - sparse_categorical_accuracy: 0.9809\n",
            "379/469 [=======================>......] - ETA: 39s - loss: 0.0618 - sparse_categorical_accuracy: 0.9808\n",
            "380/469 [=======================>......] - ETA: 39s - loss: 0.0618 - sparse_categorical_accuracy: 0.9809\n",
            "381/469 [=======================>......] - ETA: 38s - loss: 0.0616 - sparse_categorical_accuracy: 0.9809\n",
            "382/469 [=======================>......] - ETA: 38s - loss: 0.0618 - sparse_categorical_accuracy: 0.9809\n",
            "383/469 [=======================>......] - ETA: 37s - loss: 0.0619 - sparse_categorical_accuracy: 0.9808\n",
            "384/469 [=======================>......] - ETA: 37s - loss: 0.0618 - sparse_categorical_accuracy: 0.9809\n",
            "385/469 [=======================>......] - ETA: 37s - loss: 0.0617 - sparse_categorical_accuracy: 0.9809\n",
            "386/469 [=======================>......] - ETA: 36s - loss: 0.0616 - sparse_categorical_accuracy: 0.9809\n",
            "387/469 [=======================>......] - ETA: 36s - loss: 0.0617 - sparse_categorical_accuracy: 0.9809\n",
            "388/469 [=======================>......] - ETA: 35s - loss: 0.0616 - sparse_categorical_accuracy: 0.9809\n",
            "389/469 [=======================>......] - ETA: 35s - loss: 0.0615 - sparse_categorical_accuracy: 0.9810\n",
            "390/469 [=======================>......] - ETA: 34s - loss: 0.0616 - sparse_categorical_accuracy: 0.9809\n",
            "391/469 [========================>.....] - ETA: 34s - loss: 0.0615 - sparse_categorical_accuracy: 0.9810\n",
            "392/469 [========================>.....] - ETA: 34s - loss: 0.0615 - sparse_categorical_accuracy: 0.9809\n",
            "393/469 [========================>.....] - ETA: 33s - loss: 0.0614 - sparse_categorical_accuracy: 0.9810\n",
            "394/469 [========================>.....] - ETA: 33s - loss: 0.0615 - sparse_categorical_accuracy: 0.9810\n",
            "395/469 [========================>.....] - ETA: 32s - loss: 0.0615 - sparse_categorical_accuracy: 0.9810\n",
            "396/469 [========================>.....] - ETA: 32s - loss: 0.0614 - sparse_categorical_accuracy: 0.9810\n",
            "397/469 [========================>.....] - ETA: 31s - loss: 0.0614 - sparse_categorical_accuracy: 0.9810\n",
            "398/469 [========================>.....] - ETA: 31s - loss: 0.0613 - sparse_categorical_accuracy: 0.9810\n",
            "399/469 [========================>.....] - ETA: 30s - loss: 0.0613 - sparse_categorical_accuracy: 0.9810\n",
            "400/469 [========================>.....] - ETA: 30s - loss: 0.0613 - sparse_categorical_accuracy: 0.9810\n",
            "401/469 [========================>.....] - ETA: 30s - loss: 0.0612 - sparse_categorical_accuracy: 0.9810\n",
            "402/469 [========================>.....] - ETA: 29s - loss: 0.0614 - sparse_categorical_accuracy: 0.9810\n",
            "403/469 [========================>.....] - ETA: 29s - loss: 0.0613 - sparse_categorical_accuracy: 0.9810\n",
            "404/469 [========================>.....] - ETA: 28s - loss: 0.0615 - sparse_categorical_accuracy: 0.9810\n",
            "405/469 [========================>.....] - ETA: 28s - loss: 0.0615 - sparse_categorical_accuracy: 0.9810\n",
            "406/469 [========================>.....] - ETA: 27s - loss: 0.0615 - sparse_categorical_accuracy: 0.9810\n",
            "407/469 [=========================>....] - ETA: 27s - loss: 0.0616 - sparse_categorical_accuracy: 0.9810\n",
            "408/469 [=========================>....] - ETA: 26s - loss: 0.0616 - sparse_categorical_accuracy: 0.9810\n",
            "409/469 [=========================>....] - ETA: 26s - loss: 0.0616 - sparse_categorical_accuracy: 0.9810\n",
            "410/469 [=========================>....] - ETA: 26s - loss: 0.0617 - sparse_categorical_accuracy: 0.9810\n",
            "411/469 [=========================>....] - ETA: 25s - loss: 0.0617 - sparse_categorical_accuracy: 0.9810\n",
            "412/469 [=========================>....] - ETA: 25s - loss: 0.0617 - sparse_categorical_accuracy: 0.9809\n",
            "413/469 [=========================>....] - ETA: 24s - loss: 0.0616 - sparse_categorical_accuracy: 0.9810\n",
            "414/469 [=========================>....] - ETA: 24s - loss: 0.0616 - sparse_categorical_accuracy: 0.9810\n",
            "415/469 [=========================>....] - ETA: 23s - loss: 0.0617 - sparse_categorical_accuracy: 0.9810\n",
            "416/469 [=========================>....] - ETA: 23s - loss: 0.0618 - sparse_categorical_accuracy: 0.9810\n",
            "417/469 [=========================>....] - ETA: 22s - loss: 0.0617 - sparse_categorical_accuracy: 0.9810\n",
            "418/469 [=========================>....] - ETA: 22s - loss: 0.0616 - sparse_categorical_accuracy: 0.9810\n",
            "419/469 [=========================>....] - ETA: 22s - loss: 0.0617 - sparse_categorical_accuracy: 0.9810\n",
            "420/469 [=========================>....] - ETA: 21s - loss: 0.0618 - sparse_categorical_accuracy: 0.9809\n",
            "421/469 [=========================>....] - ETA: 21s - loss: 0.0617 - sparse_categorical_accuracy: 0.9809\n",
            "422/469 [=========================>....] - ETA: 20s - loss: 0.0617 - sparse_categorical_accuracy: 0.9810\n",
            "423/469 [==========================>...] - ETA: 20s - loss: 0.0616 - sparse_categorical_accuracy: 0.9810\n",
            "424/469 [==========================>...] - ETA: 19s - loss: 0.0616 - sparse_categorical_accuracy: 0.9810\n",
            "425/469 [==========================>...] - ETA: 19s - loss: 0.0617 - sparse_categorical_accuracy: 0.9810\n",
            "426/469 [==========================>...] - ETA: 19s - loss: 0.0618 - sparse_categorical_accuracy: 0.9810\n",
            "427/469 [==========================>...] - ETA: 18s - loss: 0.0619 - sparse_categorical_accuracy: 0.9810\n",
            "428/469 [==========================>...] - ETA: 18s - loss: 0.0619 - sparse_categorical_accuracy: 0.9810\n",
            "429/469 [==========================>...] - ETA: 17s - loss: 0.0620 - sparse_categorical_accuracy: 0.9809\n",
            "430/469 [==========================>...] - ETA: 17s - loss: 0.0619 - sparse_categorical_accuracy: 0.9809\n",
            "431/469 [==========================>...] - ETA: 16s - loss: 0.0619 - sparse_categorical_accuracy: 0.9809\n",
            "432/469 [==========================>...] - ETA: 16s - loss: 0.0618 - sparse_categorical_accuracy: 0.9809\n",
            "433/469 [==========================>...] - ETA: 15s - loss: 0.0619 - sparse_categorical_accuracy: 0.9809\n",
            "434/469 [==========================>...] - ETA: 15s - loss: 0.0619 - sparse_categorical_accuracy: 0.9809\n",
            "435/469 [==========================>...] - ETA: 15s - loss: 0.0618 - sparse_categorical_accuracy: 0.9809\n",
            "436/469 [==========================>...] - ETA: 14s - loss: 0.0617 - sparse_categorical_accuracy: 0.9809\n",
            "437/469 [==========================>...] - ETA: 14s - loss: 0.0617 - sparse_categorical_accuracy: 0.9809\n",
            "438/469 [===========================>..] - ETA: 13s - loss: 0.0618 - sparse_categorical_accuracy: 0.9809\n",
            "439/469 [===========================>..] - ETA: 13s - loss: 0.0618 - sparse_categorical_accuracy: 0.9809\n",
            "440/469 [===========================>..] - ETA: 12s - loss: 0.0618 - sparse_categorical_accuracy: 0.9809\n",
            "441/469 [===========================>..] - ETA: 12s - loss: 0.0617 - sparse_categorical_accuracy: 0.9810\n",
            "442/469 [===========================>..] - ETA: 11s - loss: 0.0616 - sparse_categorical_accuracy: 0.9810\n",
            "443/469 [===========================>..] - ETA: 11s - loss: 0.0616 - sparse_categorical_accuracy: 0.9810\n",
            "444/469 [===========================>..] - ETA: 11s - loss: 0.0616 - sparse_categorical_accuracy: 0.9810\n",
            "445/469 [===========================>..] - ETA: 10s - loss: 0.0615 - sparse_categorical_accuracy: 0.9810\n",
            "446/469 [===========================>..] - ETA: 10s - loss: 0.0615 - sparse_categorical_accuracy: 0.9810\n",
            "447/469 [===========================>..] - ETA: 9s - loss: 0.0614 - sparse_categorical_accuracy: 0.9811 \n",
            "448/469 [===========================>..] - ETA: 9s - loss: 0.0614 - sparse_categorical_accuracy: 0.9811\n",
            "449/469 [===========================>..] - ETA: 8s - loss: 0.0614 - sparse_categorical_accuracy: 0.9811\n",
            "450/469 [===========================>..] - ETA: 8s - loss: 0.0614 - sparse_categorical_accuracy: 0.9811\n",
            "451/469 [===========================>..] - ETA: 7s - loss: 0.0614 - sparse_categorical_accuracy: 0.9811\n",
            "452/469 [===========================>..] - ETA: 7s - loss: 0.0613 - sparse_categorical_accuracy: 0.9811\n",
            "453/469 [===========================>..] - ETA: 7s - loss: 0.0614 - sparse_categorical_accuracy: 0.9811\n",
            "454/469 [============================>.] - ETA: 6s - loss: 0.0614 - sparse_categorical_accuracy: 0.9811\n",
            "455/469 [============================>.] - ETA: 6s - loss: 0.0615 - sparse_categorical_accuracy: 0.9811\n",
            "456/469 [============================>.] - ETA: 5s - loss: 0.0615 - sparse_categorical_accuracy: 0.9811\n",
            "457/469 [============================>.] - ETA: 5s - loss: 0.0615 - sparse_categorical_accuracy: 0.9811\n",
            "458/469 [============================>.] - ETA: 4s - loss: 0.0615 - sparse_categorical_accuracy: 0.9811\n",
            "459/469 [============================>.] - ETA: 4s - loss: 0.0614 - sparse_categorical_accuracy: 0.9811\n",
            "460/469 [============================>.] - ETA: 3s - loss: 0.0614 - sparse_categorical_accuracy: 0.9811\n",
            "461/469 [============================>.] - ETA: 3s - loss: 0.0614 - sparse_categorical_accuracy: 0.9811\n",
            "462/469 [============================>.] - ETA: 3s - loss: 0.0613 - sparse_categorical_accuracy: 0.9811\n",
            "463/469 [============================>.] - ETA: 2s - loss: 0.0612 - sparse_categorical_accuracy: 0.9811\n",
            "464/469 [============================>.] - ETA: 2s - loss: 0.0613 - sparse_categorical_accuracy: 0.9811\n",
            "465/469 [============================>.] - ETA: 1s - loss: 0.0613 - sparse_categorical_accuracy: 0.9811\n",
            "466/469 [============================>.] - ETA: 1s - loss: 0.0613 - sparse_categorical_accuracy: 0.9810\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.0613 - sparse_categorical_accuracy: 0.9810\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0613 - sparse_categorical_accuracy: 0.9810\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0612 - sparse_categorical_accuracy: 0.9810\n",
            " 60%|██████    | 3/5 [1:14:13<34:52, 1046.39s/trial, best loss: -0.9839000105857849]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/04/16 01:46:14 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 207s 441ms/step - loss: 0.0612 - sparse_categorical_accuracy: 0.9810\n",
            "\n",
            " 60%|██████    | 3/5 [1:14:13<34:52, 1046.39s/trial, best loss: -0.9839000105857849]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 317 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7a89d7cb88b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - ETA: 0s\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "\n",
            " 60%|██████    | 3/5 [1:14:17<34:52, 1046.39s/trial, best loss: -0.9839000105857849]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\n",
            "  1/469 [..............................] - ETA: 7:06 - loss: 4.1588 - sparse_categorical_accuracy: 0.0156\n",
            "  2/469 [..............................] - ETA: 3:42 - loss: 4.1472 - sparse_categorical_accuracy: 0.0391\n",
            "  3/469 [..............................] - ETA: 3:38 - loss: 4.1400 - sparse_categorical_accuracy: 0.0469\n",
            "  4/469 [..............................] - ETA: 3:40 - loss: 4.1228 - sparse_categorical_accuracy: 0.0625\n",
            "  5/469 [..............................] - ETA: 3:40 - loss: 4.1048 - sparse_categorical_accuracy: 0.0672\n",
            "  6/469 [..............................] - ETA: 3:41 - loss: 4.0825 - sparse_categorical_accuracy: 0.0794\n",
            "  7/469 [..............................] - ETA: 3:41 - loss: 4.0620 - sparse_categorical_accuracy: 0.0826\n",
            "  8/469 [..............................] - ETA: 3:44 - loss: 4.0334 - sparse_categorical_accuracy: 0.0898\n",
            "  9/469 [..............................] - ETA: 4:00 - loss: 4.0001 - sparse_categorical_accuracy: 0.0990\n",
            " 10/469 [..............................] - ETA: 4:13 - loss: 3.9595 - sparse_categorical_accuracy: 0.1000\n",
            " 11/469 [..............................] - ETA: 4:22 - loss: 3.9126 - sparse_categorical_accuracy: 0.1037\n",
            " 12/469 [..............................] - ETA: 4:28 - loss: 3.8503 - sparse_categorical_accuracy: 0.1074\n",
            " 13/469 [..............................] - ETA: 4:26 - loss: 3.7762 - sparse_categorical_accuracy: 0.1106\n",
            " 14/469 [..............................] - ETA: 4:22 - loss: 3.6911 - sparse_categorical_accuracy: 0.1155\n",
            " 15/469 [..............................] - ETA: 4:18 - loss: 3.6091 - sparse_categorical_accuracy: 0.1229\n",
            " 16/469 [>.............................] - ETA: 4:14 - loss: 3.5221 - sparse_categorical_accuracy: 0.1260\n",
            " 17/469 [>.............................] - ETA: 4:10 - loss: 3.4428 - sparse_categorical_accuracy: 0.1314\n",
            " 18/469 [>.............................] - ETA: 4:08 - loss: 3.3686 - sparse_categorical_accuracy: 0.1398\n",
            " 19/469 [>.............................] - ETA: 4:06 - loss: 3.2989 - sparse_categorical_accuracy: 0.1451\n",
            " 20/469 [>.............................] - ETA: 4:03 - loss: 3.2305 - sparse_categorical_accuracy: 0.1574\n",
            " 21/469 [>.............................] - ETA: 4:01 - loss: 3.1617 - sparse_categorical_accuracy: 0.1700\n",
            " 22/469 [>.............................] - ETA: 3:59 - loss: 3.1007 - sparse_categorical_accuracy: 0.1822\n",
            " 23/469 [>.............................] - ETA: 3:58 - loss: 3.0342 - sparse_categorical_accuracy: 0.1953\n",
            " 24/469 [>.............................] - ETA: 3:56 - loss: 2.9784 - sparse_categorical_accuracy: 0.2051\n",
            " 25/469 [>.............................] - ETA: 3:55 - loss: 2.9197 - sparse_categorical_accuracy: 0.2175\n",
            " 26/469 [>.............................] - ETA: 3:53 - loss: 2.8625 - sparse_categorical_accuracy: 0.2299\n",
            " 27/469 [>.............................] - ETA: 3:51 - loss: 2.8073 - sparse_categorical_accuracy: 0.2428\n",
            " 28/469 [>.............................] - ETA: 3:50 - loss: 2.7491 - sparse_categorical_accuracy: 0.2578\n",
            " 29/469 [>.............................] - ETA: 3:49 - loss: 2.6933 - sparse_categorical_accuracy: 0.2721\n",
            " 30/469 [>.............................] - ETA: 3:47 - loss: 2.6422 - sparse_categorical_accuracy: 0.2823\n",
            " 31/469 [>.............................] - ETA: 3:46 - loss: 2.5927 - sparse_categorical_accuracy: 0.2928\n",
            " 32/469 [=>............................] - ETA: 3:45 - loss: 2.5416 - sparse_categorical_accuracy: 0.3054\n",
            " 33/469 [=>............................] - ETA: 3:44 - loss: 2.4935 - sparse_categorical_accuracy: 0.3168\n",
            " 34/469 [=>............................] - ETA: 3:44 - loss: 2.4502 - sparse_categorical_accuracy: 0.3254\n",
            " 35/469 [=>............................] - ETA: 3:46 - loss: 2.4144 - sparse_categorical_accuracy: 0.3350\n",
            " 36/469 [=>............................] - ETA: 3:48 - loss: 2.3776 - sparse_categorical_accuracy: 0.3440\n",
            " 37/469 [=>............................] - ETA: 3:50 - loss: 2.3435 - sparse_categorical_accuracy: 0.3526\n",
            " 38/469 [=>............................] - ETA: 3:52 - loss: 2.3186 - sparse_categorical_accuracy: 0.3588\n",
            " 39/469 [=>............................] - ETA: 3:51 - loss: 2.2845 - sparse_categorical_accuracy: 0.3670\n",
            " 40/469 [=>............................] - ETA: 3:50 - loss: 2.2502 - sparse_categorical_accuracy: 0.3752\n",
            " 41/469 [=>............................] - ETA: 3:49 - loss: 2.2176 - sparse_categorical_accuracy: 0.3828\n",
            " 42/469 [=>............................] - ETA: 3:47 - loss: 2.1803 - sparse_categorical_accuracy: 0.3925\n",
            " 43/469 [=>............................] - ETA: 3:46 - loss: 2.1459 - sparse_categorical_accuracy: 0.4013\n",
            " 44/469 [=>............................] - ETA: 3:45 - loss: 2.1121 - sparse_categorical_accuracy: 0.4102\n",
            " 45/469 [=>............................] - ETA: 3:44 - loss: 2.0808 - sparse_categorical_accuracy: 0.4174\n",
            " 46/469 [=>............................] - ETA: 3:43 - loss: 2.0479 - sparse_categorical_accuracy: 0.4261\n",
            " 47/469 [==>...........................] - ETA: 3:42 - loss: 2.0184 - sparse_categorical_accuracy: 0.4338\n",
            " 48/469 [==>...........................] - ETA: 3:42 - loss: 1.9988 - sparse_categorical_accuracy: 0.4390\n",
            " 49/469 [==>...........................] - ETA: 3:41 - loss: 1.9701 - sparse_categorical_accuracy: 0.4460\n",
            " 50/469 [==>...........................] - ETA: 3:40 - loss: 1.9437 - sparse_categorical_accuracy: 0.4534\n",
            " 51/469 [==>...........................] - ETA: 3:39 - loss: 1.9189 - sparse_categorical_accuracy: 0.4594\n",
            " 52/469 [==>...........................] - ETA: 3:38 - loss: 1.8894 - sparse_categorical_accuracy: 0.4677\n",
            " 53/469 [==>...........................] - ETA: 3:37 - loss: 1.8646 - sparse_categorical_accuracy: 0.4745\n",
            " 54/469 [==>...........................] - ETA: 3:36 - loss: 1.8446 - sparse_categorical_accuracy: 0.4793\n",
            " 55/469 [==>...........................] - ETA: 3:36 - loss: 1.8213 - sparse_categorical_accuracy: 0.4849\n",
            " 56/469 [==>...........................] - ETA: 3:35 - loss: 1.7975 - sparse_categorical_accuracy: 0.4916\n",
            " 57/469 [==>...........................] - ETA: 3:34 - loss: 1.7754 - sparse_categorical_accuracy: 0.4971\n",
            " 58/469 [==>...........................] - ETA: 3:35 - loss: 1.7539 - sparse_categorical_accuracy: 0.5035\n",
            " 59/469 [==>...........................] - ETA: 3:40 - loss: 1.7328 - sparse_categorical_accuracy: 0.5095\n",
            " 60/469 [==>...........................] - ETA: 3:44 - loss: 1.7118 - sparse_categorical_accuracy: 0.5154\n",
            " 61/469 [==>...........................] - ETA: 3:51 - loss: 1.6962 - sparse_categorical_accuracy: 0.5196\n",
            " 62/469 [==>...........................] - ETA: 3:56 - loss: 1.6780 - sparse_categorical_accuracy: 0.5249\n",
            " 63/469 [===>..........................] - ETA: 3:57 - loss: 1.6624 - sparse_categorical_accuracy: 0.5286\n",
            " 64/469 [===>..........................] - ETA: 3:57 - loss: 1.6433 - sparse_categorical_accuracy: 0.5339\n",
            " 65/469 [===>..........................] - ETA: 3:58 - loss: 1.6266 - sparse_categorical_accuracy: 0.5386\n",
            " 66/469 [===>..........................] - ETA: 3:59 - loss: 1.6103 - sparse_categorical_accuracy: 0.5430\n",
            " 67/469 [===>..........................] - ETA: 3:58 - loss: 1.5954 - sparse_categorical_accuracy: 0.5471\n",
            " 68/469 [===>..........................] - ETA: 3:57 - loss: 1.5811 - sparse_categorical_accuracy: 0.5508\n",
            " 69/469 [===>..........................] - ETA: 3:55 - loss: 1.5668 - sparse_categorical_accuracy: 0.5545\n",
            " 70/469 [===>..........................] - ETA: 3:54 - loss: 1.5515 - sparse_categorical_accuracy: 0.5585\n",
            " 71/469 [===>..........................] - ETA: 3:53 - loss: 1.5369 - sparse_categorical_accuracy: 0.5621\n",
            " 72/469 [===>..........................] - ETA: 3:52 - loss: 1.5228 - sparse_categorical_accuracy: 0.5658\n",
            " 73/469 [===>..........................] - ETA: 3:51 - loss: 1.5073 - sparse_categorical_accuracy: 0.5703\n",
            " 74/469 [===>..........................] - ETA: 3:50 - loss: 1.4954 - sparse_categorical_accuracy: 0.5736\n",
            " 75/469 [===>..........................] - ETA: 3:48 - loss: 1.4818 - sparse_categorical_accuracy: 0.5771\n",
            " 76/469 [===>..........................] - ETA: 3:47 - loss: 1.4688 - sparse_categorical_accuracy: 0.5811\n",
            " 77/469 [===>..........................] - ETA: 3:46 - loss: 1.4575 - sparse_categorical_accuracy: 0.5842\n",
            " 78/469 [===>..........................] - ETA: 3:45 - loss: 1.4439 - sparse_categorical_accuracy: 0.5877\n",
            " 79/469 [====>.........................] - ETA: 3:44 - loss: 1.4309 - sparse_categorical_accuracy: 0.5912\n",
            " 80/469 [====>.........................] - ETA: 3:43 - loss: 1.4195 - sparse_categorical_accuracy: 0.5941\n",
            " 81/469 [====>.........................] - ETA: 3:42 - loss: 1.4071 - sparse_categorical_accuracy: 0.5975\n",
            " 82/469 [====>.........................] - ETA: 3:42 - loss: 1.3955 - sparse_categorical_accuracy: 0.6008\n",
            " 83/469 [====>.........................] - ETA: 3:42 - loss: 1.3856 - sparse_categorical_accuracy: 0.6033\n",
            " 84/469 [====>.........................] - ETA: 3:42 - loss: 1.3745 - sparse_categorical_accuracy: 0.6061\n",
            " 85/469 [====>.........................] - ETA: 3:42 - loss: 1.3638 - sparse_categorical_accuracy: 0.6096\n",
            " 86/469 [====>.........................] - ETA: 3:42 - loss: 1.3510 - sparse_categorical_accuracy: 0.6135\n",
            " 87/469 [====>.........................] - ETA: 3:41 - loss: 1.3418 - sparse_categorical_accuracy: 0.6163\n",
            " 88/469 [====>.........................] - ETA: 3:40 - loss: 1.3337 - sparse_categorical_accuracy: 0.6183\n",
            " 89/469 [====>.........................] - ETA: 3:39 - loss: 1.3240 - sparse_categorical_accuracy: 0.6210\n",
            " 90/469 [====>.........................] - ETA: 3:38 - loss: 1.3134 - sparse_categorical_accuracy: 0.6236\n",
            " 91/469 [====>.........................] - ETA: 3:37 - loss: 1.3039 - sparse_categorical_accuracy: 0.6268\n",
            " 92/469 [====>.........................] - ETA: 3:36 - loss: 1.2939 - sparse_categorical_accuracy: 0.6297\n",
            " 93/469 [====>.........................] - ETA: 3:35 - loss: 1.2848 - sparse_categorical_accuracy: 0.6319\n",
            " 94/469 [=====>........................] - ETA: 3:34 - loss: 1.2755 - sparse_categorical_accuracy: 0.6343\n",
            " 95/469 [=====>........................] - ETA: 3:33 - loss: 1.2669 - sparse_categorical_accuracy: 0.6366\n",
            " 96/469 [=====>........................] - ETA: 3:32 - loss: 1.2576 - sparse_categorical_accuracy: 0.6392\n",
            " 97/469 [=====>........................] - ETA: 3:31 - loss: 1.2497 - sparse_categorical_accuracy: 0.6414\n",
            " 98/469 [=====>........................] - ETA: 3:31 - loss: 1.2428 - sparse_categorical_accuracy: 0.6435\n",
            " 99/469 [=====>........................] - ETA: 3:30 - loss: 1.2334 - sparse_categorical_accuracy: 0.6462\n",
            "100/469 [=====>........................] - ETA: 3:29 - loss: 1.2248 - sparse_categorical_accuracy: 0.6488\n",
            "101/469 [=====>........................] - ETA: 3:28 - loss: 1.2199 - sparse_categorical_accuracy: 0.6501\n",
            "102/469 [=====>........................] - ETA: 3:27 - loss: 1.2111 - sparse_categorical_accuracy: 0.6526\n",
            "103/469 [=====>........................] - ETA: 3:26 - loss: 1.2028 - sparse_categorical_accuracy: 0.6548\n",
            "104/469 [=====>........................] - ETA: 3:25 - loss: 1.1938 - sparse_categorical_accuracy: 0.6574\n",
            "105/469 [=====>........................] - ETA: 3:24 - loss: 1.1861 - sparse_categorical_accuracy: 0.6594\n",
            "106/469 [=====>........................] - ETA: 3:23 - loss: 1.1779 - sparse_categorical_accuracy: 0.6619\n",
            "107/469 [=====>........................] - ETA: 3:23 - loss: 1.1700 - sparse_categorical_accuracy: 0.6639\n",
            "108/469 [=====>........................] - ETA: 3:23 - loss: 1.1634 - sparse_categorical_accuracy: 0.6657\n",
            "109/469 [=====>........................] - ETA: 3:23 - loss: 1.1569 - sparse_categorical_accuracy: 0.6674\n",
            "110/469 [======>.......................] - ETA: 3:23 - loss: 1.1497 - sparse_categorical_accuracy: 0.6692\n",
            "111/469 [======>.......................] - ETA: 3:23 - loss: 1.1426 - sparse_categorical_accuracy: 0.6712\n",
            "112/469 [======>.......................] - ETA: 3:22 - loss: 1.1358 - sparse_categorical_accuracy: 0.6731\n",
            "113/469 [======>.......................] - ETA: 3:21 - loss: 1.1297 - sparse_categorical_accuracy: 0.6750\n",
            "114/469 [======>.......................] - ETA: 3:20 - loss: 1.1235 - sparse_categorical_accuracy: 0.6767\n",
            "115/469 [======>.......................] - ETA: 3:20 - loss: 1.1168 - sparse_categorical_accuracy: 0.6785\n",
            "116/469 [======>.......................] - ETA: 3:19 - loss: 1.1103 - sparse_categorical_accuracy: 0.6803\n",
            "117/469 [======>.......................] - ETA: 3:18 - loss: 1.1035 - sparse_categorical_accuracy: 0.6820\n",
            "118/469 [======>.......................] - ETA: 3:17 - loss: 1.0980 - sparse_categorical_accuracy: 0.6831\n",
            "119/469 [======>.......................] - ETA: 3:16 - loss: 1.0915 - sparse_categorical_accuracy: 0.6849\n",
            "120/469 [======>.......................] - ETA: 3:15 - loss: 1.0864 - sparse_categorical_accuracy: 0.6863\n",
            "121/469 [======>.......................] - ETA: 3:15 - loss: 1.0812 - sparse_categorical_accuracy: 0.6878\n",
            "122/469 [======>.......................] - ETA: 3:14 - loss: 1.0745 - sparse_categorical_accuracy: 0.6898\n",
            "123/469 [======>.......................] - ETA: 3:13 - loss: 1.0694 - sparse_categorical_accuracy: 0.6912\n",
            "124/469 [======>.......................] - ETA: 3:12 - loss: 1.0639 - sparse_categorical_accuracy: 0.6928\n",
            "125/469 [======>.......................] - ETA: 3:11 - loss: 1.0574 - sparse_categorical_accuracy: 0.6945\n",
            "126/469 [=======>......................] - ETA: 3:11 - loss: 1.0519 - sparse_categorical_accuracy: 0.6961\n",
            "127/469 [=======>......................] - ETA: 3:10 - loss: 1.0458 - sparse_categorical_accuracy: 0.6978\n",
            "128/469 [=======>......................] - ETA: 3:09 - loss: 1.0394 - sparse_categorical_accuracy: 0.6997\n",
            "129/469 [=======>......................] - ETA: 3:08 - loss: 1.0333 - sparse_categorical_accuracy: 0.7015\n",
            "130/469 [=======>......................] - ETA: 3:07 - loss: 1.0274 - sparse_categorical_accuracy: 0.7032\n",
            "131/469 [=======>......................] - ETA: 3:06 - loss: 1.0215 - sparse_categorical_accuracy: 0.7049\n",
            "132/469 [=======>......................] - ETA: 3:06 - loss: 1.0158 - sparse_categorical_accuracy: 0.7066\n",
            "133/469 [=======>......................] - ETA: 3:05 - loss: 1.0103 - sparse_categorical_accuracy: 0.7084\n",
            "134/469 [=======>......................] - ETA: 3:05 - loss: 1.0049 - sparse_categorical_accuracy: 0.7099\n",
            "135/469 [=======>......................] - ETA: 3:05 - loss: 0.9994 - sparse_categorical_accuracy: 0.7114\n",
            "136/469 [=======>......................] - ETA: 3:05 - loss: 0.9945 - sparse_categorical_accuracy: 0.7129\n",
            "137/469 [=======>......................] - ETA: 3:05 - loss: 0.9902 - sparse_categorical_accuracy: 0.7141\n",
            "138/469 [=======>......................] - ETA: 3:04 - loss: 0.9856 - sparse_categorical_accuracy: 0.7155\n",
            "139/469 [=======>......................] - ETA: 3:03 - loss: 0.9806 - sparse_categorical_accuracy: 0.7169\n",
            "140/469 [=======>......................] - ETA: 3:03 - loss: 0.9762 - sparse_categorical_accuracy: 0.7182\n",
            "141/469 [========>.....................] - ETA: 3:02 - loss: 0.9710 - sparse_categorical_accuracy: 0.7195\n",
            "142/469 [========>.....................] - ETA: 3:01 - loss: 0.9658 - sparse_categorical_accuracy: 0.7208\n",
            "143/469 [========>.....................] - ETA: 3:00 - loss: 0.9611 - sparse_categorical_accuracy: 0.7222\n",
            "144/469 [========>.....................] - ETA: 3:00 - loss: 0.9572 - sparse_categorical_accuracy: 0.7234\n",
            "145/469 [========>.....................] - ETA: 2:59 - loss: 0.9519 - sparse_categorical_accuracy: 0.7249\n",
            "146/469 [========>.....................] - ETA: 2:58 - loss: 0.9483 - sparse_categorical_accuracy: 0.7259\n",
            "147/469 [========>.....................] - ETA: 2:57 - loss: 0.9439 - sparse_categorical_accuracy: 0.7271\n",
            "148/469 [========>.....................] - ETA: 2:57 - loss: 0.9393 - sparse_categorical_accuracy: 0.7285\n",
            "149/469 [========>.....................] - ETA: 2:56 - loss: 0.9350 - sparse_categorical_accuracy: 0.7298\n",
            "150/469 [========>.....................] - ETA: 2:55 - loss: 0.9304 - sparse_categorical_accuracy: 0.7310\n",
            "151/469 [========>.....................] - ETA: 2:54 - loss: 0.9256 - sparse_categorical_accuracy: 0.7324\n",
            "152/469 [========>.....................] - ETA: 2:54 - loss: 0.9216 - sparse_categorical_accuracy: 0.7336\n",
            "153/469 [========>.....................] - ETA: 2:53 - loss: 0.9180 - sparse_categorical_accuracy: 0.7347\n",
            "154/469 [========>.....................] - ETA: 2:52 - loss: 0.9144 - sparse_categorical_accuracy: 0.7357\n",
            "155/469 [========>.....................] - ETA: 2:51 - loss: 0.9109 - sparse_categorical_accuracy: 0.7369\n",
            "156/469 [========>.....................] - ETA: 2:51 - loss: 0.9070 - sparse_categorical_accuracy: 0.7379\n",
            "157/469 [=========>....................] - ETA: 2:50 - loss: 0.9026 - sparse_categorical_accuracy: 0.7392\n",
            "158/469 [=========>....................] - ETA: 2:49 - loss: 0.8982 - sparse_categorical_accuracy: 0.7406\n",
            "159/469 [=========>....................] - ETA: 2:49 - loss: 0.8945 - sparse_categorical_accuracy: 0.7415\n",
            "160/469 [=========>....................] - ETA: 2:49 - loss: 0.8904 - sparse_categorical_accuracy: 0.7425\n",
            "161/469 [=========>....................] - ETA: 2:48 - loss: 0.8871 - sparse_categorical_accuracy: 0.7433\n",
            "162/469 [=========>....................] - ETA: 2:48 - loss: 0.8832 - sparse_categorical_accuracy: 0.7444\n",
            "163/469 [=========>....................] - ETA: 2:48 - loss: 0.8797 - sparse_categorical_accuracy: 0.7454\n",
            "164/469 [=========>....................] - ETA: 2:47 - loss: 0.8759 - sparse_categorical_accuracy: 0.7464\n",
            "165/469 [=========>....................] - ETA: 2:47 - loss: 0.8735 - sparse_categorical_accuracy: 0.7473\n",
            "166/469 [=========>....................] - ETA: 2:46 - loss: 0.8702 - sparse_categorical_accuracy: 0.7483\n",
            "167/469 [=========>....................] - ETA: 2:45 - loss: 0.8663 - sparse_categorical_accuracy: 0.7493\n",
            "168/469 [=========>....................] - ETA: 2:45 - loss: 0.8626 - sparse_categorical_accuracy: 0.7505\n",
            "169/469 [=========>....................] - ETA: 2:44 - loss: 0.8595 - sparse_categorical_accuracy: 0.7512\n",
            "170/469 [=========>....................] - ETA: 2:43 - loss: 0.8560 - sparse_categorical_accuracy: 0.7523\n",
            "171/469 [=========>....................] - ETA: 2:43 - loss: 0.8534 - sparse_categorical_accuracy: 0.7530\n",
            "172/469 [==========>...................] - ETA: 2:42 - loss: 0.8500 - sparse_categorical_accuracy: 0.7538\n",
            "173/469 [==========>...................] - ETA: 2:41 - loss: 0.8465 - sparse_categorical_accuracy: 0.7548\n",
            "174/469 [==========>...................] - ETA: 2:41 - loss: 0.8431 - sparse_categorical_accuracy: 0.7558\n",
            "175/469 [==========>...................] - ETA: 2:40 - loss: 0.8403 - sparse_categorical_accuracy: 0.7567\n",
            "176/469 [==========>...................] - ETA: 2:39 - loss: 0.8375 - sparse_categorical_accuracy: 0.7575\n",
            "177/469 [==========>...................] - ETA: 2:39 - loss: 0.8346 - sparse_categorical_accuracy: 0.7583\n",
            "178/469 [==========>...................] - ETA: 2:38 - loss: 0.8317 - sparse_categorical_accuracy: 0.7592\n",
            "179/469 [==========>...................] - ETA: 2:37 - loss: 0.8285 - sparse_categorical_accuracy: 0.7600\n",
            "180/469 [==========>...................] - ETA: 2:36 - loss: 0.8255 - sparse_categorical_accuracy: 0.7609\n",
            "181/469 [==========>...................] - ETA: 2:36 - loss: 0.8227 - sparse_categorical_accuracy: 0.7615\n",
            "182/469 [==========>...................] - ETA: 2:35 - loss: 0.8193 - sparse_categorical_accuracy: 0.7624\n",
            "183/469 [==========>...................] - ETA: 2:35 - loss: 0.8161 - sparse_categorical_accuracy: 0.7634\n",
            "184/469 [==========>...................] - ETA: 2:34 - loss: 0.8131 - sparse_categorical_accuracy: 0.7643\n",
            "185/469 [==========>...................] - ETA: 2:33 - loss: 0.8101 - sparse_categorical_accuracy: 0.7652\n",
            "186/469 [==========>...................] - ETA: 2:33 - loss: 0.8081 - sparse_categorical_accuracy: 0.7658\n",
            "187/469 [==========>...................] - ETA: 2:33 - loss: 0.8054 - sparse_categorical_accuracy: 0.7665\n",
            "188/469 [===========>..................] - ETA: 2:33 - loss: 0.8026 - sparse_categorical_accuracy: 0.7673\n",
            "189/469 [===========>..................] - ETA: 2:32 - loss: 0.7994 - sparse_categorical_accuracy: 0.7683\n",
            "190/469 [===========>..................] - ETA: 2:32 - loss: 0.7969 - sparse_categorical_accuracy: 0.7688\n",
            "191/469 [===========>..................] - ETA: 2:31 - loss: 0.7940 - sparse_categorical_accuracy: 0.7696\n",
            "192/469 [===========>..................] - ETA: 2:30 - loss: 0.7916 - sparse_categorical_accuracy: 0.7704\n",
            "193/469 [===========>..................] - ETA: 2:30 - loss: 0.7897 - sparse_categorical_accuracy: 0.7709\n",
            "194/469 [===========>..................] - ETA: 2:29 - loss: 0.7871 - sparse_categorical_accuracy: 0.7717\n",
            "195/469 [===========>..................] - ETA: 2:29 - loss: 0.7850 - sparse_categorical_accuracy: 0.7726\n",
            "196/469 [===========>..................] - ETA: 2:28 - loss: 0.7822 - sparse_categorical_accuracy: 0.7733\n",
            "197/469 [===========>..................] - ETA: 2:27 - loss: 0.7793 - sparse_categorical_accuracy: 0.7741\n",
            "198/469 [===========>..................] - ETA: 2:27 - loss: 0.7765 - sparse_categorical_accuracy: 0.7748\n",
            "199/469 [===========>..................] - ETA: 2:26 - loss: 0.7736 - sparse_categorical_accuracy: 0.7756\n",
            "200/469 [===========>..................] - ETA: 2:25 - loss: 0.7712 - sparse_categorical_accuracy: 0.7764\n",
            "201/469 [===========>..................] - ETA: 2:25 - loss: 0.7683 - sparse_categorical_accuracy: 0.7773\n",
            "202/469 [===========>..................] - ETA: 2:24 - loss: 0.7655 - sparse_categorical_accuracy: 0.7782\n",
            "203/469 [===========>..................] - ETA: 2:23 - loss: 0.7625 - sparse_categorical_accuracy: 0.7791\n",
            "204/469 [============>.................] - ETA: 2:23 - loss: 0.7603 - sparse_categorical_accuracy: 0.7799\n",
            "205/469 [============>.................] - ETA: 2:22 - loss: 0.7576 - sparse_categorical_accuracy: 0.7806\n",
            "206/469 [============>.................] - ETA: 2:22 - loss: 0.7550 - sparse_categorical_accuracy: 0.7814\n",
            "207/469 [============>.................] - ETA: 2:21 - loss: 0.7531 - sparse_categorical_accuracy: 0.7820\n",
            "208/469 [============>.................] - ETA: 2:20 - loss: 0.7504 - sparse_categorical_accuracy: 0.7829\n",
            "209/469 [============>.................] - ETA: 2:20 - loss: 0.7484 - sparse_categorical_accuracy: 0.7834\n",
            "210/469 [============>.................] - ETA: 2:19 - loss: 0.7460 - sparse_categorical_accuracy: 0.7841\n",
            "211/469 [============>.................] - ETA: 2:19 - loss: 0.7437 - sparse_categorical_accuracy: 0.7845\n",
            "212/469 [============>.................] - ETA: 2:19 - loss: 0.7408 - sparse_categorical_accuracy: 0.7855\n",
            "213/469 [============>.................] - ETA: 2:18 - loss: 0.7383 - sparse_categorical_accuracy: 0.7863\n",
            "214/469 [============>.................] - ETA: 2:18 - loss: 0.7363 - sparse_categorical_accuracy: 0.7868\n",
            "215/469 [============>.................] - ETA: 2:17 - loss: 0.7343 - sparse_categorical_accuracy: 0.7875\n",
            "216/469 [============>.................] - ETA: 2:17 - loss: 0.7322 - sparse_categorical_accuracy: 0.7881\n",
            "217/469 [============>.................] - ETA: 2:16 - loss: 0.7303 - sparse_categorical_accuracy: 0.7887\n",
            "218/469 [============>.................] - ETA: 2:16 - loss: 0.7277 - sparse_categorical_accuracy: 0.7895\n",
            "219/469 [=============>................] - ETA: 2:15 - loss: 0.7253 - sparse_categorical_accuracy: 0.7902\n",
            "220/469 [=============>................] - ETA: 2:14 - loss: 0.7230 - sparse_categorical_accuracy: 0.7909\n",
            "221/469 [=============>................] - ETA: 2:14 - loss: 0.7205 - sparse_categorical_accuracy: 0.7916\n",
            "222/469 [=============>................] - ETA: 2:13 - loss: 0.7180 - sparse_categorical_accuracy: 0.7923\n",
            "223/469 [=============>................] - ETA: 2:13 - loss: 0.7163 - sparse_categorical_accuracy: 0.7928\n",
            "224/469 [=============>................] - ETA: 2:12 - loss: 0.7140 - sparse_categorical_accuracy: 0.7934\n",
            "225/469 [=============>................] - ETA: 2:11 - loss: 0.7114 - sparse_categorical_accuracy: 0.7941\n",
            "226/469 [=============>................] - ETA: 2:11 - loss: 0.7093 - sparse_categorical_accuracy: 0.7947\n",
            "227/469 [=============>................] - ETA: 2:10 - loss: 0.7073 - sparse_categorical_accuracy: 0.7953\n",
            "228/469 [=============>................] - ETA: 2:10 - loss: 0.7053 - sparse_categorical_accuracy: 0.7958\n",
            "229/469 [=============>................] - ETA: 2:09 - loss: 0.7034 - sparse_categorical_accuracy: 0.7963\n",
            "230/469 [=============>................] - ETA: 2:08 - loss: 0.7011 - sparse_categorical_accuracy: 0.7969\n",
            "231/469 [=============>................] - ETA: 2:08 - loss: 0.6989 - sparse_categorical_accuracy: 0.7976\n",
            "232/469 [=============>................] - ETA: 2:07 - loss: 0.6967 - sparse_categorical_accuracy: 0.7983\n",
            "233/469 [=============>................] - ETA: 2:06 - loss: 0.6947 - sparse_categorical_accuracy: 0.7990\n",
            "234/469 [=============>................] - ETA: 2:06 - loss: 0.6929 - sparse_categorical_accuracy: 0.7995\n",
            "235/469 [==============>...............] - ETA: 2:05 - loss: 0.6908 - sparse_categorical_accuracy: 0.8001\n",
            "236/469 [==============>...............] - ETA: 2:05 - loss: 0.6886 - sparse_categorical_accuracy: 0.8008\n",
            "237/469 [==============>...............] - ETA: 2:05 - loss: 0.6869 - sparse_categorical_accuracy: 0.8012\n",
            "238/469 [==============>...............] - ETA: 2:04 - loss: 0.6846 - sparse_categorical_accuracy: 0.8018\n",
            "239/469 [==============>...............] - ETA: 2:04 - loss: 0.6823 - sparse_categorical_accuracy: 0.8025\n",
            "240/469 [==============>...............] - ETA: 2:04 - loss: 0.6804 - sparse_categorical_accuracy: 0.8031\n",
            "241/469 [==============>...............] - ETA: 2:03 - loss: 0.6782 - sparse_categorical_accuracy: 0.8037\n",
            "242/469 [==============>...............] - ETA: 2:02 - loss: 0.6760 - sparse_categorical_accuracy: 0.8044\n",
            "243/469 [==============>...............] - ETA: 2:02 - loss: 0.6741 - sparse_categorical_accuracy: 0.8048\n",
            "244/469 [==============>...............] - ETA: 2:01 - loss: 0.6720 - sparse_categorical_accuracy: 0.8053\n",
            "245/469 [==============>...............] - ETA: 2:01 - loss: 0.6702 - sparse_categorical_accuracy: 0.8057\n",
            "246/469 [==============>...............] - ETA: 2:00 - loss: 0.6682 - sparse_categorical_accuracy: 0.8063\n",
            "247/469 [==============>...............] - ETA: 1:59 - loss: 0.6667 - sparse_categorical_accuracy: 0.8067\n",
            "248/469 [==============>...............] - ETA: 1:59 - loss: 0.6646 - sparse_categorical_accuracy: 0.8073\n",
            "249/469 [==============>...............] - ETA: 1:58 - loss: 0.6625 - sparse_categorical_accuracy: 0.8079\n",
            "250/469 [==============>...............] - ETA: 1:58 - loss: 0.6608 - sparse_categorical_accuracy: 0.8084\n",
            "251/469 [===============>..............] - ETA: 1:57 - loss: 0.6589 - sparse_categorical_accuracy: 0.8089\n",
            "252/469 [===============>..............] - ETA: 1:56 - loss: 0.6571 - sparse_categorical_accuracy: 0.8094\n",
            "253/469 [===============>..............] - ETA: 1:56 - loss: 0.6554 - sparse_categorical_accuracy: 0.8098\n",
            "254/469 [===============>..............] - ETA: 1:55 - loss: 0.6535 - sparse_categorical_accuracy: 0.8104\n",
            "255/469 [===============>..............] - ETA: 1:55 - loss: 0.6518 - sparse_categorical_accuracy: 0.8109\n",
            "256/469 [===============>..............] - ETA: 1:54 - loss: 0.6503 - sparse_categorical_accuracy: 0.8114\n",
            "257/469 [===============>..............] - ETA: 1:54 - loss: 0.6484 - sparse_categorical_accuracy: 0.8119\n",
            "258/469 [===============>..............] - ETA: 1:53 - loss: 0.6465 - sparse_categorical_accuracy: 0.8126\n",
            "259/469 [===============>..............] - ETA: 1:52 - loss: 0.6446 - sparse_categorical_accuracy: 0.8131\n",
            "260/469 [===============>..............] - ETA: 1:52 - loss: 0.6430 - sparse_categorical_accuracy: 0.8136\n",
            "261/469 [===============>..............] - ETA: 1:51 - loss: 0.6415 - sparse_categorical_accuracy: 0.8140\n",
            "262/469 [===============>..............] - ETA: 1:51 - loss: 0.6399 - sparse_categorical_accuracy: 0.8144\n",
            "263/469 [===============>..............] - ETA: 1:50 - loss: 0.6380 - sparse_categorical_accuracy: 0.8149\n",
            "264/469 [===============>..............] - ETA: 1:50 - loss: 0.6367 - sparse_categorical_accuracy: 0.8153\n",
            "265/469 [===============>..............] - ETA: 1:50 - loss: 0.6349 - sparse_categorical_accuracy: 0.8157\n",
            "266/469 [================>.............] - ETA: 1:49 - loss: 0.6327 - sparse_categorical_accuracy: 0.8164\n",
            "267/469 [================>.............] - ETA: 1:49 - loss: 0.6310 - sparse_categorical_accuracy: 0.8169\n",
            "268/469 [================>.............] - ETA: 1:48 - loss: 0.6294 - sparse_categorical_accuracy: 0.8173\n",
            "269/469 [================>.............] - ETA: 1:47 - loss: 0.6276 - sparse_categorical_accuracy: 0.8178\n",
            "270/469 [================>.............] - ETA: 1:47 - loss: 0.6258 - sparse_categorical_accuracy: 0.8182\n",
            "271/469 [================>.............] - ETA: 1:46 - loss: 0.6240 - sparse_categorical_accuracy: 0.8186\n",
            "272/469 [================>.............] - ETA: 1:46 - loss: 0.6221 - sparse_categorical_accuracy: 0.8192\n",
            "273/469 [================>.............] - ETA: 1:45 - loss: 0.6204 - sparse_categorical_accuracy: 0.8197\n",
            "274/469 [================>.............] - ETA: 1:44 - loss: 0.6187 - sparse_categorical_accuracy: 0.8201\n",
            "275/469 [================>.............] - ETA: 1:44 - loss: 0.6172 - sparse_categorical_accuracy: 0.8205\n",
            "276/469 [================>.............] - ETA: 1:43 - loss: 0.6158 - sparse_categorical_accuracy: 0.8210\n",
            "277/469 [================>.............] - ETA: 1:43 - loss: 0.6143 - sparse_categorical_accuracy: 0.8214\n",
            "278/469 [================>.............] - ETA: 1:42 - loss: 0.6129 - sparse_categorical_accuracy: 0.8217\n",
            "279/469 [================>.............] - ETA: 1:41 - loss: 0.6112 - sparse_categorical_accuracy: 0.8222\n",
            "280/469 [================>.............] - ETA: 1:41 - loss: 0.6096 - sparse_categorical_accuracy: 0.8228\n",
            "281/469 [================>.............] - ETA: 1:40 - loss: 0.6086 - sparse_categorical_accuracy: 0.8230\n",
            "282/469 [=================>............] - ETA: 1:40 - loss: 0.6075 - sparse_categorical_accuracy: 0.8234\n",
            "283/469 [=================>............] - ETA: 1:39 - loss: 0.6059 - sparse_categorical_accuracy: 0.8239\n",
            "284/469 [=================>............] - ETA: 1:39 - loss: 0.6046 - sparse_categorical_accuracy: 0.8243\n",
            "285/469 [=================>............] - ETA: 1:38 - loss: 0.6030 - sparse_categorical_accuracy: 0.8247\n",
            "286/469 [=================>............] - ETA: 1:37 - loss: 0.6016 - sparse_categorical_accuracy: 0.8251\n",
            "287/469 [=================>............] - ETA: 1:37 - loss: 0.6002 - sparse_categorical_accuracy: 0.8255\n",
            "288/469 [=================>............] - ETA: 1:37 - loss: 0.5987 - sparse_categorical_accuracy: 0.8260\n",
            "289/469 [=================>............] - ETA: 1:36 - loss: 0.5971 - sparse_categorical_accuracy: 0.8265\n",
            "290/469 [=================>............] - ETA: 1:36 - loss: 0.5961 - sparse_categorical_accuracy: 0.8268\n",
            "291/469 [=================>............] - ETA: 1:35 - loss: 0.5947 - sparse_categorical_accuracy: 0.8272\n",
            "292/469 [=================>............] - ETA: 1:35 - loss: 0.5934 - sparse_categorical_accuracy: 0.8275\n",
            "293/469 [=================>............] - ETA: 1:34 - loss: 0.5920 - sparse_categorical_accuracy: 0.8279\n",
            "294/469 [=================>............] - ETA: 1:34 - loss: 0.5906 - sparse_categorical_accuracy: 0.8283\n",
            "295/469 [=================>............] - ETA: 1:33 - loss: 0.5893 - sparse_categorical_accuracy: 0.8287\n",
            "296/469 [=================>............] - ETA: 1:32 - loss: 0.5880 - sparse_categorical_accuracy: 0.8291\n",
            "297/469 [=================>............] - ETA: 1:32 - loss: 0.5867 - sparse_categorical_accuracy: 0.8295\n",
            "298/469 [==================>...........] - ETA: 1:31 - loss: 0.5856 - sparse_categorical_accuracy: 0.8298\n",
            "299/469 [==================>...........] - ETA: 1:31 - loss: 0.5841 - sparse_categorical_accuracy: 0.8303\n",
            "300/469 [==================>...........] - ETA: 1:30 - loss: 0.5829 - sparse_categorical_accuracy: 0.8307\n",
            "301/469 [==================>...........] - ETA: 1:30 - loss: 0.5815 - sparse_categorical_accuracy: 0.8311\n",
            "302/469 [==================>...........] - ETA: 1:29 - loss: 0.5803 - sparse_categorical_accuracy: 0.8314\n",
            "303/469 [==================>...........] - ETA: 1:28 - loss: 0.5788 - sparse_categorical_accuracy: 0.8318\n",
            "304/469 [==================>...........] - ETA: 1:28 - loss: 0.5776 - sparse_categorical_accuracy: 0.8322\n",
            "305/469 [==================>...........] - ETA: 1:27 - loss: 0.5764 - sparse_categorical_accuracy: 0.8325\n",
            "306/469 [==================>...........] - ETA: 1:27 - loss: 0.5752 - sparse_categorical_accuracy: 0.8328\n",
            "307/469 [==================>...........] - ETA: 1:26 - loss: 0.5738 - sparse_categorical_accuracy: 0.8332\n",
            "308/469 [==================>...........] - ETA: 1:26 - loss: 0.5724 - sparse_categorical_accuracy: 0.8337\n",
            "309/469 [==================>...........] - ETA: 1:25 - loss: 0.5713 - sparse_categorical_accuracy: 0.8340\n",
            "310/469 [==================>...........] - ETA: 1:24 - loss: 0.5699 - sparse_categorical_accuracy: 0.8344\n",
            "311/469 [==================>...........] - ETA: 1:24 - loss: 0.5688 - sparse_categorical_accuracy: 0.8347\n",
            "312/469 [==================>...........] - ETA: 1:23 - loss: 0.5677 - sparse_categorical_accuracy: 0.8350\n",
            "313/469 [===================>..........] - ETA: 1:23 - loss: 0.5665 - sparse_categorical_accuracy: 0.8354\n",
            "314/469 [===================>..........] - ETA: 1:22 - loss: 0.5655 - sparse_categorical_accuracy: 0.8356\n",
            "315/469 [===================>..........] - ETA: 1:22 - loss: 0.5646 - sparse_categorical_accuracy: 0.8358\n",
            "316/469 [===================>..........] - ETA: 1:21 - loss: 0.5634 - sparse_categorical_accuracy: 0.8362\n",
            "317/469 [===================>..........] - ETA: 1:21 - loss: 0.5625 - sparse_categorical_accuracy: 0.8365\n",
            "318/469 [===================>..........] - ETA: 1:20 - loss: 0.5615 - sparse_categorical_accuracy: 0.8367\n",
            "319/469 [===================>..........] - ETA: 1:20 - loss: 0.5602 - sparse_categorical_accuracy: 0.8371\n",
            "320/469 [===================>..........] - ETA: 1:19 - loss: 0.5590 - sparse_categorical_accuracy: 0.8375\n",
            "321/469 [===================>..........] - ETA: 1:19 - loss: 0.5575 - sparse_categorical_accuracy: 0.8380\n",
            "322/469 [===================>..........] - ETA: 1:18 - loss: 0.5563 - sparse_categorical_accuracy: 0.8383\n",
            "323/469 [===================>..........] - ETA: 1:18 - loss: 0.5551 - sparse_categorical_accuracy: 0.8386\n",
            "324/469 [===================>..........] - ETA: 1:17 - loss: 0.5538 - sparse_categorical_accuracy: 0.8390\n",
            "325/469 [===================>..........] - ETA: 1:17 - loss: 0.5531 - sparse_categorical_accuracy: 0.8392\n",
            "326/469 [===================>..........] - ETA: 1:16 - loss: 0.5517 - sparse_categorical_accuracy: 0.8397\n",
            "327/469 [===================>..........] - ETA: 1:15 - loss: 0.5504 - sparse_categorical_accuracy: 0.8400\n",
            "328/469 [===================>..........] - ETA: 1:15 - loss: 0.5493 - sparse_categorical_accuracy: 0.8403\n",
            "329/469 [====================>.........] - ETA: 1:14 - loss: 0.5482 - sparse_categorical_accuracy: 0.8406\n",
            "330/469 [====================>.........] - ETA: 1:14 - loss: 0.5471 - sparse_categorical_accuracy: 0.8409\n",
            "331/469 [====================>.........] - ETA: 1:13 - loss: 0.5460 - sparse_categorical_accuracy: 0.8412\n",
            "332/469 [====================>.........] - ETA: 1:13 - loss: 0.5449 - sparse_categorical_accuracy: 0.8416\n",
            "333/469 [====================>.........] - ETA: 1:12 - loss: 0.5437 - sparse_categorical_accuracy: 0.8419\n",
            "334/469 [====================>.........] - ETA: 1:12 - loss: 0.5424 - sparse_categorical_accuracy: 0.8423\n",
            "335/469 [====================>.........] - ETA: 1:11 - loss: 0.5416 - sparse_categorical_accuracy: 0.8426\n",
            "336/469 [====================>.........] - ETA: 1:10 - loss: 0.5405 - sparse_categorical_accuracy: 0.8429\n",
            "337/469 [====================>.........] - ETA: 1:10 - loss: 0.5395 - sparse_categorical_accuracy: 0.8431\n",
            "338/469 [====================>.........] - ETA: 1:09 - loss: 0.5385 - sparse_categorical_accuracy: 0.8434\n",
            "339/469 [====================>.........] - ETA: 1:09 - loss: 0.5373 - sparse_categorical_accuracy: 0.8438\n",
            "340/469 [====================>.........] - ETA: 1:08 - loss: 0.5361 - sparse_categorical_accuracy: 0.8442\n",
            "341/469 [====================>.........] - ETA: 1:08 - loss: 0.5351 - sparse_categorical_accuracy: 0.8445\n",
            "342/469 [====================>.........] - ETA: 1:07 - loss: 0.5337 - sparse_categorical_accuracy: 0.8449\n",
            "343/469 [====================>.........] - ETA: 1:07 - loss: 0.5328 - sparse_categorical_accuracy: 0.8452\n",
            "344/469 [=====================>........] - ETA: 1:06 - loss: 0.5317 - sparse_categorical_accuracy: 0.8456\n",
            "345/469 [=====================>........] - ETA: 1:06 - loss: 0.5306 - sparse_categorical_accuracy: 0.8459\n",
            "346/469 [=====================>........] - ETA: 1:05 - loss: 0.5296 - sparse_categorical_accuracy: 0.8462\n",
            "347/469 [=====================>........] - ETA: 1:05 - loss: 0.5285 - sparse_categorical_accuracy: 0.8465\n",
            "348/469 [=====================>........] - ETA: 1:04 - loss: 0.5276 - sparse_categorical_accuracy: 0.8468\n",
            "349/469 [=====================>........] - ETA: 1:04 - loss: 0.5264 - sparse_categorical_accuracy: 0.8471\n",
            "350/469 [=====================>........] - ETA: 1:03 - loss: 0.5254 - sparse_categorical_accuracy: 0.8474\n",
            "351/469 [=====================>........] - ETA: 1:03 - loss: 0.5244 - sparse_categorical_accuracy: 0.8477\n",
            "352/469 [=====================>........] - ETA: 1:02 - loss: 0.5238 - sparse_categorical_accuracy: 0.8479\n",
            "353/469 [=====================>........] - ETA: 1:01 - loss: 0.5232 - sparse_categorical_accuracy: 0.8481\n",
            "354/469 [=====================>........] - ETA: 1:01 - loss: 0.5222 - sparse_categorical_accuracy: 0.8485\n",
            "355/469 [=====================>........] - ETA: 1:00 - loss: 0.5215 - sparse_categorical_accuracy: 0.8487\n",
            "356/469 [=====================>........] - ETA: 1:00 - loss: 0.5206 - sparse_categorical_accuracy: 0.8490\n",
            "357/469 [=====================>........] - ETA: 59s - loss: 0.5194 - sparse_categorical_accuracy: 0.8493 \n",
            "358/469 [=====================>........] - ETA: 59s - loss: 0.5188 - sparse_categorical_accuracy: 0.8496\n",
            "359/469 [=====================>........] - ETA: 58s - loss: 0.5180 - sparse_categorical_accuracy: 0.8498\n",
            "360/469 [======================>.......] - ETA: 58s - loss: 0.5176 - sparse_categorical_accuracy: 0.8499\n",
            "361/469 [======================>.......] - ETA: 57s - loss: 0.5165 - sparse_categorical_accuracy: 0.8502\n",
            "362/469 [======================>.......] - ETA: 56s - loss: 0.5155 - sparse_categorical_accuracy: 0.8505\n",
            "363/469 [======================>.......] - ETA: 56s - loss: 0.5144 - sparse_categorical_accuracy: 0.8509\n",
            "364/469 [======================>.......] - ETA: 55s - loss: 0.5136 - sparse_categorical_accuracy: 0.8511\n",
            "365/469 [======================>.......] - ETA: 55s - loss: 0.5126 - sparse_categorical_accuracy: 0.8514\n",
            "366/469 [======================>.......] - ETA: 54s - loss: 0.5117 - sparse_categorical_accuracy: 0.8516\n",
            "367/469 [======================>.......] - ETA: 54s - loss: 0.5108 - sparse_categorical_accuracy: 0.8519\n",
            "368/469 [======================>.......] - ETA: 53s - loss: 0.5097 - sparse_categorical_accuracy: 0.8522\n",
            "369/469 [======================>.......] - ETA: 53s - loss: 0.5088 - sparse_categorical_accuracy: 0.8525\n",
            "370/469 [======================>.......] - ETA: 52s - loss: 0.5080 - sparse_categorical_accuracy: 0.8527\n",
            "371/469 [======================>.......] - ETA: 52s - loss: 0.5072 - sparse_categorical_accuracy: 0.8528\n",
            "372/469 [======================>.......] - ETA: 51s - loss: 0.5063 - sparse_categorical_accuracy: 0.8531\n",
            "373/469 [======================>.......] - ETA: 51s - loss: 0.5054 - sparse_categorical_accuracy: 0.8533\n",
            "374/469 [======================>.......] - ETA: 50s - loss: 0.5043 - sparse_categorical_accuracy: 0.8537\n",
            "375/469 [======================>.......] - ETA: 50s - loss: 0.5033 - sparse_categorical_accuracy: 0.8540\n",
            "376/469 [=======================>......] - ETA: 49s - loss: 0.5026 - sparse_categorical_accuracy: 0.8541\n",
            "377/469 [=======================>......] - ETA: 49s - loss: 0.5017 - sparse_categorical_accuracy: 0.8544\n",
            "378/469 [=======================>......] - ETA: 48s - loss: 0.5008 - sparse_categorical_accuracy: 0.8547\n",
            "379/469 [=======================>......] - ETA: 47s - loss: 0.5000 - sparse_categorical_accuracy: 0.8550\n",
            "380/469 [=======================>......] - ETA: 47s - loss: 0.4991 - sparse_categorical_accuracy: 0.8552\n",
            "381/469 [=======================>......] - ETA: 46s - loss: 0.4987 - sparse_categorical_accuracy: 0.8554\n",
            "382/469 [=======================>......] - ETA: 46s - loss: 0.4979 - sparse_categorical_accuracy: 0.8556\n",
            "383/469 [=======================>......] - ETA: 45s - loss: 0.4970 - sparse_categorical_accuracy: 0.8558\n",
            "384/469 [=======================>......] - ETA: 45s - loss: 0.4961 - sparse_categorical_accuracy: 0.8560\n",
            "385/469 [=======================>......] - ETA: 44s - loss: 0.4954 - sparse_categorical_accuracy: 0.8562\n",
            "386/469 [=======================>......] - ETA: 44s - loss: 0.4945 - sparse_categorical_accuracy: 0.8564\n",
            "387/469 [=======================>......] - ETA: 43s - loss: 0.4937 - sparse_categorical_accuracy: 0.8567\n",
            "388/469 [=======================>......] - ETA: 43s - loss: 0.4929 - sparse_categorical_accuracy: 0.8569\n",
            "389/469 [=======================>......] - ETA: 42s - loss: 0.4922 - sparse_categorical_accuracy: 0.8571\n",
            "390/469 [=======================>......] - ETA: 42s - loss: 0.4912 - sparse_categorical_accuracy: 0.8574\n",
            "391/469 [========================>.....] - ETA: 41s - loss: 0.4903 - sparse_categorical_accuracy: 0.8576\n",
            "392/469 [========================>.....] - ETA: 41s - loss: 0.4893 - sparse_categorical_accuracy: 0.8579\n",
            "393/469 [========================>.....] - ETA: 40s - loss: 0.4885 - sparse_categorical_accuracy: 0.8582\n",
            "394/469 [========================>.....] - ETA: 40s - loss: 0.4879 - sparse_categorical_accuracy: 0.8583\n",
            "395/469 [========================>.....] - ETA: 39s - loss: 0.4873 - sparse_categorical_accuracy: 0.8585\n",
            "396/469 [========================>.....] - ETA: 38s - loss: 0.4864 - sparse_categorical_accuracy: 0.8588\n",
            "397/469 [========================>.....] - ETA: 38s - loss: 0.4855 - sparse_categorical_accuracy: 0.8591\n",
            "398/469 [========================>.....] - ETA: 37s - loss: 0.4847 - sparse_categorical_accuracy: 0.8593\n",
            "399/469 [========================>.....] - ETA: 37s - loss: 0.4840 - sparse_categorical_accuracy: 0.8595\n",
            "400/469 [========================>.....] - ETA: 36s - loss: 0.4832 - sparse_categorical_accuracy: 0.8597\n",
            "401/469 [========================>.....] - ETA: 36s - loss: 0.4823 - sparse_categorical_accuracy: 0.8599\n",
            "402/469 [========================>.....] - ETA: 35s - loss: 0.4815 - sparse_categorical_accuracy: 0.8602\n",
            "403/469 [========================>.....] - ETA: 35s - loss: 0.4808 - sparse_categorical_accuracy: 0.8603\n",
            "404/469 [========================>.....] - ETA: 34s - loss: 0.4801 - sparse_categorical_accuracy: 0.8606\n",
            "405/469 [========================>.....] - ETA: 34s - loss: 0.4793 - sparse_categorical_accuracy: 0.8608\n",
            "406/469 [========================>.....] - ETA: 33s - loss: 0.4784 - sparse_categorical_accuracy: 0.8610\n",
            "407/469 [=========================>....] - ETA: 33s - loss: 0.4778 - sparse_categorical_accuracy: 0.8612\n",
            "408/469 [=========================>....] - ETA: 32s - loss: 0.4771 - sparse_categorical_accuracy: 0.8614\n",
            "409/469 [=========================>....] - ETA: 31s - loss: 0.4762 - sparse_categorical_accuracy: 0.8616\n",
            "410/469 [=========================>....] - ETA: 31s - loss: 0.4754 - sparse_categorical_accuracy: 0.8619\n",
            "411/469 [=========================>....] - ETA: 30s - loss: 0.4745 - sparse_categorical_accuracy: 0.8622\n",
            "412/469 [=========================>....] - ETA: 30s - loss: 0.4741 - sparse_categorical_accuracy: 0.8623\n",
            "413/469 [=========================>....] - ETA: 29s - loss: 0.4733 - sparse_categorical_accuracy: 0.8626\n",
            "414/469 [=========================>....] - ETA: 29s - loss: 0.4724 - sparse_categorical_accuracy: 0.8628\n",
            "415/469 [=========================>....] - ETA: 28s - loss: 0.4716 - sparse_categorical_accuracy: 0.8630\n",
            "416/469 [=========================>....] - ETA: 28s - loss: 0.4708 - sparse_categorical_accuracy: 0.8633\n",
            "417/469 [=========================>....] - ETA: 27s - loss: 0.4701 - sparse_categorical_accuracy: 0.8634\n",
            "418/469 [=========================>....] - ETA: 27s - loss: 0.4693 - sparse_categorical_accuracy: 0.8637\n",
            "419/469 [=========================>....] - ETA: 26s - loss: 0.4688 - sparse_categorical_accuracy: 0.8638\n",
            "420/469 [=========================>....] - ETA: 26s - loss: 0.4678 - sparse_categorical_accuracy: 0.8641\n",
            "421/469 [=========================>....] - ETA: 25s - loss: 0.4670 - sparse_categorical_accuracy: 0.8643\n",
            "422/469 [=========================>....] - ETA: 25s - loss: 0.4663 - sparse_categorical_accuracy: 0.8645\n",
            "423/469 [==========================>...] - ETA: 24s - loss: 0.4655 - sparse_categorical_accuracy: 0.8647\n",
            "424/469 [==========================>...] - ETA: 24s - loss: 0.4646 - sparse_categorical_accuracy: 0.8650\n",
            "425/469 [==========================>...] - ETA: 23s - loss: 0.4639 - sparse_categorical_accuracy: 0.8651\n",
            "426/469 [==========================>...] - ETA: 22s - loss: 0.4631 - sparse_categorical_accuracy: 0.8654\n",
            "427/469 [==========================>...] - ETA: 22s - loss: 0.4623 - sparse_categorical_accuracy: 0.8656\n",
            "428/469 [==========================>...] - ETA: 21s - loss: 0.4615 - sparse_categorical_accuracy: 0.8659\n",
            "429/469 [==========================>...] - ETA: 21s - loss: 0.4606 - sparse_categorical_accuracy: 0.8661\n",
            "430/469 [==========================>...] - ETA: 20s - loss: 0.4597 - sparse_categorical_accuracy: 0.8664\n",
            "431/469 [==========================>...] - ETA: 20s - loss: 0.4590 - sparse_categorical_accuracy: 0.8666\n",
            "432/469 [==========================>...] - ETA: 19s - loss: 0.4582 - sparse_categorical_accuracy: 0.8669\n",
            "433/469 [==========================>...] - ETA: 19s - loss: 0.4573 - sparse_categorical_accuracy: 0.8672\n",
            "434/469 [==========================>...] - ETA: 18s - loss: 0.4565 - sparse_categorical_accuracy: 0.8674\n",
            "435/469 [==========================>...] - ETA: 18s - loss: 0.4558 - sparse_categorical_accuracy: 0.8676\n",
            "436/469 [==========================>...] - ETA: 17s - loss: 0.4551 - sparse_categorical_accuracy: 0.8678\n",
            "437/469 [==========================>...] - ETA: 17s - loss: 0.4544 - sparse_categorical_accuracy: 0.8680\n",
            "438/469 [===========================>..] - ETA: 16s - loss: 0.4537 - sparse_categorical_accuracy: 0.8682\n",
            "439/469 [===========================>..] - ETA: 15s - loss: 0.4529 - sparse_categorical_accuracy: 0.8684\n",
            "440/469 [===========================>..] - ETA: 15s - loss: 0.4521 - sparse_categorical_accuracy: 0.8686\n",
            "441/469 [===========================>..] - ETA: 14s - loss: 0.4513 - sparse_categorical_accuracy: 0.8688\n",
            "442/469 [===========================>..] - ETA: 14s - loss: 0.4508 - sparse_categorical_accuracy: 0.8690\n",
            "443/469 [===========================>..] - ETA: 13s - loss: 0.4502 - sparse_categorical_accuracy: 0.8691\n",
            "444/469 [===========================>..] - ETA: 13s - loss: 0.4497 - sparse_categorical_accuracy: 0.8692\n",
            "445/469 [===========================>..] - ETA: 12s - loss: 0.4490 - sparse_categorical_accuracy: 0.8694\n",
            "446/469 [===========================>..] - ETA: 12s - loss: 0.4485 - sparse_categorical_accuracy: 0.8696\n",
            "447/469 [===========================>..] - ETA: 11s - loss: 0.4479 - sparse_categorical_accuracy: 0.8698\n",
            "448/469 [===========================>..] - ETA: 11s - loss: 0.4473 - sparse_categorical_accuracy: 0.8700\n",
            "449/469 [===========================>..] - ETA: 10s - loss: 0.4465 - sparse_categorical_accuracy: 0.8702\n",
            "450/469 [===========================>..] - ETA: 10s - loss: 0.4458 - sparse_categorical_accuracy: 0.8704\n",
            "451/469 [===========================>..] - ETA: 9s - loss: 0.4450 - sparse_categorical_accuracy: 0.8706 \n",
            "452/469 [===========================>..] - ETA: 9s - loss: 0.4444 - sparse_categorical_accuracy: 0.8708\n",
            "453/469 [===========================>..] - ETA: 8s - loss: 0.4438 - sparse_categorical_accuracy: 0.8710\n",
            "454/469 [============================>.] - ETA: 7s - loss: 0.4431 - sparse_categorical_accuracy: 0.8711\n",
            "455/469 [============================>.] - ETA: 7s - loss: 0.4426 - sparse_categorical_accuracy: 0.8713\n",
            "456/469 [============================>.] - ETA: 6s - loss: 0.4420 - sparse_categorical_accuracy: 0.8715\n",
            "457/469 [============================>.] - ETA: 6s - loss: 0.4412 - sparse_categorical_accuracy: 0.8718\n",
            "458/469 [============================>.] - ETA: 5s - loss: 0.4407 - sparse_categorical_accuracy: 0.8719\n",
            "459/469 [============================>.] - ETA: 5s - loss: 0.4400 - sparse_categorical_accuracy: 0.8721\n",
            "460/469 [============================>.] - ETA: 4s - loss: 0.4394 - sparse_categorical_accuracy: 0.8723\n",
            "461/469 [============================>.] - ETA: 4s - loss: 0.4388 - sparse_categorical_accuracy: 0.8725\n",
            "462/469 [============================>.] - ETA: 3s - loss: 0.4381 - sparse_categorical_accuracy: 0.8726\n",
            "463/469 [============================>.] - ETA: 3s - loss: 0.4375 - sparse_categorical_accuracy: 0.8728\n",
            "464/469 [============================>.] - ETA: 2s - loss: 0.4367 - sparse_categorical_accuracy: 0.8730\n",
            "465/469 [============================>.] - ETA: 2s - loss: 0.4361 - sparse_categorical_accuracy: 0.8732\n",
            "466/469 [============================>.] - ETA: 1s - loss: 0.4354 - sparse_categorical_accuracy: 0.8734\n",
            "467/469 [============================>.] - ETA: 1s - loss: 0.4347 - sparse_categorical_accuracy: 0.8735\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.4341 - sparse_categorical_accuracy: 0.8737\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.4336 - sparse_categorical_accuracy: 0.8738\n",
            " 80%|████████  | 4/5 [1:18:47<17:32, 1052.88s/trial, best loss: -0.9850000143051147]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/04/16 01:50:48 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "469/469 [==============================] - 250s 531ms/step - loss: 0.4336 - sparse_categorical_accuracy: 0.8738\n",
            "\n",
            "Epoch 2/5\n",
            "\n",
            "  1/469 [..............................] - ETA: 5:41 - loss: 0.2396 - sparse_categorical_accuracy: 0.9062\n",
            "  2/469 [..............................] - ETA: 5:51 - loss: 0.1713 - sparse_categorical_accuracy: 0.9375\n",
            "  3/469 [..............................] - ETA: 5:32 - loss: 0.1456 - sparse_categorical_accuracy: 0.9505\n",
            "  4/469 [..............................] - ETA: 4:54 - loss: 0.1341 - sparse_categorical_accuracy: 0.9570\n",
            "  5/469 [..............................] - ETA: 4:35 - loss: 0.1316 - sparse_categorical_accuracy: 0.9563\n",
            "  6/469 [..............................] - ETA: 4:23 - loss: 0.1244 - sparse_categorical_accuracy: 0.9583\n",
            "  7/469 [..............................] - ETA: 4:14 - loss: 0.1187 - sparse_categorical_accuracy: 0.9621\n",
            "  8/469 [..............................] - ETA: 4:08 - loss: 0.1277 - sparse_categorical_accuracy: 0.9609\n",
            "  9/469 [..............................] - ETA: 4:03 - loss: 0.1357 - sparse_categorical_accuracy: 0.9609\n",
            " 10/469 [..............................] - ETA: 3:59 - loss: 0.1346 - sparse_categorical_accuracy: 0.9602\n",
            " 11/469 [..............................] - ETA: 3:56 - loss: 0.1411 - sparse_categorical_accuracy: 0.9588\n",
            " 12/469 [..............................] - ETA: 3:54 - loss: 0.1362 - sparse_categorical_accuracy: 0.9603\n",
            " 13/469 [..............................] - ETA: 3:51 - loss: 0.1377 - sparse_categorical_accuracy: 0.9597\n",
            " 14/469 [..............................] - ETA: 3:49 - loss: 0.1324 - sparse_categorical_accuracy: 0.9609\n",
            " 15/469 [..............................] - ETA: 3:47 - loss: 0.1357 - sparse_categorical_accuracy: 0.9604\n",
            " 16/469 [>.............................] - ETA: 3:45 - loss: 0.1331 - sparse_categorical_accuracy: 0.9609\n",
            " 17/469 [>.............................] - ETA: 3:44 - loss: 0.1332 - sparse_categorical_accuracy: 0.9605\n",
            " 18/469 [>.............................] - ETA: 3:42 - loss: 0.1335 - sparse_categorical_accuracy: 0.9601\n",
            " 19/469 [>.............................] - ETA: 3:41 - loss: 0.1314 - sparse_categorical_accuracy: 0.9593\n",
            " 20/469 [>.............................] - ETA: 3:40 - loss: 0.1314 - sparse_categorical_accuracy: 0.9602\n",
            " 21/469 [>.............................] - ETA: 3:39 - loss: 0.1293 - sparse_categorical_accuracy: 0.9613\n",
            " 22/469 [>.............................] - ETA: 3:38 - loss: 0.1305 - sparse_categorical_accuracy: 0.9613\n",
            " 23/469 [>.............................] - ETA: 3:38 - loss: 0.1278 - sparse_categorical_accuracy: 0.9620\n",
            " 24/469 [>.............................] - ETA: 3:37 - loss: 0.1298 - sparse_categorical_accuracy: 0.9619\n",
            " 25/469 [>.............................] - ETA: 3:40 - loss: 0.1305 - sparse_categorical_accuracy: 0.9613\n",
            " 26/469 [>.............................] - ETA: 3:44 - loss: 0.1310 - sparse_categorical_accuracy: 0.9606\n",
            " 27/469 [>.............................] - ETA: 3:48 - loss: 0.1341 - sparse_categorical_accuracy: 0.9583\n",
            " 28/469 [>.............................] - ETA: 3:51 - loss: 0.1332 - sparse_categorical_accuracy: 0.9587\n",
            " 29/469 [>.............................] - ETA: 3:53 - loss: 0.1335 - sparse_categorical_accuracy: 0.9588\n",
            " 30/469 [>.............................] - ETA: 3:52 - loss: 0.1332 - sparse_categorical_accuracy: 0.9591\n",
            " 31/469 [>.............................] - ETA: 3:51 - loss: 0.1311 - sparse_categorical_accuracy: 0.9599\n",
            " 32/469 [=>............................] - ETA: 3:49 - loss: 0.1336 - sparse_categorical_accuracy: 0.9592\n",
            " 33/469 [=>............................] - ETA: 3:48 - loss: 0.1330 - sparse_categorical_accuracy: 0.9595\n",
            " 34/469 [=>............................] - ETA: 3:47 - loss: 0.1343 - sparse_categorical_accuracy: 0.9591\n",
            " 35/469 [=>............................] - ETA: 3:46 - loss: 0.1335 - sparse_categorical_accuracy: 0.9596\n",
            " 36/469 [=>............................] - ETA: 3:45 - loss: 0.1317 - sparse_categorical_accuracy: 0.9601\n",
            " 37/469 [=>............................] - ETA: 3:45 - loss: 0.1330 - sparse_categorical_accuracy: 0.9599\n",
            " 38/469 [=>............................] - ETA: 3:44 - loss: 0.1336 - sparse_categorical_accuracy: 0.9599\n",
            " 39/469 [=>............................] - ETA: 3:43 - loss: 0.1345 - sparse_categorical_accuracy: 0.9589\n",
            " 40/469 [=>............................] - ETA: 3:42 - loss: 0.1348 - sparse_categorical_accuracy: 0.9588\n",
            " 41/469 [=>............................] - ETA: 3:41 - loss: 0.1354 - sparse_categorical_accuracy: 0.9587\n",
            " 42/469 [=>............................] - ETA: 3:40 - loss: 0.1362 - sparse_categorical_accuracy: 0.9580\n",
            " 43/469 [=>............................] - ETA: 3:39 - loss: 0.1359 - sparse_categorical_accuracy: 0.9580\n",
            " 44/469 [=>............................] - ETA: 3:38 - loss: 0.1364 - sparse_categorical_accuracy: 0.9579\n",
            " 45/469 [=>............................] - ETA: 3:37 - loss: 0.1359 - sparse_categorical_accuracy: 0.9583\n",
            " 46/469 [=>............................] - ETA: 3:36 - loss: 0.1340 - sparse_categorical_accuracy: 0.9589\n",
            " 47/469 [==>...........................] - ETA: 3:36 - loss: 0.1329 - sparse_categorical_accuracy: 0.9594\n",
            " 48/469 [==>...........................] - ETA: 3:35 - loss: 0.1323 - sparse_categorical_accuracy: 0.9600\n",
            " 49/469 [==>...........................] - ETA: 3:34 - loss: 0.1331 - sparse_categorical_accuracy: 0.9597\n",
            " 50/469 [==>...........................] - ETA: 3:34 - loss: 0.1320 - sparse_categorical_accuracy: 0.9600\n",
            " 51/469 [==>...........................] - ETA: 3:35 - loss: 0.1308 - sparse_categorical_accuracy: 0.9605\n",
            " 52/469 [==>...........................] - ETA: 3:36 - loss: 0.1294 - sparse_categorical_accuracy: 0.9609\n",
            " 53/469 [==>...........................] - ETA: 3:38 - loss: 0.1295 - sparse_categorical_accuracy: 0.9609\n",
            " 54/469 [==>...........................] - ETA: 3:39 - loss: 0.1288 - sparse_categorical_accuracy: 0.9611\n",
            " 55/469 [==>...........................] - ETA: 3:40 - loss: 0.1295 - sparse_categorical_accuracy: 0.9608\n",
            " 56/469 [==>...........................] - ETA: 3:39 - loss: 0.1303 - sparse_categorical_accuracy: 0.9607\n",
            " 57/469 [==>...........................] - ETA: 3:38 - loss: 0.1312 - sparse_categorical_accuracy: 0.9604\n",
            " 58/469 [==>...........................] - ETA: 3:37 - loss: 0.1306 - sparse_categorical_accuracy: 0.9605\n",
            " 59/469 [==>...........................] - ETA: 3:37 - loss: 0.1310 - sparse_categorical_accuracy: 0.9604\n",
            " 60/469 [==>...........................] - ETA: 3:36 - loss: 0.1309 - sparse_categorical_accuracy: 0.9605\n",
            " 61/469 [==>...........................] - ETA: 3:35 - loss: 0.1307 - sparse_categorical_accuracy: 0.9604\n",
            " 62/469 [==>...........................] - ETA: 3:34 - loss: 0.1304 - sparse_categorical_accuracy: 0.9606\n",
            " 63/469 [===>..........................] - ETA: 3:33 - loss: 0.1301 - sparse_categorical_accuracy: 0.9604\n",
            " 64/469 [===>..........................] - ETA: 3:32 - loss: 0.1297 - sparse_categorical_accuracy: 0.9606\n",
            " 65/469 [===>..........................] - ETA: 3:32 - loss: 0.1291 - sparse_categorical_accuracy: 0.9607\n",
            " 66/469 [===>..........................] - ETA: 3:31 - loss: 0.1287 - sparse_categorical_accuracy: 0.9612\n",
            " 67/469 [===>..........................] - ETA: 3:30 - loss: 0.1294 - sparse_categorical_accuracy: 0.9612\n",
            " 68/469 [===>..........................] - ETA: 3:29 - loss: 0.1290 - sparse_categorical_accuracy: 0.9613\n",
            " 69/469 [===>..........................] - ETA: 3:29 - loss: 0.1317 - sparse_categorical_accuracy: 0.9605\n",
            " 70/469 [===>..........................] - ETA: 3:28 - loss: 0.1318 - sparse_categorical_accuracy: 0.9605\n",
            " 71/469 [===>..........................] - ETA: 3:27 - loss: 0.1319 - sparse_categorical_accuracy: 0.9606\n",
            " 72/469 [===>..........................] - ETA: 3:27 - loss: 0.1318 - sparse_categorical_accuracy: 0.9606\n",
            " 73/469 [===>..........................] - ETA: 3:26 - loss: 0.1314 - sparse_categorical_accuracy: 0.9607\n",
            " 74/469 [===>..........................] - ETA: 3:25 - loss: 0.1330 - sparse_categorical_accuracy: 0.9605\n",
            " 75/469 [===>..........................] - ETA: 3:25 - loss: 0.1335 - sparse_categorical_accuracy: 0.9603\n",
            " 76/469 [===>..........................] - ETA: 3:25 - loss: 0.1334 - sparse_categorical_accuracy: 0.9604\n",
            " 77/469 [===>..........................] - ETA: 3:26 - loss: 0.1330 - sparse_categorical_accuracy: 0.9605\n",
            " 78/469 [===>..........................] - ETA: 3:27 - loss: 0.1326 - sparse_categorical_accuracy: 0.9606\n",
            " 79/469 [====>.........................] - ETA: 3:27 - loss: 0.1340 - sparse_categorical_accuracy: 0.9602\n",
            " 80/469 [====>.........................] - ETA: 3:27 - loss: 0.1339 - sparse_categorical_accuracy: 0.9602\n",
            " 81/469 [====>.........................] - ETA: 3:27 - loss: 0.1341 - sparse_categorical_accuracy: 0.9601\n",
            " 82/469 [====>.........................] - ETA: 3:27 - loss: 0.1339 - sparse_categorical_accuracy: 0.9601\n",
            " 83/469 [====>.........................] - ETA: 3:26 - loss: 0.1335 - sparse_categorical_accuracy: 0.9599\n",
            " 84/469 [====>.........................] - ETA: 3:25 - loss: 0.1345 - sparse_categorical_accuracy: 0.9595\n",
            " 85/469 [====>.........................] - ETA: 3:24 - loss: 0.1352 - sparse_categorical_accuracy: 0.9594\n",
            " 86/469 [====>.........................] - ETA: 3:24 - loss: 0.1346 - sparse_categorical_accuracy: 0.9597\n",
            " 87/469 [====>.........................] - ETA: 3:23 - loss: 0.1355 - sparse_categorical_accuracy: 0.9594\n",
            " 88/469 [====>.........................] - ETA: 3:22 - loss: 0.1351 - sparse_categorical_accuracy: 0.9595\n",
            " 89/469 [====>.........................] - ETA: 3:22 - loss: 0.1378 - sparse_categorical_accuracy: 0.9588\n",
            " 90/469 [====>.........................] - ETA: 3:21 - loss: 0.1382 - sparse_categorical_accuracy: 0.9587\n",
            " 91/469 [====>.........................] - ETA: 3:20 - loss: 0.1382 - sparse_categorical_accuracy: 0.9585\n",
            " 92/469 [====>.........................] - ETA: 3:20 - loss: 0.1383 - sparse_categorical_accuracy: 0.9587\n",
            " 93/469 [====>.........................] - ETA: 3:19 - loss: 0.1401 - sparse_categorical_accuracy: 0.9582\n",
            " 94/469 [=====>........................] - ETA: 3:18 - loss: 0.1399 - sparse_categorical_accuracy: 0.9582\n",
            " 95/469 [=====>........................] - ETA: 3:17 - loss: 0.1394 - sparse_categorical_accuracy: 0.9585\n",
            " 96/469 [=====>........................] - ETA: 3:17 - loss: 0.1386 - sparse_categorical_accuracy: 0.9587\n",
            " 97/469 [=====>........................] - ETA: 3:16 - loss: 0.1383 - sparse_categorical_accuracy: 0.9586\n",
            " 98/469 [=====>........................] - ETA: 3:15 - loss: 0.1377 - sparse_categorical_accuracy: 0.9588\n",
            " 99/469 [=====>........................] - ETA: 3:15 - loss: 0.1378 - sparse_categorical_accuracy: 0.9590\n",
            "100/469 [=====>........................] - ETA: 3:14 - loss: 0.1373 - sparse_categorical_accuracy: 0.9591\n",
            "101/469 [=====>........................] - ETA: 3:14 - loss: 0.1370 - sparse_categorical_accuracy: 0.9591\n",
            "102/469 [=====>........................] - ETA: 3:14 - loss: 0.1372 - sparse_categorical_accuracy: 0.9592\n",
            "103/469 [=====>........................] - ETA: 3:15 - loss: 0.1366 - sparse_categorical_accuracy: 0.9595\n",
            "104/469 [=====>........................] - ETA: 3:15 - loss: 0.1365 - sparse_categorical_accuracy: 0.9597\n",
            "105/469 [=====>........................] - ETA: 3:15 - loss: 0.1362 - sparse_categorical_accuracy: 0.9597\n",
            "106/469 [=====>........................] - ETA: 3:14 - loss: 0.1362 - sparse_categorical_accuracy: 0.9598\n",
            "107/469 [=====>........................] - ETA: 3:14 - loss: 0.1371 - sparse_categorical_accuracy: 0.9596\n",
            "108/469 [=====>........................] - ETA: 3:13 - loss: 0.1370 - sparse_categorical_accuracy: 0.9596\n",
            "109/469 [=====>........................] - ETA: 3:12 - loss: 0.1367 - sparse_categorical_accuracy: 0.9596\n",
            "110/469 [======>.......................] - ETA: 3:12 - loss: 0.1369 - sparse_categorical_accuracy: 0.9596\n",
            "111/469 [======>.......................] - ETA: 3:11 - loss: 0.1375 - sparse_categorical_accuracy: 0.9592\n",
            "112/469 [======>.......................] - ETA: 3:10 - loss: 0.1380 - sparse_categorical_accuracy: 0.9591\n",
            "113/469 [======>.......................] - ETA: 3:09 - loss: 0.1377 - sparse_categorical_accuracy: 0.9592\n",
            "114/469 [======>.......................] - ETA: 3:09 - loss: 0.1373 - sparse_categorical_accuracy: 0.9592\n",
            "115/469 [======>.......................] - ETA: 3:08 - loss: 0.1374 - sparse_categorical_accuracy: 0.9593\n",
            "116/469 [======>.......................] - ETA: 3:08 - loss: 0.1372 - sparse_categorical_accuracy: 0.9594\n",
            "117/469 [======>.......................] - ETA: 3:07 - loss: 0.1371 - sparse_categorical_accuracy: 0.9594\n",
            "118/469 [======>.......................] - ETA: 3:06 - loss: 0.1374 - sparse_categorical_accuracy: 0.9592\n",
            "119/469 [======>.......................] - ETA: 3:05 - loss: 0.1380 - sparse_categorical_accuracy: 0.9591\n",
            "120/469 [======>.......................] - ETA: 3:05 - loss: 0.1374 - sparse_categorical_accuracy: 0.9593\n",
            "121/469 [======>.......................] - ETA: 3:04 - loss: 0.1378 - sparse_categorical_accuracy: 0.9592\n",
            "122/469 [======>.......................] - ETA: 3:03 - loss: 0.1381 - sparse_categorical_accuracy: 0.9591\n",
            "123/469 [======>.......................] - ETA: 3:03 - loss: 0.1376 - sparse_categorical_accuracy: 0.9593\n",
            "124/469 [======>.......................] - ETA: 3:02 - loss: 0.1381 - sparse_categorical_accuracy: 0.9592\n",
            "125/469 [======>.......................] - ETA: 3:01 - loss: 0.1377 - sparse_categorical_accuracy: 0.9593\n",
            "126/469 [=======>......................] - ETA: 3:01 - loss: 0.1379 - sparse_categorical_accuracy: 0.9592\n",
            "127/469 [=======>......................] - ETA: 3:01 - loss: 0.1379 - sparse_categorical_accuracy: 0.9592\n",
            "128/469 [=======>......................] - ETA: 3:01 - loss: 0.1378 - sparse_categorical_accuracy: 0.9593\n",
            "129/469 [=======>......................] - ETA: 3:01 - loss: 0.1380 - sparse_categorical_accuracy: 0.9592\n",
            "130/469 [=======>......................] - ETA: 3:01 - loss: 0.1380 - sparse_categorical_accuracy: 0.9593\n",
            "131/469 [=======>......................] - ETA: 3:01 - loss: 0.1378 - sparse_categorical_accuracy: 0.9593\n",
            "132/469 [=======>......................] - ETA: 3:00 - loss: 0.1375 - sparse_categorical_accuracy: 0.9593\n",
            "133/469 [=======>......................] - ETA: 3:00 - loss: 0.1381 - sparse_categorical_accuracy: 0.9592\n",
            "134/469 [=======>......................] - ETA: 2:59 - loss: 0.1380 - sparse_categorical_accuracy: 0.9594\n",
            "135/469 [=======>......................] - ETA: 2:58 - loss: 0.1378 - sparse_categorical_accuracy: 0.9594\n",
            "136/469 [=======>......................] - ETA: 2:58 - loss: 0.1377 - sparse_categorical_accuracy: 0.9594\n",
            "137/469 [=======>......................] - ETA: 2:57 - loss: 0.1375 - sparse_categorical_accuracy: 0.9595\n",
            "138/469 [=======>......................] - ETA: 2:56 - loss: 0.1380 - sparse_categorical_accuracy: 0.9594\n",
            "139/469 [=======>......................] - ETA: 2:56 - loss: 0.1379 - sparse_categorical_accuracy: 0.9594\n",
            "140/469 [=======>......................] - ETA: 2:55 - loss: 0.1378 - sparse_categorical_accuracy: 0.9594\n",
            "141/469 [========>.....................] - ETA: 2:54 - loss: 0.1387 - sparse_categorical_accuracy: 0.9591\n",
            "142/469 [========>.....................] - ETA: 2:54 - loss: 0.1385 - sparse_categorical_accuracy: 0.9591\n",
            "143/469 [========>.....................] - ETA: 2:53 - loss: 0.1386 - sparse_categorical_accuracy: 0.9590\n",
            "144/469 [========>.....................] - ETA: 2:52 - loss: 0.1381 - sparse_categorical_accuracy: 0.9592\n",
            "145/469 [========>.....................] - ETA: 2:52 - loss: 0.1377 - sparse_categorical_accuracy: 0.9593\n",
            "146/469 [========>.....................] - ETA: 2:51 - loss: 0.1374 - sparse_categorical_accuracy: 0.9594\n",
            "147/469 [========>.....................] - ETA: 2:50 - loss: 0.1372 - sparse_categorical_accuracy: 0.9594\n",
            "148/469 [========>.....................] - ETA: 2:50 - loss: 0.1372 - sparse_categorical_accuracy: 0.9594\n",
            "149/469 [========>.....................] - ETA: 2:49 - loss: 0.1375 - sparse_categorical_accuracy: 0.9593\n",
            "150/469 [========>.....................] - ETA: 2:48 - loss: 0.1370 - sparse_categorical_accuracy: 0.9594\n",
            "151/469 [========>.....................] - ETA: 2:48 - loss: 0.1371 - sparse_categorical_accuracy: 0.9594\n",
            "152/469 [========>.....................] - ETA: 2:47 - loss: 0.1369 - sparse_categorical_accuracy: 0.9595\n",
            "153/469 [========>.....................] - ETA: 2:47 - loss: 0.1366 - sparse_categorical_accuracy: 0.9596\n",
            "154/469 [========>.....................] - ETA: 2:47 - loss: 0.1374 - sparse_categorical_accuracy: 0.9594\n",
            "155/469 [========>.....................] - ETA: 2:47 - loss: 0.1373 - sparse_categorical_accuracy: 0.9593\n",
            "156/469 [========>.....................] - ETA: 2:47 - loss: 0.1376 - sparse_categorical_accuracy: 0.9593\n",
            "157/469 [=========>....................] - ETA: 2:47 - loss: 0.1372 - sparse_categorical_accuracy: 0.9593\n",
            "158/469 [=========>....................] - ETA: 2:46 - loss: 0.1372 - sparse_categorical_accuracy: 0.9594\n",
            "159/469 [=========>....................] - ETA: 2:45 - loss: 0.1367 - sparse_categorical_accuracy: 0.9595\n",
            "160/469 [=========>....................] - ETA: 2:45 - loss: 0.1364 - sparse_categorical_accuracy: 0.9596\n",
            "161/469 [=========>....................] - ETA: 2:44 - loss: 0.1359 - sparse_categorical_accuracy: 0.9598\n",
            "162/469 [=========>....................] - ETA: 2:44 - loss: 0.1359 - sparse_categorical_accuracy: 0.9597\n",
            "163/469 [=========>....................] - ETA: 2:43 - loss: 0.1361 - sparse_categorical_accuracy: 0.9595\n",
            "164/469 [=========>....................] - ETA: 2:42 - loss: 0.1361 - sparse_categorical_accuracy: 0.9595\n",
            "165/469 [=========>....................] - ETA: 2:42 - loss: 0.1359 - sparse_categorical_accuracy: 0.9595\n",
            "166/469 [=========>....................] - ETA: 2:41 - loss: 0.1356 - sparse_categorical_accuracy: 0.9596\n",
            "167/469 [=========>....................] - ETA: 2:40 - loss: 0.1359 - sparse_categorical_accuracy: 0.9596\n",
            "168/469 [=========>....................] - ETA: 2:40 - loss: 0.1355 - sparse_categorical_accuracy: 0.9597\n",
            "169/469 [=========>....................] - ETA: 2:39 - loss: 0.1351 - sparse_categorical_accuracy: 0.9598\n",
            "170/469 [=========>....................] - ETA: 2:39 - loss: 0.1347 - sparse_categorical_accuracy: 0.9599\n",
            "171/469 [=========>....................] - ETA: 2:38 - loss: 0.1346 - sparse_categorical_accuracy: 0.9600\n",
            "172/469 [==========>...................] - ETA: 2:37 - loss: 0.1345 - sparse_categorical_accuracy: 0.9600\n",
            "173/469 [==========>...................] - ETA: 2:37 - loss: 0.1340 - sparse_categorical_accuracy: 0.9602\n",
            "174/469 [==========>...................] - ETA: 2:36 - loss: 0.1337 - sparse_categorical_accuracy: 0.9602\n",
            "175/469 [==========>...................] - ETA: 2:36 - loss: 0.1334 - sparse_categorical_accuracy: 0.9603\n",
            "176/469 [==========>...................] - ETA: 2:35 - loss: 0.1336 - sparse_categorical_accuracy: 0.9603\n",
            "177/469 [==========>...................] - ETA: 2:34 - loss: 0.1332 - sparse_categorical_accuracy: 0.9604\n",
            "178/469 [==========>...................] - ETA: 2:34 - loss: 0.1330 - sparse_categorical_accuracy: 0.9605\n",
            "179/469 [==========>...................] - ETA: 2:34 - loss: 0.1329 - sparse_categorical_accuracy: 0.9605\n",
            "180/469 [==========>...................] - ETA: 2:34 - loss: 0.1327 - sparse_categorical_accuracy: 0.9605\n",
            "181/469 [==========>...................] - ETA: 2:34 - loss: 0.1325 - sparse_categorical_accuracy: 0.9605\n",
            "182/469 [==========>...................] - ETA: 2:33 - loss: 0.1328 - sparse_categorical_accuracy: 0.9605\n",
            "183/469 [==========>...................] - ETA: 2:33 - loss: 0.1331 - sparse_categorical_accuracy: 0.9603\n",
            "184/469 [==========>...................] - ETA: 2:32 - loss: 0.1334 - sparse_categorical_accuracy: 0.9602\n",
            "185/469 [==========>...................] - ETA: 2:31 - loss: 0.1329 - sparse_categorical_accuracy: 0.9603\n",
            "186/469 [==========>...................] - ETA: 2:31 - loss: 0.1328 - sparse_categorical_accuracy: 0.9603\n",
            "187/469 [==========>...................] - ETA: 2:30 - loss: 0.1330 - sparse_categorical_accuracy: 0.9602\n",
            "188/469 [===========>..................] - ETA: 2:30 - loss: 0.1328 - sparse_categorical_accuracy: 0.9603\n",
            "189/469 [===========>..................] - ETA: 2:29 - loss: 0.1326 - sparse_categorical_accuracy: 0.9603\n",
            "190/469 [===========>..................] - ETA: 2:28 - loss: 0.1324 - sparse_categorical_accuracy: 0.9602\n",
            "191/469 [===========>..................] - ETA: 2:28 - loss: 0.1323 - sparse_categorical_accuracy: 0.9604\n",
            "192/469 [===========>..................] - ETA: 2:27 - loss: 0.1326 - sparse_categorical_accuracy: 0.9603\n",
            "193/469 [===========>..................] - ETA: 2:27 - loss: 0.1324 - sparse_categorical_accuracy: 0.9604\n",
            "194/469 [===========>..................] - ETA: 2:26 - loss: 0.1327 - sparse_categorical_accuracy: 0.9604\n",
            "195/469 [===========>..................] - ETA: 2:25 - loss: 0.1326 - sparse_categorical_accuracy: 0.9604\n",
            "196/469 [===========>..................] - ETA: 2:25 - loss: 0.1325 - sparse_categorical_accuracy: 0.9605\n",
            "197/469 [===========>..................] - ETA: 2:24 - loss: 0.1324 - sparse_categorical_accuracy: 0.9605\n",
            "198/469 [===========>..................] - ETA: 2:23 - loss: 0.1327 - sparse_categorical_accuracy: 0.9604\n",
            "199/469 [===========>..................] - ETA: 2:23 - loss: 0.1328 - sparse_categorical_accuracy: 0.9604\n",
            "200/469 [===========>..................] - ETA: 2:22 - loss: 0.1326 - sparse_categorical_accuracy: 0.9605\n",
            "201/469 [===========>..................] - ETA: 2:22 - loss: 0.1325 - sparse_categorical_accuracy: 0.9605\n",
            "202/469 [===========>..................] - ETA: 2:21 - loss: 0.1323 - sparse_categorical_accuracy: 0.9606\n",
            "203/469 [===========>..................] - ETA: 2:21 - loss: 0.1321 - sparse_categorical_accuracy: 0.9606\n",
            "204/469 [============>.................] - ETA: 2:21 - loss: 0.1319 - sparse_categorical_accuracy: 0.9607\n",
            "205/469 [============>.................] - ETA: 2:20 - loss: 0.1318 - sparse_categorical_accuracy: 0.9607\n",
            "206/469 [============>.................] - ETA: 2:20 - loss: 0.1317 - sparse_categorical_accuracy: 0.9608\n",
            "207/469 [============>.................] - ETA: 2:20 - loss: 0.1317 - sparse_categorical_accuracy: 0.9608\n",
            "208/469 [============>.................] - ETA: 2:19 - loss: 0.1318 - sparse_categorical_accuracy: 0.9607\n",
            "209/469 [============>.................] - ETA: 2:19 - loss: 0.1314 - sparse_categorical_accuracy: 0.9608\n",
            "210/469 [============>.................] - ETA: 2:18 - loss: 0.1312 - sparse_categorical_accuracy: 0.9608\n",
            "211/469 [============>.................] - ETA: 2:17 - loss: 0.1313 - sparse_categorical_accuracy: 0.9608\n",
            "212/469 [============>.................] - ETA: 2:17 - loss: 0.1309 - sparse_categorical_accuracy: 0.9609\n",
            "213/469 [============>.................] - ETA: 2:16 - loss: 0.1308 - sparse_categorical_accuracy: 0.9610\n",
            "214/469 [============>.................] - ETA: 2:16 - loss: 0.1308 - sparse_categorical_accuracy: 0.9609\n",
            "215/469 [============>.................] - ETA: 2:15 - loss: 0.1306 - sparse_categorical_accuracy: 0.9609\n",
            "216/469 [============>.................] - ETA: 2:15 - loss: 0.1306 - sparse_categorical_accuracy: 0.9608\n",
            "217/469 [============>.................] - ETA: 2:14 - loss: 0.1305 - sparse_categorical_accuracy: 0.9609\n",
            "218/469 [============>.................] - ETA: 2:13 - loss: 0.1306 - sparse_categorical_accuracy: 0.9609\n",
            "219/469 [=============>................] - ETA: 2:13 - loss: 0.1305 - sparse_categorical_accuracy: 0.9609\n",
            "220/469 [=============>................] - ETA: 2:12 - loss: 0.1304 - sparse_categorical_accuracy: 0.9610\n",
            "221/469 [=============>................] - ETA: 2:12 - loss: 0.1308 - sparse_categorical_accuracy: 0.9608\n",
            "222/469 [=============>................] - ETA: 2:11 - loss: 0.1305 - sparse_categorical_accuracy: 0.9609\n",
            "223/469 [=============>................] - ETA: 2:10 - loss: 0.1303 - sparse_categorical_accuracy: 0.9610\n",
            "224/469 [=============>................] - ETA: 2:10 - loss: 0.1303 - sparse_categorical_accuracy: 0.9610\n",
            "225/469 [=============>................] - ETA: 2:09 - loss: 0.1303 - sparse_categorical_accuracy: 0.9610\n",
            "226/469 [=============>................] - ETA: 2:09 - loss: 0.1304 - sparse_categorical_accuracy: 0.9610\n",
            "227/469 [=============>................] - ETA: 2:08 - loss: 0.1303 - sparse_categorical_accuracy: 0.9611\n",
            "228/469 [=============>................] - ETA: 2:08 - loss: 0.1300 - sparse_categorical_accuracy: 0.9612\n",
            "229/469 [=============>................] - ETA: 2:07 - loss: 0.1299 - sparse_categorical_accuracy: 0.9613\n",
            "230/469 [=============>................] - ETA: 2:07 - loss: 0.1300 - sparse_categorical_accuracy: 0.9613\n",
            "231/469 [=============>................] - ETA: 2:07 - loss: 0.1301 - sparse_categorical_accuracy: 0.9612\n",
            "232/469 [=============>................] - ETA: 2:06 - loss: 0.1300 - sparse_categorical_accuracy: 0.9613\n",
            "233/469 [=============>................] - ETA: 2:06 - loss: 0.1299 - sparse_categorical_accuracy: 0.9613\n",
            "234/469 [=============>................] - ETA: 2:05 - loss: 0.1298 - sparse_categorical_accuracy: 0.9613\n",
            "235/469 [==============>...............] - ETA: 2:05 - loss: 0.1297 - sparse_categorical_accuracy: 0.9614\n",
            "236/469 [==============>...............] - ETA: 2:04 - loss: 0.1294 - sparse_categorical_accuracy: 0.9615\n",
            "237/469 [==============>...............] - ETA: 2:04 - loss: 0.1298 - sparse_categorical_accuracy: 0.9614\n",
            "238/469 [==============>...............] - ETA: 2:03 - loss: 0.1298 - sparse_categorical_accuracy: 0.9614\n",
            "239/469 [==============>...............] - ETA: 2:02 - loss: 0.1301 - sparse_categorical_accuracy: 0.9613\n",
            "240/469 [==============>...............] - ETA: 2:02 - loss: 0.1299 - sparse_categorical_accuracy: 0.9614\n",
            "241/469 [==============>...............] - ETA: 2:01 - loss: 0.1298 - sparse_categorical_accuracy: 0.9614\n",
            "242/469 [==============>...............] - ETA: 2:01 - loss: 0.1295 - sparse_categorical_accuracy: 0.9614\n",
            "243/469 [==============>...............] - ETA: 2:00 - loss: 0.1294 - sparse_categorical_accuracy: 0.9615\n",
            "244/469 [==============>...............] - ETA: 1:59 - loss: 0.1295 - sparse_categorical_accuracy: 0.9615\n",
            "245/469 [==============>...............] - ETA: 1:59 - loss: 0.1293 - sparse_categorical_accuracy: 0.9615\n",
            "246/469 [==============>...............] - ETA: 1:58 - loss: 0.1293 - sparse_categorical_accuracy: 0.9615\n",
            "247/469 [==============>...............] - ETA: 1:58 - loss: 0.1291 - sparse_categorical_accuracy: 0.9616\n",
            "248/469 [==============>...............] - ETA: 1:57 - loss: 0.1290 - sparse_categorical_accuracy: 0.9616\n",
            "249/469 [==============>...............] - ETA: 1:57 - loss: 0.1288 - sparse_categorical_accuracy: 0.9617\n",
            "250/469 [==============>...............] - ETA: 1:56 - loss: 0.1286 - sparse_categorical_accuracy: 0.9617\n",
            "251/469 [===============>..............] - ETA: 1:55 - loss: 0.1284 - sparse_categorical_accuracy: 0.9618\n",
            "252/469 [===============>..............] - ETA: 1:55 - loss: 0.1281 - sparse_categorical_accuracy: 0.9619\n",
            "253/469 [===============>..............] - ETA: 1:54 - loss: 0.1279 - sparse_categorical_accuracy: 0.9619\n",
            "254/469 [===============>..............] - ETA: 1:54 - loss: 0.1281 - sparse_categorical_accuracy: 0.9619\n",
            "255/469 [===============>..............] - ETA: 1:53 - loss: 0.1280 - sparse_categorical_accuracy: 0.9619\n",
            "256/469 [===============>..............] - ETA: 1:53 - loss: 0.1280 - sparse_categorical_accuracy: 0.9619\n",
            "257/469 [===============>..............] - ETA: 1:53 - loss: 0.1280 - sparse_categorical_accuracy: 0.9620\n",
            "258/469 [===============>..............] - ETA: 1:52 - loss: 0.1280 - sparse_categorical_accuracy: 0.9619\n",
            "259/469 [===============>..............] - ETA: 1:52 - loss: 0.1283 - sparse_categorical_accuracy: 0.9619\n",
            "260/469 [===============>..............] - ETA: 1:51 - loss: 0.1284 - sparse_categorical_accuracy: 0.9618\n",
            "261/469 [===============>..............] - ETA: 1:51 - loss: 0.1284 - sparse_categorical_accuracy: 0.9618\n",
            "262/469 [===============>..............] - ETA: 1:50 - loss: 0.1282 - sparse_categorical_accuracy: 0.9619\n",
            "263/469 [===============>..............] - ETA: 1:50 - loss: 0.1279 - sparse_categorical_accuracy: 0.9619\n",
            "264/469 [===============>..............] - ETA: 1:49 - loss: 0.1280 - sparse_categorical_accuracy: 0.9619\n",
            "265/469 [===============>..............] - ETA: 1:48 - loss: 0.1279 - sparse_categorical_accuracy: 0.9619\n",
            "266/469 [================>.............] - ETA: 1:48 - loss: 0.1278 - sparse_categorical_accuracy: 0.9619\n",
            "267/469 [================>.............] - ETA: 1:47 - loss: 0.1278 - sparse_categorical_accuracy: 0.9619\n",
            "268/469 [================>.............] - ETA: 1:47 - loss: 0.1280 - sparse_categorical_accuracy: 0.9619\n",
            "269/469 [================>.............] - ETA: 1:46 - loss: 0.1277 - sparse_categorical_accuracy: 0.9619\n",
            "270/469 [================>.............] - ETA: 1:45 - loss: 0.1277 - sparse_categorical_accuracy: 0.9619\n",
            "271/469 [================>.............] - ETA: 1:45 - loss: 0.1274 - sparse_categorical_accuracy: 0.9620\n",
            "272/469 [================>.............] - ETA: 1:44 - loss: 0.1273 - sparse_categorical_accuracy: 0.9620\n",
            "273/469 [================>.............] - ETA: 1:44 - loss: 0.1271 - sparse_categorical_accuracy: 0.9620\n",
            "274/469 [================>.............] - ETA: 1:43 - loss: 0.1272 - sparse_categorical_accuracy: 0.9620\n",
            "275/469 [================>.............] - ETA: 1:43 - loss: 0.1272 - sparse_categorical_accuracy: 0.9620\n",
            "276/469 [================>.............] - ETA: 1:42 - loss: 0.1272 - sparse_categorical_accuracy: 0.9620\n",
            "277/469 [================>.............] - ETA: 1:41 - loss: 0.1269 - sparse_categorical_accuracy: 0.9622\n",
            "278/469 [================>.............] - ETA: 1:41 - loss: 0.1266 - sparse_categorical_accuracy: 0.9622\n",
            "279/469 [================>.............] - ETA: 1:40 - loss: 0.1264 - sparse_categorical_accuracy: 0.9623\n",
            "280/469 [================>.............] - ETA: 1:40 - loss: 0.1263 - sparse_categorical_accuracy: 0.9623\n",
            "281/469 [================>.............] - ETA: 1:39 - loss: 0.1261 - sparse_categorical_accuracy: 0.9623\n",
            "282/469 [=================>............] - ETA: 1:39 - loss: 0.1259 - sparse_categorical_accuracy: 0.9624\n",
            "283/469 [=================>............] - ETA: 1:39 - loss: 0.1257 - sparse_categorical_accuracy: 0.9624\n",
            "284/469 [=================>............] - ETA: 1:38 - loss: 0.1259 - sparse_categorical_accuracy: 0.9624\n",
            "285/469 [=================>............] - ETA: 1:38 - loss: 0.1258 - sparse_categorical_accuracy: 0.9624\n",
            "286/469 [=================>............] - ETA: 1:37 - loss: 0.1258 - sparse_categorical_accuracy: 0.9624\n",
            "287/469 [=================>............] - ETA: 1:37 - loss: 0.1258 - sparse_categorical_accuracy: 0.9623\n",
            "288/469 [=================>............] - ETA: 1:36 - loss: 0.1257 - sparse_categorical_accuracy: 0.9623\n",
            "289/469 [=================>............] - ETA: 1:35 - loss: 0.1256 - sparse_categorical_accuracy: 0.9623\n",
            "290/469 [=================>............] - ETA: 1:35 - loss: 0.1255 - sparse_categorical_accuracy: 0.9624\n",
            "291/469 [=================>............] - ETA: 1:34 - loss: 0.1255 - sparse_categorical_accuracy: 0.9624\n",
            "292/469 [=================>............] - ETA: 1:34 - loss: 0.1252 - sparse_categorical_accuracy: 0.9625\n",
            "293/469 [=================>............] - ETA: 1:33 - loss: 0.1253 - sparse_categorical_accuracy: 0.9624\n",
            "294/469 [=================>............] - ETA: 1:33 - loss: 0.1253 - sparse_categorical_accuracy: 0.9625\n",
            "295/469 [=================>............] - ETA: 1:32 - loss: 0.1251 - sparse_categorical_accuracy: 0.9625\n",
            "296/469 [=================>............] - ETA: 1:32 - loss: 0.1251 - sparse_categorical_accuracy: 0.9625\n",
            "297/469 [=================>............] - ETA: 1:31 - loss: 0.1250 - sparse_categorical_accuracy: 0.9625\n",
            "298/469 [==================>...........] - ETA: 1:30 - loss: 0.1250 - sparse_categorical_accuracy: 0.9625\n",
            "299/469 [==================>...........] - ETA: 1:30 - loss: 0.1248 - sparse_categorical_accuracy: 0.9626\n",
            "300/469 [==================>...........] - ETA: 1:29 - loss: 0.1245 - sparse_categorical_accuracy: 0.9627\n",
            "301/469 [==================>...........] - ETA: 1:29 - loss: 0.1244 - sparse_categorical_accuracy: 0.9627\n",
            "302/469 [==================>...........] - ETA: 1:28 - loss: 0.1243 - sparse_categorical_accuracy: 0.9627\n",
            "303/469 [==================>...........] - ETA: 1:28 - loss: 0.1240 - sparse_categorical_accuracy: 0.9628\n",
            "304/469 [==================>...........] - ETA: 1:27 - loss: 0.1244 - sparse_categorical_accuracy: 0.9628\n",
            "305/469 [==================>...........] - ETA: 1:27 - loss: 0.1247 - sparse_categorical_accuracy: 0.9628\n",
            "306/469 [==================>...........] - ETA: 1:26 - loss: 0.1247 - sparse_categorical_accuracy: 0.9628\n",
            "307/469 [==================>...........] - ETA: 1:26 - loss: 0.1247 - sparse_categorical_accuracy: 0.9628\n",
            "308/469 [==================>...........] - ETA: 1:25 - loss: 0.1245 - sparse_categorical_accuracy: 0.9628\n",
            "309/469 [==================>...........] - ETA: 1:25 - loss: 0.1246 - sparse_categorical_accuracy: 0.9627\n",
            "310/469 [==================>...........] - ETA: 1:24 - loss: 0.1245 - sparse_categorical_accuracy: 0.9628\n",
            "311/469 [==================>...........] - ETA: 1:24 - loss: 0.1244 - sparse_categorical_accuracy: 0.9627\n",
            "312/469 [==================>...........] - ETA: 1:23 - loss: 0.1242 - sparse_categorical_accuracy: 0.9628\n",
            "313/469 [===================>..........] - ETA: 1:23 - loss: 0.1244 - sparse_categorical_accuracy: 0.9629\n",
            "314/469 [===================>..........] - ETA: 1:22 - loss: 0.1243 - sparse_categorical_accuracy: 0.9629\n",
            "315/469 [===================>..........] - ETA: 1:22 - loss: 0.1243 - sparse_categorical_accuracy: 0.9630\n",
            "316/469 [===================>..........] - ETA: 1:21 - loss: 0.1245 - sparse_categorical_accuracy: 0.9629\n",
            "317/469 [===================>..........] - ETA: 1:21 - loss: 0.1243 - sparse_categorical_accuracy: 0.9630\n",
            "318/469 [===================>..........] - ETA: 1:20 - loss: 0.1241 - sparse_categorical_accuracy: 0.9631\n",
            "319/469 [===================>..........] - ETA: 1:19 - loss: 0.1242 - sparse_categorical_accuracy: 0.9630\n",
            "320/469 [===================>..........] - ETA: 1:19 - loss: 0.1241 - sparse_categorical_accuracy: 0.9630\n",
            "321/469 [===================>..........] - ETA: 1:18 - loss: 0.1240 - sparse_categorical_accuracy: 0.9630\n",
            "322/469 [===================>..........] - ETA: 1:18 - loss: 0.1240 - sparse_categorical_accuracy: 0.9630\n",
            "323/469 [===================>..........] - ETA: 1:17 - loss: 0.1240 - sparse_categorical_accuracy: 0.9629\n",
            "324/469 [===================>..........] - ETA: 1:17 - loss: 0.1243 - sparse_categorical_accuracy: 0.9629\n",
            "325/469 [===================>..........] - ETA: 1:16 - loss: 0.1242 - sparse_categorical_accuracy: 0.9629\n",
            "326/469 [===================>..........] - ETA: 1:16 - loss: 0.1242 - sparse_categorical_accuracy: 0.9629\n",
            "327/469 [===================>..........] - ETA: 1:15 - loss: 0.1244 - sparse_categorical_accuracy: 0.9629\n",
            "328/469 [===================>..........] - ETA: 1:14 - loss: 0.1244 - sparse_categorical_accuracy: 0.9628\n",
            "329/469 [====================>.........] - ETA: 1:14 - loss: 0.1244 - sparse_categorical_accuracy: 0.9628\n",
            "330/469 [====================>.........] - ETA: 1:14 - loss: 0.1245 - sparse_categorical_accuracy: 0.9628\n",
            "331/469 [====================>.........] - ETA: 1:13 - loss: 0.1247 - sparse_categorical_accuracy: 0.9628\n",
            "332/469 [====================>.........] - ETA: 1:13 - loss: 0.1248 - sparse_categorical_accuracy: 0.9627\n",
            "333/469 [====================>.........] - ETA: 1:12 - loss: 0.1248 - sparse_categorical_accuracy: 0.9627\n",
            "334/469 [====================>.........] - ETA: 1:12 - loss: 0.1247 - sparse_categorical_accuracy: 0.9627\n",
            "335/469 [====================>.........] - ETA: 1:11 - loss: 0.1246 - sparse_categorical_accuracy: 0.9628\n",
            "336/469 [====================>.........] - ETA: 1:11 - loss: 0.1245 - sparse_categorical_accuracy: 0.9628\n",
            "337/469 [====================>.........] - ETA: 1:10 - loss: 0.1244 - sparse_categorical_accuracy: 0.9629\n",
            "338/469 [====================>.........] - ETA: 1:10 - loss: 0.1243 - sparse_categorical_accuracy: 0.9629\n",
            "339/469 [====================>.........] - ETA: 1:09 - loss: 0.1243 - sparse_categorical_accuracy: 0.9629\n",
            "340/469 [====================>.........] - ETA: 1:08 - loss: 0.1242 - sparse_categorical_accuracy: 0.9629\n",
            "341/469 [====================>.........] - ETA: 1:08 - loss: 0.1241 - sparse_categorical_accuracy: 0.9629\n",
            "342/469 [====================>.........] - ETA: 1:07 - loss: 0.1241 - sparse_categorical_accuracy: 0.9629\n",
            "343/469 [====================>.........] - ETA: 1:07 - loss: 0.1241 - sparse_categorical_accuracy: 0.9629\n",
            "344/469 [=====================>........] - ETA: 1:06 - loss: 0.1243 - sparse_categorical_accuracy: 0.9628\n",
            "345/469 [=====================>........] - ETA: 1:06 - loss: 0.1241 - sparse_categorical_accuracy: 0.9628\n",
            "346/469 [=====================>........] - ETA: 1:05 - loss: 0.1240 - sparse_categorical_accuracy: 0.9629\n",
            "347/469 [=====================>........] - ETA: 1:05 - loss: 0.1242 - sparse_categorical_accuracy: 0.9629\n",
            "348/469 [=====================>........] - ETA: 1:04 - loss: 0.1244 - sparse_categorical_accuracy: 0.9628\n",
            "349/469 [=====================>........] - ETA: 1:03 - loss: 0.1244 - sparse_categorical_accuracy: 0.9628\n",
            "350/469 [=====================>........] - ETA: 1:03 - loss: 0.1244 - sparse_categorical_accuracy: 0.9628\n",
            "351/469 [=====================>........] - ETA: 1:02 - loss: 0.1242 - sparse_categorical_accuracy: 0.9629\n",
            "352/469 [=====================>........] - ETA: 1:02 - loss: 0.1244 - sparse_categorical_accuracy: 0.9628\n",
            "353/469 [=====================>........] - ETA: 1:01 - loss: 0.1244 - sparse_categorical_accuracy: 0.9629\n",
            "354/469 [=====================>........] - ETA: 1:01 - loss: 0.1243 - sparse_categorical_accuracy: 0.9630\n",
            "355/469 [=====================>........] - ETA: 1:00 - loss: 0.1246 - sparse_categorical_accuracy: 0.9629\n",
            "356/469 [=====================>........] - ETA: 1:00 - loss: 0.1243 - sparse_categorical_accuracy: 0.9630\n",
            "357/469 [=====================>........] - ETA: 59s - loss: 0.1244 - sparse_categorical_accuracy: 0.9630 \n",
            "358/469 [=====================>........] - ETA: 59s - loss: 0.1244 - sparse_categorical_accuracy: 0.9629\n",
            "359/469 [=====================>........] - ETA: 58s - loss: 0.1246 - sparse_categorical_accuracy: 0.9629\n",
            "360/469 [======================>.......] - ETA: 58s - loss: 0.1244 - sparse_categorical_accuracy: 0.9629\n",
            "361/469 [======================>.......] - ETA: 57s - loss: 0.1243 - sparse_categorical_accuracy: 0.9629\n",
            "362/469 [======================>.......] - ETA: 57s - loss: 0.1244 - sparse_categorical_accuracy: 0.9629\n",
            "363/469 [======================>.......] - ETA: 56s - loss: 0.1244 - sparse_categorical_accuracy: 0.9629\n",
            "364/469 [======================>.......] - ETA: 56s - loss: 0.1245 - sparse_categorical_accuracy: 0.9629\n",
            "365/469 [======================>.......] - ETA: 55s - loss: 0.1245 - sparse_categorical_accuracy: 0.9628\n",
            "366/469 [======================>.......] - ETA: 54s - loss: 0.1245 - sparse_categorical_accuracy: 0.9628\n",
            "367/469 [======================>.......] - ETA: 54s - loss: 0.1244 - sparse_categorical_accuracy: 0.9629\n",
            "368/469 [======================>.......] - ETA: 53s - loss: 0.1243 - sparse_categorical_accuracy: 0.9629\n",
            "369/469 [======================>.......] - ETA: 53s - loss: 0.1242 - sparse_categorical_accuracy: 0.9629\n",
            "370/469 [======================>.......] - ETA: 52s - loss: 0.1241 - sparse_categorical_accuracy: 0.9629\n",
            "371/469 [======================>.......] - ETA: 52s - loss: 0.1240 - sparse_categorical_accuracy: 0.9629\n",
            "372/469 [======================>.......] - ETA: 51s - loss: 0.1239 - sparse_categorical_accuracy: 0.9629\n",
            "373/469 [======================>.......] - ETA: 51s - loss: 0.1240 - sparse_categorical_accuracy: 0.9629\n",
            "374/469 [======================>.......] - ETA: 50s - loss: 0.1240 - sparse_categorical_accuracy: 0.9629\n",
            "375/469 [======================>.......] - ETA: 50s - loss: 0.1239 - sparse_categorical_accuracy: 0.9629\n",
            "376/469 [=======================>......] - ETA: 49s - loss: 0.1237 - sparse_categorical_accuracy: 0.9629\n",
            "377/469 [=======================>......] - ETA: 48s - loss: 0.1240 - sparse_categorical_accuracy: 0.9629\n",
            "378/469 [=======================>......] - ETA: 48s - loss: 0.1241 - sparse_categorical_accuracy: 0.9628\n",
            "379/469 [=======================>......] - ETA: 47s - loss: 0.1241 - sparse_categorical_accuracy: 0.9628\n",
            "380/469 [=======================>......] - ETA: 47s - loss: 0.1241 - sparse_categorical_accuracy: 0.9628\n",
            "381/469 [=======================>......] - ETA: 46s - loss: 0.1239 - sparse_categorical_accuracy: 0.9629\n",
            "382/469 [=======================>......] - ETA: 46s - loss: 0.1238 - sparse_categorical_accuracy: 0.9629\n",
            "383/469 [=======================>......] - ETA: 45s - loss: 0.1239 - sparse_categorical_accuracy: 0.9628\n",
            "384/469 [=======================>......] - ETA: 45s - loss: 0.1239 - sparse_categorical_accuracy: 0.9628\n",
            "385/469 [=======================>......] - ETA: 44s - loss: 0.1237 - sparse_categorical_accuracy: 0.9628\n",
            "386/469 [=======================>......] - ETA: 44s - loss: 0.1236 - sparse_categorical_accuracy: 0.9629\n",
            "387/469 [=======================>......] - ETA: 43s - loss: 0.1235 - sparse_categorical_accuracy: 0.9629\n",
            "388/469 [=======================>......] - ETA: 43s - loss: 0.1234 - sparse_categorical_accuracy: 0.9630\n",
            "389/469 [=======================>......] - ETA: 42s - loss: 0.1235 - sparse_categorical_accuracy: 0.9629\n",
            "390/469 [=======================>......] - ETA: 42s - loss: 0.1234 - sparse_categorical_accuracy: 0.9630\n",
            "391/469 [========================>.....] - ETA: 41s - loss: 0.1233 - sparse_categorical_accuracy: 0.9630\n",
            "392/469 [========================>.....] - ETA: 41s - loss: 0.1231 - sparse_categorical_accuracy: 0.9631\n",
            "393/469 [========================>.....] - ETA: 40s - loss: 0.1231 - sparse_categorical_accuracy: 0.9631\n",
            "394/469 [========================>.....] - ETA: 40s - loss: 0.1230 - sparse_categorical_accuracy: 0.9631\n",
            "395/469 [========================>.....] - ETA: 39s - loss: 0.1228 - sparse_categorical_accuracy: 0.9632\n",
            "396/469 [========================>.....] - ETA: 38s - loss: 0.1227 - sparse_categorical_accuracy: 0.9632\n",
            "397/469 [========================>.....] - ETA: 38s - loss: 0.1227 - sparse_categorical_accuracy: 0.9632\n",
            "398/469 [========================>.....] - ETA: 37s - loss: 0.1226 - sparse_categorical_accuracy: 0.9632\n",
            "399/469 [========================>.....] - ETA: 37s - loss: 0.1225 - sparse_categorical_accuracy: 0.9632\n",
            "400/469 [========================>.....] - ETA: 36s - loss: 0.1224 - sparse_categorical_accuracy: 0.9633\n",
            "401/469 [========================>.....] - ETA: 36s - loss: 0.1222 - sparse_categorical_accuracy: 0.9633\n",
            "402/469 [========================>.....] - ETA: 35s - loss: 0.1222 - sparse_categorical_accuracy: 0.9633\n",
            "403/469 [========================>.....] - ETA: 35s - loss: 0.1221 - sparse_categorical_accuracy: 0.9634\n",
            "404/469 [========================>.....] - ETA: 34s - loss: 0.1221 - sparse_categorical_accuracy: 0.9634\n",
            "405/469 [========================>.....] - ETA: 34s - loss: 0.1221 - sparse_categorical_accuracy: 0.9634\n",
            "406/469 [========================>.....] - ETA: 33s - loss: 0.1221 - sparse_categorical_accuracy: 0.9634\n",
            "407/469 [=========================>....] - ETA: 33s - loss: 0.1222 - sparse_categorical_accuracy: 0.9634\n",
            "408/469 [=========================>....] - ETA: 32s - loss: 0.1221 - sparse_categorical_accuracy: 0.9635\n",
            "409/469 [=========================>....] - ETA: 32s - loss: 0.1219 - sparse_categorical_accuracy: 0.9635\n",
            "410/469 [=========================>....] - ETA: 31s - loss: 0.1218 - sparse_categorical_accuracy: 0.9635\n",
            "411/469 [=========================>....] - ETA: 31s - loss: 0.1217 - sparse_categorical_accuracy: 0.9636\n",
            "412/469 [=========================>....] - ETA: 30s - loss: 0.1216 - sparse_categorical_accuracy: 0.9635\n",
            "413/469 [=========================>....] - ETA: 29s - loss: 0.1215 - sparse_categorical_accuracy: 0.9635\n",
            "414/469 [=========================>....] - ETA: 29s - loss: 0.1214 - sparse_categorical_accuracy: 0.9636\n",
            "415/469 [=========================>....] - ETA: 28s - loss: 0.1219 - sparse_categorical_accuracy: 0.9635\n",
            "416/469 [=========================>....] - ETA: 28s - loss: 0.1218 - sparse_categorical_accuracy: 0.9635\n",
            "417/469 [=========================>....] - ETA: 27s - loss: 0.1217 - sparse_categorical_accuracy: 0.9635\n",
            "418/469 [=========================>....] - ETA: 27s - loss: 0.1217 - sparse_categorical_accuracy: 0.9635\n",
            "419/469 [=========================>....] - ETA: 26s - loss: 0.1216 - sparse_categorical_accuracy: 0.9636\n",
            "420/469 [=========================>....] - ETA: 26s - loss: 0.1215 - sparse_categorical_accuracy: 0.9637\n",
            "421/469 [=========================>....] - ETA: 25s - loss: 0.1216 - sparse_categorical_accuracy: 0.9636\n",
            "422/469 [=========================>....] - ETA: 25s - loss: 0.1215 - sparse_categorical_accuracy: 0.9637\n",
            "423/469 [==========================>...] - ETA: 24s - loss: 0.1213 - sparse_categorical_accuracy: 0.9637\n",
            "424/469 [==========================>...] - ETA: 24s - loss: 0.1212 - sparse_categorical_accuracy: 0.9637\n",
            "425/469 [==========================>...] - ETA: 23s - loss: 0.1211 - sparse_categorical_accuracy: 0.9638\n",
            "426/469 [==========================>...] - ETA: 22s - loss: 0.1213 - sparse_categorical_accuracy: 0.9637\n",
            "427/469 [==========================>...] - ETA: 22s - loss: 0.1211 - sparse_categorical_accuracy: 0.9638\n",
            "428/469 [==========================>...] - ETA: 21s - loss: 0.1210 - sparse_categorical_accuracy: 0.9638\n",
            "429/469 [==========================>...] - ETA: 21s - loss: 0.1213 - sparse_categorical_accuracy: 0.9638\n",
            "430/469 [==========================>...] - ETA: 20s - loss: 0.1211 - sparse_categorical_accuracy: 0.9638\n",
            "431/469 [==========================>...] - ETA: 20s - loss: 0.1211 - sparse_categorical_accuracy: 0.9638\n",
            "432/469 [==========================>...] - ETA: 19s - loss: 0.1212 - sparse_categorical_accuracy: 0.9638\n",
            "433/469 [==========================>...] - ETA: 19s - loss: 0.1211 - sparse_categorical_accuracy: 0.9638\n",
            "434/469 [==========================>...] - ETA: 18s - loss: 0.1210 - sparse_categorical_accuracy: 0.9638\n",
            "435/469 [==========================>...] - ETA: 18s - loss: 0.1208 - sparse_categorical_accuracy: 0.9639\n",
            "436/469 [==========================>...] - ETA: 17s - loss: 0.1207 - sparse_categorical_accuracy: 0.9639\n",
            "437/469 [==========================>...] - ETA: 17s - loss: 0.1207 - sparse_categorical_accuracy: 0.9639\n",
            "438/469 [===========================>..] - ETA: 16s - loss: 0.1208 - sparse_categorical_accuracy: 0.9639\n",
            "439/469 [===========================>..] - ETA: 16s - loss: 0.1208 - sparse_categorical_accuracy: 0.9639\n",
            "440/469 [===========================>..] - ETA: 15s - loss: 0.1207 - sparse_categorical_accuracy: 0.9639\n",
            "441/469 [===========================>..] - ETA: 14s - loss: 0.1206 - sparse_categorical_accuracy: 0.9640\n",
            "442/469 [===========================>..] - ETA: 14s - loss: 0.1208 - sparse_categorical_accuracy: 0.9640\n",
            "443/469 [===========================>..] - ETA: 13s - loss: 0.1207 - sparse_categorical_accuracy: 0.9640\n",
            "444/469 [===========================>..] - ETA: 13s - loss: 0.1206 - sparse_categorical_accuracy: 0.9640\n",
            "445/469 [===========================>..] - ETA: 12s - loss: 0.1204 - sparse_categorical_accuracy: 0.9641\n",
            "446/469 [===========================>..] - ETA: 12s - loss: 0.1204 - sparse_categorical_accuracy: 0.9641\n",
            "447/469 [===========================>..] - ETA: 11s - loss: 0.1205 - sparse_categorical_accuracy: 0.9641\n",
            "448/469 [===========================>..] - ETA: 11s - loss: 0.1204 - sparse_categorical_accuracy: 0.9641\n",
            "449/469 [===========================>..] - ETA: 10s - loss: 0.1204 - sparse_categorical_accuracy: 0.9641\n",
            "450/469 [===========================>..] - ETA: 10s - loss: 0.1204 - sparse_categorical_accuracy: 0.9641\n",
            "451/469 [===========================>..] - ETA: 9s - loss: 0.1203 - sparse_categorical_accuracy: 0.9642 \n",
            "452/469 [===========================>..] - ETA: 9s - loss: 0.1202 - sparse_categorical_accuracy: 0.9642\n",
            "453/469 [===========================>..] - ETA: 8s - loss: 0.1202 - sparse_categorical_accuracy: 0.9642\n",
            "454/469 [============================>.] - ETA: 7s - loss: 0.1200 - sparse_categorical_accuracy: 0.9642\n",
            "455/469 [============================>.] - ETA: 7s - loss: 0.1200 - sparse_categorical_accuracy: 0.9642\n",
            "456/469 [============================>.] - ETA: 6s - loss: 0.1199 - sparse_categorical_accuracy: 0.9643\n",
            "457/469 [============================>.] - ETA: 6s - loss: 0.1199 - sparse_categorical_accuracy: 0.9643\n",
            "458/469 [============================>.] - ETA: 5s - loss: 0.1198 - sparse_categorical_accuracy: 0.9643\n",
            "459/469 [============================>.] - ETA: 5s - loss: 0.1197 - sparse_categorical_accuracy: 0.9642\n",
            "460/469 [============================>.] - ETA: 4s - loss: 0.1198 - sparse_categorical_accuracy: 0.9643\n",
            "461/469 [============================>.] - ETA: 4s - loss: 0.1197 - sparse_categorical_accuracy: 0.9643\n",
            "462/469 [============================>.] - ETA: 3s - loss: 0.1197 - sparse_categorical_accuracy: 0.9643\n",
            "463/469 [============================>.] - ETA: 3s - loss: 0.1197 - sparse_categorical_accuracy: 0.9642\n",
            "464/469 [============================>.] - ETA: 2s - loss: 0.1197 - sparse_categorical_accuracy: 0.9642\n",
            "465/469 [============================>.] - ETA: 2s - loss: 0.1195 - sparse_categorical_accuracy: 0.9643\n",
            "466/469 [============================>.] - ETA: 1s - loss: 0.1195 - sparse_categorical_accuracy: 0.9643\n",
            "467/469 [============================>.] - ETA: 1s - loss: 0.1195 - sparse_categorical_accuracy: 0.9643\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.1196 - sparse_categorical_accuracy: 0.9643\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.1196 - sparse_categorical_accuracy: 0.9643\n",
            " 80%|████████  | 4/5 [1:22:57<17:32, 1052.88s/trial, best loss: -0.9850000143051147]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/04/16 01:54:58 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "469/469 [==============================] - 251s 534ms/step - loss: 0.1196 - sparse_categorical_accuracy: 0.9643\n",
            "\n",
            "Epoch 3/5\n",
            "\n",
            "  1/469 [..............................] - ETA: 4:30 - loss: 0.0694 - sparse_categorical_accuracy: 0.9844\n",
            "  2/469 [..............................] - ETA: 3:45 - loss: 0.1428 - sparse_categorical_accuracy: 0.9531\n",
            "  3/469 [..............................] - ETA: 3:52 - loss: 0.1408 - sparse_categorical_accuracy: 0.9557\n",
            "  4/469 [..............................] - ETA: 3:50 - loss: 0.1362 - sparse_categorical_accuracy: 0.9590\n",
            "  5/469 [..............................] - ETA: 3:49 - loss: 0.1289 - sparse_categorical_accuracy: 0.9625\n",
            "  6/469 [..............................] - ETA: 3:48 - loss: 0.1238 - sparse_categorical_accuracy: 0.9609\n",
            "  7/469 [..............................] - ETA: 3:47 - loss: 0.1200 - sparse_categorical_accuracy: 0.9621\n",
            "  8/469 [..............................] - ETA: 3:45 - loss: 0.1163 - sparse_categorical_accuracy: 0.9648\n",
            "  9/469 [..............................] - ETA: 3:46 - loss: 0.1131 - sparse_categorical_accuracy: 0.9653\n",
            " 10/469 [..............................] - ETA: 3:45 - loss: 0.1078 - sparse_categorical_accuracy: 0.9672\n",
            " 11/469 [..............................] - ETA: 3:45 - loss: 0.1108 - sparse_categorical_accuracy: 0.9673\n",
            " 12/469 [..............................] - ETA: 3:50 - loss: 0.1066 - sparse_categorical_accuracy: 0.9674\n",
            " 13/469 [..............................] - ETA: 4:00 - loss: 0.1052 - sparse_categorical_accuracy: 0.9681\n",
            " 14/469 [..............................] - ETA: 4:09 - loss: 0.1077 - sparse_categorical_accuracy: 0.9671\n",
            " 15/469 [..............................] - ETA: 4:14 - loss: 0.1030 - sparse_categorical_accuracy: 0.9693\n",
            " 16/469 [>.............................] - ETA: 4:19 - loss: 0.1004 - sparse_categorical_accuracy: 0.9707\n",
            " 17/469 [>.............................] - ETA: 4:18 - loss: 0.0980 - sparse_categorical_accuracy: 0.9706\n",
            " 18/469 [>.............................] - ETA: 4:14 - loss: 0.0989 - sparse_categorical_accuracy: 0.9705\n",
            " 19/469 [>.............................] - ETA: 4:11 - loss: 0.0968 - sparse_categorical_accuracy: 0.9712\n",
            " 20/469 [>.............................] - ETA: 4:09 - loss: 0.0969 - sparse_categorical_accuracy: 0.9711\n",
            " 21/469 [>.............................] - ETA: 4:06 - loss: 0.0949 - sparse_categorical_accuracy: 0.9717\n",
            " 22/469 [>.............................] - ETA: 4:04 - loss: 0.0937 - sparse_categorical_accuracy: 0.9727\n",
            " 23/469 [>.............................] - ETA: 4:03 - loss: 0.0925 - sparse_categorical_accuracy: 0.9725\n",
            " 24/469 [>.............................] - ETA: 4:01 - loss: 0.0908 - sparse_categorical_accuracy: 0.9733\n",
            " 25/469 [>.............................] - ETA: 3:59 - loss: 0.0900 - sparse_categorical_accuracy: 0.9737\n",
            " 26/469 [>.............................] - ETA: 3:58 - loss: 0.0909 - sparse_categorical_accuracy: 0.9733\n",
            " 27/469 [>.............................] - ETA: 3:56 - loss: 0.0919 - sparse_categorical_accuracy: 0.9722\n",
            " 28/469 [>.............................] - ETA: 3:55 - loss: 0.0899 - sparse_categorical_accuracy: 0.9727\n",
            " 29/469 [>.............................] - ETA: 3:53 - loss: 0.0926 - sparse_categorical_accuracy: 0.9717\n",
            " 30/469 [>.............................] - ETA: 3:52 - loss: 0.0953 - sparse_categorical_accuracy: 0.9714\n",
            " 31/469 [>.............................] - ETA: 3:50 - loss: 0.0956 - sparse_categorical_accuracy: 0.9710\n",
            " 32/469 [=>............................] - ETA: 3:49 - loss: 0.0949 - sparse_categorical_accuracy: 0.9712\n",
            " 33/469 [=>............................] - ETA: 3:48 - loss: 0.0955 - sparse_categorical_accuracy: 0.9709\n",
            " 34/469 [=>............................] - ETA: 3:47 - loss: 0.0961 - sparse_categorical_accuracy: 0.9701\n",
            " 35/469 [=>............................] - ETA: 3:46 - loss: 0.0951 - sparse_categorical_accuracy: 0.9705\n",
            " 36/469 [=>............................] - ETA: 3:44 - loss: 0.0958 - sparse_categorical_accuracy: 0.9703\n",
            " 37/469 [=>............................] - ETA: 3:44 - loss: 0.0964 - sparse_categorical_accuracy: 0.9694\n",
            " 38/469 [=>............................] - ETA: 3:46 - loss: 0.0960 - sparse_categorical_accuracy: 0.9698\n",
            " 39/469 [=>............................] - ETA: 3:49 - loss: 0.0962 - sparse_categorical_accuracy: 0.9696\n",
            " 40/469 [=>............................] - ETA: 3:51 - loss: 0.0953 - sparse_categorical_accuracy: 0.9697\n",
            " 41/469 [=>............................] - ETA: 3:53 - loss: 0.0941 - sparse_categorical_accuracy: 0.9703\n",
            " 42/469 [=>............................] - ETA: 3:53 - loss: 0.0939 - sparse_categorical_accuracy: 0.9706\n",
            " 43/469 [=>............................] - ETA: 3:52 - loss: 0.0939 - sparse_categorical_accuracy: 0.9707\n",
            " 44/469 [=>............................] - ETA: 3:51 - loss: 0.0948 - sparse_categorical_accuracy: 0.9705\n",
            " 45/469 [=>............................] - ETA: 3:50 - loss: 0.0940 - sparse_categorical_accuracy: 0.9708\n",
            " 46/469 [=>............................] - ETA: 3:48 - loss: 0.0929 - sparse_categorical_accuracy: 0.9713\n",
            " 47/469 [==>...........................] - ETA: 3:47 - loss: 0.0929 - sparse_categorical_accuracy: 0.9711\n",
            " 48/469 [==>...........................] - ETA: 3:46 - loss: 0.0943 - sparse_categorical_accuracy: 0.9710\n",
            " 49/469 [==>...........................] - ETA: 3:45 - loss: 0.0944 - sparse_categorical_accuracy: 0.9711\n",
            " 50/469 [==>...........................] - ETA: 3:44 - loss: 0.0946 - sparse_categorical_accuracy: 0.9711\n",
            " 51/469 [==>...........................] - ETA: 3:43 - loss: 0.0957 - sparse_categorical_accuracy: 0.9710\n",
            " 52/469 [==>...........................] - ETA: 3:42 - loss: 0.0947 - sparse_categorical_accuracy: 0.9715\n",
            " 53/469 [==>...........................] - ETA: 3:41 - loss: 0.0948 - sparse_categorical_accuracy: 0.9714\n",
            " 54/469 [==>...........................] - ETA: 3:40 - loss: 0.0946 - sparse_categorical_accuracy: 0.9715\n",
            " 55/469 [==>...........................] - ETA: 3:39 - loss: 0.0941 - sparse_categorical_accuracy: 0.9717\n",
            " 56/469 [==>...........................] - ETA: 3:38 - loss: 0.0944 - sparse_categorical_accuracy: 0.9718\n",
            " 57/469 [==>...........................] - ETA: 3:37 - loss: 0.0949 - sparse_categorical_accuracy: 0.9716\n",
            " 58/469 [==>...........................] - ETA: 3:36 - loss: 0.0941 - sparse_categorical_accuracy: 0.9720\n",
            " 59/469 [==>...........................] - ETA: 3:36 - loss: 0.0929 - sparse_categorical_accuracy: 0.9723\n",
            " 60/469 [==>...........................] - ETA: 3:35 - loss: 0.0930 - sparse_categorical_accuracy: 0.9724\n",
            " 61/469 [==>...........................] - ETA: 3:34 - loss: 0.0921 - sparse_categorical_accuracy: 0.9728\n",
            " 62/469 [==>...........................] - ETA: 3:33 - loss: 0.0915 - sparse_categorical_accuracy: 0.9729\n",
            " 63/469 [===>..........................] - ETA: 3:33 - loss: 0.0915 - sparse_categorical_accuracy: 0.9728\n",
            " 64/469 [===>..........................] - ETA: 3:35 - loss: 0.0918 - sparse_categorical_accuracy: 0.9727\n",
            " 65/469 [===>..........................] - ETA: 3:36 - loss: 0.0916 - sparse_categorical_accuracy: 0.9727\n",
            " 66/469 [===>..........................] - ETA: 3:37 - loss: 0.0916 - sparse_categorical_accuracy: 0.9724\n",
            " 67/469 [===>..........................] - ETA: 3:37 - loss: 0.0909 - sparse_categorical_accuracy: 0.9727\n",
            " 68/469 [===>..........................] - ETA: 3:36 - loss: 0.0908 - sparse_categorical_accuracy: 0.9728\n",
            " 69/469 [===>..........................] - ETA: 3:35 - loss: 0.0909 - sparse_categorical_accuracy: 0.9728\n",
            " 70/469 [===>..........................] - ETA: 3:34 - loss: 0.0918 - sparse_categorical_accuracy: 0.9728\n",
            " 71/469 [===>..........................] - ETA: 3:33 - loss: 0.0918 - sparse_categorical_accuracy: 0.9727\n",
            " 72/469 [===>..........................] - ETA: 3:33 - loss: 0.0912 - sparse_categorical_accuracy: 0.9729\n",
            " 73/469 [===>..........................] - ETA: 3:32 - loss: 0.0911 - sparse_categorical_accuracy: 0.9726\n",
            " 74/469 [===>..........................] - ETA: 3:31 - loss: 0.0915 - sparse_categorical_accuracy: 0.9724\n",
            " 75/469 [===>..........................] - ETA: 3:30 - loss: 0.0928 - sparse_categorical_accuracy: 0.9720\n",
            " 76/469 [===>..........................] - ETA: 3:29 - loss: 0.0929 - sparse_categorical_accuracy: 0.9717\n",
            " 77/469 [===>..........................] - ETA: 3:28 - loss: 0.0937 - sparse_categorical_accuracy: 0.9715\n",
            " 78/469 [===>..........................] - ETA: 3:27 - loss: 0.0949 - sparse_categorical_accuracy: 0.9713\n",
            " 79/469 [====>.........................] - ETA: 3:26 - loss: 0.0944 - sparse_categorical_accuracy: 0.9714\n",
            " 80/469 [====>.........................] - ETA: 3:26 - loss: 0.0948 - sparse_categorical_accuracy: 0.9713\n",
            " 81/469 [====>.........................] - ETA: 3:25 - loss: 0.0947 - sparse_categorical_accuracy: 0.9715\n",
            " 82/469 [====>.........................] - ETA: 3:24 - loss: 0.0942 - sparse_categorical_accuracy: 0.9716\n",
            " 83/469 [====>.........................] - ETA: 3:23 - loss: 0.0940 - sparse_categorical_accuracy: 0.9719\n",
            " 84/469 [====>.........................] - ETA: 3:22 - loss: 0.0951 - sparse_categorical_accuracy: 0.9715\n",
            " 85/469 [====>.........................] - ETA: 3:22 - loss: 0.0952 - sparse_categorical_accuracy: 0.9717\n",
            " 86/469 [====>.........................] - ETA: 3:21 - loss: 0.0948 - sparse_categorical_accuracy: 0.9718\n",
            " 87/469 [====>.........................] - ETA: 3:20 - loss: 0.0946 - sparse_categorical_accuracy: 0.9720\n",
            " 88/469 [====>.........................] - ETA: 3:19 - loss: 0.0942 - sparse_categorical_accuracy: 0.9720\n",
            " 89/469 [====>.........................] - ETA: 3:20 - loss: 0.0940 - sparse_categorical_accuracy: 0.9720\n",
            " 90/469 [====>.........................] - ETA: 3:20 - loss: 0.0938 - sparse_categorical_accuracy: 0.9720\n",
            " 91/469 [====>.........................] - ETA: 3:21 - loss: 0.0932 - sparse_categorical_accuracy: 0.9722\n",
            " 92/469 [====>.........................] - ETA: 3:21 - loss: 0.0932 - sparse_categorical_accuracy: 0.9721\n",
            " 93/469 [====>.........................] - ETA: 3:21 - loss: 0.0933 - sparse_categorical_accuracy: 0.9720\n",
            " 94/469 [=====>........................] - ETA: 3:20 - loss: 0.0931 - sparse_categorical_accuracy: 0.9719\n",
            " 95/469 [=====>........................] - ETA: 3:19 - loss: 0.0924 - sparse_categorical_accuracy: 0.9722\n",
            " 96/469 [=====>........................] - ETA: 3:18 - loss: 0.0922 - sparse_categorical_accuracy: 0.9723\n",
            " 97/469 [=====>........................] - ETA: 3:17 - loss: 0.0923 - sparse_categorical_accuracy: 0.9724\n",
            " 98/469 [=====>........................] - ETA: 3:17 - loss: 0.0924 - sparse_categorical_accuracy: 0.9723\n",
            " 99/469 [=====>........................] - ETA: 3:16 - loss: 0.0924 - sparse_categorical_accuracy: 0.9722\n",
            "100/469 [=====>........................] - ETA: 3:15 - loss: 0.0923 - sparse_categorical_accuracy: 0.9721\n",
            "101/469 [=====>........................] - ETA: 3:14 - loss: 0.0925 - sparse_categorical_accuracy: 0.9721\n",
            "102/469 [=====>........................] - ETA: 3:14 - loss: 0.0921 - sparse_categorical_accuracy: 0.9723\n",
            "103/469 [=====>........................] - ETA: 3:13 - loss: 0.0920 - sparse_categorical_accuracy: 0.9723\n",
            "104/469 [=====>........................] - ETA: 3:12 - loss: 0.0919 - sparse_categorical_accuracy: 0.9723\n",
            "105/469 [=====>........................] - ETA: 3:12 - loss: 0.0921 - sparse_categorical_accuracy: 0.9722\n",
            "106/469 [=====>........................] - ETA: 3:11 - loss: 0.0925 - sparse_categorical_accuracy: 0.9721\n",
            "107/469 [=====>........................] - ETA: 3:10 - loss: 0.0923 - sparse_categorical_accuracy: 0.9721\n",
            "108/469 [=====>........................] - ETA: 3:10 - loss: 0.0919 - sparse_categorical_accuracy: 0.9721\n",
            "109/469 [=====>........................] - ETA: 3:09 - loss: 0.0919 - sparse_categorical_accuracy: 0.9720\n",
            "110/469 [======>.......................] - ETA: 3:08 - loss: 0.0924 - sparse_categorical_accuracy: 0.9719\n",
            "111/469 [======>.......................] - ETA: 3:08 - loss: 0.0922 - sparse_categorical_accuracy: 0.9720\n",
            "112/469 [======>.......................] - ETA: 3:07 - loss: 0.0922 - sparse_categorical_accuracy: 0.9720\n",
            "113/469 [======>.......................] - ETA: 3:06 - loss: 0.0921 - sparse_categorical_accuracy: 0.9720\n",
            "114/469 [======>.......................] - ETA: 3:06 - loss: 0.0922 - sparse_categorical_accuracy: 0.9719\n",
            "115/469 [======>.......................] - ETA: 3:06 - loss: 0.0922 - sparse_categorical_accuracy: 0.9719\n",
            "116/469 [======>.......................] - ETA: 3:06 - loss: 0.0920 - sparse_categorical_accuracy: 0.9719\n",
            "117/469 [======>.......................] - ETA: 3:07 - loss: 0.0925 - sparse_categorical_accuracy: 0.9718\n",
            "118/469 [======>.......................] - ETA: 3:07 - loss: 0.0932 - sparse_categorical_accuracy: 0.9716\n",
            "119/469 [======>.......................] - ETA: 3:06 - loss: 0.0944 - sparse_categorical_accuracy: 0.9714\n",
            "120/469 [======>.......................] - ETA: 3:05 - loss: 0.0940 - sparse_categorical_accuracy: 0.9716\n",
            "121/469 [======>.......................] - ETA: 3:05 - loss: 0.0935 - sparse_categorical_accuracy: 0.9717\n",
            "122/469 [======>.......................] - ETA: 3:04 - loss: 0.0938 - sparse_categorical_accuracy: 0.9715\n",
            "123/469 [======>.......................] - ETA: 3:03 - loss: 0.0936 - sparse_categorical_accuracy: 0.9715\n",
            "124/469 [======>.......................] - ETA: 3:03 - loss: 0.0936 - sparse_categorical_accuracy: 0.9716\n",
            "125/469 [======>.......................] - ETA: 3:02 - loss: 0.0939 - sparse_categorical_accuracy: 0.9714\n",
            "126/469 [=======>......................] - ETA: 3:01 - loss: 0.0943 - sparse_categorical_accuracy: 0.9714\n",
            "127/469 [=======>......................] - ETA: 3:01 - loss: 0.0943 - sparse_categorical_accuracy: 0.9712\n",
            "128/469 [=======>......................] - ETA: 3:00 - loss: 0.0947 - sparse_categorical_accuracy: 0.9711\n",
            "129/469 [=======>......................] - ETA: 2:59 - loss: 0.0948 - sparse_categorical_accuracy: 0.9711\n",
            "130/469 [=======>......................] - ETA: 2:59 - loss: 0.0944 - sparse_categorical_accuracy: 0.9712\n",
            "131/469 [=======>......................] - ETA: 2:58 - loss: 0.0946 - sparse_categorical_accuracy: 0.9711\n",
            "132/469 [=======>......................] - ETA: 2:57 - loss: 0.0944 - sparse_categorical_accuracy: 0.9711\n",
            "133/469 [=======>......................] - ETA: 2:57 - loss: 0.0946 - sparse_categorical_accuracy: 0.9710\n",
            "134/469 [=======>......................] - ETA: 2:56 - loss: 0.0943 - sparse_categorical_accuracy: 0.9711\n",
            "135/469 [=======>......................] - ETA: 2:55 - loss: 0.0941 - sparse_categorical_accuracy: 0.9712\n",
            "136/469 [=======>......................] - ETA: 2:55 - loss: 0.0939 - sparse_categorical_accuracy: 0.9712\n",
            "137/469 [=======>......................] - ETA: 2:54 - loss: 0.0942 - sparse_categorical_accuracy: 0.9711\n",
            "138/469 [=======>......................] - ETA: 2:53 - loss: 0.0945 - sparse_categorical_accuracy: 0.9711\n",
            "139/469 [=======>......................] - ETA: 2:53 - loss: 0.0943 - sparse_categorical_accuracy: 0.9711\n",
            "140/469 [=======>......................] - ETA: 2:52 - loss: 0.0947 - sparse_categorical_accuracy: 0.9709\n",
            "141/469 [========>.....................] - ETA: 2:53 - loss: 0.0951 - sparse_categorical_accuracy: 0.9707\n",
            "142/469 [========>.....................] - ETA: 2:52 - loss: 0.0955 - sparse_categorical_accuracy: 0.9707\n",
            "143/469 [========>.....................] - ETA: 2:52 - loss: 0.0957 - sparse_categorical_accuracy: 0.9707\n",
            "144/469 [========>.....................] - ETA: 2:52 - loss: 0.0957 - sparse_categorical_accuracy: 0.9706\n",
            "145/469 [========>.....................] - ETA: 2:51 - loss: 0.0958 - sparse_categorical_accuracy: 0.9705\n",
            "146/469 [========>.....................] - ETA: 2:51 - loss: 0.0959 - sparse_categorical_accuracy: 0.9704\n",
            "147/469 [========>.....................] - ETA: 2:50 - loss: 0.0960 - sparse_categorical_accuracy: 0.9702\n",
            "148/469 [========>.....................] - ETA: 2:49 - loss: 0.0961 - sparse_categorical_accuracy: 0.9702\n",
            "149/469 [========>.....................] - ETA: 2:49 - loss: 0.0958 - sparse_categorical_accuracy: 0.9703\n",
            "150/469 [========>.....................] - ETA: 2:48 - loss: 0.0955 - sparse_categorical_accuracy: 0.9704\n",
            "151/469 [========>.....................] - ETA: 2:47 - loss: 0.0955 - sparse_categorical_accuracy: 0.9704\n",
            "152/469 [========>.....................] - ETA: 2:47 - loss: 0.0960 - sparse_categorical_accuracy: 0.9703\n",
            "153/469 [========>.....................] - ETA: 2:46 - loss: 0.0958 - sparse_categorical_accuracy: 0.9704\n",
            "154/469 [========>.....................] - ETA: 2:45 - loss: 0.0954 - sparse_categorical_accuracy: 0.9705\n",
            "155/469 [========>.....................] - ETA: 2:44 - loss: 0.0955 - sparse_categorical_accuracy: 0.9706\n",
            "156/469 [========>.....................] - ETA: 2:44 - loss: 0.0958 - sparse_categorical_accuracy: 0.9706\n",
            "157/469 [=========>....................] - ETA: 2:43 - loss: 0.0954 - sparse_categorical_accuracy: 0.9707\n",
            "158/469 [=========>....................] - ETA: 2:43 - loss: 0.0957 - sparse_categorical_accuracy: 0.9706\n",
            "159/469 [=========>....................] - ETA: 2:42 - loss: 0.0960 - sparse_categorical_accuracy: 0.9705\n",
            "160/469 [=========>....................] - ETA: 2:41 - loss: 0.0957 - sparse_categorical_accuracy: 0.9707\n",
            "161/469 [=========>....................] - ETA: 2:41 - loss: 0.0956 - sparse_categorical_accuracy: 0.9706\n",
            "162/469 [=========>....................] - ETA: 2:40 - loss: 0.0955 - sparse_categorical_accuracy: 0.9706\n",
            "163/469 [=========>....................] - ETA: 2:40 - loss: 0.0961 - sparse_categorical_accuracy: 0.9706\n",
            "164/469 [=========>....................] - ETA: 2:39 - loss: 0.0963 - sparse_categorical_accuracy: 0.9705\n",
            "165/469 [=========>....................] - ETA: 2:38 - loss: 0.0965 - sparse_categorical_accuracy: 0.9704\n",
            "166/469 [=========>....................] - ETA: 2:38 - loss: 0.0966 - sparse_categorical_accuracy: 0.9704\n",
            "167/469 [=========>....................] - ETA: 2:38 - loss: 0.0973 - sparse_categorical_accuracy: 0.9704\n",
            "168/469 [=========>....................] - ETA: 2:38 - loss: 0.0971 - sparse_categorical_accuracy: 0.9704\n",
            "169/469 [=========>....................] - ETA: 2:38 - loss: 0.0967 - sparse_categorical_accuracy: 0.9706\n",
            "170/469 [=========>....................] - ETA: 2:37 - loss: 0.0963 - sparse_categorical_accuracy: 0.9707\n",
            "171/469 [=========>....................] - ETA: 2:37 - loss: 0.0964 - sparse_categorical_accuracy: 0.9706\n",
            "172/469 [==========>...................] - ETA: 2:36 - loss: 0.0962 - sparse_categorical_accuracy: 0.9706\n",
            "173/469 [==========>...................] - ETA: 2:36 - loss: 0.0964 - sparse_categorical_accuracy: 0.9705\n",
            "174/469 [==========>...................] - ETA: 2:35 - loss: 0.0966 - sparse_categorical_accuracy: 0.9705\n",
            "175/469 [==========>...................] - ETA: 2:34 - loss: 0.0965 - sparse_categorical_accuracy: 0.9705\n",
            "176/469 [==========>...................] - ETA: 2:34 - loss: 0.0964 - sparse_categorical_accuracy: 0.9705\n",
            "177/469 [==========>...................] - ETA: 2:33 - loss: 0.0961 - sparse_categorical_accuracy: 0.9706\n",
            "178/469 [==========>...................] - ETA: 2:32 - loss: 0.0960 - sparse_categorical_accuracy: 0.9708\n",
            "179/469 [==========>...................] - ETA: 2:32 - loss: 0.0959 - sparse_categorical_accuracy: 0.9708\n",
            "180/469 [==========>...................] - ETA: 2:31 - loss: 0.0958 - sparse_categorical_accuracy: 0.9708\n",
            "181/469 [==========>...................] - ETA: 2:31 - loss: 0.0955 - sparse_categorical_accuracy: 0.9710\n",
            "182/469 [==========>...................] - ETA: 2:30 - loss: 0.0958 - sparse_categorical_accuracy: 0.9709\n",
            "183/469 [==========>...................] - ETA: 2:29 - loss: 0.0957 - sparse_categorical_accuracy: 0.9709\n",
            "184/469 [==========>...................] - ETA: 2:29 - loss: 0.0956 - sparse_categorical_accuracy: 0.9709\n",
            "185/469 [==========>...................] - ETA: 2:28 - loss: 0.0955 - sparse_categorical_accuracy: 0.9710\n",
            "186/469 [==========>...................] - ETA: 2:28 - loss: 0.0958 - sparse_categorical_accuracy: 0.9708\n",
            "187/469 [==========>...................] - ETA: 2:27 - loss: 0.0956 - sparse_categorical_accuracy: 0.9708\n",
            "188/469 [===========>..................] - ETA: 2:26 - loss: 0.0955 - sparse_categorical_accuracy: 0.9709\n",
            "189/469 [===========>..................] - ETA: 2:26 - loss: 0.0954 - sparse_categorical_accuracy: 0.9709\n",
            "190/469 [===========>..................] - ETA: 2:25 - loss: 0.0955 - sparse_categorical_accuracy: 0.9709\n",
            "191/469 [===========>..................] - ETA: 2:25 - loss: 0.0954 - sparse_categorical_accuracy: 0.9709\n",
            "192/469 [===========>..................] - ETA: 2:25 - loss: 0.0951 - sparse_categorical_accuracy: 0.9710\n",
            "193/469 [===========>..................] - ETA: 2:24 - loss: 0.0956 - sparse_categorical_accuracy: 0.9708\n",
            "194/469 [===========>..................] - ETA: 2:24 - loss: 0.0954 - sparse_categorical_accuracy: 0.9709\n",
            "195/469 [===========>..................] - ETA: 2:24 - loss: 0.0954 - sparse_categorical_accuracy: 0.9709\n",
            "196/469 [===========>..................] - ETA: 2:23 - loss: 0.0954 - sparse_categorical_accuracy: 0.9709\n",
            "197/469 [===========>..................] - ETA: 2:23 - loss: 0.0956 - sparse_categorical_accuracy: 0.9709\n",
            "198/469 [===========>..................] - ETA: 2:22 - loss: 0.0959 - sparse_categorical_accuracy: 0.9707\n",
            "199/469 [===========>..................] - ETA: 2:22 - loss: 0.0957 - sparse_categorical_accuracy: 0.9708\n",
            "200/469 [===========>..................] - ETA: 2:21 - loss: 0.0954 - sparse_categorical_accuracy: 0.9709\n",
            "201/469 [===========>..................] - ETA: 2:20 - loss: 0.0953 - sparse_categorical_accuracy: 0.9709\n",
            "202/469 [===========>..................] - ETA: 2:20 - loss: 0.0955 - sparse_categorical_accuracy: 0.9708\n",
            "203/469 [===========>..................] - ETA: 2:19 - loss: 0.0953 - sparse_categorical_accuracy: 0.9708\n",
            "204/469 [============>.................] - ETA: 2:18 - loss: 0.0951 - sparse_categorical_accuracy: 0.9709\n",
            "205/469 [============>.................] - ETA: 2:18 - loss: 0.0952 - sparse_categorical_accuracy: 0.9709\n",
            "206/469 [============>.................] - ETA: 2:17 - loss: 0.0951 - sparse_categorical_accuracy: 0.9708\n",
            "207/469 [============>.................] - ETA: 2:17 - loss: 0.0954 - sparse_categorical_accuracy: 0.9708\n",
            "208/469 [============>.................] - ETA: 2:16 - loss: 0.0953 - sparse_categorical_accuracy: 0.9708\n",
            "209/469 [============>.................] - ETA: 2:15 - loss: 0.0952 - sparse_categorical_accuracy: 0.9709\n",
            "210/469 [============>.................] - ETA: 2:15 - loss: 0.0949 - sparse_categorical_accuracy: 0.9710\n",
            "211/469 [============>.................] - ETA: 2:14 - loss: 0.0951 - sparse_categorical_accuracy: 0.9710\n",
            "212/469 [============>.................] - ETA: 2:14 - loss: 0.0950 - sparse_categorical_accuracy: 0.9710\n",
            "213/469 [============>.................] - ETA: 2:13 - loss: 0.0952 - sparse_categorical_accuracy: 0.9710\n",
            "214/469 [============>.................] - ETA: 2:12 - loss: 0.0951 - sparse_categorical_accuracy: 0.9710\n",
            "215/469 [============>.................] - ETA: 2:12 - loss: 0.0953 - sparse_categorical_accuracy: 0.9710\n",
            "216/469 [============>.................] - ETA: 2:11 - loss: 0.0955 - sparse_categorical_accuracy: 0.9710\n",
            "217/469 [============>.................] - ETA: 2:11 - loss: 0.0959 - sparse_categorical_accuracy: 0.9709\n",
            "218/469 [============>.................] - ETA: 2:10 - loss: 0.0959 - sparse_categorical_accuracy: 0.9710\n",
            "219/469 [=============>................] - ETA: 2:10 - loss: 0.0965 - sparse_categorical_accuracy: 0.9709\n",
            "220/469 [=============>................] - ETA: 2:10 - loss: 0.0966 - sparse_categorical_accuracy: 0.9710\n",
            "221/469 [=============>................] - ETA: 2:10 - loss: 0.0968 - sparse_categorical_accuracy: 0.9709\n",
            "222/469 [=============>................] - ETA: 2:09 - loss: 0.0972 - sparse_categorical_accuracy: 0.9708\n",
            "223/469 [=============>................] - ETA: 2:09 - loss: 0.0970 - sparse_categorical_accuracy: 0.9708\n",
            "224/469 [=============>................] - ETA: 2:08 - loss: 0.0968 - sparse_categorical_accuracy: 0.9708\n",
            "225/469 [=============>................] - ETA: 2:07 - loss: 0.0967 - sparse_categorical_accuracy: 0.9709\n",
            "226/469 [=============>................] - ETA: 2:07 - loss: 0.0965 - sparse_categorical_accuracy: 0.9709\n",
            "227/469 [=============>................] - ETA: 2:06 - loss: 0.0968 - sparse_categorical_accuracy: 0.9708\n",
            "228/469 [=============>................] - ETA: 2:06 - loss: 0.0965 - sparse_categorical_accuracy: 0.9709\n",
            "229/469 [=============>................] - ETA: 2:05 - loss: 0.0965 - sparse_categorical_accuracy: 0.9709\n",
            "230/469 [=============>................] - ETA: 2:04 - loss: 0.0964 - sparse_categorical_accuracy: 0.9709\n",
            "231/469 [=============>................] - ETA: 2:04 - loss: 0.0963 - sparse_categorical_accuracy: 0.9709\n",
            "232/469 [=============>................] - ETA: 2:03 - loss: 0.0964 - sparse_categorical_accuracy: 0.9709\n",
            "233/469 [=============>................] - ETA: 2:03 - loss: 0.0963 - sparse_categorical_accuracy: 0.9710\n",
            "234/469 [=============>................] - ETA: 2:02 - loss: 0.0962 - sparse_categorical_accuracy: 0.9710\n",
            "235/469 [==============>...............] - ETA: 2:02 - loss: 0.0960 - sparse_categorical_accuracy: 0.9711\n",
            "236/469 [==============>...............] - ETA: 2:01 - loss: 0.0959 - sparse_categorical_accuracy: 0.9712\n",
            "237/469 [==============>...............] - ETA: 2:01 - loss: 0.0961 - sparse_categorical_accuracy: 0.9711\n",
            "238/469 [==============>...............] - ETA: 2:00 - loss: 0.0960 - sparse_categorical_accuracy: 0.9711\n",
            "239/469 [==============>...............] - ETA: 1:59 - loss: 0.0959 - sparse_categorical_accuracy: 0.9710\n",
            "240/469 [==============>...............] - ETA: 1:59 - loss: 0.0960 - sparse_categorical_accuracy: 0.9710\n",
            "241/469 [==============>...............] - ETA: 1:58 - loss: 0.0961 - sparse_categorical_accuracy: 0.9709\n",
            "242/469 [==============>...............] - ETA: 1:58 - loss: 0.0964 - sparse_categorical_accuracy: 0.9708\n",
            "243/469 [==============>...............] - ETA: 1:57 - loss: 0.0964 - sparse_categorical_accuracy: 0.9708\n",
            "244/469 [==============>...............] - ETA: 1:57 - loss: 0.0963 - sparse_categorical_accuracy: 0.9708\n",
            "245/469 [==============>...............] - ETA: 1:57 - loss: 0.0962 - sparse_categorical_accuracy: 0.9709\n",
            "246/469 [==============>...............] - ETA: 1:56 - loss: 0.0960 - sparse_categorical_accuracy: 0.9709\n",
            "247/469 [==============>...............] - ETA: 1:56 - loss: 0.0959 - sparse_categorical_accuracy: 0.9710\n",
            "248/469 [==============>...............] - ETA: 1:56 - loss: 0.0961 - sparse_categorical_accuracy: 0.9709\n",
            "249/469 [==============>...............] - ETA: 1:55 - loss: 0.0959 - sparse_categorical_accuracy: 0.9710\n",
            "250/469 [==============>...............] - ETA: 1:54 - loss: 0.0957 - sparse_categorical_accuracy: 0.9711\n",
            "251/469 [===============>..............] - ETA: 1:54 - loss: 0.0958 - sparse_categorical_accuracy: 0.9710\n",
            "252/469 [===============>..............] - ETA: 1:53 - loss: 0.0956 - sparse_categorical_accuracy: 0.9710\n",
            "253/469 [===============>..............] - ETA: 1:53 - loss: 0.0955 - sparse_categorical_accuracy: 0.9711\n",
            "254/469 [===============>..............] - ETA: 1:52 - loss: 0.0956 - sparse_categorical_accuracy: 0.9710\n",
            "255/469 [===============>..............] - ETA: 1:52 - loss: 0.0956 - sparse_categorical_accuracy: 0.9710\n",
            "256/469 [===============>..............] - ETA: 1:51 - loss: 0.0955 - sparse_categorical_accuracy: 0.9710\n",
            "257/469 [===============>..............] - ETA: 1:50 - loss: 0.0956 - sparse_categorical_accuracy: 0.9710\n",
            "258/469 [===============>..............] - ETA: 1:50 - loss: 0.0955 - sparse_categorical_accuracy: 0.9710\n",
            "259/469 [===============>..............] - ETA: 1:49 - loss: 0.0954 - sparse_categorical_accuracy: 0.9710\n",
            "260/469 [===============>..............] - ETA: 1:49 - loss: 0.0955 - sparse_categorical_accuracy: 0.9710\n",
            "261/469 [===============>..............] - ETA: 1:48 - loss: 0.0953 - sparse_categorical_accuracy: 0.9710\n",
            "262/469 [===============>..............] - ETA: 1:48 - loss: 0.0955 - sparse_categorical_accuracy: 0.9709\n",
            "263/469 [===============>..............] - ETA: 1:47 - loss: 0.0955 - sparse_categorical_accuracy: 0.9709\n",
            "264/469 [===============>..............] - ETA: 1:47 - loss: 0.0954 - sparse_categorical_accuracy: 0.9709\n",
            "265/469 [===============>..............] - ETA: 1:46 - loss: 0.0953 - sparse_categorical_accuracy: 0.9709\n",
            "266/469 [================>.............] - ETA: 1:45 - loss: 0.0953 - sparse_categorical_accuracy: 0.9709\n",
            "267/469 [================>.............] - ETA: 1:45 - loss: 0.0954 - sparse_categorical_accuracy: 0.9709\n",
            "268/469 [================>.............] - ETA: 1:44 - loss: 0.0954 - sparse_categorical_accuracy: 0.9708\n",
            "269/469 [================>.............] - ETA: 1:44 - loss: 0.0953 - sparse_categorical_accuracy: 0.9709\n",
            "270/469 [================>.............] - ETA: 1:44 - loss: 0.0953 - sparse_categorical_accuracy: 0.9708\n",
            "271/469 [================>.............] - ETA: 1:43 - loss: 0.0955 - sparse_categorical_accuracy: 0.9708\n",
            "272/469 [================>.............] - ETA: 1:43 - loss: 0.0954 - sparse_categorical_accuracy: 0.9708\n",
            "273/469 [================>.............] - ETA: 1:42 - loss: 0.0952 - sparse_categorical_accuracy: 0.9709\n",
            "274/469 [================>.............] - ETA: 1:42 - loss: 0.0952 - sparse_categorical_accuracy: 0.9709\n",
            "275/469 [================>.............] - ETA: 1:41 - loss: 0.0952 - sparse_categorical_accuracy: 0.9708\n",
            "276/469 [================>.............] - ETA: 1:41 - loss: 0.0954 - sparse_categorical_accuracy: 0.9707\n",
            "277/469 [================>.............] - ETA: 1:40 - loss: 0.0957 - sparse_categorical_accuracy: 0.9707\n",
            "278/469 [================>.............] - ETA: 1:40 - loss: 0.0957 - sparse_categorical_accuracy: 0.9706\n",
            "279/469 [================>.............] - ETA: 1:39 - loss: 0.0956 - sparse_categorical_accuracy: 0.9707\n",
            "280/469 [================>.............] - ETA: 1:39 - loss: 0.0954 - sparse_categorical_accuracy: 0.9707\n",
            "281/469 [================>.............] - ETA: 1:38 - loss: 0.0955 - sparse_categorical_accuracy: 0.9708\n",
            "282/469 [=================>............] - ETA: 1:38 - loss: 0.0958 - sparse_categorical_accuracy: 0.9708\n",
            "283/469 [=================>............] - ETA: 1:37 - loss: 0.0957 - sparse_categorical_accuracy: 0.9708\n",
            "284/469 [=================>............] - ETA: 1:36 - loss: 0.0956 - sparse_categorical_accuracy: 0.9709\n",
            "285/469 [=================>............] - ETA: 1:36 - loss: 0.0954 - sparse_categorical_accuracy: 0.9710\n",
            "286/469 [=================>............] - ETA: 1:35 - loss: 0.0954 - sparse_categorical_accuracy: 0.9709\n",
            "287/469 [=================>............] - ETA: 1:35 - loss: 0.0954 - sparse_categorical_accuracy: 0.9710\n",
            "288/469 [=================>............] - ETA: 1:34 - loss: 0.0953 - sparse_categorical_accuracy: 0.9709\n",
            "289/469 [=================>............] - ETA: 1:34 - loss: 0.0954 - sparse_categorical_accuracy: 0.9709\n",
            "290/469 [=================>............] - ETA: 1:33 - loss: 0.0953 - sparse_categorical_accuracy: 0.9709\n",
            "291/469 [=================>............] - ETA: 1:33 - loss: 0.0950 - sparse_categorical_accuracy: 0.9710\n",
            "292/469 [=================>............] - ETA: 1:32 - loss: 0.0952 - sparse_categorical_accuracy: 0.9710\n",
            "293/469 [=================>............] - ETA: 1:31 - loss: 0.0953 - sparse_categorical_accuracy: 0.9710\n",
            "294/469 [=================>............] - ETA: 1:31 - loss: 0.0951 - sparse_categorical_accuracy: 0.9710\n",
            "295/469 [=================>............] - ETA: 1:30 - loss: 0.0950 - sparse_categorical_accuracy: 0.9711\n",
            "296/469 [=================>............] - ETA: 1:30 - loss: 0.0949 - sparse_categorical_accuracy: 0.9712\n",
            "297/469 [=================>............] - ETA: 1:30 - loss: 0.0948 - sparse_categorical_accuracy: 0.9712\n",
            "298/469 [==================>...........] - ETA: 1:29 - loss: 0.0949 - sparse_categorical_accuracy: 0.9712\n",
            "299/469 [==================>...........] - ETA: 1:29 - loss: 0.0948 - sparse_categorical_accuracy: 0.9713\n",
            "300/469 [==================>...........] - ETA: 1:28 - loss: 0.0948 - sparse_categorical_accuracy: 0.9712\n",
            "301/469 [==================>...........] - ETA: 1:28 - loss: 0.0947 - sparse_categorical_accuracy: 0.9712\n",
            "302/469 [==================>...........] - ETA: 1:27 - loss: 0.0946 - sparse_categorical_accuracy: 0.9712\n",
            "303/469 [==================>...........] - ETA: 1:27 - loss: 0.0945 - sparse_categorical_accuracy: 0.9713\n",
            "304/469 [==================>...........] - ETA: 1:26 - loss: 0.0946 - sparse_categorical_accuracy: 0.9712\n",
            "305/469 [==================>...........] - ETA: 1:25 - loss: 0.0947 - sparse_categorical_accuracy: 0.9712\n",
            "306/469 [==================>...........] - ETA: 1:25 - loss: 0.0946 - sparse_categorical_accuracy: 0.9712\n",
            "307/469 [==================>...........] - ETA: 1:24 - loss: 0.0945 - sparse_categorical_accuracy: 0.9712\n",
            "308/469 [==================>...........] - ETA: 1:24 - loss: 0.0943 - sparse_categorical_accuracy: 0.9712\n",
            "309/469 [==================>...........] - ETA: 1:23 - loss: 0.0943 - sparse_categorical_accuracy: 0.9712\n",
            "310/469 [==================>...........] - ETA: 1:23 - loss: 0.0941 - sparse_categorical_accuracy: 0.9713\n",
            "311/469 [==================>...........] - ETA: 1:22 - loss: 0.0942 - sparse_categorical_accuracy: 0.9712\n",
            "312/469 [==================>...........] - ETA: 1:22 - loss: 0.0942 - sparse_categorical_accuracy: 0.9713\n",
            "313/469 [===================>..........] - ETA: 1:21 - loss: 0.0943 - sparse_categorical_accuracy: 0.9712\n",
            "314/469 [===================>..........] - ETA: 1:21 - loss: 0.0943 - sparse_categorical_accuracy: 0.9713\n",
            "315/469 [===================>..........] - ETA: 1:20 - loss: 0.0945 - sparse_categorical_accuracy: 0.9712\n",
            "316/469 [===================>..........] - ETA: 1:19 - loss: 0.0944 - sparse_categorical_accuracy: 0.9712\n",
            "317/469 [===================>..........] - ETA: 1:19 - loss: 0.0944 - sparse_categorical_accuracy: 0.9712\n",
            "318/469 [===================>..........] - ETA: 1:18 - loss: 0.0942 - sparse_categorical_accuracy: 0.9712\n",
            "319/469 [===================>..........] - ETA: 1:18 - loss: 0.0940 - sparse_categorical_accuracy: 0.9713\n",
            "320/469 [===================>..........] - ETA: 1:17 - loss: 0.0940 - sparse_categorical_accuracy: 0.9713\n",
            "321/469 [===================>..........] - ETA: 1:17 - loss: 0.0939 - sparse_categorical_accuracy: 0.9713\n",
            "322/469 [===================>..........] - ETA: 1:16 - loss: 0.0940 - sparse_categorical_accuracy: 0.9713\n",
            "323/469 [===================>..........] - ETA: 1:16 - loss: 0.0938 - sparse_categorical_accuracy: 0.9713\n",
            "324/469 [===================>..........] - ETA: 1:16 - loss: 0.0936 - sparse_categorical_accuracy: 0.9714\n",
            "325/469 [===================>..........] - ETA: 1:15 - loss: 0.0936 - sparse_categorical_accuracy: 0.9714\n",
            "326/469 [===================>..........] - ETA: 1:14 - loss: 0.0935 - sparse_categorical_accuracy: 0.9714\n",
            "327/469 [===================>..........] - ETA: 1:14 - loss: 0.0935 - sparse_categorical_accuracy: 0.9715\n",
            "328/469 [===================>..........] - ETA: 1:13 - loss: 0.0934 - sparse_categorical_accuracy: 0.9714\n",
            "329/469 [====================>.........] - ETA: 1:13 - loss: 0.0935 - sparse_categorical_accuracy: 0.9715\n",
            "330/469 [====================>.........] - ETA: 1:12 - loss: 0.0936 - sparse_categorical_accuracy: 0.9714\n",
            "331/469 [====================>.........] - ETA: 1:12 - loss: 0.0934 - sparse_categorical_accuracy: 0.9715\n",
            "332/469 [====================>.........] - ETA: 1:11 - loss: 0.0935 - sparse_categorical_accuracy: 0.9715\n",
            "333/469 [====================>.........] - ETA: 1:11 - loss: 0.0935 - sparse_categorical_accuracy: 0.9715\n",
            "334/469 [====================>.........] - ETA: 1:10 - loss: 0.0933 - sparse_categorical_accuracy: 0.9715\n",
            "335/469 [====================>.........] - ETA: 1:10 - loss: 0.0935 - sparse_categorical_accuracy: 0.9715\n",
            "336/469 [====================>.........] - ETA: 1:09 - loss: 0.0934 - sparse_categorical_accuracy: 0.9715\n",
            "337/469 [====================>.........] - ETA: 1:08 - loss: 0.0933 - sparse_categorical_accuracy: 0.9715\n",
            "338/469 [====================>.........] - ETA: 1:08 - loss: 0.0934 - sparse_categorical_accuracy: 0.9715\n",
            "339/469 [====================>.........] - ETA: 1:07 - loss: 0.0935 - sparse_categorical_accuracy: 0.9714\n",
            "340/469 [====================>.........] - ETA: 1:07 - loss: 0.0934 - sparse_categorical_accuracy: 0.9715\n",
            "341/469 [====================>.........] - ETA: 1:06 - loss: 0.0932 - sparse_categorical_accuracy: 0.9715\n",
            "342/469 [====================>.........] - ETA: 1:06 - loss: 0.0931 - sparse_categorical_accuracy: 0.9716\n",
            "343/469 [====================>.........] - ETA: 1:05 - loss: 0.0929 - sparse_categorical_accuracy: 0.9717\n",
            "344/469 [=====================>........] - ETA: 1:05 - loss: 0.0929 - sparse_categorical_accuracy: 0.9717\n",
            "345/469 [=====================>........] - ETA: 1:04 - loss: 0.0928 - sparse_categorical_accuracy: 0.9717\n",
            "346/469 [=====================>........] - ETA: 1:04 - loss: 0.0930 - sparse_categorical_accuracy: 0.9717\n",
            "347/469 [=====================>........] - ETA: 1:03 - loss: 0.0930 - sparse_categorical_accuracy: 0.9717\n",
            "348/469 [=====================>........] - ETA: 1:03 - loss: 0.0934 - sparse_categorical_accuracy: 0.9717\n",
            "349/469 [=====================>........] - ETA: 1:02 - loss: 0.0935 - sparse_categorical_accuracy: 0.9717\n",
            "350/469 [=====================>........] - ETA: 1:02 - loss: 0.0934 - sparse_categorical_accuracy: 0.9716\n",
            "351/469 [=====================>........] - ETA: 1:01 - loss: 0.0934 - sparse_categorical_accuracy: 0.9716\n",
            "352/469 [=====================>........] - ETA: 1:01 - loss: 0.0932 - sparse_categorical_accuracy: 0.9717\n",
            "353/469 [=====================>........] - ETA: 1:00 - loss: 0.0933 - sparse_categorical_accuracy: 0.9716\n",
            "354/469 [=====================>........] - ETA: 1:00 - loss: 0.0932 - sparse_categorical_accuracy: 0.9717\n",
            "355/469 [=====================>........] - ETA: 59s - loss: 0.0931 - sparse_categorical_accuracy: 0.9717 \n",
            "356/469 [=====================>........] - ETA: 59s - loss: 0.0930 - sparse_categorical_accuracy: 0.9718\n",
            "357/469 [=====================>........] - ETA: 58s - loss: 0.0930 - sparse_categorical_accuracy: 0.9718\n",
            "358/469 [=====================>........] - ETA: 58s - loss: 0.0929 - sparse_categorical_accuracy: 0.9718\n",
            "359/469 [=====================>........] - ETA: 57s - loss: 0.0931 - sparse_categorical_accuracy: 0.9717\n",
            "360/469 [======================>.......] - ETA: 56s - loss: 0.0930 - sparse_categorical_accuracy: 0.9717\n",
            "361/469 [======================>.......] - ETA: 56s - loss: 0.0934 - sparse_categorical_accuracy: 0.9717\n",
            "362/469 [======================>.......] - ETA: 55s - loss: 0.0932 - sparse_categorical_accuracy: 0.9717\n",
            "363/469 [======================>.......] - ETA: 55s - loss: 0.0933 - sparse_categorical_accuracy: 0.9718\n",
            "364/469 [======================>.......] - ETA: 54s - loss: 0.0932 - sparse_categorical_accuracy: 0.9718\n",
            "365/469 [======================>.......] - ETA: 54s - loss: 0.0932 - sparse_categorical_accuracy: 0.9718\n",
            "366/469 [======================>.......] - ETA: 53s - loss: 0.0931 - sparse_categorical_accuracy: 0.9718\n",
            "367/469 [======================>.......] - ETA: 53s - loss: 0.0932 - sparse_categorical_accuracy: 0.9718\n",
            "368/469 [======================>.......] - ETA: 52s - loss: 0.0931 - sparse_categorical_accuracy: 0.9718\n",
            "369/469 [======================>.......] - ETA: 52s - loss: 0.0931 - sparse_categorical_accuracy: 0.9718\n",
            "370/469 [======================>.......] - ETA: 51s - loss: 0.0930 - sparse_categorical_accuracy: 0.9718\n",
            "371/469 [======================>.......] - ETA: 51s - loss: 0.0929 - sparse_categorical_accuracy: 0.9718\n",
            "372/469 [======================>.......] - ETA: 50s - loss: 0.0928 - sparse_categorical_accuracy: 0.9719\n",
            "373/469 [======================>.......] - ETA: 50s - loss: 0.0928 - sparse_categorical_accuracy: 0.9719\n",
            "374/469 [======================>.......] - ETA: 49s - loss: 0.0930 - sparse_categorical_accuracy: 0.9719\n",
            "375/469 [======================>.......] - ETA: 49s - loss: 0.0930 - sparse_categorical_accuracy: 0.9719\n",
            "376/469 [=======================>......] - ETA: 48s - loss: 0.0929 - sparse_categorical_accuracy: 0.9719\n",
            "377/469 [=======================>......] - ETA: 48s - loss: 0.0927 - sparse_categorical_accuracy: 0.9719\n",
            "378/469 [=======================>......] - ETA: 47s - loss: 0.0926 - sparse_categorical_accuracy: 0.9720\n",
            "379/469 [=======================>......] - ETA: 47s - loss: 0.0926 - sparse_categorical_accuracy: 0.9720\n",
            "380/469 [=======================>......] - ETA: 46s - loss: 0.0924 - sparse_categorical_accuracy: 0.9720\n",
            "381/469 [=======================>......] - ETA: 46s - loss: 0.0922 - sparse_categorical_accuracy: 0.9721\n",
            "382/469 [=======================>......] - ETA: 45s - loss: 0.0921 - sparse_categorical_accuracy: 0.9721\n",
            "383/469 [=======================>......] - ETA: 44s - loss: 0.0923 - sparse_categorical_accuracy: 0.9721\n",
            "384/469 [=======================>......] - ETA: 44s - loss: 0.0921 - sparse_categorical_accuracy: 0.9721\n",
            "385/469 [=======================>......] - ETA: 43s - loss: 0.0922 - sparse_categorical_accuracy: 0.9721\n",
            "386/469 [=======================>......] - ETA: 43s - loss: 0.0921 - sparse_categorical_accuracy: 0.9722\n",
            "387/469 [=======================>......] - ETA: 42s - loss: 0.0919 - sparse_categorical_accuracy: 0.9722\n",
            "388/469 [=======================>......] - ETA: 42s - loss: 0.0920 - sparse_categorical_accuracy: 0.9722\n",
            "389/469 [=======================>......] - ETA: 41s - loss: 0.0920 - sparse_categorical_accuracy: 0.9722\n",
            "390/469 [=======================>......] - ETA: 41s - loss: 0.0920 - sparse_categorical_accuracy: 0.9722\n",
            "391/469 [========================>.....] - ETA: 40s - loss: 0.0919 - sparse_categorical_accuracy: 0.9722\n",
            "392/469 [========================>.....] - ETA: 40s - loss: 0.0919 - sparse_categorical_accuracy: 0.9722\n",
            "393/469 [========================>.....] - ETA: 39s - loss: 0.0920 - sparse_categorical_accuracy: 0.9722\n",
            "394/469 [========================>.....] - ETA: 39s - loss: 0.0919 - sparse_categorical_accuracy: 0.9722\n",
            "395/469 [========================>.....] - ETA: 38s - loss: 0.0918 - sparse_categorical_accuracy: 0.9722\n",
            "396/469 [========================>.....] - ETA: 38s - loss: 0.0919 - sparse_categorical_accuracy: 0.9722\n",
            "397/469 [========================>.....] - ETA: 37s - loss: 0.0921 - sparse_categorical_accuracy: 0.9721\n",
            "398/469 [========================>.....] - ETA: 37s - loss: 0.0921 - sparse_categorical_accuracy: 0.9721\n",
            "399/469 [========================>.....] - ETA: 36s - loss: 0.0921 - sparse_categorical_accuracy: 0.9721\n",
            "400/469 [========================>.....] - ETA: 36s - loss: 0.0920 - sparse_categorical_accuracy: 0.9722\n",
            "401/469 [========================>.....] - ETA: 35s - loss: 0.0918 - sparse_categorical_accuracy: 0.9722\n",
            "402/469 [========================>.....] - ETA: 35s - loss: 0.0918 - sparse_categorical_accuracy: 0.9722\n",
            "403/469 [========================>.....] - ETA: 34s - loss: 0.0917 - sparse_categorical_accuracy: 0.9723\n",
            "404/469 [========================>.....] - ETA: 34s - loss: 0.0916 - sparse_categorical_accuracy: 0.9723\n",
            "405/469 [========================>.....] - ETA: 33s - loss: 0.0916 - sparse_categorical_accuracy: 0.9723\n",
            "406/469 [========================>.....] - ETA: 32s - loss: 0.0916 - sparse_categorical_accuracy: 0.9723\n",
            "407/469 [=========================>....] - ETA: 32s - loss: 0.0916 - sparse_categorical_accuracy: 0.9722\n",
            "408/469 [=========================>....] - ETA: 31s - loss: 0.0915 - sparse_categorical_accuracy: 0.9722\n",
            "409/469 [=========================>....] - ETA: 31s - loss: 0.0916 - sparse_categorical_accuracy: 0.9722\n",
            "410/469 [=========================>....] - ETA: 30s - loss: 0.0914 - sparse_categorical_accuracy: 0.9722\n",
            "411/469 [=========================>....] - ETA: 30s - loss: 0.0913 - sparse_categorical_accuracy: 0.9723\n",
            "412/469 [=========================>....] - ETA: 29s - loss: 0.0914 - sparse_categorical_accuracy: 0.9723\n",
            "413/469 [=========================>....] - ETA: 29s - loss: 0.0912 - sparse_categorical_accuracy: 0.9723\n",
            "414/469 [=========================>....] - ETA: 28s - loss: 0.0912 - sparse_categorical_accuracy: 0.9723\n",
            "415/469 [=========================>....] - ETA: 28s - loss: 0.0911 - sparse_categorical_accuracy: 0.9723\n",
            "416/469 [=========================>....] - ETA: 27s - loss: 0.0911 - sparse_categorical_accuracy: 0.9723\n",
            "417/469 [=========================>....] - ETA: 27s - loss: 0.0910 - sparse_categorical_accuracy: 0.9723\n",
            "418/469 [=========================>....] - ETA: 26s - loss: 0.0909 - sparse_categorical_accuracy: 0.9724\n",
            "419/469 [=========================>....] - ETA: 26s - loss: 0.0910 - sparse_categorical_accuracy: 0.9724\n",
            "420/469 [=========================>....] - ETA: 25s - loss: 0.0910 - sparse_categorical_accuracy: 0.9724\n",
            "421/469 [=========================>....] - ETA: 25s - loss: 0.0911 - sparse_categorical_accuracy: 0.9724\n",
            "422/469 [=========================>....] - ETA: 24s - loss: 0.0910 - sparse_categorical_accuracy: 0.9723\n",
            "423/469 [==========================>...] - ETA: 24s - loss: 0.0911 - sparse_categorical_accuracy: 0.9723\n",
            "424/469 [==========================>...] - ETA: 23s - loss: 0.0913 - sparse_categorical_accuracy: 0.9723\n",
            "425/469 [==========================>...] - ETA: 23s - loss: 0.0914 - sparse_categorical_accuracy: 0.9722\n",
            "426/469 [==========================>...] - ETA: 22s - loss: 0.0913 - sparse_categorical_accuracy: 0.9722\n",
            "427/469 [==========================>...] - ETA: 22s - loss: 0.0913 - sparse_categorical_accuracy: 0.9722\n",
            "428/469 [==========================>...] - ETA: 21s - loss: 0.0913 - sparse_categorical_accuracy: 0.9722\n",
            "429/469 [==========================>...] - ETA: 20s - loss: 0.0913 - sparse_categorical_accuracy: 0.9722\n",
            "430/469 [==========================>...] - ETA: 20s - loss: 0.0912 - sparse_categorical_accuracy: 0.9722\n",
            "431/469 [==========================>...] - ETA: 19s - loss: 0.0912 - sparse_categorical_accuracy: 0.9722\n",
            "432/469 [==========================>...] - ETA: 19s - loss: 0.0911 - sparse_categorical_accuracy: 0.9723\n",
            "433/469 [==========================>...] - ETA: 18s - loss: 0.0912 - sparse_categorical_accuracy: 0.9723\n",
            "434/469 [==========================>...] - ETA: 18s - loss: 0.0911 - sparse_categorical_accuracy: 0.9723\n",
            "435/469 [==========================>...] - ETA: 17s - loss: 0.0910 - sparse_categorical_accuracy: 0.9723\n",
            "436/469 [==========================>...] - ETA: 17s - loss: 0.0910 - sparse_categorical_accuracy: 0.9723\n",
            "437/469 [==========================>...] - ETA: 16s - loss: 0.0910 - sparse_categorical_accuracy: 0.9723\n",
            "438/469 [===========================>..] - ETA: 16s - loss: 0.0910 - sparse_categorical_accuracy: 0.9722\n",
            "439/469 [===========================>..] - ETA: 15s - loss: 0.0912 - sparse_categorical_accuracy: 0.9722\n",
            "440/469 [===========================>..] - ETA: 15s - loss: 0.0912 - sparse_categorical_accuracy: 0.9722\n",
            "441/469 [===========================>..] - ETA: 14s - loss: 0.0912 - sparse_categorical_accuracy: 0.9722\n",
            "442/469 [===========================>..] - ETA: 14s - loss: 0.0912 - sparse_categorical_accuracy: 0.9721\n",
            "443/469 [===========================>..] - ETA: 13s - loss: 0.0913 - sparse_categorical_accuracy: 0.9721\n",
            "444/469 [===========================>..] - ETA: 13s - loss: 0.0913 - sparse_categorical_accuracy: 0.9721\n",
            "445/469 [===========================>..] - ETA: 12s - loss: 0.0912 - sparse_categorical_accuracy: 0.9722\n",
            "446/469 [===========================>..] - ETA: 11s - loss: 0.0911 - sparse_categorical_accuracy: 0.9722\n",
            "447/469 [===========================>..] - ETA: 11s - loss: 0.0912 - sparse_categorical_accuracy: 0.9721\n",
            "448/469 [===========================>..] - ETA: 10s - loss: 0.0911 - sparse_categorical_accuracy: 0.9722\n",
            "449/469 [===========================>..] - ETA: 10s - loss: 0.0911 - sparse_categorical_accuracy: 0.9721\n",
            "450/469 [===========================>..] - ETA: 9s - loss: 0.0911 - sparse_categorical_accuracy: 0.9720 \n",
            "451/469 [===========================>..] - ETA: 9s - loss: 0.0910 - sparse_categorical_accuracy: 0.9721\n",
            "452/469 [===========================>..] - ETA: 8s - loss: 0.0909 - sparse_categorical_accuracy: 0.9721\n",
            "453/469 [===========================>..] - ETA: 8s - loss: 0.0909 - sparse_categorical_accuracy: 0.9721\n",
            "454/469 [============================>.] - ETA: 7s - loss: 0.0908 - sparse_categorical_accuracy: 0.9721\n",
            "455/469 [============================>.] - ETA: 7s - loss: 0.0908 - sparse_categorical_accuracy: 0.9721\n",
            "456/469 [============================>.] - ETA: 6s - loss: 0.0907 - sparse_categorical_accuracy: 0.9722\n",
            "457/469 [============================>.] - ETA: 6s - loss: 0.0906 - sparse_categorical_accuracy: 0.9722\n",
            "458/469 [============================>.] - ETA: 5s - loss: 0.0906 - sparse_categorical_accuracy: 0.9722\n",
            "459/469 [============================>.] - ETA: 5s - loss: 0.0905 - sparse_categorical_accuracy: 0.9723\n",
            "460/469 [============================>.] - ETA: 4s - loss: 0.0904 - sparse_categorical_accuracy: 0.9723\n",
            "461/469 [============================>.] - ETA: 4s - loss: 0.0903 - sparse_categorical_accuracy: 0.9723\n",
            "462/469 [============================>.] - ETA: 3s - loss: 0.0903 - sparse_categorical_accuracy: 0.9724\n",
            "463/469 [============================>.] - ETA: 3s - loss: 0.0902 - sparse_categorical_accuracy: 0.9724\n",
            "464/469 [============================>.] - ETA: 2s - loss: 0.0904 - sparse_categorical_accuracy: 0.9723\n",
            "465/469 [============================>.] - ETA: 2s - loss: 0.0904 - sparse_categorical_accuracy: 0.9723\n",
            "466/469 [============================>.] - ETA: 1s - loss: 0.0904 - sparse_categorical_accuracy: 0.9723\n",
            "467/469 [============================>.] - ETA: 1s - loss: 0.0903 - sparse_categorical_accuracy: 0.9723\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0904 - sparse_categorical_accuracy: 0.9723\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0903 - sparse_categorical_accuracy: 0.9724\n",
            " 80%|████████  | 4/5 [1:27:02<17:32, 1052.88s/trial, best loss: -0.9850000143051147]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/04/16 01:59:03 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "469/469 [==============================] - 245s 522ms/step - loss: 0.0903 - sparse_categorical_accuracy: 0.9724\n",
            "\n",
            "Epoch 4/5\n",
            "\n",
            "  1/469 [..............................] - ETA: 4:42 - loss: 0.0634 - sparse_categorical_accuracy: 0.9688\n",
            "  2/469 [..............................] - ETA: 3:38 - loss: 0.1090 - sparse_categorical_accuracy: 0.9609\n",
            "  3/469 [..............................] - ETA: 3:34 - loss: 0.0933 - sparse_categorical_accuracy: 0.9661\n",
            "  4/469 [..............................] - ETA: 3:35 - loss: 0.0999 - sparse_categorical_accuracy: 0.9648\n",
            "  5/469 [..............................] - ETA: 3:34 - loss: 0.0879 - sparse_categorical_accuracy: 0.9688\n",
            "  6/469 [..............................] - ETA: 3:42 - loss: 0.0934 - sparse_categorical_accuracy: 0.9688\n",
            "  7/469 [..............................] - ETA: 4:00 - loss: 0.0875 - sparse_categorical_accuracy: 0.9710\n",
            "  8/469 [..............................] - ETA: 4:17 - loss: 0.0820 - sparse_categorical_accuracy: 0.9736\n",
            "  9/469 [..............................] - ETA: 4:25 - loss: 0.0838 - sparse_categorical_accuracy: 0.9740\n",
            " 10/469 [..............................] - ETA: 4:33 - loss: 0.0866 - sparse_categorical_accuracy: 0.9719\n",
            " 11/469 [..............................] - ETA: 4:28 - loss: 0.0845 - sparse_categorical_accuracy: 0.9709\n",
            " 12/469 [..............................] - ETA: 4:23 - loss: 0.0932 - sparse_categorical_accuracy: 0.9674\n",
            " 13/469 [..............................] - ETA: 4:18 - loss: 0.0910 - sparse_categorical_accuracy: 0.9681\n",
            " 14/469 [..............................] - ETA: 4:15 - loss: 0.0913 - sparse_categorical_accuracy: 0.9688\n",
            " 15/469 [..............................] - ETA: 4:12 - loss: 0.0911 - sparse_categorical_accuracy: 0.9693\n",
            " 16/469 [>.............................] - ETA: 4:10 - loss: 0.0889 - sparse_categorical_accuracy: 0.9697\n",
            " 17/469 [>.............................] - ETA: 4:07 - loss: 0.0863 - sparse_categorical_accuracy: 0.9706\n",
            " 18/469 [>.............................] - ETA: 4:04 - loss: 0.0828 - sparse_categorical_accuracy: 0.9722\n",
            " 19/469 [>.............................] - ETA: 4:01 - loss: 0.0828 - sparse_categorical_accuracy: 0.9716\n",
            " 20/469 [>.............................] - ETA: 3:59 - loss: 0.0802 - sparse_categorical_accuracy: 0.9723\n",
            " 21/469 [>.............................] - ETA: 3:57 - loss: 0.0781 - sparse_categorical_accuracy: 0.9732\n",
            " 22/469 [>.............................] - ETA: 3:55 - loss: 0.0790 - sparse_categorical_accuracy: 0.9734\n",
            " 23/469 [>.............................] - ETA: 3:53 - loss: 0.0776 - sparse_categorical_accuracy: 0.9735\n",
            " 24/469 [>.............................] - ETA: 3:51 - loss: 0.0792 - sparse_categorical_accuracy: 0.9733\n",
            " 25/469 [>.............................] - ETA: 3:50 - loss: 0.0793 - sparse_categorical_accuracy: 0.9734\n",
            " 26/469 [>.............................] - ETA: 3:49 - loss: 0.0769 - sparse_categorical_accuracy: 0.9745\n",
            " 27/469 [>.............................] - ETA: 3:48 - loss: 0.0767 - sparse_categorical_accuracy: 0.9745\n",
            " 28/469 [>.............................] - ETA: 3:47 - loss: 0.0778 - sparse_categorical_accuracy: 0.9741\n",
            " 29/469 [>.............................] - ETA: 3:46 - loss: 0.0778 - sparse_categorical_accuracy: 0.9736\n",
            " 30/469 [>.............................] - ETA: 3:45 - loss: 0.0773 - sparse_categorical_accuracy: 0.9740\n",
            " 31/469 [>.............................] - ETA: 3:43 - loss: 0.0774 - sparse_categorical_accuracy: 0.9738\n",
            " 32/469 [=>............................] - ETA: 3:45 - loss: 0.0760 - sparse_categorical_accuracy: 0.9744\n",
            " 33/469 [=>............................] - ETA: 3:49 - loss: 0.0746 - sparse_categorical_accuracy: 0.9749\n",
            " 34/469 [=>............................] - ETA: 3:52 - loss: 0.0740 - sparse_categorical_accuracy: 0.9754\n",
            " 35/469 [=>............................] - ETA: 3:54 - loss: 0.0733 - sparse_categorical_accuracy: 0.9757\n",
            " 36/469 [=>............................] - ETA: 3:54 - loss: 0.0745 - sparse_categorical_accuracy: 0.9750\n",
            " 37/469 [=>............................] - ETA: 3:52 - loss: 0.0735 - sparse_categorical_accuracy: 0.9755\n",
            " 38/469 [=>............................] - ETA: 3:51 - loss: 0.0725 - sparse_categorical_accuracy: 0.9759\n",
            " 39/469 [=>............................] - ETA: 3:49 - loss: 0.0725 - sparse_categorical_accuracy: 0.9760\n",
            " 40/469 [=>............................] - ETA: 3:48 - loss: 0.0726 - sparse_categorical_accuracy: 0.9758\n",
            " 41/469 [=>............................] - ETA: 3:47 - loss: 0.0725 - sparse_categorical_accuracy: 0.9758\n",
            " 42/469 [=>............................] - ETA: 3:46 - loss: 0.0721 - sparse_categorical_accuracy: 0.9758\n",
            " 43/469 [=>............................] - ETA: 3:44 - loss: 0.0720 - sparse_categorical_accuracy: 0.9760\n",
            " 44/469 [=>............................] - ETA: 3:44 - loss: 0.0747 - sparse_categorical_accuracy: 0.9755\n",
            " 45/469 [=>............................] - ETA: 3:42 - loss: 0.0740 - sparse_categorical_accuracy: 0.9759\n",
            " 46/469 [=>............................] - ETA: 3:41 - loss: 0.0740 - sparse_categorical_accuracy: 0.9757\n",
            " 47/469 [==>...........................] - ETA: 3:40 - loss: 0.0745 - sparse_categorical_accuracy: 0.9751\n",
            " 48/469 [==>...........................] - ETA: 3:39 - loss: 0.0739 - sparse_categorical_accuracy: 0.9749\n",
            " 49/469 [==>...........................] - ETA: 3:38 - loss: 0.0734 - sparse_categorical_accuracy: 0.9753\n",
            " 50/469 [==>...........................] - ETA: 3:37 - loss: 0.0737 - sparse_categorical_accuracy: 0.9750\n",
            " 51/469 [==>...........................] - ETA: 3:36 - loss: 0.0735 - sparse_categorical_accuracy: 0.9752\n",
            " 52/469 [==>...........................] - ETA: 3:35 - loss: 0.0745 - sparse_categorical_accuracy: 0.9751\n",
            " 53/469 [==>...........................] - ETA: 3:34 - loss: 0.0737 - sparse_categorical_accuracy: 0.9754\n",
            " 54/469 [==>...........................] - ETA: 3:34 - loss: 0.0735 - sparse_categorical_accuracy: 0.9754\n",
            " 55/469 [==>...........................] - ETA: 3:33 - loss: 0.0731 - sparse_categorical_accuracy: 0.9756\n",
            " 56/469 [==>...........................] - ETA: 3:32 - loss: 0.0733 - sparse_categorical_accuracy: 0.9754\n",
            " 57/469 [==>...........................] - ETA: 3:32 - loss: 0.0727 - sparse_categorical_accuracy: 0.9759\n",
            " 58/469 [==>...........................] - ETA: 3:33 - loss: 0.0726 - sparse_categorical_accuracy: 0.9758\n",
            " 59/469 [==>...........................] - ETA: 3:34 - loss: 0.0719 - sparse_categorical_accuracy: 0.9762\n",
            " 60/469 [==>...........................] - ETA: 3:35 - loss: 0.0728 - sparse_categorical_accuracy: 0.9758\n",
            " 61/469 [==>...........................] - ETA: 3:36 - loss: 0.0735 - sparse_categorical_accuracy: 0.9757\n",
            " 62/469 [==>...........................] - ETA: 3:35 - loss: 0.0741 - sparse_categorical_accuracy: 0.9752\n",
            " 63/469 [===>..........................] - ETA: 3:34 - loss: 0.0743 - sparse_categorical_accuracy: 0.9752\n",
            " 64/469 [===>..........................] - ETA: 3:33 - loss: 0.0740 - sparse_categorical_accuracy: 0.9753\n",
            " 65/469 [===>..........................] - ETA: 3:33 - loss: 0.0741 - sparse_categorical_accuracy: 0.9755\n",
            " 66/469 [===>..........................] - ETA: 3:32 - loss: 0.0733 - sparse_categorical_accuracy: 0.9757\n",
            " 67/469 [===>..........................] - ETA: 3:31 - loss: 0.0736 - sparse_categorical_accuracy: 0.9756\n",
            " 68/469 [===>..........................] - ETA: 3:30 - loss: 0.0733 - sparse_categorical_accuracy: 0.9756\n",
            " 69/469 [===>..........................] - ETA: 3:29 - loss: 0.0747 - sparse_categorical_accuracy: 0.9755\n",
            " 70/469 [===>..........................] - ETA: 3:28 - loss: 0.0746 - sparse_categorical_accuracy: 0.9756\n",
            " 71/469 [===>..........................] - ETA: 3:27 - loss: 0.0742 - sparse_categorical_accuracy: 0.9757\n",
            " 72/469 [===>..........................] - ETA: 3:27 - loss: 0.0744 - sparse_categorical_accuracy: 0.9757\n",
            " 73/469 [===>..........................] - ETA: 3:26 - loss: 0.0741 - sparse_categorical_accuracy: 0.9758\n",
            " 74/469 [===>..........................] - ETA: 3:25 - loss: 0.0742 - sparse_categorical_accuracy: 0.9758\n",
            " 75/469 [===>..........................] - ETA: 3:24 - loss: 0.0740 - sparse_categorical_accuracy: 0.9759\n",
            " 76/469 [===>..........................] - ETA: 3:24 - loss: 0.0735 - sparse_categorical_accuracy: 0.9760\n",
            " 77/469 [===>..........................] - ETA: 3:23 - loss: 0.0734 - sparse_categorical_accuracy: 0.9761\n",
            " 78/469 [===>..........................] - ETA: 3:22 - loss: 0.0730 - sparse_categorical_accuracy: 0.9762\n",
            " 79/469 [====>.........................] - ETA: 3:21 - loss: 0.0725 - sparse_categorical_accuracy: 0.9764\n",
            " 80/469 [====>.........................] - ETA: 3:21 - loss: 0.0728 - sparse_categorical_accuracy: 0.9761\n",
            " 81/469 [====>.........................] - ETA: 3:20 - loss: 0.0730 - sparse_categorical_accuracy: 0.9761\n",
            " 82/469 [====>.........................] - ETA: 3:19 - loss: 0.0736 - sparse_categorical_accuracy: 0.9757\n",
            " 83/469 [====>.........................] - ETA: 3:19 - loss: 0.0739 - sparse_categorical_accuracy: 0.9756\n",
            " 84/469 [====>.........................] - ETA: 3:19 - loss: 0.0735 - sparse_categorical_accuracy: 0.9758\n",
            " 85/469 [====>.........................] - ETA: 3:20 - loss: 0.0730 - sparse_categorical_accuracy: 0.9760\n",
            " 86/469 [====>.........................] - ETA: 3:20 - loss: 0.0726 - sparse_categorical_accuracy: 0.9760\n",
            " 87/469 [====>.........................] - ETA: 3:20 - loss: 0.0726 - sparse_categorical_accuracy: 0.9761\n",
            " 88/469 [====>.........................] - ETA: 3:20 - loss: 0.0724 - sparse_categorical_accuracy: 0.9761\n",
            " 89/469 [====>.........................] - ETA: 3:19 - loss: 0.0735 - sparse_categorical_accuracy: 0.9760\n",
            " 90/469 [====>.........................] - ETA: 3:18 - loss: 0.0730 - sparse_categorical_accuracy: 0.9762\n",
            " 91/469 [====>.........................] - ETA: 3:17 - loss: 0.0732 - sparse_categorical_accuracy: 0.9762\n",
            " 92/469 [====>.........................] - ETA: 3:17 - loss: 0.0737 - sparse_categorical_accuracy: 0.9761\n",
            " 93/469 [====>.........................] - ETA: 3:16 - loss: 0.0743 - sparse_categorical_accuracy: 0.9760\n",
            " 94/469 [=====>........................] - ETA: 3:15 - loss: 0.0740 - sparse_categorical_accuracy: 0.9760\n",
            " 95/469 [=====>........................] - ETA: 3:14 - loss: 0.0739 - sparse_categorical_accuracy: 0.9760\n",
            " 96/469 [=====>........................] - ETA: 3:14 - loss: 0.0737 - sparse_categorical_accuracy: 0.9762\n",
            " 97/469 [=====>........................] - ETA: 3:13 - loss: 0.0733 - sparse_categorical_accuracy: 0.9764\n",
            " 98/469 [=====>........................] - ETA: 3:12 - loss: 0.0736 - sparse_categorical_accuracy: 0.9764\n",
            " 99/469 [=====>........................] - ETA: 3:11 - loss: 0.0740 - sparse_categorical_accuracy: 0.9764\n",
            "100/469 [=====>........................] - ETA: 3:11 - loss: 0.0744 - sparse_categorical_accuracy: 0.9762\n",
            "101/469 [=====>........................] - ETA: 3:10 - loss: 0.0741 - sparse_categorical_accuracy: 0.9763\n",
            "102/469 [=====>........................] - ETA: 3:09 - loss: 0.0743 - sparse_categorical_accuracy: 0.9761\n",
            "103/469 [=====>........................] - ETA: 3:09 - loss: 0.0744 - sparse_categorical_accuracy: 0.9760\n",
            "104/469 [=====>........................] - ETA: 3:08 - loss: 0.0746 - sparse_categorical_accuracy: 0.9759\n",
            "105/469 [=====>........................] - ETA: 3:07 - loss: 0.0748 - sparse_categorical_accuracy: 0.9758\n",
            "106/469 [=====>........................] - ETA: 3:07 - loss: 0.0759 - sparse_categorical_accuracy: 0.9756\n",
            "107/469 [=====>........................] - ETA: 3:06 - loss: 0.0755 - sparse_categorical_accuracy: 0.9757\n",
            "108/469 [=====>........................] - ETA: 3:05 - loss: 0.0751 - sparse_categorical_accuracy: 0.9758\n",
            "109/469 [=====>........................] - ETA: 3:05 - loss: 0.0754 - sparse_categorical_accuracy: 0.9758\n",
            "110/469 [======>.......................] - ETA: 3:05 - loss: 0.0753 - sparse_categorical_accuracy: 0.9759\n",
            "111/469 [======>.......................] - ETA: 3:05 - loss: 0.0751 - sparse_categorical_accuracy: 0.9759\n",
            "112/469 [======>.......................] - ETA: 3:05 - loss: 0.0757 - sparse_categorical_accuracy: 0.9759\n",
            "113/469 [======>.......................] - ETA: 3:05 - loss: 0.0756 - sparse_categorical_accuracy: 0.9759\n",
            "114/469 [======>.......................] - ETA: 3:05 - loss: 0.0753 - sparse_categorical_accuracy: 0.9759\n",
            "115/469 [======>.......................] - ETA: 3:04 - loss: 0.0752 - sparse_categorical_accuracy: 0.9758\n",
            "116/469 [======>.......................] - ETA: 3:04 - loss: 0.0759 - sparse_categorical_accuracy: 0.9756\n",
            "117/469 [======>.......................] - ETA: 3:03 - loss: 0.0764 - sparse_categorical_accuracy: 0.9754\n",
            "118/469 [======>.......................] - ETA: 3:03 - loss: 0.0764 - sparse_categorical_accuracy: 0.9753\n",
            "119/469 [======>.......................] - ETA: 3:02 - loss: 0.0763 - sparse_categorical_accuracy: 0.9753\n",
            "120/469 [======>.......................] - ETA: 3:01 - loss: 0.0760 - sparse_categorical_accuracy: 0.9754\n",
            "121/469 [======>.......................] - ETA: 3:01 - loss: 0.0760 - sparse_categorical_accuracy: 0.9755\n",
            "122/469 [======>.......................] - ETA: 3:00 - loss: 0.0772 - sparse_categorical_accuracy: 0.9752\n",
            "123/469 [======>.......................] - ETA: 2:59 - loss: 0.0773 - sparse_categorical_accuracy: 0.9752\n",
            "124/469 [======>.......................] - ETA: 2:59 - loss: 0.0771 - sparse_categorical_accuracy: 0.9752\n",
            "125/469 [======>.......................] - ETA: 2:58 - loss: 0.0767 - sparse_categorical_accuracy: 0.9753\n",
            "126/469 [=======>......................] - ETA: 2:57 - loss: 0.0764 - sparse_categorical_accuracy: 0.9754\n",
            "127/469 [=======>......................] - ETA: 2:57 - loss: 0.0761 - sparse_categorical_accuracy: 0.9755\n",
            "128/469 [=======>......................] - ETA: 2:56 - loss: 0.0759 - sparse_categorical_accuracy: 0.9755\n",
            "129/469 [=======>......................] - ETA: 2:55 - loss: 0.0758 - sparse_categorical_accuracy: 0.9755\n",
            "130/469 [=======>......................] - ETA: 2:55 - loss: 0.0757 - sparse_categorical_accuracy: 0.9755\n",
            "131/469 [=======>......................] - ETA: 2:54 - loss: 0.0762 - sparse_categorical_accuracy: 0.9756\n",
            "132/469 [=======>......................] - ETA: 2:54 - loss: 0.0765 - sparse_categorical_accuracy: 0.9756\n",
            "133/469 [=======>......................] - ETA: 2:53 - loss: 0.0766 - sparse_categorical_accuracy: 0.9756\n",
            "134/469 [=======>......................] - ETA: 2:52 - loss: 0.0763 - sparse_categorical_accuracy: 0.9757\n",
            "135/469 [=======>......................] - ETA: 2:52 - loss: 0.0761 - sparse_categorical_accuracy: 0.9758\n",
            "136/469 [=======>......................] - ETA: 2:52 - loss: 0.0764 - sparse_categorical_accuracy: 0.9757\n",
            "137/469 [=======>......................] - ETA: 2:52 - loss: 0.0765 - sparse_categorical_accuracy: 0.9757\n",
            "138/469 [=======>......................] - ETA: 2:52 - loss: 0.0762 - sparse_categorical_accuracy: 0.9757\n",
            "139/469 [=======>......................] - ETA: 2:52 - loss: 0.0770 - sparse_categorical_accuracy: 0.9755\n",
            "140/469 [=======>......................] - ETA: 2:51 - loss: 0.0769 - sparse_categorical_accuracy: 0.9756\n",
            "141/469 [========>.....................] - ETA: 2:51 - loss: 0.0766 - sparse_categorical_accuracy: 0.9757\n",
            "142/469 [========>.....................] - ETA: 2:50 - loss: 0.0765 - sparse_categorical_accuracy: 0.9757\n",
            "143/469 [========>.....................] - ETA: 2:49 - loss: 0.0768 - sparse_categorical_accuracy: 0.9755\n",
            "144/469 [========>.....................] - ETA: 2:49 - loss: 0.0773 - sparse_categorical_accuracy: 0.9754\n",
            "145/469 [========>.....................] - ETA: 2:48 - loss: 0.0775 - sparse_categorical_accuracy: 0.9753\n",
            "146/469 [========>.....................] - ETA: 2:48 - loss: 0.0772 - sparse_categorical_accuracy: 0.9754\n",
            "147/469 [========>.....................] - ETA: 2:47 - loss: 0.0769 - sparse_categorical_accuracy: 0.9755\n",
            "148/469 [========>.....................] - ETA: 2:46 - loss: 0.0766 - sparse_categorical_accuracy: 0.9756\n",
            "149/469 [========>.....................] - ETA: 2:46 - loss: 0.0764 - sparse_categorical_accuracy: 0.9757\n",
            "150/469 [========>.....................] - ETA: 2:45 - loss: 0.0763 - sparse_categorical_accuracy: 0.9757\n",
            "151/469 [========>.....................] - ETA: 2:44 - loss: 0.0770 - sparse_categorical_accuracy: 0.9756\n",
            "152/469 [========>.....................] - ETA: 2:44 - loss: 0.0767 - sparse_categorical_accuracy: 0.9756\n",
            "153/469 [========>.....................] - ETA: 2:43 - loss: 0.0770 - sparse_categorical_accuracy: 0.9756\n",
            "154/469 [========>.....................] - ETA: 2:43 - loss: 0.0776 - sparse_categorical_accuracy: 0.9754\n",
            "155/469 [========>.....................] - ETA: 2:42 - loss: 0.0778 - sparse_categorical_accuracy: 0.9754\n",
            "156/469 [========>.....................] - ETA: 2:41 - loss: 0.0779 - sparse_categorical_accuracy: 0.9754\n",
            "157/469 [=========>....................] - ETA: 2:41 - loss: 0.0780 - sparse_categorical_accuracy: 0.9754\n",
            "158/469 [=========>....................] - ETA: 2:40 - loss: 0.0787 - sparse_categorical_accuracy: 0.9751\n",
            "159/469 [=========>....................] - ETA: 2:40 - loss: 0.0792 - sparse_categorical_accuracy: 0.9750\n",
            "160/469 [=========>....................] - ETA: 2:39 - loss: 0.0795 - sparse_categorical_accuracy: 0.9749\n",
            "161/469 [=========>....................] - ETA: 2:39 - loss: 0.0798 - sparse_categorical_accuracy: 0.9749\n",
            "162/469 [=========>....................] - ETA: 2:39 - loss: 0.0803 - sparse_categorical_accuracy: 0.9748\n",
            "163/469 [=========>....................] - ETA: 2:39 - loss: 0.0805 - sparse_categorical_accuracy: 0.9747\n",
            "164/469 [=========>....................] - ETA: 2:39 - loss: 0.0803 - sparse_categorical_accuracy: 0.9748\n",
            "165/469 [=========>....................] - ETA: 2:39 - loss: 0.0803 - sparse_categorical_accuracy: 0.9749\n",
            "166/469 [=========>....................] - ETA: 2:38 - loss: 0.0801 - sparse_categorical_accuracy: 0.9750\n",
            "167/469 [=========>....................] - ETA: 2:37 - loss: 0.0800 - sparse_categorical_accuracy: 0.9750\n",
            "168/469 [=========>....................] - ETA: 2:37 - loss: 0.0801 - sparse_categorical_accuracy: 0.9749\n",
            "169/469 [=========>....................] - ETA: 2:36 - loss: 0.0798 - sparse_categorical_accuracy: 0.9751\n",
            "170/469 [=========>....................] - ETA: 2:36 - loss: 0.0795 - sparse_categorical_accuracy: 0.9752\n",
            "171/469 [=========>....................] - ETA: 2:35 - loss: 0.0795 - sparse_categorical_accuracy: 0.9752\n",
            "172/469 [==========>...................] - ETA: 2:35 - loss: 0.0798 - sparse_categorical_accuracy: 0.9751\n",
            "173/469 [==========>...................] - ETA: 2:34 - loss: 0.0796 - sparse_categorical_accuracy: 0.9752\n",
            "174/469 [==========>...................] - ETA: 2:33 - loss: 0.0794 - sparse_categorical_accuracy: 0.9752\n",
            "175/469 [==========>...................] - ETA: 2:33 - loss: 0.0794 - sparse_categorical_accuracy: 0.9752\n",
            "176/469 [==========>...................] - ETA: 2:32 - loss: 0.0798 - sparse_categorical_accuracy: 0.9751\n",
            "177/469 [==========>...................] - ETA: 2:31 - loss: 0.0800 - sparse_categorical_accuracy: 0.9750\n",
            "178/469 [==========>...................] - ETA: 2:31 - loss: 0.0803 - sparse_categorical_accuracy: 0.9749\n",
            "179/469 [==========>...................] - ETA: 2:30 - loss: 0.0803 - sparse_categorical_accuracy: 0.9749\n",
            "180/469 [==========>...................] - ETA: 2:30 - loss: 0.0802 - sparse_categorical_accuracy: 0.9750\n",
            "181/469 [==========>...................] - ETA: 2:29 - loss: 0.0801 - sparse_categorical_accuracy: 0.9750\n",
            "182/469 [==========>...................] - ETA: 2:29 - loss: 0.0800 - sparse_categorical_accuracy: 0.9750\n",
            "183/469 [==========>...................] - ETA: 2:28 - loss: 0.0801 - sparse_categorical_accuracy: 0.9749\n",
            "184/469 [==========>...................] - ETA: 2:27 - loss: 0.0801 - sparse_categorical_accuracy: 0.9749\n",
            "185/469 [==========>...................] - ETA: 2:27 - loss: 0.0800 - sparse_categorical_accuracy: 0.9750\n",
            "186/469 [==========>...................] - ETA: 2:27 - loss: 0.0799 - sparse_categorical_accuracy: 0.9750\n",
            "187/469 [==========>...................] - ETA: 2:26 - loss: 0.0799 - sparse_categorical_accuracy: 0.9749\n",
            "188/469 [===========>..................] - ETA: 2:26 - loss: 0.0796 - sparse_categorical_accuracy: 0.9750\n",
            "189/469 [===========>..................] - ETA: 2:26 - loss: 0.0797 - sparse_categorical_accuracy: 0.9750\n",
            "190/469 [===========>..................] - ETA: 2:26 - loss: 0.0796 - sparse_categorical_accuracy: 0.9750\n",
            "191/469 [===========>..................] - ETA: 2:25 - loss: 0.0796 - sparse_categorical_accuracy: 0.9750\n",
            "192/469 [===========>..................] - ETA: 2:24 - loss: 0.0798 - sparse_categorical_accuracy: 0.9750\n",
            "193/469 [===========>..................] - ETA: 2:24 - loss: 0.0798 - sparse_categorical_accuracy: 0.9750\n",
            "194/469 [===========>..................] - ETA: 2:23 - loss: 0.0797 - sparse_categorical_accuracy: 0.9750\n",
            "195/469 [===========>..................] - ETA: 2:23 - loss: 0.0796 - sparse_categorical_accuracy: 0.9750\n",
            "196/469 [===========>..................] - ETA: 2:22 - loss: 0.0799 - sparse_categorical_accuracy: 0.9749\n",
            "197/469 [===========>..................] - ETA: 2:21 - loss: 0.0798 - sparse_categorical_accuracy: 0.9749\n",
            "198/469 [===========>..................] - ETA: 2:21 - loss: 0.0796 - sparse_categorical_accuracy: 0.9750\n",
            "199/469 [===========>..................] - ETA: 2:20 - loss: 0.0797 - sparse_categorical_accuracy: 0.9750\n",
            "200/469 [===========>..................] - ETA: 2:20 - loss: 0.0795 - sparse_categorical_accuracy: 0.9750\n",
            "201/469 [===========>..................] - ETA: 2:19 - loss: 0.0793 - sparse_categorical_accuracy: 0.9751\n",
            "202/469 [===========>..................] - ETA: 2:19 - loss: 0.0791 - sparse_categorical_accuracy: 0.9752\n",
            "203/469 [===========>..................] - ETA: 2:18 - loss: 0.0791 - sparse_categorical_accuracy: 0.9752\n",
            "204/469 [============>.................] - ETA: 2:17 - loss: 0.0790 - sparse_categorical_accuracy: 0.9752\n",
            "205/469 [============>.................] - ETA: 2:17 - loss: 0.0789 - sparse_categorical_accuracy: 0.9753\n",
            "206/469 [============>.................] - ETA: 2:16 - loss: 0.0791 - sparse_categorical_accuracy: 0.9752\n",
            "207/469 [============>.................] - ETA: 2:16 - loss: 0.0789 - sparse_categorical_accuracy: 0.9753\n",
            "208/469 [============>.................] - ETA: 2:15 - loss: 0.0788 - sparse_categorical_accuracy: 0.9754\n",
            "209/469 [============>.................] - ETA: 2:15 - loss: 0.0789 - sparse_categorical_accuracy: 0.9753\n",
            "210/469 [============>.................] - ETA: 2:14 - loss: 0.0789 - sparse_categorical_accuracy: 0.9754\n",
            "211/469 [============>.................] - ETA: 2:13 - loss: 0.0786 - sparse_categorical_accuracy: 0.9755\n",
            "212/469 [============>.................] - ETA: 2:13 - loss: 0.0785 - sparse_categorical_accuracy: 0.9755\n",
            "213/469 [============>.................] - ETA: 2:13 - loss: 0.0783 - sparse_categorical_accuracy: 0.9756\n",
            "214/469 [============>.................] - ETA: 2:13 - loss: 0.0785 - sparse_categorical_accuracy: 0.9756\n",
            "215/469 [============>.................] - ETA: 2:12 - loss: 0.0783 - sparse_categorical_accuracy: 0.9756\n",
            "216/469 [============>.................] - ETA: 2:12 - loss: 0.0782 - sparse_categorical_accuracy: 0.9756\n",
            "217/469 [============>.................] - ETA: 2:11 - loss: 0.0782 - sparse_categorical_accuracy: 0.9756\n",
            "218/469 [============>.................] - ETA: 2:11 - loss: 0.0782 - sparse_categorical_accuracy: 0.9755\n",
            "219/469 [=============>................] - ETA: 2:10 - loss: 0.0785 - sparse_categorical_accuracy: 0.9755\n",
            "220/469 [=============>................] - ETA: 2:10 - loss: 0.0782 - sparse_categorical_accuracy: 0.9756\n",
            "221/469 [=============>................] - ETA: 2:09 - loss: 0.0781 - sparse_categorical_accuracy: 0.9756\n",
            "222/469 [=============>................] - ETA: 2:08 - loss: 0.0781 - sparse_categorical_accuracy: 0.9756\n",
            "223/469 [=============>................] - ETA: 2:08 - loss: 0.0787 - sparse_categorical_accuracy: 0.9757\n",
            "224/469 [=============>................] - ETA: 2:07 - loss: 0.0788 - sparse_categorical_accuracy: 0.9756\n",
            "225/469 [=============>................] - ETA: 2:07 - loss: 0.0786 - sparse_categorical_accuracy: 0.9757\n",
            "226/469 [=============>................] - ETA: 2:06 - loss: 0.0789 - sparse_categorical_accuracy: 0.9756\n",
            "227/469 [=============>................] - ETA: 2:06 - loss: 0.0789 - sparse_categorical_accuracy: 0.9756\n",
            "228/469 [=============>................] - ETA: 2:05 - loss: 0.0788 - sparse_categorical_accuracy: 0.9755\n",
            "229/469 [=============>................] - ETA: 2:05 - loss: 0.0790 - sparse_categorical_accuracy: 0.9755\n",
            "230/469 [=============>................] - ETA: 2:04 - loss: 0.0792 - sparse_categorical_accuracy: 0.9754\n",
            "231/469 [=============>................] - ETA: 2:03 - loss: 0.0792 - sparse_categorical_accuracy: 0.9753\n",
            "232/469 [=============>................] - ETA: 2:03 - loss: 0.0791 - sparse_categorical_accuracy: 0.9754\n",
            "233/469 [=============>................] - ETA: 2:02 - loss: 0.0789 - sparse_categorical_accuracy: 0.9755\n",
            "234/469 [=============>................] - ETA: 2:02 - loss: 0.0790 - sparse_categorical_accuracy: 0.9754\n",
            "235/469 [==============>...............] - ETA: 2:01 - loss: 0.0789 - sparse_categorical_accuracy: 0.9754\n",
            "236/469 [==============>...............] - ETA: 2:01 - loss: 0.0789 - sparse_categorical_accuracy: 0.9754\n",
            "237/469 [==============>...............] - ETA: 2:00 - loss: 0.0790 - sparse_categorical_accuracy: 0.9754\n",
            "238/469 [==============>...............] - ETA: 2:00 - loss: 0.0789 - sparse_categorical_accuracy: 0.9754\n",
            "239/469 [==============>...............] - ETA: 2:00 - loss: 0.0788 - sparse_categorical_accuracy: 0.9754\n",
            "240/469 [==============>...............] - ETA: 1:59 - loss: 0.0788 - sparse_categorical_accuracy: 0.9754\n",
            "241/469 [==============>...............] - ETA: 1:59 - loss: 0.0787 - sparse_categorical_accuracy: 0.9755\n",
            "242/469 [==============>...............] - ETA: 1:59 - loss: 0.0790 - sparse_categorical_accuracy: 0.9754\n",
            "243/469 [==============>...............] - ETA: 1:58 - loss: 0.0788 - sparse_categorical_accuracy: 0.9754\n",
            "244/469 [==============>...............] - ETA: 1:57 - loss: 0.0788 - sparse_categorical_accuracy: 0.9755\n",
            "245/469 [==============>...............] - ETA: 1:57 - loss: 0.0786 - sparse_categorical_accuracy: 0.9755\n",
            "246/469 [==============>...............] - ETA: 1:56 - loss: 0.0786 - sparse_categorical_accuracy: 0.9755\n",
            "247/469 [==============>...............] - ETA: 1:56 - loss: 0.0786 - sparse_categorical_accuracy: 0.9756\n",
            "248/469 [==============>...............] - ETA: 1:55 - loss: 0.0784 - sparse_categorical_accuracy: 0.9756\n",
            "249/469 [==============>...............] - ETA: 1:55 - loss: 0.0789 - sparse_categorical_accuracy: 0.9755\n",
            "250/469 [==============>...............] - ETA: 1:54 - loss: 0.0789 - sparse_categorical_accuracy: 0.9756\n",
            "251/469 [===============>..............] - ETA: 1:53 - loss: 0.0788 - sparse_categorical_accuracy: 0.9756\n",
            "252/469 [===============>..............] - ETA: 1:53 - loss: 0.0787 - sparse_categorical_accuracy: 0.9756\n",
            "253/469 [===============>..............] - ETA: 1:52 - loss: 0.0787 - sparse_categorical_accuracy: 0.9756\n",
            "254/469 [===============>..............] - ETA: 1:52 - loss: 0.0787 - sparse_categorical_accuracy: 0.9756\n",
            "255/469 [===============>..............] - ETA: 1:51 - loss: 0.0787 - sparse_categorical_accuracy: 0.9756\n",
            "256/469 [===============>..............] - ETA: 1:51 - loss: 0.0788 - sparse_categorical_accuracy: 0.9756\n",
            "257/469 [===============>..............] - ETA: 1:50 - loss: 0.0787 - sparse_categorical_accuracy: 0.9756\n",
            "258/469 [===============>..............] - ETA: 1:50 - loss: 0.0787 - sparse_categorical_accuracy: 0.9756\n",
            "259/469 [===============>..............] - ETA: 1:49 - loss: 0.0785 - sparse_categorical_accuracy: 0.9757\n",
            "260/469 [===============>..............] - ETA: 1:48 - loss: 0.0785 - sparse_categorical_accuracy: 0.9757\n",
            "261/469 [===============>..............] - ETA: 1:48 - loss: 0.0784 - sparse_categorical_accuracy: 0.9758\n",
            "262/469 [===============>..............] - ETA: 1:47 - loss: 0.0784 - sparse_categorical_accuracy: 0.9758\n",
            "263/469 [===============>..............] - ETA: 1:47 - loss: 0.0785 - sparse_categorical_accuracy: 0.9757\n",
            "264/469 [===============>..............] - ETA: 1:46 - loss: 0.0785 - sparse_categorical_accuracy: 0.9757\n",
            "265/469 [===============>..............] - ETA: 1:46 - loss: 0.0784 - sparse_categorical_accuracy: 0.9757\n",
            "266/469 [================>.............] - ETA: 1:46 - loss: 0.0782 - sparse_categorical_accuracy: 0.9758\n",
            "267/469 [================>.............] - ETA: 1:45 - loss: 0.0781 - sparse_categorical_accuracy: 0.9758\n",
            "268/469 [================>.............] - ETA: 1:45 - loss: 0.0780 - sparse_categorical_accuracy: 0.9759\n",
            "269/469 [================>.............] - ETA: 1:44 - loss: 0.0778 - sparse_categorical_accuracy: 0.9760\n",
            "270/469 [================>.............] - ETA: 1:44 - loss: 0.0779 - sparse_categorical_accuracy: 0.9760\n",
            "271/469 [================>.............] - ETA: 1:43 - loss: 0.0781 - sparse_categorical_accuracy: 0.9759\n",
            "272/469 [================>.............] - ETA: 1:43 - loss: 0.0782 - sparse_categorical_accuracy: 0.9759\n",
            "273/469 [================>.............] - ETA: 1:42 - loss: 0.0782 - sparse_categorical_accuracy: 0.9759\n",
            "274/469 [================>.............] - ETA: 1:42 - loss: 0.0781 - sparse_categorical_accuracy: 0.9759\n",
            "275/469 [================>.............] - ETA: 1:41 - loss: 0.0780 - sparse_categorical_accuracy: 0.9759\n",
            "276/469 [================>.............] - ETA: 1:40 - loss: 0.0779 - sparse_categorical_accuracy: 0.9759\n",
            "277/469 [================>.............] - ETA: 1:40 - loss: 0.0780 - sparse_categorical_accuracy: 0.9759\n",
            "278/469 [================>.............] - ETA: 1:39 - loss: 0.0781 - sparse_categorical_accuracy: 0.9759\n",
            "279/469 [================>.............] - ETA: 1:39 - loss: 0.0784 - sparse_categorical_accuracy: 0.9759\n",
            "280/469 [================>.............] - ETA: 1:38 - loss: 0.0782 - sparse_categorical_accuracy: 0.9759\n",
            "281/469 [================>.............] - ETA: 1:38 - loss: 0.0781 - sparse_categorical_accuracy: 0.9760\n",
            "282/469 [=================>............] - ETA: 1:37 - loss: 0.0782 - sparse_categorical_accuracy: 0.9760\n",
            "283/469 [=================>............] - ETA: 1:37 - loss: 0.0783 - sparse_categorical_accuracy: 0.9760\n",
            "284/469 [=================>............] - ETA: 1:36 - loss: 0.0783 - sparse_categorical_accuracy: 0.9760\n",
            "285/469 [=================>............] - ETA: 1:35 - loss: 0.0781 - sparse_categorical_accuracy: 0.9761\n",
            "286/469 [=================>............] - ETA: 1:35 - loss: 0.0780 - sparse_categorical_accuracy: 0.9761\n",
            "287/469 [=================>............] - ETA: 1:34 - loss: 0.0780 - sparse_categorical_accuracy: 0.9761\n",
            "288/469 [=================>............] - ETA: 1:34 - loss: 0.0779 - sparse_categorical_accuracy: 0.9762\n",
            "289/469 [=================>............] - ETA: 1:33 - loss: 0.0778 - sparse_categorical_accuracy: 0.9762\n",
            "290/469 [=================>............] - ETA: 1:33 - loss: 0.0778 - sparse_categorical_accuracy: 0.9762\n",
            "291/469 [=================>............] - ETA: 1:33 - loss: 0.0782 - sparse_categorical_accuracy: 0.9761\n",
            "292/469 [=================>............] - ETA: 1:32 - loss: 0.0782 - sparse_categorical_accuracy: 0.9760\n",
            "293/469 [=================>............] - ETA: 1:32 - loss: 0.0783 - sparse_categorical_accuracy: 0.9759\n",
            "294/469 [=================>............] - ETA: 1:31 - loss: 0.0786 - sparse_categorical_accuracy: 0.9759\n",
            "295/469 [=================>............] - ETA: 1:31 - loss: 0.0786 - sparse_categorical_accuracy: 0.9759\n",
            "296/469 [=================>............] - ETA: 1:30 - loss: 0.0786 - sparse_categorical_accuracy: 0.9759\n",
            "297/469 [=================>............] - ETA: 1:30 - loss: 0.0785 - sparse_categorical_accuracy: 0.9759\n",
            "298/469 [==================>...........] - ETA: 1:29 - loss: 0.0786 - sparse_categorical_accuracy: 0.9759\n",
            "299/469 [==================>...........] - ETA: 1:29 - loss: 0.0784 - sparse_categorical_accuracy: 0.9759\n",
            "300/469 [==================>...........] - ETA: 1:28 - loss: 0.0784 - sparse_categorical_accuracy: 0.9759\n",
            "301/469 [==================>...........] - ETA: 1:28 - loss: 0.0785 - sparse_categorical_accuracy: 0.9759\n",
            "302/469 [==================>...........] - ETA: 1:27 - loss: 0.0786 - sparse_categorical_accuracy: 0.9758\n",
            "303/469 [==================>...........] - ETA: 1:26 - loss: 0.0785 - sparse_categorical_accuracy: 0.9758\n",
            "304/469 [==================>...........] - ETA: 1:26 - loss: 0.0785 - sparse_categorical_accuracy: 0.9758\n",
            "305/469 [==================>...........] - ETA: 1:25 - loss: 0.0784 - sparse_categorical_accuracy: 0.9758\n",
            "306/469 [==================>...........] - ETA: 1:25 - loss: 0.0784 - sparse_categorical_accuracy: 0.9758\n",
            "307/469 [==================>...........] - ETA: 1:24 - loss: 0.0783 - sparse_categorical_accuracy: 0.9758\n",
            "308/469 [==================>...........] - ETA: 1:24 - loss: 0.0783 - sparse_categorical_accuracy: 0.9759\n",
            "309/469 [==================>...........] - ETA: 1:23 - loss: 0.0782 - sparse_categorical_accuracy: 0.9759\n",
            "310/469 [==================>...........] - ETA: 1:23 - loss: 0.0782 - sparse_categorical_accuracy: 0.9759\n",
            "311/469 [==================>...........] - ETA: 1:22 - loss: 0.0784 - sparse_categorical_accuracy: 0.9757\n",
            "312/469 [==================>...........] - ETA: 1:22 - loss: 0.0785 - sparse_categorical_accuracy: 0.9757\n",
            "313/469 [===================>..........] - ETA: 1:21 - loss: 0.0784 - sparse_categorical_accuracy: 0.9757\n",
            "314/469 [===================>..........] - ETA: 1:21 - loss: 0.0783 - sparse_categorical_accuracy: 0.9758\n",
            "315/469 [===================>..........] - ETA: 1:20 - loss: 0.0783 - sparse_categorical_accuracy: 0.9758\n",
            "316/469 [===================>..........] - ETA: 1:20 - loss: 0.0784 - sparse_categorical_accuracy: 0.9757\n",
            "317/469 [===================>..........] - ETA: 1:19 - loss: 0.0785 - sparse_categorical_accuracy: 0.9757\n",
            "318/469 [===================>..........] - ETA: 1:19 - loss: 0.0783 - sparse_categorical_accuracy: 0.9758\n",
            "319/469 [===================>..........] - ETA: 1:18 - loss: 0.0783 - sparse_categorical_accuracy: 0.9758\n",
            "320/469 [===================>..........] - ETA: 1:18 - loss: 0.0784 - sparse_categorical_accuracy: 0.9757\n",
            "321/469 [===================>..........] - ETA: 1:17 - loss: 0.0784 - sparse_categorical_accuracy: 0.9757\n",
            "322/469 [===================>..........] - ETA: 1:17 - loss: 0.0784 - sparse_categorical_accuracy: 0.9757\n",
            "323/469 [===================>..........] - ETA: 1:16 - loss: 0.0785 - sparse_categorical_accuracy: 0.9757\n",
            "324/469 [===================>..........] - ETA: 1:16 - loss: 0.0784 - sparse_categorical_accuracy: 0.9757\n",
            "325/469 [===================>..........] - ETA: 1:15 - loss: 0.0784 - sparse_categorical_accuracy: 0.9757\n",
            "326/469 [===================>..........] - ETA: 1:15 - loss: 0.0783 - sparse_categorical_accuracy: 0.9757\n",
            "327/469 [===================>..........] - ETA: 1:14 - loss: 0.0781 - sparse_categorical_accuracy: 0.9758\n",
            "328/469 [===================>..........] - ETA: 1:13 - loss: 0.0781 - sparse_categorical_accuracy: 0.9758\n",
            "329/469 [====================>.........] - ETA: 1:13 - loss: 0.0782 - sparse_categorical_accuracy: 0.9758\n",
            "330/469 [====================>.........] - ETA: 1:12 - loss: 0.0780 - sparse_categorical_accuracy: 0.9759\n",
            "331/469 [====================>.........] - ETA: 1:12 - loss: 0.0780 - sparse_categorical_accuracy: 0.9759\n",
            "332/469 [====================>.........] - ETA: 1:11 - loss: 0.0779 - sparse_categorical_accuracy: 0.9759\n",
            "333/469 [====================>.........] - ETA: 1:11 - loss: 0.0780 - sparse_categorical_accuracy: 0.9759\n",
            "334/469 [====================>.........] - ETA: 1:10 - loss: 0.0779 - sparse_categorical_accuracy: 0.9759\n",
            "335/469 [====================>.........] - ETA: 1:10 - loss: 0.0777 - sparse_categorical_accuracy: 0.9760\n",
            "336/469 [====================>.........] - ETA: 1:09 - loss: 0.0776 - sparse_categorical_accuracy: 0.9760\n",
            "337/469 [====================>.........] - ETA: 1:09 - loss: 0.0777 - sparse_categorical_accuracy: 0.9760\n",
            "338/469 [====================>.........] - ETA: 1:08 - loss: 0.0777 - sparse_categorical_accuracy: 0.9761\n",
            "339/469 [====================>.........] - ETA: 1:08 - loss: 0.0775 - sparse_categorical_accuracy: 0.9761\n",
            "340/469 [====================>.........] - ETA: 1:07 - loss: 0.0774 - sparse_categorical_accuracy: 0.9761\n",
            "341/469 [====================>.........] - ETA: 1:07 - loss: 0.0774 - sparse_categorical_accuracy: 0.9761\n",
            "342/469 [====================>.........] - ETA: 1:06 - loss: 0.0774 - sparse_categorical_accuracy: 0.9761\n",
            "343/469 [====================>.........] - ETA: 1:06 - loss: 0.0774 - sparse_categorical_accuracy: 0.9760\n",
            "344/469 [=====================>........] - ETA: 1:05 - loss: 0.0772 - sparse_categorical_accuracy: 0.9761\n",
            "345/469 [=====================>........] - ETA: 1:05 - loss: 0.0772 - sparse_categorical_accuracy: 0.9760\n",
            "346/469 [=====================>........] - ETA: 1:04 - loss: 0.0771 - sparse_categorical_accuracy: 0.9761\n",
            "347/469 [=====================>........] - ETA: 1:04 - loss: 0.0770 - sparse_categorical_accuracy: 0.9761\n",
            "348/469 [=====================>........] - ETA: 1:03 - loss: 0.0770 - sparse_categorical_accuracy: 0.9761\n",
            "349/469 [=====================>........] - ETA: 1:03 - loss: 0.0771 - sparse_categorical_accuracy: 0.9760\n",
            "350/469 [=====================>........] - ETA: 1:02 - loss: 0.0771 - sparse_categorical_accuracy: 0.9760\n",
            "351/469 [=====================>........] - ETA: 1:02 - loss: 0.0770 - sparse_categorical_accuracy: 0.9760\n",
            "352/469 [=====================>........] - ETA: 1:01 - loss: 0.0770 - sparse_categorical_accuracy: 0.9761\n",
            "353/469 [=====================>........] - ETA: 1:00 - loss: 0.0769 - sparse_categorical_accuracy: 0.9761\n",
            "354/469 [=====================>........] - ETA: 1:00 - loss: 0.0768 - sparse_categorical_accuracy: 0.9761\n",
            "355/469 [=====================>........] - ETA: 59s - loss: 0.0768 - sparse_categorical_accuracy: 0.9761 \n",
            "356/469 [=====================>........] - ETA: 59s - loss: 0.0770 - sparse_categorical_accuracy: 0.9760\n",
            "357/469 [=====================>........] - ETA: 58s - loss: 0.0770 - sparse_categorical_accuracy: 0.9759\n",
            "358/469 [=====================>........] - ETA: 58s - loss: 0.0771 - sparse_categorical_accuracy: 0.9759\n",
            "359/469 [=====================>........] - ETA: 57s - loss: 0.0772 - sparse_categorical_accuracy: 0.9759\n",
            "360/469 [======================>.......] - ETA: 57s - loss: 0.0771 - sparse_categorical_accuracy: 0.9759\n",
            "361/469 [======================>.......] - ETA: 56s - loss: 0.0771 - sparse_categorical_accuracy: 0.9759\n",
            "362/469 [======================>.......] - ETA: 56s - loss: 0.0772 - sparse_categorical_accuracy: 0.9759\n",
            "363/469 [======================>.......] - ETA: 55s - loss: 0.0772 - sparse_categorical_accuracy: 0.9759\n",
            "364/469 [======================>.......] - ETA: 55s - loss: 0.0772 - sparse_categorical_accuracy: 0.9759\n",
            "365/469 [======================>.......] - ETA: 54s - loss: 0.0771 - sparse_categorical_accuracy: 0.9759\n",
            "366/469 [======================>.......] - ETA: 54s - loss: 0.0772 - sparse_categorical_accuracy: 0.9758\n",
            "367/469 [======================>.......] - ETA: 53s - loss: 0.0771 - sparse_categorical_accuracy: 0.9758\n",
            "368/469 [======================>.......] - ETA: 53s - loss: 0.0773 - sparse_categorical_accuracy: 0.9758\n",
            "369/469 [======================>.......] - ETA: 52s - loss: 0.0771 - sparse_categorical_accuracy: 0.9759\n",
            "370/469 [======================>.......] - ETA: 52s - loss: 0.0770 - sparse_categorical_accuracy: 0.9759\n",
            "371/469 [======================>.......] - ETA: 51s - loss: 0.0769 - sparse_categorical_accuracy: 0.9760\n",
            "372/469 [======================>.......] - ETA: 51s - loss: 0.0769 - sparse_categorical_accuracy: 0.9759\n",
            "373/469 [======================>.......] - ETA: 50s - loss: 0.0768 - sparse_categorical_accuracy: 0.9760\n",
            "374/469 [======================>.......] - ETA: 49s - loss: 0.0768 - sparse_categorical_accuracy: 0.9760\n",
            "375/469 [======================>.......] - ETA: 49s - loss: 0.0767 - sparse_categorical_accuracy: 0.9760\n",
            "376/469 [=======================>......] - ETA: 48s - loss: 0.0768 - sparse_categorical_accuracy: 0.9760\n",
            "377/469 [=======================>......] - ETA: 48s - loss: 0.0769 - sparse_categorical_accuracy: 0.9760\n",
            "378/469 [=======================>......] - ETA: 47s - loss: 0.0768 - sparse_categorical_accuracy: 0.9760\n",
            "379/469 [=======================>......] - ETA: 47s - loss: 0.0768 - sparse_categorical_accuracy: 0.9760\n",
            "380/469 [=======================>......] - ETA: 46s - loss: 0.0768 - sparse_categorical_accuracy: 0.9761\n",
            "381/469 [=======================>......] - ETA: 46s - loss: 0.0770 - sparse_categorical_accuracy: 0.9761\n",
            "382/469 [=======================>......] - ETA: 45s - loss: 0.0770 - sparse_categorical_accuracy: 0.9761\n",
            "383/469 [=======================>......] - ETA: 45s - loss: 0.0771 - sparse_categorical_accuracy: 0.9761\n",
            "384/469 [=======================>......] - ETA: 44s - loss: 0.0773 - sparse_categorical_accuracy: 0.9760\n",
            "385/469 [=======================>......] - ETA: 44s - loss: 0.0773 - sparse_categorical_accuracy: 0.9760\n",
            "386/469 [=======================>......] - ETA: 43s - loss: 0.0774 - sparse_categorical_accuracy: 0.9759\n",
            "387/469 [=======================>......] - ETA: 43s - loss: 0.0774 - sparse_categorical_accuracy: 0.9759\n",
            "388/469 [=======================>......] - ETA: 42s - loss: 0.0772 - sparse_categorical_accuracy: 0.9760\n",
            "389/469 [=======================>......] - ETA: 41s - loss: 0.0771 - sparse_categorical_accuracy: 0.9760\n",
            "390/469 [=======================>......] - ETA: 41s - loss: 0.0770 - sparse_categorical_accuracy: 0.9760\n",
            "391/469 [========================>.....] - ETA: 41s - loss: 0.0768 - sparse_categorical_accuracy: 0.9761\n",
            "392/469 [========================>.....] - ETA: 40s - loss: 0.0768 - sparse_categorical_accuracy: 0.9761\n",
            "393/469 [========================>.....] - ETA: 40s - loss: 0.0768 - sparse_categorical_accuracy: 0.9761\n",
            "394/469 [========================>.....] - ETA: 39s - loss: 0.0769 - sparse_categorical_accuracy: 0.9761\n",
            "395/469 [========================>.....] - ETA: 38s - loss: 0.0771 - sparse_categorical_accuracy: 0.9760\n",
            "396/469 [========================>.....] - ETA: 38s - loss: 0.0771 - sparse_categorical_accuracy: 0.9760\n",
            "397/469 [========================>.....] - ETA: 37s - loss: 0.0771 - sparse_categorical_accuracy: 0.9760\n",
            "398/469 [========================>.....] - ETA: 37s - loss: 0.0770 - sparse_categorical_accuracy: 0.9760\n",
            "399/469 [========================>.....] - ETA: 36s - loss: 0.0770 - sparse_categorical_accuracy: 0.9760\n",
            "400/469 [========================>.....] - ETA: 36s - loss: 0.0769 - sparse_categorical_accuracy: 0.9761\n",
            "401/469 [========================>.....] - ETA: 35s - loss: 0.0768 - sparse_categorical_accuracy: 0.9761\n",
            "402/469 [========================>.....] - ETA: 35s - loss: 0.0768 - sparse_categorical_accuracy: 0.9761\n",
            "403/469 [========================>.....] - ETA: 34s - loss: 0.0768 - sparse_categorical_accuracy: 0.9761\n",
            "404/469 [========================>.....] - ETA: 34s - loss: 0.0768 - sparse_categorical_accuracy: 0.9761\n",
            "405/469 [========================>.....] - ETA: 33s - loss: 0.0768 - sparse_categorical_accuracy: 0.9761\n",
            "406/469 [========================>.....] - ETA: 33s - loss: 0.0767 - sparse_categorical_accuracy: 0.9761\n",
            "407/469 [=========================>....] - ETA: 32s - loss: 0.0769 - sparse_categorical_accuracy: 0.9760\n",
            "408/469 [=========================>....] - ETA: 32s - loss: 0.0769 - sparse_categorical_accuracy: 0.9761\n",
            "409/469 [=========================>....] - ETA: 31s - loss: 0.0768 - sparse_categorical_accuracy: 0.9761\n",
            "410/469 [=========================>....] - ETA: 30s - loss: 0.0769 - sparse_categorical_accuracy: 0.9761\n",
            "411/469 [=========================>....] - ETA: 30s - loss: 0.0769 - sparse_categorical_accuracy: 0.9761\n",
            "412/469 [=========================>....] - ETA: 29s - loss: 0.0768 - sparse_categorical_accuracy: 0.9761\n",
            "413/469 [=========================>....] - ETA: 29s - loss: 0.0767 - sparse_categorical_accuracy: 0.9761\n",
            "414/469 [=========================>....] - ETA: 28s - loss: 0.0767 - sparse_categorical_accuracy: 0.9761\n",
            "415/469 [=========================>....] - ETA: 28s - loss: 0.0768 - sparse_categorical_accuracy: 0.9761\n",
            "416/469 [=========================>....] - ETA: 27s - loss: 0.0771 - sparse_categorical_accuracy: 0.9761\n",
            "417/469 [=========================>....] - ETA: 27s - loss: 0.0772 - sparse_categorical_accuracy: 0.9760\n",
            "418/469 [=========================>....] - ETA: 26s - loss: 0.0772 - sparse_categorical_accuracy: 0.9760\n",
            "419/469 [=========================>....] - ETA: 26s - loss: 0.0772 - sparse_categorical_accuracy: 0.9760\n",
            "420/469 [=========================>....] - ETA: 25s - loss: 0.0771 - sparse_categorical_accuracy: 0.9760\n",
            "421/469 [=========================>....] - ETA: 25s - loss: 0.0770 - sparse_categorical_accuracy: 0.9760\n",
            "422/469 [=========================>....] - ETA: 24s - loss: 0.0770 - sparse_categorical_accuracy: 0.9760\n",
            "423/469 [==========================>...] - ETA: 24s - loss: 0.0770 - sparse_categorical_accuracy: 0.9760\n",
            "424/469 [==========================>...] - ETA: 23s - loss: 0.0769 - sparse_categorical_accuracy: 0.9760\n",
            "425/469 [==========================>...] - ETA: 23s - loss: 0.0769 - sparse_categorical_accuracy: 0.9760\n",
            "426/469 [==========================>...] - ETA: 22s - loss: 0.0768 - sparse_categorical_accuracy: 0.9760\n",
            "427/469 [==========================>...] - ETA: 22s - loss: 0.0767 - sparse_categorical_accuracy: 0.9761\n",
            "428/469 [==========================>...] - ETA: 21s - loss: 0.0767 - sparse_categorical_accuracy: 0.9761\n",
            "429/469 [==========================>...] - ETA: 21s - loss: 0.0766 - sparse_categorical_accuracy: 0.9761\n",
            "430/469 [==========================>...] - ETA: 20s - loss: 0.0766 - sparse_categorical_accuracy: 0.9761\n",
            "431/469 [==========================>...] - ETA: 19s - loss: 0.0766 - sparse_categorical_accuracy: 0.9761\n",
            "432/469 [==========================>...] - ETA: 19s - loss: 0.0767 - sparse_categorical_accuracy: 0.9760\n",
            "433/469 [==========================>...] - ETA: 18s - loss: 0.0766 - sparse_categorical_accuracy: 0.9761\n",
            "434/469 [==========================>...] - ETA: 18s - loss: 0.0767 - sparse_categorical_accuracy: 0.9761\n",
            "435/469 [==========================>...] - ETA: 17s - loss: 0.0767 - sparse_categorical_accuracy: 0.9760\n",
            "436/469 [==========================>...] - ETA: 17s - loss: 0.0766 - sparse_categorical_accuracy: 0.9761\n",
            "437/469 [==========================>...] - ETA: 16s - loss: 0.0766 - sparse_categorical_accuracy: 0.9761\n",
            "438/469 [===========================>..] - ETA: 16s - loss: 0.0765 - sparse_categorical_accuracy: 0.9761\n",
            "439/469 [===========================>..] - ETA: 15s - loss: 0.0765 - sparse_categorical_accuracy: 0.9761\n",
            "440/469 [===========================>..] - ETA: 15s - loss: 0.0765 - sparse_categorical_accuracy: 0.9761\n",
            "441/469 [===========================>..] - ETA: 14s - loss: 0.0765 - sparse_categorical_accuracy: 0.9761\n",
            "442/469 [===========================>..] - ETA: 14s - loss: 0.0764 - sparse_categorical_accuracy: 0.9761\n",
            "443/469 [===========================>..] - ETA: 13s - loss: 0.0763 - sparse_categorical_accuracy: 0.9762\n",
            "444/469 [===========================>..] - ETA: 13s - loss: 0.0764 - sparse_categorical_accuracy: 0.9762\n",
            "445/469 [===========================>..] - ETA: 12s - loss: 0.0765 - sparse_categorical_accuracy: 0.9761\n",
            "446/469 [===========================>..] - ETA: 12s - loss: 0.0765 - sparse_categorical_accuracy: 0.9761\n",
            "447/469 [===========================>..] - ETA: 11s - loss: 0.0765 - sparse_categorical_accuracy: 0.9761\n",
            "448/469 [===========================>..] - ETA: 11s - loss: 0.0765 - sparse_categorical_accuracy: 0.9761\n",
            "449/469 [===========================>..] - ETA: 10s - loss: 0.0765 - sparse_categorical_accuracy: 0.9761\n",
            "450/469 [===========================>..] - ETA: 10s - loss: 0.0763 - sparse_categorical_accuracy: 0.9761\n",
            "451/469 [===========================>..] - ETA: 9s - loss: 0.0764 - sparse_categorical_accuracy: 0.9761 \n",
            "452/469 [===========================>..] - ETA: 8s - loss: 0.0763 - sparse_categorical_accuracy: 0.9761\n",
            "453/469 [===========================>..] - ETA: 8s - loss: 0.0763 - sparse_categorical_accuracy: 0.9761\n",
            "454/469 [============================>.] - ETA: 7s - loss: 0.0764 - sparse_categorical_accuracy: 0.9761\n",
            "455/469 [============================>.] - ETA: 7s - loss: 0.0764 - sparse_categorical_accuracy: 0.9762\n",
            "456/469 [============================>.] - ETA: 6s - loss: 0.0764 - sparse_categorical_accuracy: 0.9762\n",
            "457/469 [============================>.] - ETA: 6s - loss: 0.0764 - sparse_categorical_accuracy: 0.9762\n",
            "458/469 [============================>.] - ETA: 5s - loss: 0.0764 - sparse_categorical_accuracy: 0.9762\n",
            "459/469 [============================>.] - ETA: 5s - loss: 0.0764 - sparse_categorical_accuracy: 0.9762\n",
            "460/469 [============================>.] - ETA: 4s - loss: 0.0765 - sparse_categorical_accuracy: 0.9762\n",
            "461/469 [============================>.] - ETA: 4s - loss: 0.0764 - sparse_categorical_accuracy: 0.9762\n",
            "462/469 [============================>.] - ETA: 3s - loss: 0.0763 - sparse_categorical_accuracy: 0.9763\n",
            "463/469 [============================>.] - ETA: 3s - loss: 0.0763 - sparse_categorical_accuracy: 0.9762\n",
            "464/469 [============================>.] - ETA: 2s - loss: 0.0763 - sparse_categorical_accuracy: 0.9762\n",
            "465/469 [============================>.] - ETA: 2s - loss: 0.0763 - sparse_categorical_accuracy: 0.9762\n",
            "466/469 [============================>.] - ETA: 1s - loss: 0.0764 - sparse_categorical_accuracy: 0.9762\n",
            "467/469 [============================>.] - ETA: 1s - loss: 0.0763 - sparse_categorical_accuracy: 0.9762\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0763 - sparse_categorical_accuracy: 0.9762\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0763 - sparse_categorical_accuracy: 0.9762\n",
            " 80%|████████  | 4/5 [1:31:10<17:32, 1052.88s/trial, best loss: -0.9850000143051147]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/04/16 02:03:11 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "469/469 [==============================] - 248s 528ms/step - loss: 0.0763 - sparse_categorical_accuracy: 0.9762\n",
            "\n",
            "Epoch 5/5\n",
            "\n",
            "  1/469 [..............................] - ETA: 4:14 - loss: 0.0256 - sparse_categorical_accuracy: 0.9922\n",
            "  2/469 [..............................] - ETA: 3:36 - loss: 0.0700 - sparse_categorical_accuracy: 0.9844\n",
            "  3/469 [..............................] - ETA: 3:38 - loss: 0.0632 - sparse_categorical_accuracy: 0.9844\n",
            "  4/469 [..............................] - ETA: 3:36 - loss: 0.0608 - sparse_categorical_accuracy: 0.9824\n",
            "  5/469 [..............................] - ETA: 3:33 - loss: 0.0605 - sparse_categorical_accuracy: 0.9812\n",
            "  6/469 [..............................] - ETA: 3:39 - loss: 0.0610 - sparse_categorical_accuracy: 0.9818\n",
            "  7/469 [..............................] - ETA: 3:38 - loss: 0.0618 - sparse_categorical_accuracy: 0.9821\n",
            "  8/469 [..............................] - ETA: 3:39 - loss: 0.0612 - sparse_categorical_accuracy: 0.9824\n",
            "  9/469 [..............................] - ETA: 3:39 - loss: 0.0704 - sparse_categorical_accuracy: 0.9800\n",
            " 10/469 [..............................] - ETA: 3:39 - loss: 0.0692 - sparse_categorical_accuracy: 0.9805\n",
            " 11/469 [..............................] - ETA: 3:38 - loss: 0.0638 - sparse_categorical_accuracy: 0.9822\n",
            " 12/469 [..............................] - ETA: 3:38 - loss: 0.0641 - sparse_categorical_accuracy: 0.9818\n",
            " 13/469 [..............................] - ETA: 3:37 - loss: 0.0624 - sparse_categorical_accuracy: 0.9820\n",
            " 14/469 [..............................] - ETA: 3:37 - loss: 0.0612 - sparse_categorical_accuracy: 0.9816\n",
            " 15/469 [..............................] - ETA: 3:36 - loss: 0.0630 - sparse_categorical_accuracy: 0.9812\n",
            " 16/469 [>.............................] - ETA: 3:36 - loss: 0.0632 - sparse_categorical_accuracy: 0.9819\n",
            " 17/469 [>.............................] - ETA: 3:35 - loss: 0.0664 - sparse_categorical_accuracy: 0.9812\n",
            " 18/469 [>.............................] - ETA: 3:34 - loss: 0.0670 - sparse_categorical_accuracy: 0.9809\n",
            " 19/469 [>.............................] - ETA: 3:33 - loss: 0.0661 - sparse_categorical_accuracy: 0.9815\n",
            " 20/469 [>.............................] - ETA: 3:33 - loss: 0.0693 - sparse_categorical_accuracy: 0.9805\n",
            " 21/469 [>.............................] - ETA: 3:35 - loss: 0.0700 - sparse_categorical_accuracy: 0.9799\n",
            " 22/469 [>.............................] - ETA: 3:40 - loss: 0.0691 - sparse_categorical_accuracy: 0.9801\n",
            " 23/469 [>.............................] - ETA: 3:45 - loss: 0.0695 - sparse_categorical_accuracy: 0.9793\n",
            " 24/469 [>.............................] - ETA: 3:49 - loss: 0.0680 - sparse_categorical_accuracy: 0.9798\n",
            " 25/469 [>.............................] - ETA: 3:52 - loss: 0.0707 - sparse_categorical_accuracy: 0.9784\n",
            " 26/469 [>.............................] - ETA: 3:52 - loss: 0.0711 - sparse_categorical_accuracy: 0.9781\n",
            " 27/469 [>.............................] - ETA: 3:50 - loss: 0.0702 - sparse_categorical_accuracy: 0.9783\n",
            " 28/469 [>.............................] - ETA: 3:49 - loss: 0.0684 - sparse_categorical_accuracy: 0.9791\n",
            " 29/469 [>.............................] - ETA: 3:48 - loss: 0.0691 - sparse_categorical_accuracy: 0.9787\n",
            " 30/469 [>.............................] - ETA: 3:46 - loss: 0.0694 - sparse_categorical_accuracy: 0.9786\n",
            " 31/469 [>.............................] - ETA: 3:45 - loss: 0.0696 - sparse_categorical_accuracy: 0.9788\n",
            " 32/469 [=>............................] - ETA: 3:44 - loss: 0.0686 - sparse_categorical_accuracy: 0.9790\n",
            " 33/469 [=>............................] - ETA: 3:43 - loss: 0.0684 - sparse_categorical_accuracy: 0.9787\n",
            " 34/469 [=>............................] - ETA: 3:41 - loss: 0.0674 - sparse_categorical_accuracy: 0.9789\n",
            " 35/469 [=>............................] - ETA: 3:41 - loss: 0.0711 - sparse_categorical_accuracy: 0.9783\n",
            " 36/469 [=>............................] - ETA: 3:39 - loss: 0.0702 - sparse_categorical_accuracy: 0.9785\n",
            " 37/469 [=>............................] - ETA: 3:39 - loss: 0.0699 - sparse_categorical_accuracy: 0.9789\n",
            " 38/469 [=>............................] - ETA: 3:38 - loss: 0.0699 - sparse_categorical_accuracy: 0.9790\n",
            " 39/469 [=>............................] - ETA: 3:37 - loss: 0.0699 - sparse_categorical_accuracy: 0.9786\n",
            " 40/469 [=>............................] - ETA: 3:36 - loss: 0.0691 - sparse_categorical_accuracy: 0.9785\n",
            " 41/469 [=>............................] - ETA: 3:35 - loss: 0.0681 - sparse_categorical_accuracy: 0.9788\n",
            " 42/469 [=>............................] - ETA: 3:34 - loss: 0.0702 - sparse_categorical_accuracy: 0.9788\n",
            " 43/469 [=>............................] - ETA: 3:33 - loss: 0.0710 - sparse_categorical_accuracy: 0.9787\n",
            " 44/469 [=>............................] - ETA: 3:32 - loss: 0.0697 - sparse_categorical_accuracy: 0.9792\n",
            " 45/469 [=>............................] - ETA: 3:32 - loss: 0.0690 - sparse_categorical_accuracy: 0.9793\n",
            " 46/469 [=>............................] - ETA: 3:31 - loss: 0.0684 - sparse_categorical_accuracy: 0.9794\n",
            " 47/469 [==>...........................] - ETA: 3:31 - loss: 0.0675 - sparse_categorical_accuracy: 0.9797\n",
            " 48/469 [==>...........................] - ETA: 3:33 - loss: 0.0681 - sparse_categorical_accuracy: 0.9792\n",
            " 49/469 [==>...........................] - ETA: 3:34 - loss: 0.0680 - sparse_categorical_accuracy: 0.9791\n",
            " 50/469 [==>...........................] - ETA: 3:36 - loss: 0.0671 - sparse_categorical_accuracy: 0.9794\n",
            " 51/469 [==>...........................] - ETA: 3:37 - loss: 0.0694 - sparse_categorical_accuracy: 0.9787\n",
            " 52/469 [==>...........................] - ETA: 3:37 - loss: 0.0690 - sparse_categorical_accuracy: 0.9788\n",
            " 53/469 [==>...........................] - ETA: 3:36 - loss: 0.0699 - sparse_categorical_accuracy: 0.9786\n",
            " 54/469 [==>...........................] - ETA: 3:35 - loss: 0.0690 - sparse_categorical_accuracy: 0.9790\n",
            " 55/469 [==>...........................] - ETA: 3:34 - loss: 0.0691 - sparse_categorical_accuracy: 0.9790\n",
            " 56/469 [==>...........................] - ETA: 3:33 - loss: 0.0689 - sparse_categorical_accuracy: 0.9791\n",
            " 57/469 [==>...........................] - ETA: 3:32 - loss: 0.0685 - sparse_categorical_accuracy: 0.9789\n",
            " 58/469 [==>...........................] - ETA: 3:31 - loss: 0.0695 - sparse_categorical_accuracy: 0.9787\n",
            " 59/469 [==>...........................] - ETA: 3:30 - loss: 0.0699 - sparse_categorical_accuracy: 0.9784\n",
            " 60/469 [==>...........................] - ETA: 3:30 - loss: 0.0709 - sparse_categorical_accuracy: 0.9779\n",
            " 61/469 [==>...........................] - ETA: 3:29 - loss: 0.0709 - sparse_categorical_accuracy: 0.9778\n",
            " 62/469 [==>...........................] - ETA: 3:28 - loss: 0.0709 - sparse_categorical_accuracy: 0.9778\n",
            " 63/469 [===>..........................] - ETA: 3:27 - loss: 0.0704 - sparse_categorical_accuracy: 0.9781\n",
            " 64/469 [===>..........................] - ETA: 3:26 - loss: 0.0699 - sparse_categorical_accuracy: 0.9781\n",
            " 65/469 [===>..........................] - ETA: 3:26 - loss: 0.0695 - sparse_categorical_accuracy: 0.9784\n",
            " 66/469 [===>..........................] - ETA: 3:25 - loss: 0.0691 - sparse_categorical_accuracy: 0.9785\n",
            " 67/469 [===>..........................] - ETA: 3:24 - loss: 0.0697 - sparse_categorical_accuracy: 0.9784\n",
            " 68/469 [===>..........................] - ETA: 3:24 - loss: 0.0693 - sparse_categorical_accuracy: 0.9785\n",
            " 69/469 [===>..........................] - ETA: 3:23 - loss: 0.0695 - sparse_categorical_accuracy: 0.9783\n",
            " 70/469 [===>..........................] - ETA: 3:22 - loss: 0.0695 - sparse_categorical_accuracy: 0.9782\n",
            " 71/469 [===>..........................] - ETA: 3:22 - loss: 0.0690 - sparse_categorical_accuracy: 0.9784\n",
            " 72/469 [===>..........................] - ETA: 3:21 - loss: 0.0685 - sparse_categorical_accuracy: 0.9786\n",
            " 73/469 [===>..........................] - ETA: 3:22 - loss: 0.0682 - sparse_categorical_accuracy: 0.9786\n",
            " 74/469 [===>..........................] - ETA: 3:23 - loss: 0.0675 - sparse_categorical_accuracy: 0.9789\n",
            " 75/469 [===>..........................] - ETA: 3:23 - loss: 0.0668 - sparse_categorical_accuracy: 0.9792\n",
            " 76/469 [===>..........................] - ETA: 3:24 - loss: 0.0686 - sparse_categorical_accuracy: 0.9788\n",
            " 77/469 [===>..........................] - ETA: 3:24 - loss: 0.0682 - sparse_categorical_accuracy: 0.9789\n",
            " 78/469 [===>..........................] - ETA: 3:23 - loss: 0.0689 - sparse_categorical_accuracy: 0.9789\n",
            " 79/469 [====>.........................] - ETA: 3:22 - loss: 0.0692 - sparse_categorical_accuracy: 0.9788\n",
            " 80/469 [====>.........................] - ETA: 3:22 - loss: 0.0685 - sparse_categorical_accuracy: 0.9791\n",
            " 81/469 [====>.........................] - ETA: 3:21 - loss: 0.0688 - sparse_categorical_accuracy: 0.9790\n",
            " 82/469 [====>.........................] - ETA: 3:21 - loss: 0.0685 - sparse_categorical_accuracy: 0.9790\n",
            " 83/469 [====>.........................] - ETA: 3:20 - loss: 0.0700 - sparse_categorical_accuracy: 0.9791\n",
            " 84/469 [====>.........................] - ETA: 3:19 - loss: 0.0698 - sparse_categorical_accuracy: 0.9792\n",
            " 85/469 [====>.........................] - ETA: 3:18 - loss: 0.0697 - sparse_categorical_accuracy: 0.9793\n",
            " 86/469 [====>.........................] - ETA: 3:18 - loss: 0.0694 - sparse_categorical_accuracy: 0.9794\n",
            " 87/469 [====>.........................] - ETA: 3:17 - loss: 0.0689 - sparse_categorical_accuracy: 0.9796\n",
            " 88/469 [====>.........................] - ETA: 3:16 - loss: 0.0687 - sparse_categorical_accuracy: 0.9798\n",
            " 89/469 [====>.........................] - ETA: 3:16 - loss: 0.0683 - sparse_categorical_accuracy: 0.9798\n",
            " 90/469 [====>.........................] - ETA: 3:15 - loss: 0.0678 - sparse_categorical_accuracy: 0.9799\n",
            " 91/469 [====>.........................] - ETA: 3:14 - loss: 0.0676 - sparse_categorical_accuracy: 0.9801\n",
            " 92/469 [====>.........................] - ETA: 3:14 - loss: 0.0680 - sparse_categorical_accuracy: 0.9801\n",
            " 93/469 [====>.........................] - ETA: 3:13 - loss: 0.0685 - sparse_categorical_accuracy: 0.9799\n",
            " 94/469 [=====>........................] - ETA: 3:12 - loss: 0.0684 - sparse_categorical_accuracy: 0.9800\n",
            " 95/469 [=====>........................] - ETA: 3:12 - loss: 0.0685 - sparse_categorical_accuracy: 0.9799\n",
            " 96/469 [=====>........................] - ETA: 3:11 - loss: 0.0685 - sparse_categorical_accuracy: 0.9798\n",
            " 97/469 [=====>........................] - ETA: 3:11 - loss: 0.0682 - sparse_categorical_accuracy: 0.9799\n",
            " 98/469 [=====>........................] - ETA: 3:11 - loss: 0.0681 - sparse_categorical_accuracy: 0.9798\n",
            " 99/469 [=====>........................] - ETA: 3:11 - loss: 0.0680 - sparse_categorical_accuracy: 0.9800\n",
            "100/469 [=====>........................] - ETA: 3:12 - loss: 0.0684 - sparse_categorical_accuracy: 0.9799\n",
            "101/469 [=====>........................] - ETA: 3:12 - loss: 0.0685 - sparse_categorical_accuracy: 0.9799\n",
            "102/469 [=====>........................] - ETA: 3:12 - loss: 0.0686 - sparse_categorical_accuracy: 0.9798\n",
            "103/469 [=====>........................] - ETA: 3:11 - loss: 0.0687 - sparse_categorical_accuracy: 0.9797\n",
            "104/469 [=====>........................] - ETA: 3:10 - loss: 0.0690 - sparse_categorical_accuracy: 0.9798\n",
            "105/469 [=====>........................] - ETA: 3:10 - loss: 0.0691 - sparse_categorical_accuracy: 0.9798\n",
            "106/469 [=====>........................] - ETA: 3:09 - loss: 0.0693 - sparse_categorical_accuracy: 0.9799\n",
            "107/469 [=====>........................] - ETA: 3:08 - loss: 0.0690 - sparse_categorical_accuracy: 0.9799\n",
            "108/469 [=====>........................] - ETA: 3:08 - loss: 0.0685 - sparse_categorical_accuracy: 0.9800\n",
            "109/469 [=====>........................] - ETA: 3:07 - loss: 0.0686 - sparse_categorical_accuracy: 0.9799\n",
            "110/469 [======>.......................] - ETA: 3:06 - loss: 0.0686 - sparse_categorical_accuracy: 0.9798\n",
            "111/469 [======>.......................] - ETA: 3:06 - loss: 0.0683 - sparse_categorical_accuracy: 0.9799\n",
            "112/469 [======>.......................] - ETA: 3:05 - loss: 0.0683 - sparse_categorical_accuracy: 0.9800\n",
            "113/469 [======>.......................] - ETA: 3:04 - loss: 0.0689 - sparse_categorical_accuracy: 0.9797\n",
            "114/469 [======>.......................] - ETA: 3:04 - loss: 0.0688 - sparse_categorical_accuracy: 0.9797\n",
            "115/469 [======>.......................] - ETA: 3:03 - loss: 0.0693 - sparse_categorical_accuracy: 0.9796\n",
            "116/469 [======>.......................] - ETA: 3:02 - loss: 0.0688 - sparse_categorical_accuracy: 0.9798\n",
            "117/469 [======>.......................] - ETA: 3:02 - loss: 0.0689 - sparse_categorical_accuracy: 0.9797\n",
            "118/469 [======>.......................] - ETA: 3:01 - loss: 0.0688 - sparse_categorical_accuracy: 0.9797\n",
            "119/469 [======>.......................] - ETA: 3:01 - loss: 0.0687 - sparse_categorical_accuracy: 0.9797\n",
            "120/469 [======>.......................] - ETA: 3:00 - loss: 0.0692 - sparse_categorical_accuracy: 0.9797\n",
            "121/469 [======>.......................] - ETA: 2:59 - loss: 0.0691 - sparse_categorical_accuracy: 0.9797\n",
            "122/469 [======>.......................] - ETA: 2:59 - loss: 0.0692 - sparse_categorical_accuracy: 0.9796\n",
            "123/469 [======>.......................] - ETA: 2:58 - loss: 0.0690 - sparse_categorical_accuracy: 0.9796\n",
            "124/469 [======>.......................] - ETA: 2:58 - loss: 0.0688 - sparse_categorical_accuracy: 0.9796\n",
            "125/469 [======>.......................] - ETA: 2:59 - loss: 0.0692 - sparse_categorical_accuracy: 0.9794\n",
            "126/469 [=======>......................] - ETA: 2:59 - loss: 0.0693 - sparse_categorical_accuracy: 0.9792\n",
            "127/469 [=======>......................] - ETA: 2:59 - loss: 0.0697 - sparse_categorical_accuracy: 0.9790\n",
            "128/469 [=======>......................] - ETA: 2:58 - loss: 0.0697 - sparse_categorical_accuracy: 0.9788\n",
            "129/469 [=======>......................] - ETA: 2:58 - loss: 0.0696 - sparse_categorical_accuracy: 0.9789\n",
            "130/469 [=======>......................] - ETA: 2:57 - loss: 0.0695 - sparse_categorical_accuracy: 0.9789\n",
            "131/469 [=======>......................] - ETA: 2:56 - loss: 0.0696 - sparse_categorical_accuracy: 0.9790\n",
            "132/469 [=======>......................] - ETA: 2:56 - loss: 0.0695 - sparse_categorical_accuracy: 0.9790\n",
            "133/469 [=======>......................] - ETA: 2:55 - loss: 0.0698 - sparse_categorical_accuracy: 0.9789\n",
            "134/469 [=======>......................] - ETA: 2:54 - loss: 0.0694 - sparse_categorical_accuracy: 0.9790\n",
            "135/469 [=======>......................] - ETA: 2:54 - loss: 0.0693 - sparse_categorical_accuracy: 0.9790\n",
            "136/469 [=======>......................] - ETA: 2:53 - loss: 0.0695 - sparse_categorical_accuracy: 0.9789\n",
            "137/469 [=======>......................] - ETA: 2:52 - loss: 0.0695 - sparse_categorical_accuracy: 0.9787\n",
            "138/469 [=======>......................] - ETA: 2:52 - loss: 0.0695 - sparse_categorical_accuracy: 0.9788\n",
            "139/469 [=======>......................] - ETA: 2:51 - loss: 0.0693 - sparse_categorical_accuracy: 0.9789\n",
            "140/469 [=======>......................] - ETA: 2:50 - loss: 0.0693 - sparse_categorical_accuracy: 0.9788\n",
            "141/469 [========>.....................] - ETA: 2:50 - loss: 0.0692 - sparse_categorical_accuracy: 0.9787\n",
            "142/469 [========>.....................] - ETA: 2:49 - loss: 0.0689 - sparse_categorical_accuracy: 0.9789\n",
            "143/469 [========>.....................] - ETA: 2:49 - loss: 0.0691 - sparse_categorical_accuracy: 0.9786\n",
            "144/469 [========>.....................] - ETA: 2:48 - loss: 0.0692 - sparse_categorical_accuracy: 0.9786\n",
            "145/469 [========>.....................] - ETA: 2:47 - loss: 0.0691 - sparse_categorical_accuracy: 0.9787\n",
            "146/469 [========>.....................] - ETA: 2:47 - loss: 0.0690 - sparse_categorical_accuracy: 0.9788\n",
            "147/469 [========>.....................] - ETA: 2:46 - loss: 0.0689 - sparse_categorical_accuracy: 0.9787\n",
            "148/469 [========>.....................] - ETA: 2:45 - loss: 0.0689 - sparse_categorical_accuracy: 0.9787\n",
            "149/469 [========>.....................] - ETA: 2:45 - loss: 0.0689 - sparse_categorical_accuracy: 0.9787\n",
            "150/469 [========>.....................] - ETA: 2:45 - loss: 0.0690 - sparse_categorical_accuracy: 0.9787\n",
            "151/469 [========>.....................] - ETA: 2:45 - loss: 0.0691 - sparse_categorical_accuracy: 0.9787\n",
            "152/469 [========>.....................] - ETA: 2:45 - loss: 0.0697 - sparse_categorical_accuracy: 0.9785\n",
            "153/469 [========>.....................] - ETA: 2:45 - loss: 0.0698 - sparse_categorical_accuracy: 0.9785\n",
            "154/469 [========>.....................] - ETA: 2:44 - loss: 0.0700 - sparse_categorical_accuracy: 0.9784\n",
            "155/469 [========>.....................] - ETA: 2:44 - loss: 0.0698 - sparse_categorical_accuracy: 0.9784\n",
            "156/469 [========>.....................] - ETA: 2:43 - loss: 0.0702 - sparse_categorical_accuracy: 0.9784\n",
            "157/469 [=========>....................] - ETA: 2:42 - loss: 0.0699 - sparse_categorical_accuracy: 0.9786\n",
            "158/469 [=========>....................] - ETA: 2:42 - loss: 0.0699 - sparse_categorical_accuracy: 0.9785\n",
            "159/469 [=========>....................] - ETA: 2:41 - loss: 0.0699 - sparse_categorical_accuracy: 0.9785\n",
            "160/469 [=========>....................] - ETA: 2:41 - loss: 0.0698 - sparse_categorical_accuracy: 0.9785\n",
            "161/469 [=========>....................] - ETA: 2:40 - loss: 0.0700 - sparse_categorical_accuracy: 0.9785\n",
            "162/469 [=========>....................] - ETA: 2:39 - loss: 0.0699 - sparse_categorical_accuracy: 0.9784\n",
            "163/469 [=========>....................] - ETA: 2:39 - loss: 0.0703 - sparse_categorical_accuracy: 0.9784\n",
            "164/469 [=========>....................] - ETA: 2:38 - loss: 0.0703 - sparse_categorical_accuracy: 0.9784\n",
            "165/469 [=========>....................] - ETA: 2:38 - loss: 0.0703 - sparse_categorical_accuracy: 0.9784\n",
            "166/469 [=========>....................] - ETA: 2:37 - loss: 0.0704 - sparse_categorical_accuracy: 0.9784\n",
            "167/469 [=========>....................] - ETA: 2:36 - loss: 0.0702 - sparse_categorical_accuracy: 0.9784\n",
            "168/469 [=========>....................] - ETA: 2:36 - loss: 0.0700 - sparse_categorical_accuracy: 0.9784\n",
            "169/469 [=========>....................] - ETA: 2:35 - loss: 0.0703 - sparse_categorical_accuracy: 0.9783\n",
            "170/469 [=========>....................] - ETA: 2:35 - loss: 0.0705 - sparse_categorical_accuracy: 0.9783\n",
            "171/469 [=========>....................] - ETA: 2:34 - loss: 0.0706 - sparse_categorical_accuracy: 0.9783\n",
            "172/469 [==========>...................] - ETA: 2:33 - loss: 0.0704 - sparse_categorical_accuracy: 0.9784\n",
            "173/469 [==========>...................] - ETA: 2:33 - loss: 0.0707 - sparse_categorical_accuracy: 0.9783\n",
            "174/469 [==========>...................] - ETA: 2:32 - loss: 0.0705 - sparse_categorical_accuracy: 0.9784\n",
            "175/469 [==========>...................] - ETA: 2:32 - loss: 0.0706 - sparse_categorical_accuracy: 0.9783\n",
            "176/469 [==========>...................] - ETA: 2:32 - loss: 0.0707 - sparse_categorical_accuracy: 0.9783\n",
            "177/469 [==========>...................] - ETA: 2:32 - loss: 0.0706 - sparse_categorical_accuracy: 0.9783\n",
            "178/469 [==========>...................] - ETA: 2:32 - loss: 0.0704 - sparse_categorical_accuracy: 0.9784\n",
            "179/469 [==========>...................] - ETA: 2:31 - loss: 0.0707 - sparse_categorical_accuracy: 0.9784\n",
            "180/469 [==========>...................] - ETA: 2:31 - loss: 0.0706 - sparse_categorical_accuracy: 0.9783\n",
            "181/469 [==========>...................] - ETA: 2:30 - loss: 0.0706 - sparse_categorical_accuracy: 0.9783\n",
            "182/469 [==========>...................] - ETA: 2:30 - loss: 0.0706 - sparse_categorical_accuracy: 0.9783\n",
            "183/469 [==========>...................] - ETA: 2:29 - loss: 0.0705 - sparse_categorical_accuracy: 0.9784\n",
            "184/469 [==========>...................] - ETA: 2:28 - loss: 0.0703 - sparse_categorical_accuracy: 0.9784\n",
            "185/469 [==========>...................] - ETA: 2:28 - loss: 0.0704 - sparse_categorical_accuracy: 0.9783\n",
            "186/469 [==========>...................] - ETA: 2:27 - loss: 0.0705 - sparse_categorical_accuracy: 0.9783\n",
            "187/469 [==========>...................] - ETA: 2:27 - loss: 0.0704 - sparse_categorical_accuracy: 0.9783\n",
            "188/469 [===========>..................] - ETA: 2:26 - loss: 0.0703 - sparse_categorical_accuracy: 0.9784\n",
            "189/469 [===========>..................] - ETA: 2:26 - loss: 0.0706 - sparse_categorical_accuracy: 0.9784\n",
            "190/469 [===========>..................] - ETA: 2:25 - loss: 0.0705 - sparse_categorical_accuracy: 0.9784\n",
            "191/469 [===========>..................] - ETA: 2:24 - loss: 0.0704 - sparse_categorical_accuracy: 0.9785\n",
            "192/469 [===========>..................] - ETA: 2:24 - loss: 0.0706 - sparse_categorical_accuracy: 0.9784\n",
            "193/469 [===========>..................] - ETA: 2:23 - loss: 0.0708 - sparse_categorical_accuracy: 0.9783\n",
            "194/469 [===========>..................] - ETA: 2:23 - loss: 0.0707 - sparse_categorical_accuracy: 0.9783\n",
            "195/469 [===========>..................] - ETA: 2:22 - loss: 0.0712 - sparse_categorical_accuracy: 0.9782\n",
            "196/469 [===========>..................] - ETA: 2:21 - loss: 0.0712 - sparse_categorical_accuracy: 0.9783\n",
            "197/469 [===========>..................] - ETA: 2:21 - loss: 0.0713 - sparse_categorical_accuracy: 0.9783\n",
            "198/469 [===========>..................] - ETA: 2:20 - loss: 0.0710 - sparse_categorical_accuracy: 0.9784\n",
            "199/469 [===========>..................] - ETA: 2:20 - loss: 0.0709 - sparse_categorical_accuracy: 0.9784\n",
            "200/469 [===========>..................] - ETA: 2:19 - loss: 0.0707 - sparse_categorical_accuracy: 0.9785\n",
            "201/469 [===========>..................] - ETA: 2:19 - loss: 0.0706 - sparse_categorical_accuracy: 0.9785\n",
            "202/469 [===========>..................] - ETA: 2:19 - loss: 0.0704 - sparse_categorical_accuracy: 0.9786\n",
            "203/469 [===========>..................] - ETA: 2:19 - loss: 0.0704 - sparse_categorical_accuracy: 0.9785\n",
            "204/469 [============>.................] - ETA: 2:18 - loss: 0.0704 - sparse_categorical_accuracy: 0.9785\n",
            "205/469 [============>.................] - ETA: 2:18 - loss: 0.0702 - sparse_categorical_accuracy: 0.9785\n",
            "206/469 [============>.................] - ETA: 2:17 - loss: 0.0702 - sparse_categorical_accuracy: 0.9785\n",
            "207/469 [============>.................] - ETA: 2:17 - loss: 0.0702 - sparse_categorical_accuracy: 0.9785\n",
            "208/469 [============>.................] - ETA: 2:16 - loss: 0.0701 - sparse_categorical_accuracy: 0.9784\n",
            "209/469 [============>.................] - ETA: 2:16 - loss: 0.0700 - sparse_categorical_accuracy: 0.9784\n",
            "210/469 [============>.................] - ETA: 2:15 - loss: 0.0700 - sparse_categorical_accuracy: 0.9784\n",
            "211/469 [============>.................] - ETA: 2:14 - loss: 0.0699 - sparse_categorical_accuracy: 0.9785\n",
            "212/469 [============>.................] - ETA: 2:14 - loss: 0.0698 - sparse_categorical_accuracy: 0.9785\n",
            "213/469 [============>.................] - ETA: 2:13 - loss: 0.0697 - sparse_categorical_accuracy: 0.9785\n",
            "214/469 [============>.................] - ETA: 2:13 - loss: 0.0701 - sparse_categorical_accuracy: 0.9784\n",
            "215/469 [============>.................] - ETA: 2:12 - loss: 0.0698 - sparse_categorical_accuracy: 0.9785\n",
            "216/469 [============>.................] - ETA: 2:12 - loss: 0.0696 - sparse_categorical_accuracy: 0.9786\n",
            "217/469 [============>.................] - ETA: 2:11 - loss: 0.0700 - sparse_categorical_accuracy: 0.9784\n",
            "218/469 [============>.................] - ETA: 2:10 - loss: 0.0700 - sparse_categorical_accuracy: 0.9784\n",
            "219/469 [=============>................] - ETA: 2:10 - loss: 0.0699 - sparse_categorical_accuracy: 0.9784\n",
            "220/469 [=============>................] - ETA: 2:09 - loss: 0.0700 - sparse_categorical_accuracy: 0.9784\n",
            "221/469 [=============>................] - ETA: 2:09 - loss: 0.0700 - sparse_categorical_accuracy: 0.9784\n",
            "222/469 [=============>................] - ETA: 2:08 - loss: 0.0702 - sparse_categorical_accuracy: 0.9783\n",
            "223/469 [=============>................] - ETA: 2:07 - loss: 0.0701 - sparse_categorical_accuracy: 0.9783\n",
            "224/469 [=============>................] - ETA: 2:07 - loss: 0.0702 - sparse_categorical_accuracy: 0.9783\n",
            "225/469 [=============>................] - ETA: 2:06 - loss: 0.0705 - sparse_categorical_accuracy: 0.9782\n",
            "226/469 [=============>................] - ETA: 2:06 - loss: 0.0706 - sparse_categorical_accuracy: 0.9782\n",
            "227/469 [=============>................] - ETA: 2:06 - loss: 0.0706 - sparse_categorical_accuracy: 0.9781\n",
            "228/469 [=============>................] - ETA: 2:05 - loss: 0.0705 - sparse_categorical_accuracy: 0.9781\n",
            "229/469 [=============>................] - ETA: 2:05 - loss: 0.0705 - sparse_categorical_accuracy: 0.9781\n",
            "230/469 [=============>................] - ETA: 2:05 - loss: 0.0705 - sparse_categorical_accuracy: 0.9781\n",
            "231/469 [=============>................] - ETA: 2:04 - loss: 0.0704 - sparse_categorical_accuracy: 0.9782\n",
            "232/469 [=============>................] - ETA: 2:04 - loss: 0.0704 - sparse_categorical_accuracy: 0.9782\n",
            "233/469 [=============>................] - ETA: 2:03 - loss: 0.0704 - sparse_categorical_accuracy: 0.9782\n",
            "234/469 [=============>................] - ETA: 2:02 - loss: 0.0703 - sparse_categorical_accuracy: 0.9782\n",
            "235/469 [==============>...............] - ETA: 2:02 - loss: 0.0701 - sparse_categorical_accuracy: 0.9782\n",
            "236/469 [==============>...............] - ETA: 2:01 - loss: 0.0700 - sparse_categorical_accuracy: 0.9783\n",
            "237/469 [==============>...............] - ETA: 2:01 - loss: 0.0701 - sparse_categorical_accuracy: 0.9783\n",
            "238/469 [==============>...............] - ETA: 2:00 - loss: 0.0699 - sparse_categorical_accuracy: 0.9783\n",
            "239/469 [==============>...............] - ETA: 2:00 - loss: 0.0698 - sparse_categorical_accuracy: 0.9784\n",
            "240/469 [==============>...............] - ETA: 1:59 - loss: 0.0698 - sparse_categorical_accuracy: 0.9783\n",
            "241/469 [==============>...............] - ETA: 1:59 - loss: 0.0696 - sparse_categorical_accuracy: 0.9784\n",
            "242/469 [==============>...............] - ETA: 1:58 - loss: 0.0694 - sparse_categorical_accuracy: 0.9784\n",
            "243/469 [==============>...............] - ETA: 1:57 - loss: 0.0693 - sparse_categorical_accuracy: 0.9785\n",
            "244/469 [==============>...............] - ETA: 1:57 - loss: 0.0693 - sparse_categorical_accuracy: 0.9785\n",
            "245/469 [==============>...............] - ETA: 1:56 - loss: 0.0691 - sparse_categorical_accuracy: 0.9785\n",
            "246/469 [==============>...............] - ETA: 1:56 - loss: 0.0692 - sparse_categorical_accuracy: 0.9785\n",
            "247/469 [==============>...............] - ETA: 1:55 - loss: 0.0692 - sparse_categorical_accuracy: 0.9785\n",
            "248/469 [==============>...............] - ETA: 1:55 - loss: 0.0690 - sparse_categorical_accuracy: 0.9786\n",
            "249/469 [==============>...............] - ETA: 1:54 - loss: 0.0689 - sparse_categorical_accuracy: 0.9786\n",
            "250/469 [==============>...............] - ETA: 1:53 - loss: 0.0689 - sparse_categorical_accuracy: 0.9786\n",
            "251/469 [===============>..............] - ETA: 1:53 - loss: 0.0692 - sparse_categorical_accuracy: 0.9786\n",
            "252/469 [===============>..............] - ETA: 1:53 - loss: 0.0691 - sparse_categorical_accuracy: 0.9786\n",
            "253/469 [===============>..............] - ETA: 1:52 - loss: 0.0692 - sparse_categorical_accuracy: 0.9786\n",
            "254/469 [===============>..............] - ETA: 1:52 - loss: 0.0691 - sparse_categorical_accuracy: 0.9787\n",
            "255/469 [===============>..............] - ETA: 1:52 - loss: 0.0690 - sparse_categorical_accuracy: 0.9787\n",
            "256/469 [===============>..............] - ETA: 1:51 - loss: 0.0689 - sparse_categorical_accuracy: 0.9787\n",
            "257/469 [===============>..............] - ETA: 1:51 - loss: 0.0688 - sparse_categorical_accuracy: 0.9787\n",
            "258/469 [===============>..............] - ETA: 1:50 - loss: 0.0687 - sparse_categorical_accuracy: 0.9787\n",
            "259/469 [===============>..............] - ETA: 1:49 - loss: 0.0689 - sparse_categorical_accuracy: 0.9787\n",
            "260/469 [===============>..............] - ETA: 1:49 - loss: 0.0688 - sparse_categorical_accuracy: 0.9787\n",
            "261/469 [===============>..............] - ETA: 1:48 - loss: 0.0687 - sparse_categorical_accuracy: 0.9787\n",
            "262/469 [===============>..............] - ETA: 1:48 - loss: 0.0687 - sparse_categorical_accuracy: 0.9786\n",
            "263/469 [===============>..............] - ETA: 1:47 - loss: 0.0688 - sparse_categorical_accuracy: 0.9786\n",
            "264/469 [===============>..............] - ETA: 1:47 - loss: 0.0687 - sparse_categorical_accuracy: 0.9786\n",
            "265/469 [===============>..............] - ETA: 1:46 - loss: 0.0690 - sparse_categorical_accuracy: 0.9786\n",
            "266/469 [================>.............] - ETA: 1:45 - loss: 0.0689 - sparse_categorical_accuracy: 0.9786\n",
            "267/469 [================>.............] - ETA: 1:45 - loss: 0.0691 - sparse_categorical_accuracy: 0.9786\n",
            "268/469 [================>.............] - ETA: 1:44 - loss: 0.0692 - sparse_categorical_accuracy: 0.9786\n",
            "269/469 [================>.............] - ETA: 1:44 - loss: 0.0694 - sparse_categorical_accuracy: 0.9785\n",
            "270/469 [================>.............] - ETA: 1:43 - loss: 0.0693 - sparse_categorical_accuracy: 0.9785\n",
            "271/469 [================>.............] - ETA: 1:43 - loss: 0.0692 - sparse_categorical_accuracy: 0.9786\n",
            "272/469 [================>.............] - ETA: 1:42 - loss: 0.0691 - sparse_categorical_accuracy: 0.9786\n",
            "273/469 [================>.............] - ETA: 1:42 - loss: 0.0691 - sparse_categorical_accuracy: 0.9786\n",
            "274/469 [================>.............] - ETA: 1:41 - loss: 0.0690 - sparse_categorical_accuracy: 0.9786\n",
            "275/469 [================>.............] - ETA: 1:41 - loss: 0.0690 - sparse_categorical_accuracy: 0.9786\n",
            "276/469 [================>.............] - ETA: 1:40 - loss: 0.0689 - sparse_categorical_accuracy: 0.9786\n",
            "277/469 [================>.............] - ETA: 1:40 - loss: 0.0688 - sparse_categorical_accuracy: 0.9787\n",
            "278/469 [================>.............] - ETA: 1:39 - loss: 0.0687 - sparse_categorical_accuracy: 0.9787\n",
            "279/469 [================>.............] - ETA: 1:39 - loss: 0.0686 - sparse_categorical_accuracy: 0.9787\n",
            "280/469 [================>.............] - ETA: 1:39 - loss: 0.0684 - sparse_categorical_accuracy: 0.9788\n",
            "281/469 [================>.............] - ETA: 1:38 - loss: 0.0685 - sparse_categorical_accuracy: 0.9788\n",
            "282/469 [=================>............] - ETA: 1:38 - loss: 0.0685 - sparse_categorical_accuracy: 0.9789\n",
            "283/469 [=================>............] - ETA: 1:37 - loss: 0.0685 - sparse_categorical_accuracy: 0.9789\n",
            "284/469 [=================>............] - ETA: 1:37 - loss: 0.0683 - sparse_categorical_accuracy: 0.9789\n",
            "285/469 [=================>............] - ETA: 1:36 - loss: 0.0686 - sparse_categorical_accuracy: 0.9788\n",
            "286/469 [=================>............] - ETA: 1:35 - loss: 0.0687 - sparse_categorical_accuracy: 0.9788\n",
            "287/469 [=================>............] - ETA: 1:35 - loss: 0.0685 - sparse_categorical_accuracy: 0.9788\n",
            "288/469 [=================>............] - ETA: 1:34 - loss: 0.0686 - sparse_categorical_accuracy: 0.9788\n",
            "289/469 [=================>............] - ETA: 1:34 - loss: 0.0688 - sparse_categorical_accuracy: 0.9787\n",
            "290/469 [=================>............] - ETA: 1:33 - loss: 0.0692 - sparse_categorical_accuracy: 0.9786\n",
            "291/469 [=================>............] - ETA: 1:33 - loss: 0.0693 - sparse_categorical_accuracy: 0.9786\n",
            "292/469 [=================>............] - ETA: 1:32 - loss: 0.0693 - sparse_categorical_accuracy: 0.9786\n",
            "293/469 [=================>............] - ETA: 1:32 - loss: 0.0692 - sparse_categorical_accuracy: 0.9786\n",
            "294/469 [=================>............] - ETA: 1:31 - loss: 0.0693 - sparse_categorical_accuracy: 0.9786\n",
            "295/469 [=================>............] - ETA: 1:31 - loss: 0.0692 - sparse_categorical_accuracy: 0.9786\n",
            "296/469 [=================>............] - ETA: 1:30 - loss: 0.0693 - sparse_categorical_accuracy: 0.9786\n",
            "297/469 [=================>............] - ETA: 1:29 - loss: 0.0694 - sparse_categorical_accuracy: 0.9786\n",
            "298/469 [==================>...........] - ETA: 1:29 - loss: 0.0694 - sparse_categorical_accuracy: 0.9786\n",
            "299/469 [==================>...........] - ETA: 1:28 - loss: 0.0694 - sparse_categorical_accuracy: 0.9786\n",
            "300/469 [==================>...........] - ETA: 1:28 - loss: 0.0694 - sparse_categorical_accuracy: 0.9786\n",
            "301/469 [==================>...........] - ETA: 1:27 - loss: 0.0695 - sparse_categorical_accuracy: 0.9786\n",
            "302/469 [==================>...........] - ETA: 1:27 - loss: 0.0695 - sparse_categorical_accuracy: 0.9786\n",
            "303/469 [==================>...........] - ETA: 1:26 - loss: 0.0696 - sparse_categorical_accuracy: 0.9786\n",
            "304/469 [==================>...........] - ETA: 1:26 - loss: 0.0695 - sparse_categorical_accuracy: 0.9786\n",
            "305/469 [==================>...........] - ETA: 1:26 - loss: 0.0694 - sparse_categorical_accuracy: 0.9787\n",
            "306/469 [==================>...........] - ETA: 1:25 - loss: 0.0694 - sparse_categorical_accuracy: 0.9787\n",
            "307/469 [==================>...........] - ETA: 1:25 - loss: 0.0695 - sparse_categorical_accuracy: 0.9787\n",
            "308/469 [==================>...........] - ETA: 1:24 - loss: 0.0695 - sparse_categorical_accuracy: 0.9787\n",
            "309/469 [==================>...........] - ETA: 1:24 - loss: 0.0697 - sparse_categorical_accuracy: 0.9787\n",
            "310/469 [==================>...........] - ETA: 1:23 - loss: 0.0696 - sparse_categorical_accuracy: 0.9787\n",
            "311/469 [==================>...........] - ETA: 1:22 - loss: 0.0696 - sparse_categorical_accuracy: 0.9787\n",
            "312/469 [==================>...........] - ETA: 1:22 - loss: 0.0698 - sparse_categorical_accuracy: 0.9786\n",
            "313/469 [===================>..........] - ETA: 1:21 - loss: 0.0699 - sparse_categorical_accuracy: 0.9786\n",
            "314/469 [===================>..........] - ETA: 1:21 - loss: 0.0698 - sparse_categorical_accuracy: 0.9787\n",
            "315/469 [===================>..........] - ETA: 1:20 - loss: 0.0696 - sparse_categorical_accuracy: 0.9787\n",
            "316/469 [===================>..........] - ETA: 1:20 - loss: 0.0696 - sparse_categorical_accuracy: 0.9788\n",
            "317/469 [===================>..........] - ETA: 1:19 - loss: 0.0697 - sparse_categorical_accuracy: 0.9788\n",
            "318/469 [===================>..........] - ETA: 1:19 - loss: 0.0698 - sparse_categorical_accuracy: 0.9787\n",
            "319/469 [===================>..........] - ETA: 1:18 - loss: 0.0698 - sparse_categorical_accuracy: 0.9787\n",
            "320/469 [===================>..........] - ETA: 1:17 - loss: 0.0699 - sparse_categorical_accuracy: 0.9786\n",
            "321/469 [===================>..........] - ETA: 1:17 - loss: 0.0698 - sparse_categorical_accuracy: 0.9787\n",
            "322/469 [===================>..........] - ETA: 1:16 - loss: 0.0697 - sparse_categorical_accuracy: 0.9787\n",
            "323/469 [===================>..........] - ETA: 1:16 - loss: 0.0697 - sparse_categorical_accuracy: 0.9788\n",
            "324/469 [===================>..........] - ETA: 1:15 - loss: 0.0697 - sparse_categorical_accuracy: 0.9788\n",
            "325/469 [===================>..........] - ETA: 1:15 - loss: 0.0697 - sparse_categorical_accuracy: 0.9787\n",
            "326/469 [===================>..........] - ETA: 1:14 - loss: 0.0698 - sparse_categorical_accuracy: 0.9787\n",
            "327/469 [===================>..........] - ETA: 1:14 - loss: 0.0697 - sparse_categorical_accuracy: 0.9787\n",
            "328/469 [===================>..........] - ETA: 1:13 - loss: 0.0696 - sparse_categorical_accuracy: 0.9788\n",
            "329/469 [====================>.........] - ETA: 1:13 - loss: 0.0696 - sparse_categorical_accuracy: 0.9787\n",
            "330/469 [====================>.........] - ETA: 1:13 - loss: 0.0697 - sparse_categorical_accuracy: 0.9787\n",
            "331/469 [====================>.........] - ETA: 1:12 - loss: 0.0697 - sparse_categorical_accuracy: 0.9787\n",
            "332/469 [====================>.........] - ETA: 1:11 - loss: 0.0696 - sparse_categorical_accuracy: 0.9787\n",
            "333/469 [====================>.........] - ETA: 1:11 - loss: 0.0696 - sparse_categorical_accuracy: 0.9787\n",
            "334/469 [====================>.........] - ETA: 1:10 - loss: 0.0696 - sparse_categorical_accuracy: 0.9787\n",
            "335/469 [====================>.........] - ETA: 1:10 - loss: 0.0699 - sparse_categorical_accuracy: 0.9787\n",
            "336/469 [====================>.........] - ETA: 1:09 - loss: 0.0698 - sparse_categorical_accuracy: 0.9787\n",
            "337/469 [====================>.........] - ETA: 1:09 - loss: 0.0699 - sparse_categorical_accuracy: 0.9787\n",
            "338/469 [====================>.........] - ETA: 1:08 - loss: 0.0699 - sparse_categorical_accuracy: 0.9787\n",
            "339/469 [====================>.........] - ETA: 1:08 - loss: 0.0699 - sparse_categorical_accuracy: 0.9787\n",
            "340/469 [====================>.........] - ETA: 1:07 - loss: 0.0704 - sparse_categorical_accuracy: 0.9786\n",
            "341/469 [====================>.........] - ETA: 1:07 - loss: 0.0704 - sparse_categorical_accuracy: 0.9786\n",
            "342/469 [====================>.........] - ETA: 1:06 - loss: 0.0703 - sparse_categorical_accuracy: 0.9786\n",
            "343/469 [====================>.........] - ETA: 1:06 - loss: 0.0702 - sparse_categorical_accuracy: 0.9786\n",
            "344/469 [=====================>........] - ETA: 1:05 - loss: 0.0701 - sparse_categorical_accuracy: 0.9786\n",
            "345/469 [=====================>........] - ETA: 1:04 - loss: 0.0701 - sparse_categorical_accuracy: 0.9786\n",
            "346/469 [=====================>........] - ETA: 1:04 - loss: 0.0700 - sparse_categorical_accuracy: 0.9786\n",
            "347/469 [=====================>........] - ETA: 1:03 - loss: 0.0701 - sparse_categorical_accuracy: 0.9786\n",
            "348/469 [=====================>........] - ETA: 1:03 - loss: 0.0701 - sparse_categorical_accuracy: 0.9786\n",
            "349/469 [=====================>........] - ETA: 1:02 - loss: 0.0701 - sparse_categorical_accuracy: 0.9786\n",
            "350/469 [=====================>........] - ETA: 1:02 - loss: 0.0701 - sparse_categorical_accuracy: 0.9786\n",
            "351/469 [=====================>........] - ETA: 1:01 - loss: 0.0700 - sparse_categorical_accuracy: 0.9787\n",
            "352/469 [=====================>........] - ETA: 1:01 - loss: 0.0700 - sparse_categorical_accuracy: 0.9786\n",
            "353/469 [=====================>........] - ETA: 1:00 - loss: 0.0698 - sparse_categorical_accuracy: 0.9787\n",
            "354/469 [=====================>........] - ETA: 1:00 - loss: 0.0698 - sparse_categorical_accuracy: 0.9787\n",
            "355/469 [=====================>........] - ETA: 59s - loss: 0.0697 - sparse_categorical_accuracy: 0.9787 \n",
            "356/469 [=====================>........] - ETA: 59s - loss: 0.0695 - sparse_categorical_accuracy: 0.9788\n",
            "357/469 [=====================>........] - ETA: 58s - loss: 0.0695 - sparse_categorical_accuracy: 0.9788\n",
            "358/469 [=====================>........] - ETA: 58s - loss: 0.0693 - sparse_categorical_accuracy: 0.9789\n",
            "359/469 [=====================>........] - ETA: 57s - loss: 0.0696 - sparse_categorical_accuracy: 0.9788\n",
            "360/469 [======================>.......] - ETA: 57s - loss: 0.0696 - sparse_categorical_accuracy: 0.9788\n",
            "361/469 [======================>.......] - ETA: 56s - loss: 0.0696 - sparse_categorical_accuracy: 0.9788\n",
            "362/469 [======================>.......] - ETA: 56s - loss: 0.0696 - sparse_categorical_accuracy: 0.9788\n",
            "363/469 [======================>.......] - ETA: 55s - loss: 0.0696 - sparse_categorical_accuracy: 0.9787\n",
            "364/469 [======================>.......] - ETA: 55s - loss: 0.0696 - sparse_categorical_accuracy: 0.9788\n",
            "365/469 [======================>.......] - ETA: 54s - loss: 0.0695 - sparse_categorical_accuracy: 0.9788\n",
            "366/469 [======================>.......] - ETA: 54s - loss: 0.0694 - sparse_categorical_accuracy: 0.9788\n",
            "367/469 [======================>.......] - ETA: 53s - loss: 0.0694 - sparse_categorical_accuracy: 0.9788\n",
            "368/469 [======================>.......] - ETA: 52s - loss: 0.0695 - sparse_categorical_accuracy: 0.9788\n",
            "369/469 [======================>.......] - ETA: 52s - loss: 0.0694 - sparse_categorical_accuracy: 0.9788\n",
            "370/469 [======================>.......] - ETA: 51s - loss: 0.0693 - sparse_categorical_accuracy: 0.9788\n",
            "371/469 [======================>.......] - ETA: 51s - loss: 0.0693 - sparse_categorical_accuracy: 0.9788\n",
            "372/469 [======================>.......] - ETA: 50s - loss: 0.0693 - sparse_categorical_accuracy: 0.9788\n",
            "373/469 [======================>.......] - ETA: 50s - loss: 0.0693 - sparse_categorical_accuracy: 0.9788\n",
            "374/469 [======================>.......] - ETA: 49s - loss: 0.0692 - sparse_categorical_accuracy: 0.9788\n",
            "375/469 [======================>.......] - ETA: 49s - loss: 0.0691 - sparse_categorical_accuracy: 0.9789\n",
            "376/469 [=======================>......] - ETA: 48s - loss: 0.0691 - sparse_categorical_accuracy: 0.9788\n",
            "377/469 [=======================>......] - ETA: 48s - loss: 0.0690 - sparse_categorical_accuracy: 0.9788\n",
            "378/469 [=======================>......] - ETA: 47s - loss: 0.0691 - sparse_categorical_accuracy: 0.9788\n",
            "379/469 [=======================>......] - ETA: 47s - loss: 0.0692 - sparse_categorical_accuracy: 0.9788\n",
            "380/469 [=======================>......] - ETA: 46s - loss: 0.0691 - sparse_categorical_accuracy: 0.9788\n",
            "381/469 [=======================>......] - ETA: 46s - loss: 0.0690 - sparse_categorical_accuracy: 0.9788\n",
            "382/469 [=======================>......] - ETA: 45s - loss: 0.0690 - sparse_categorical_accuracy: 0.9788\n",
            "383/469 [=======================>......] - ETA: 45s - loss: 0.0691 - sparse_categorical_accuracy: 0.9788\n",
            "384/469 [=======================>......] - ETA: 44s - loss: 0.0689 - sparse_categorical_accuracy: 0.9788\n",
            "385/469 [=======================>......] - ETA: 44s - loss: 0.0689 - sparse_categorical_accuracy: 0.9789\n",
            "386/469 [=======================>......] - ETA: 43s - loss: 0.0688 - sparse_categorical_accuracy: 0.9789\n",
            "387/469 [=======================>......] - ETA: 43s - loss: 0.0689 - sparse_categorical_accuracy: 0.9788\n",
            "388/469 [=======================>......] - ETA: 42s - loss: 0.0689 - sparse_categorical_accuracy: 0.9788\n",
            "389/469 [=======================>......] - ETA: 42s - loss: 0.0688 - sparse_categorical_accuracy: 0.9788\n",
            "390/469 [=======================>......] - ETA: 41s - loss: 0.0689 - sparse_categorical_accuracy: 0.9788\n",
            "391/469 [========================>.....] - ETA: 40s - loss: 0.0688 - sparse_categorical_accuracy: 0.9789\n",
            "392/469 [========================>.....] - ETA: 40s - loss: 0.0688 - sparse_categorical_accuracy: 0.9789\n",
            "393/469 [========================>.....] - ETA: 39s - loss: 0.0687 - sparse_categorical_accuracy: 0.9789\n",
            "394/469 [========================>.....] - ETA: 39s - loss: 0.0687 - sparse_categorical_accuracy: 0.9789\n",
            "395/469 [========================>.....] - ETA: 38s - loss: 0.0686 - sparse_categorical_accuracy: 0.9789\n",
            "396/469 [========================>.....] - ETA: 38s - loss: 0.0686 - sparse_categorical_accuracy: 0.9789\n",
            "397/469 [========================>.....] - ETA: 37s - loss: 0.0686 - sparse_categorical_accuracy: 0.9789\n",
            "398/469 [========================>.....] - ETA: 37s - loss: 0.0685 - sparse_categorical_accuracy: 0.9789\n",
            "399/469 [========================>.....] - ETA: 36s - loss: 0.0685 - sparse_categorical_accuracy: 0.9789\n",
            "400/469 [========================>.....] - ETA: 36s - loss: 0.0685 - sparse_categorical_accuracy: 0.9789\n",
            "401/469 [========================>.....] - ETA: 35s - loss: 0.0686 - sparse_categorical_accuracy: 0.9789\n",
            "402/469 [========================>.....] - ETA: 35s - loss: 0.0686 - sparse_categorical_accuracy: 0.9789\n",
            "403/469 [========================>.....] - ETA: 34s - loss: 0.0685 - sparse_categorical_accuracy: 0.9789\n",
            "404/469 [========================>.....] - ETA: 34s - loss: 0.0688 - sparse_categorical_accuracy: 0.9789\n",
            "405/469 [========================>.....] - ETA: 33s - loss: 0.0687 - sparse_categorical_accuracy: 0.9789\n",
            "406/469 [========================>.....] - ETA: 33s - loss: 0.0688 - sparse_categorical_accuracy: 0.9789\n",
            "407/469 [=========================>....] - ETA: 32s - loss: 0.0688 - sparse_categorical_accuracy: 0.9789\n",
            "408/469 [=========================>....] - ETA: 32s - loss: 0.0688 - sparse_categorical_accuracy: 0.9789\n",
            "409/469 [=========================>....] - ETA: 31s - loss: 0.0687 - sparse_categorical_accuracy: 0.9789\n",
            "410/469 [=========================>....] - ETA: 31s - loss: 0.0688 - sparse_categorical_accuracy: 0.9789\n",
            "411/469 [=========================>....] - ETA: 30s - loss: 0.0688 - sparse_categorical_accuracy: 0.9789\n",
            "412/469 [=========================>....] - ETA: 30s - loss: 0.0688 - sparse_categorical_accuracy: 0.9789\n",
            "413/469 [=========================>....] - ETA: 29s - loss: 0.0687 - sparse_categorical_accuracy: 0.9789\n",
            "414/469 [=========================>....] - ETA: 28s - loss: 0.0687 - sparse_categorical_accuracy: 0.9789\n",
            "415/469 [=========================>....] - ETA: 28s - loss: 0.0687 - sparse_categorical_accuracy: 0.9789\n",
            "416/469 [=========================>....] - ETA: 27s - loss: 0.0688 - sparse_categorical_accuracy: 0.9789\n",
            "417/469 [=========================>....] - ETA: 27s - loss: 0.0687 - sparse_categorical_accuracy: 0.9790\n",
            "418/469 [=========================>....] - ETA: 26s - loss: 0.0686 - sparse_categorical_accuracy: 0.9790\n",
            "419/469 [=========================>....] - ETA: 26s - loss: 0.0687 - sparse_categorical_accuracy: 0.9790\n",
            "420/469 [=========================>....] - ETA: 25s - loss: 0.0687 - sparse_categorical_accuracy: 0.9790\n",
            "421/469 [=========================>....] - ETA: 25s - loss: 0.0686 - sparse_categorical_accuracy: 0.9790\n",
            "422/469 [=========================>....] - ETA: 24s - loss: 0.0686 - sparse_categorical_accuracy: 0.9790\n",
            "423/469 [==========================>...] - ETA: 24s - loss: 0.0685 - sparse_categorical_accuracy: 0.9791\n",
            "424/469 [==========================>...] - ETA: 23s - loss: 0.0685 - sparse_categorical_accuracy: 0.9791\n",
            "425/469 [==========================>...] - ETA: 23s - loss: 0.0686 - sparse_categorical_accuracy: 0.9791\n",
            "426/469 [==========================>...] - ETA: 22s - loss: 0.0687 - sparse_categorical_accuracy: 0.9790\n",
            "427/469 [==========================>...] - ETA: 22s - loss: 0.0689 - sparse_categorical_accuracy: 0.9790\n",
            "428/469 [==========================>...] - ETA: 21s - loss: 0.0689 - sparse_categorical_accuracy: 0.9790\n",
            "429/469 [==========================>...] - ETA: 21s - loss: 0.0690 - sparse_categorical_accuracy: 0.9789\n",
            "430/469 [==========================>...] - ETA: 20s - loss: 0.0689 - sparse_categorical_accuracy: 0.9789\n",
            "431/469 [==========================>...] - ETA: 20s - loss: 0.0689 - sparse_categorical_accuracy: 0.9789\n",
            "432/469 [==========================>...] - ETA: 19s - loss: 0.0688 - sparse_categorical_accuracy: 0.9789\n",
            "433/469 [==========================>...] - ETA: 19s - loss: 0.0688 - sparse_categorical_accuracy: 0.9789\n",
            "434/469 [==========================>...] - ETA: 18s - loss: 0.0688 - sparse_categorical_accuracy: 0.9789\n",
            "435/469 [==========================>...] - ETA: 17s - loss: 0.0688 - sparse_categorical_accuracy: 0.9789\n",
            "436/469 [==========================>...] - ETA: 17s - loss: 0.0687 - sparse_categorical_accuracy: 0.9789\n",
            "437/469 [==========================>...] - ETA: 16s - loss: 0.0687 - sparse_categorical_accuracy: 0.9789\n",
            "438/469 [===========================>..] - ETA: 16s - loss: 0.0688 - sparse_categorical_accuracy: 0.9789\n",
            "439/469 [===========================>..] - ETA: 15s - loss: 0.0687 - sparse_categorical_accuracy: 0.9789\n",
            "440/469 [===========================>..] - ETA: 15s - loss: 0.0688 - sparse_categorical_accuracy: 0.9789\n",
            "441/469 [===========================>..] - ETA: 14s - loss: 0.0687 - sparse_categorical_accuracy: 0.9790\n",
            "442/469 [===========================>..] - ETA: 14s - loss: 0.0686 - sparse_categorical_accuracy: 0.9790\n",
            "443/469 [===========================>..] - ETA: 13s - loss: 0.0685 - sparse_categorical_accuracy: 0.9790\n",
            "444/469 [===========================>..] - ETA: 13s - loss: 0.0685 - sparse_categorical_accuracy: 0.9790\n",
            "445/469 [===========================>..] - ETA: 12s - loss: 0.0684 - sparse_categorical_accuracy: 0.9790\n",
            "446/469 [===========================>..] - ETA: 12s - loss: 0.0683 - sparse_categorical_accuracy: 0.9791\n",
            "447/469 [===========================>..] - ETA: 11s - loss: 0.0682 - sparse_categorical_accuracy: 0.9791\n",
            "448/469 [===========================>..] - ETA: 11s - loss: 0.0681 - sparse_categorical_accuracy: 0.9791\n",
            "449/469 [===========================>..] - ETA: 10s - loss: 0.0681 - sparse_categorical_accuracy: 0.9792\n",
            "450/469 [===========================>..] - ETA: 10s - loss: 0.0681 - sparse_categorical_accuracy: 0.9791\n",
            "451/469 [===========================>..] - ETA: 9s - loss: 0.0681 - sparse_categorical_accuracy: 0.9791 \n",
            "452/469 [===========================>..] - ETA: 8s - loss: 0.0681 - sparse_categorical_accuracy: 0.9791\n",
            "453/469 [===========================>..] - ETA: 8s - loss: 0.0681 - sparse_categorical_accuracy: 0.9791\n",
            "454/469 [============================>.] - ETA: 7s - loss: 0.0680 - sparse_categorical_accuracy: 0.9791\n",
            "455/469 [============================>.] - ETA: 7s - loss: 0.0681 - sparse_categorical_accuracy: 0.9791\n",
            "456/469 [============================>.] - ETA: 6s - loss: 0.0681 - sparse_categorical_accuracy: 0.9792\n",
            "457/469 [============================>.] - ETA: 6s - loss: 0.0680 - sparse_categorical_accuracy: 0.9792\n",
            "458/469 [============================>.] - ETA: 5s - loss: 0.0680 - sparse_categorical_accuracy: 0.9792\n",
            "459/469 [============================>.] - ETA: 5s - loss: 0.0680 - sparse_categorical_accuracy: 0.9792\n",
            "460/469 [============================>.] - ETA: 4s - loss: 0.0679 - sparse_categorical_accuracy: 0.9792\n",
            "461/469 [============================>.] - ETA: 4s - loss: 0.0680 - sparse_categorical_accuracy: 0.9792\n",
            "462/469 [============================>.] - ETA: 3s - loss: 0.0679 - sparse_categorical_accuracy: 0.9792\n",
            "463/469 [============================>.] - ETA: 3s - loss: 0.0678 - sparse_categorical_accuracy: 0.9792\n",
            "464/469 [============================>.] - ETA: 2s - loss: 0.0678 - sparse_categorical_accuracy: 0.9792\n",
            "465/469 [============================>.] - ETA: 2s - loss: 0.0678 - sparse_categorical_accuracy: 0.9792\n",
            "466/469 [============================>.] - ETA: 1s - loss: 0.0679 - sparse_categorical_accuracy: 0.9792\n",
            "467/469 [============================>.] - ETA: 1s - loss: 0.0679 - sparse_categorical_accuracy: 0.9792\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0679 - sparse_categorical_accuracy: 0.9792\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0679 - sparse_categorical_accuracy: 0.9792\n",
            " 80%|████████  | 4/5 [1:35:18<17:32, 1052.88s/trial, best loss: -0.9850000143051147]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/04/16 02:07:18 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "469/469 [==============================] - 248s 528ms/step - loss: 0.0679 - sparse_categorical_accuracy: 0.9792\n",
            "\n",
            " 80%|████████  | 4/5 [1:35:18<17:32, 1052.88s/trial, best loss: -0.9850000143051147]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 318 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7a89c0ba5090> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - ETA: 0s\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "\n",
            " 80%|████████  | 4/5 [1:35:18<17:32, 1052.88s/trial, best loss: -0.9850000143051147]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 5/5 [1:35:34<00:00, 1146.83s/trial, best loss: -0.9850000143051147]\n",
            "Best HyperParameters: {'conv1_filters': 1, 'conv2_filters': 2, 'dense_units': 0, 'dropout_rate': 0.24316801384750011}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Best HyperParameters: {'conv1_filters': 1, 'conv2_filters': 2, 'dense_units': 0, 'dropout_rate': 0.24678363652581475}"
      ],
      "metadata": {
        "id": "8RzDs8cUp4dg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UPDATED on 4/15/2024 at 10:10 PM ET Best HyperParameters: {'conv1_filters': 1, 'conv2_filters': 2, 'dense_units': 0, 'dropout_rate': 0.24316801384750011}**"
      ],
      "metadata": {
        "id": "gPZh8DhJqrpc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wk_eOGRLqjN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #param_space is the same as search_space\n",
        "# param_space = {\n",
        "#     'conv1_filters': hp.choice('conv1_filters', [32,64,128]),\n",
        "#     'conv2_filters': hp.choice('conv2_filters', [64,128,256]),\n",
        "#     'dropout_rate': hp.uniform('dropout_rate', 0.2,0.3),\n",
        "#     'dense_units': hp.choice('dense_units', [64,128,256])}"
      ],
      "metadata": {
        "id": "CWh8tuuXqrH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Observation: From the Best HyperParameters output, 'conv1_filters' chose 1 which means it chose 64. Also, 'conv2_filters' chose 2 which means it chose 256. The dropout rate was 0.24678 and the dense units was 64.**"
      ],
      "metadata": {
        "id": "GMYaA_D-qv_v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Re-running the previous model with the Best HyperParameters results from above!"
      ],
      "metadata": {
        "id": "FJ1COePsuied"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running the optimized model after HyperOpt"
      ],
      "metadata": {
        "id": "H3GdD95IuwNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def best_model():\n",
        "  '''\n",
        "   Build a Sequential model with regular densely-connected NN layers.\n",
        "   Return the constructed model.\n",
        "  '''\n",
        "  input_shape = (28, 28, 1)  # 1 is the count of channels (no RGB)\n",
        "\n",
        "  model = keras.Sequential ([\n",
        "\n",
        "    # // The input layer\n",
        "    layers.Input(shape=input_shape),\n",
        "\n",
        "    # // Hidden layers\n",
        "    layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\", name='CL1'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2), name='MPL1'),\n",
        "\n",
        "    layers.Conv2D(256, kernel_size=(3, 3), activation=\"relu\", name='CL2'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2), name='MPL2'),\n",
        "\n",
        "    layers.Flatten(name='FL'),\n",
        "    layers.Dropout(0.243168), #update when you are running this piece again\n",
        "    # // The model's output layer\n",
        "    # We create a classifier for as many classes as there are in the input data\n",
        "    #model.add(layers.Dense(num_classes, name=\"OUTL\", activation='softmax'))\n",
        "    layers.Dense(64, name=\"OUTL\", activation='softmax') #update num_classes with results from hyperopt\n",
        "  ])\n",
        "\n",
        "  model.summary()\n",
        "  print (model.inputs, model.outputs)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "iE4haNOLr5wV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compiling the optimized model after HyperOpt"
      ],
      "metadata": {
        "id": "qrRkRpKPu43N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compile_best_model(model):\n",
        "  '''\n",
        "    Compile the pre-built model with the model hyperparameters.\n",
        "    Return the compiled model\n",
        "  '''\n",
        "  model.compile(\n",
        "      #optimizer=keras.optimizers.RMSprop(),\n",
        "      optimizer=SGD(learning_rate=1e-2, momentum=0.9, nesterov=True),\n",
        "\n",
        "      # The loss function that we need to minimize\n",
        "      loss=keras.losses.SparseCategoricalCrossentropy(),  # we have a lot of \"holes\" in the dataset (the black pixels with a value of 0)\n",
        "\n",
        "      # The metrics (can be more than one) to monitor\n",
        "      metrics=[keras.metrics.SparseCategoricalAccuracy()], # The \"dangling\" comma , before the closing bracket is good practice ...\n",
        "  )\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "ofRh62cKuUbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the optimized model after HyperOpt"
      ],
      "metadata": {
        "id": "olMX_mZpu8wh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_X_train_augmented = train_generator\n",
        "optimal_validation_generator = validation_generator"
      ],
      "metadata": {
        "id": "KjlKIUxwsWgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_X_train_augmented"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86zqipXHsy_o",
        "outputId": "fa6e9ea0-ce9d-4ae0-ca8b-1688eb772bb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.preprocessing.image.NumpyArrayIterator at 0x7a8a120fdf60>"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_validation_generator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0F0Nncq7s1My",
        "outputId": "f8be7e7f-cfee-4fd4-b43e-7528ac002c14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.preprocessing.image.NumpyArrayIterator at 0x7a8a2c82ae00>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_best_model(model):\n",
        "  '''\n",
        "    Train the model with a fixed number of epochs\n",
        "    Return the history (log)\n",
        "  '''\n",
        "  # In a CPU-only CoLab environment, training may take about 5 minutes, give or take, so be patient and wait until the training is done ...\n",
        "  history = model.fit_generator(optimal_X_train_augmented, validation_data=optimal_validation_generator, epochs = 10, verbose=1)\n",
        "\n",
        "  return history"
      ],
      "metadata": {
        "id": "OO68Llo-ufMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def train_best_model(model):\n",
        "#   '''\n",
        "#     Train the model with a fixed number of epochs\n",
        "#     Return the history (log)\n",
        "#   '''\n",
        "#   # In a CPU-only CoLab environment, training may take about 5 minutes, give or take, so be patient and wait until the training is done ...\n",
        "#   history = model.fit_generator(train_generator, validation_data=validation_generator, epochs = 10, verbose=1)\n",
        "\n",
        "#   return history"
      ],
      "metadata": {
        "id": "TdR1UFdrvjVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def train(model):\n",
        "#   '''\n",
        "#     Train the model with a fixed number of epochs\n",
        "#     Return the history (log)\n",
        "#   '''\n",
        "#   # In a CPU-only CoLab environment, training may take about 5 minutes, give or take, so be patient and wait until the training is done ...\n",
        "#   history = model.fit_generator(train_generator, validation_data = validation_generator, epochs = 5, verbose=1)\n",
        "\n",
        "#   return history"
      ],
      "metadata": {
        "id": "qyaREq6XsInM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seed the random generator for reproducible results\n",
        "from tensorflow.python.platform import _pywrap_tf2\n",
        "tf.keras.utils.set_random_seed(2424)\n",
        "\n",
        "# Trigger the sequence ..\n",
        "model = best_model()\n",
        "model = compile_best_model(model)\n",
        "history = train_best_model(model)\n",
        "\n",
        "# Note: CoLab reports the wall time of running a cell at the bottom of the browser window"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xa6W-LVdxSBK",
        "outputId": "014afe7d-3af0-44e1-91d7-d79a9da4a75e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " CL1 (Conv2D)                (None, 26, 26, 64)        640       \n",
            "                                                                 \n",
            " MPL1 (MaxPooling2D)         (None, 13, 13, 64)        0         \n",
            "                                                                 \n",
            " CL2 (Conv2D)                (None, 11, 11, 256)       147712    \n",
            "                                                                 \n",
            " MPL2 (MaxPooling2D)         (None, 5, 5, 256)         0         \n",
            "                                                                 \n",
            " FL (Flatten)                (None, 6400)              0         \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 6400)              0         \n",
            "                                                                 \n",
            " OUTL (Dense)                (None, 64)                409664    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 558,016\n",
            "Trainable params: 558,016\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-103-4fa8365c1303>:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(optimal_X_train_augmented, validation_data=optimal_validation_generator, epochs = 10, verbose=1)\n",
            "2024/04/16 02:47:39 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'bbfc22542ddf45e594355e38ec18b92c', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n",
            "2024/04/16 02:47:39 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'keras.preprocessing.image.NumpyArrayIterator'>. Dataset logging skipped.\n",
            "2024/04/16 02:47:39 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'keras.preprocessing.image.NumpyArrayIterator'>. Dataset logging skipped.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<KerasTensor: shape=(None, 28, 28, 1) dtype=float32 (created by layer 'input_20')>] [<KerasTensor: shape=(None, 64) dtype=float32 (created by layer 'OUTL')>]\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 179s 119ms/step - loss: 1.5363 - sparse_categorical_accuracy: 0.4738 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 175s 116ms/step - loss: 0.7844 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 174s 116ms/step - loss: 0.5931 - sparse_categorical_accuracy: 0.8111 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 174s 116ms/step - loss: 0.5164 - sparse_categorical_accuracy: 0.8385 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 175s 116ms/step - loss: 0.4565 - sparse_categorical_accuracy: 0.8554 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 174s 116ms/step - loss: 0.4210 - sparse_categorical_accuracy: 0.8684 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 173s 115ms/step - loss: 0.3992 - sparse_categorical_accuracy: 0.8757 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 174s 116ms/step - loss: 0.3726 - sparse_categorical_accuracy: 0.8836 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 174s 116ms/step - loss: 0.3675 - sparse_categorical_accuracy: 0.8853 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 174s 116ms/step - loss: 0.3524 - sparse_categorical_accuracy: 0.8901 - val_loss: 0.0000e+00 - val_sparse_categorical_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/04/16 03:17:41 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: '>=' not supported between instances of 'slice' and 'int'\n",
            "2024/04/16 03:17:41 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Use the information from print(Best HyperParameters) to adjust the model"
      ],
      "metadata": {
        "id": "hyZ0G427PXD4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gbbJ5gpnrZQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the best model definition which will use the results from the hyperopt"
      ],
      "metadata": {
        "id": "KynTz2p-Maj2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Use TensorBoard to perform detailed analysis of model performance, including confusion matrices and histograms of model weights."
      ],
      "metadata": {
        "id": "lCXjqFZfHpMv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AEEjQr5HHtqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Investigate layer activations and feature maps to understand what the model is learning."
      ],
      "metadata": {
        "id": "OtL8arYrHtby"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7yavDlrJ57yS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Experiment with different architectures using model.get_config() and hyperparameters to improve performance."
      ],
      "metadata": {
        "id": "zGHeCpjE6Jf-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8E2blfB4H8hI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Apply techniques like dropout and batch normalization to mitigate overfitting."
      ],
      "metadata": {
        "id": "TD_JWX5xH84u"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dmqzLdAAIJE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Evaluate the effects of data augmentation on model robustness using TensorBoard."
      ],
      "metadata": {
        "id": "v3zN3f5CIJa_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ziv-AiEAIRhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Conduct ablation studies, using TensorBoard to track and compare results."
      ],
      "metadata": {
        "id": "hdlZptkXIR4w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n"
      ],
      "metadata": {
        "id": "9PcEAXv8T6qN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oeW5DcGVIOo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **Task 6: Model Deployment and Documentation**  \n",
        "\n",
        "**Objective:** Prepare the model for deployment using MLflow and document the project for reproducibility and sharing. Create and test an API endpoint for the model using Postman.\n",
        "\n",
        "**Activities:**\n",
        "\n",
        "1. Convert the trained model into a MLflow-compatible format and log the model in MLflow.\n",
        "2. Set up MLflow tracking server to manage and store model artifacts.\n",
        "3. Develop a Flask or FastAPI application that loads the MLflow model and creates an API endpoint for making predictions.\n",
        "4. Test the API endpoint locally to ensure it is working as expected.\n",
        "5. Use MLflow to package the API application into a Docker container for easy deployment and scaling.\n",
        "6. Write comprehensive documentation, detailing the steps for model conversion, MLflow integration, API usage, and deployment process.\n",
        "7. Use Postman to create and send requests to the deployed API endpoint, validating the model's responses and functionality.\n",
        "8. Create a GitHub repository to host the project code, MLflow tracking information, documentation, and deployment instructions.\n",
        "\n",
        "**Estimated Completion Time:** 240 minutes\n",
        "\n",
        "---\n",
        "---\n"
      ],
      "metadata": {
        "id": "jJUFy96o2zUS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Convert the trained model into a MLflow-compatible format and log the model in MLflow."
      ],
      "metadata": {
        "id": "qp75u83XsmNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow"
      ],
      "metadata": {
        "id": "JdLw7uAAsuwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import mlflow.tensorflow\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "Q1enQ8rmJRwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(activation='relu', dropout_rate=0.2):\n",
        "    with mlflow.start_run():\n",
        "        model = tf.keras.models.Sequential([\n",
        "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "            tf.keras.layers.Dense(512, activation=activation),\n",
        "            tf.keras.layers.Dropout(dropout_rate),\n",
        "            tf.keras.layers.Dense(10, activation='softmax')\n",
        "        ])\n",
        "\n",
        "        model.compile(optimizer='adam',\n",
        "                      loss='sparse_categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        mlflow.log_param(\"activation\", activation)\n",
        "        mlflow.log_param(\"dropout_rate\", dropout_rate)\n",
        "\n",
        "        # Automatic logging of metrics, parameters, and models.\n",
        "        mlflow.tensorflow.autolog()\n",
        "\n",
        "        model.fit(X_train_scaled, y_train, epochs=10, validation_data=(X_test_scaled, y_test))\n",
        "\n",
        "# Example training run\n",
        "train_model('relu', 0.2)\n",
        "train_model('leaky_relu', 0.3)\n",
        "train_model('sigmoid', 0.2)"
      ],
      "metadata": {
        "id": "EIhE9BUAtFDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sourced from online"
      ],
      "metadata": {
        "id": "V6FiCvmM7aVH"
      }
    }
  ]
}